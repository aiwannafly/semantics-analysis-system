GNMT есть система машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.

Так родился статистический метод анализа текста word2vec (англ. Word to vector).

Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.

В задаче классификации использовался logloss, вычисляемый как среднее значение метрики sklearn.metrics.log_loss по классам болезней.

Во-первых, конкретно для этого соревнования наиболее эффективный подход - это доразметка спанов тренировочных данных для задачи NER.

Ответ очень прост, Docker compose нужен для быстрого развертывания приложения, например, перенос приложения на другой сервер займет несколько минут, также в сочетании с kubernetes - дает превосходные результаты по автоматизации развертывания, масштабирования и координации работы нашего приложения в условиях кластера.

В этой статье я расскажу все, что вам нужно знать про ALBERT, RoBERTa, и DistilBERT. Если непонятно по названию, эти модели — модифицированные версии оригинального современного трансформера BERT. Эти три модели из библиотеки Hugging Face — самые популярные на сегодняшний день. Я рассмотрю их сходства и различия по сравнению друг с другом и добавлю фрагменты кода. Они покажут, как вы можете их использовать.

Чтобы размер скрытых слоев и размерность эмбеддинга были разными, ALBERTa деконструирует матрицу эмбеддинга на 2 части. Это увеличивает размер скрытого слоя, не меняя фактического размера эмбеддинга. После разложения матрицы, ALBERT добавляет линейный или полносвязный слой после завершения фазы эмбеддинга. Это гарантирует, что размерность размерности эмбеддинга будет такой же правильной. Здесь об этом рассказано подробнее.

В будущем эксперты не исключают возможности использования генеративных нейросетей для создания новых лекарств и тестирования их эффективности. А уже сейчас многие компании внедряют ГИИ для постановки диагноза и проведения обследований. Более того ИИ может помогать в создании новых лекарств. Ученые из Вашингтонского университета, придумали искусственный интеллект (ИИ), который создает белки для использования в лекарственных препаратах. Ученые из Бостонского университета представили алгоритм, который обучался на полноформатных фотографиях легочных тканей пациентов и теперь способен распознавать аденокарциному легкого, плоскоклеточный рак легкого и участки здоровой ткани. Другие компании обучают нейросеть распознавать рак кожи на ранней стадии и анализировать МРТ-снимки для выявления онкологических заболеваний.

Мы использовали деревья решений для этой задачи классификации

Представители «Яндекса», VK, «Мегафона», «Ростелекома» и «Билайна» отказались от комментариев. В пресс-службе правительства вопросы СМИ переадресовали в Минцифры, где на запрос не ответили. СМИ также направили запросы в Microsoft и Amazon.

На выходе мы получаем эмбеддинг (embedding).

Столкнувшись с описанными выше проблемами, мы решили собрать свой датасет для распознавания эмоций и назвали его Dusha, по аналогии с датасетом для распознавания речи — Golos.

Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.

В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14]

По большей части, LLMs стали популярны из-за их универсальности и эффективности. Они хорошо справляются с переводом, резюмированием, анализом и т.д.

Fine‑tuning — это процесс дообучения ранее обученной LLM на определенном датасете. Напрашивается вопрос — а зачем дообучать модель, если можно добавить данные с помощью RAG? Простой ответ заключается в том, что только дообучение может адаптировать вашу модель для понимания конкретной области или определить ее стиль. К примеру, я создал копию самого себя, используя fine‑tuning на личной переписке:

Рост мощи LLM привёл к разработке множества помощников с искусственным интеллектом, каждый из которых предназначен для конкретных задач, например, программирование, планирование работ, бронирование мест. Количество решаемых такими помощниками задачи и качество решений растёт реально каждый месяц. Примеры: Pi и собственно ChatGPT. Честно говоря, после урезанных возможностей голосовых ассистентов, типа Siri и Google Assistant, которые в итоге используются только чтобы поставить будильник или песню запустить, помощники на основе современных LLM – как глоток свежего воздуха и огромное множество вариантов применения даже для плохо сформулированных запросов.

Алгоритм АдаГрад (AdaGrad) довольно часто используется в задаче классификации.

В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM.

Второе, мы стандартно провели экстенсивный тюнинг гиперпараметров и изменили нашу метрику с точности на F1, чтобы ставить больше акцента на точность по каждому классу, так как общая точность предвзято относится к доминирующим классам.

Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.

Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.

Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.

Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.

Сейчас в Яндексе мой основной проект это Алиса, голосовой помощник, который Яндекс запустил в октябре прошлого года, и моя группа отвечает за то, что можно условно назвать мозгами Алисы.

Пробуем запустить с датасетом по умолчанию — Alpaca. Успех. Обучение завершилось за 2.5 минуты. Видим, что создался некий .bin файл, размером 800мб.

В последнее время большие языковые модели (Large Language Models, LLM), которые представляют собой важный взгляд на технологии обработки естественного языка (Natural Language Processing, NLP), стали очень популярны. LLM способны работать с текстами, понимать, переводить, отвечать на вопросы, генерировать речь.

LLM-приложение — это приложение, которое использует LLM для применений в различных областях, таких как образование, развлечения, бизнес, наука и т. д. Например, LLM-приложения могут:

Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).
