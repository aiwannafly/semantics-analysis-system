# sent_id = 1
# text =   1 January 2010 at 07:59 Заметки об NLP (часть 2) Artificial Intelligence Natural Language Processing.
# relations = "Science_isAlternativeNameFor_Science 2 0"
1	1 O
2	January O
3	2010 O
4	at O
5	07:59 O
6	Заметки O
7	об O
8	NLP B-Science
9	( O
10	часть O
11	2 O
12	) O
13	Artificial B-Science
14	Intelligence I-Science
15	Natural B-Science
16	Language I-Science
17	Processing I-Science
18	. O

# sent_id = 2
# text =   Заметки об NLP (Natural Language Processing).
# relations = "Science_isAlternativeNameFor_Science 1 0"
1	Заметки O
2	об O
3	NLP B-Science
4	( O
5	Natural B-Science
6	Language I-Science
7	Processing I-Science
8	) O
9	. O

# sent_id = 3
# text =   Хотя в первой части я и говорил, что не собираюсь останавливаться на морфологии, видимо, совсем без неё не получится
# relations = ""
1	Хотя O
2	в O
3	первой O
4	части O
5	я O
6	и O
7	говорил O
8	, O
9	что O
10	не O
11	собираюсь O
12	останавливаться O
13	на O
14	морфологии B-Science
15	, O
16	видимо O
17	, O
18	совсем O
19	без O
20	неё O
21	не O
22	получится O
23	. O

# sent_id = 4
# text =   Всё-таки обработка предложений сильно завязана на предшествующий морфологический анализ.
# relations = "Method_solves_Task 0 0"
1	Всё O
2	- O
3	таки O
4	обработка B-Task
5	предложений I-Task
6	сильно O
7	завязана B-Method_solves_Task
8	на O
9	предшествующий O
10	морфологический B-Method
11	анализ I-Method
12	. O

# sent_id = 5
# text =   Наш с вами родной русский язык очень хорош (для нас) и труден (для иностранцев) богатой фонетикой и разнообразием грамматических средств.
# relations = ""
1	Наш O
2	с O
3	вами O
4	родной O
5	русский B-Lang
6	язык I-Lang
7	очень O
8	хорош O
9	( O
10	для O
11	нас O
12	) O
13	и O
14	труден O
15	( O
16	для O
17	иностранцев O
18	) O
19	богатой O
20	фонетикой B-Science
21	и O
22	разнообразием O
23	грамматических B-Object
24	средств I-Object
25	. O

# sent_id = 6
# text =   Во-первых, в них не так много незнакомых нам фонем.
# relations = ""
1	Во O
2	- O
3	первых O
4	, O
5	в O
6	них O
7	не O
8	так O
9	много O
10	незнакомых O
11	нам O
12	фонем B-Object
13	. O

# sent_id = 7
# text =   Во-вторых, обилие грамматических явлений редко сталкивает нас с чем-либо непонятным.
# relations = ""
1	Во O
2	- O
3	вторых O
4	, O
5	обилие O
6	грамматических B-Object
7	явлений I-Object
8	редко O
9	сталкивает O
10	нас O
11	с O
12	чем O
13	- O
14	либо O
15	непонятным O
16	. O

# sent_id = 8
# text =   А для американца, например, само понятие рода или падежа совершенно неочевидно.
# relations = ""
1	А O
2	для O
3	американца O
4	, O
5	например O
6	, O
7	само O
8	понятие O
9	рода B-Object
10	или O
11	падежа B-Object
12	совершенно O
13	неочевидно O
14	. O

# sent_id = 9
# text =   Теперь о морфологии.
# relations = ""
1	Теперь O
2	о O
3	морфологии B-Science
4	. O

# sent_id = 10
# text =   Автоматические морфологические анализаторы работают хорошо.
# relations = ""
1	Автоматические B-Object
2	морфологические I-Object
3	анализаторы I-Object
4	работают O
5	хорошо O
6	. O

# sent_id = 11
# text =   Если кому интересно посмотреть, как работает автоматический анализатор — можно поэкспериментировать на сайте С.А. Старостина.
# relations = ""
1	Если O
2	кому O
3	интересно O
4	посмотреть O
5	, O
6	как O
7	работает O
8	автоматический B-Application
9	анализатор I-Application
10	— O
11	можно O
12	поэкспериментировать O
13	на O
14	сайте B-InfoResource
15	С.А. B-Person
16	Старостина I-Person
17	. O

# sent_id = 12
# text =   Смею предположить, что едва ли не все морфологические анализаторы русского так или иначе опираются на Грамматический словарь Зализняка.
# relations = ""
1	Смею O
2	предположить O
3	, O
4	что O
5	едва O
6	ли O
7	не O
8	все O
9	морфологические B-Application
10	анализаторы I-Application
11	русского O
12	так O
13	или O
14	иначе O
15	опираются O
16	на O
17	Грамматический B-InfoResource
18	словарь I-InfoResource
19	Зализняка I-InfoResource
20	. O

# sent_id = 13
# text =   Сам я пользуюсь разработками Алексея Сокирко, «обёрнутыми» в удобный интерфейс на сайте Lemmatizer.
# relations = ""
1	Сам O
2	я O
3	пользуюсь O
4	разработками O
5	Алексея B-Person
6	Сокирко I-Person
7	, O
8	« O
9	обёрнутыми O
10	» O
11	в O
12	удобный O
13	интерфейс O
14	на O
15	сайте O
16	Lemmatizer B-InfoResource
17	. O

# sent_id = 14
# text =   Судите сами: упомянутый русский морфологический анализатор Алексея Сокирко оперирует базой данных в 18,5 мегабайт.
# relations = ""
1	Судите O
2	сами O
3	: O
4	упомянутый O
5	русский B-Application
6	морфологический I-Application
7	анализатор I-Application
8	Алексея I-Application
9	Сокирко I-Application
10	оперирует B-Application_uses_InfoResource
11	базой B-InfoResource
12	данных I-InfoResource
13	в O
14	18,5 O
15	мегабайт O
16	. O

# sent_id = 15
# text =   На Грамоте предлагают относить их к «предикативам», но общепринятого подхода нет.
# relations = ""
1	На O
2	Грамоте B-InfoResource
3	предлагают O
4	относить O
5	их O
6	к O
7	« O
8	предикативам O
9	» O
10	, O
11	но O
12	общепринятого O
13	подхода O
14	нет O
15	. O

# sent_id = 16
# text =   Например, ещё одна «фича» анализатора Сокирко: он называет глаголы в личной форме («бегаю») глаголами, а в начальной форме («бегать») — инфинитивами.
# relations = ""
1	Например O
2	, O
3	ещё O
4	одна O
5	« O
6	фича O
7	» O
8	анализатора B-InfoResource
9	Сокирко I-InfoResource
10	: O
11	он O
12	называет O
13	глаголы O
14	в O
15	личной O
16	форме O
17	( O
18	« O
19	бегаю O
20	» O
21	) O
22	глаголами O
23	, O
24	а O
25	в O
26	начальной O
27	форме O
28	( O
29	« O
30	бегать O
31	» O
32	) O
33	— O
34	инфинитивами O
35	. O

# sent_id = 17
# text =   Tags: NLP, обработка текстовб, компьютерная лингвистика.
# relations = ""
1	Tags O
2	: O
3	NLP B-Science
4	, O
5	обработка B-Task
6	текстов I-Task
7	, O
8	компьютерная B-Science
9	лингвистика I-Science

# sent_id = 18
# text =   Туториал по фреймворку для программирования датасетов MTS AI corporate blog.
# relations = ""
1	Туториал O
2	по O
3	фреймворку O
4	для O
5	программирования B-Science
6	датасетов O
7	MTS B-Organization
8	AI I-Organization
9	corporate B-InfoResource
10	blog I-InfoResource

# sent_id = 19
# text =   Я Игорь Буянов, старший разработчик группы разметки данных MTS AI.
# relations = ""
1	Я O
2	Игорь B-Person
3	Буянов I-Person
4	, O
5	старший O
6	разработчик O
7	группы O
8	разметки B-Method
9	данных O
10	MTS B-Organization
11	AI I-Organization
12	. O

# sent_id = 20
# text =   Недавно рассказывал о том, как делать иерархически датасет из Википедии.
# relations = ""
1	Недавно O
2	рассказывал O
3	о O
4	том O
5	, O
6	как O
7	делать O
8	иерархически O
9	датасет O
10	из O
11	Википедии B-InfoResource
12	. O

# sent_id = 21
# text =   В этом посте хочу рассказать вам о Сноркеле - фреймворке для программирования данных (data programming).
# relations = ""
1	В O
2	этом O
3	посте O
4	хочу O
5	рассказать O
6	вам O
7	о O
8	Сноркеле B-Technology
9	- O
10	фреймворке B-Environment
11	для I-Environment
12	программирования I-Environment
13	данных I-Environment
14	( O
15	data B-Task
16	programming I-Task
17	) O
18	. O

# sent_id = 22
# text =   Проект стартовал в Стэнфорде как инструмент для помощи в разметке датасетов для задачи information extraction, а сейчас разработчики делают платформу для пользования внешними заказчиками. 
# relations = "Activity_hasAuthor_Organization 0 0, Object_isUsedInSolving_Task 0 0, Object_isUsedInSolving_Task 0 1"
1	Проект B-Activity
2	стартовал O
3	в O
4	Стэнфорде B-Organization
5	как O
6	инструмент B-Object
7	для O
8	помощи O
9	в O
10	разметке B-Task
11	датасетов I-Task
12	для O
13	задачи O
14	information B-Task
15	extraction I-Task
16	, O
17	а O
18	сейчас O
19	разработчики O
20	делают O
21	платформу O
22	для O
23	пользования O
24	внешними O
25	заказчиками O
26	. O

# sent_id = 23
# text =   В разметочные функции (labeling functions) закодированы все возможные правила, по которым можно поставить какую-либо метку каждому примеру из набора данных.
# relations = "Method_includes_Method 0 2, Method_includes_Method 1 2, Method_isAlternativeNameFor_Method 1 0"
1	В O
2	разметочные B-Method
3	функции I-Method
4	( O
5	labeling B-Method
6	functions I-Method
7	) O
8	закодированы B-Method_includes_Method
9	все O
10	возможные O
11	правила B-Method
12	, O
13	по O
14	которым O
15	можно O
16	поставить O
17	какую O
18	- O
19	либо O
20	метку O
21	каждому O
22	примеру O
23	из O
24	набора B-Dataset
25	данных I-Dataset
26	. O

# sent_id = 24
# text =   В качестве основы для таких функций используются:внешние базы данных, такие как WordNet или WikiBase.
# relations = ""
1	В O
2	качестве O
3	основы O
4	для O
5	таких O
6	функций O
7	используются O
8	: O
9	внешние O
10	базы B-InfoResource
11	данных I-InfoResource
12	, O
13	такие O
14	как O
15	WordNet B-InfoResource
16	или O
17	WikiBase B-InfoResource
18	. O

# sent_id = 25
# text =   Генеративная модель, являющаяся сердцем Сноркеля, попытается учесть недостатки отдельных функций.
# relations = "Model_isUsedIn_Application 0 0"
1	Генеративная B-Model
2	модель I-Model
3	, O
4	являющаяся B-Model_isUsedIn_Application
5	сердцем O
6	Сноркеля B-Application
7	, O
8	попытается O
9	учесть O
10	недостатки O
11	отдельных O
12	функций O
13	. O

# sent_id = 26
# text =   Для наглядности оставляю здесь иллюстрацию с последовательностью работы со Снокрелем для задачи information extraction из оригинальной статьи.
# relations = "Application_isUsedForSolving_Task 0 0"
1	Для O
2	наглядности O
3	оставляю O
4	здесь O
5	иллюстрацию O
6	с O
7	последовательностью O
8	работы O
9	со O
10	Снокрелем B-Application
11	для O
12	задачи O
13	information B-Task
14	extraction I-Task
15	из O
16	оригинальной O
17	статьи O
18	. O

# sent_id = 27
# text =   Авторы оригинальной статьи представляют ее как факторный граф, или графическую вероятностную модель.
# relations = ""
1	Авторы O
2	оригинальной O
3	статьи O
4	представляют O
5	ее O
6	как O
7	факторный B-Object
8	граф I-Object
9	, O
10	или O
11	графическую B-Model
12	вероятностную I-Model
13	модель I-Model
14	. O

# sent_id = 28
# text =  Тогда модель определяется так, чтобы обучить эту модель без доступа к истинным меткам, это нужно обучаться с помощью логарифмического негативного маргинализированного правдоподобия, зная матрицу.
# relations = "Method_isAppliedTo_Object 0 0"
1	Тогда O
2	модель O
3	определяется O
4	так O
5	, O
6	чтобы O
7	обучить O
8	эту O
9	модель O
10	без O
11	доступа O
12	к O
13	истинным O
14	меткам O
15	, O
16	это O
17	нужно O
18	обучаться O
19	с O
20	помощью O
21	логарифмического B-Method
22	негативного I-Method
23	маргинализированного I-Method
24	правдоподобия I-Method
25	, O
26	зная O
27	матрицу B-Object
28	. O

# sent_id = 29
# text =  Оптимизацию авторы проводили с помощью SGD с семплированием Гиббса.
# relations = ""
1	Оптимизацию B-Activity
2	авторы O
3	проводили B-Method_isUsedIn_Activity
4	с I-Method_isUsedIn_Activity
5	помощью I-Method_isUsedIn_Activity
6	SGD B-Method
7	с O
8	семплированием B-Method
9	Гиббса I-Method
10	. O

# sent_id = 30
# text =   Загрузим заранее обученную модель fastText, чей выбор объясняется наличием огромного количества опечаток в текстах.
# relations = ""
1	Загрузим O
2	заранее O
3	обученную O
4	модель O
5	fastText B-Model
6	, O
7	чей O
8	выбор O
9	объясняется O
10	наличием O
11	огромного O
12	количества O
13	опечаток O
14	в O
15	текстах B-Object
16	. O

# sent_id = 31
# text =   Таким образом мы получили опорный вектор для класса "диарея".
# relations = ""
1	Таким O
2	образом O
3	мы O
4	получили B-Method_isAppliedTo_Object
5	опорный B-Object
6	вектор I-Object
7	для O
8	класса O
9	" O
10	диарея O
11	" O
12	. O

# sent_id = 32
# text =   Зайдя на несколько из них я увидел что большая половина типа Wix используют технологию Искусственного Интеллекта, чтобы создать шаблон разметки страницы и далее её уже заполнить.
# relations = "Application_isUsedForSolving_Task 0 0"
1	Зайдя O
2	на O
3	несколько O
4	из O
5	них O
6	я O
7	увидел O
8	что O
9	большая O
10	половина O
11	типа O
12	Wix B-Organization
13	используют O
14	технологию B-Application
15	Искусственного I-Application
16	Интеллекта I-Application
17	, O
18	чтобы O
19	создать B-Task
20	шаблон I-Task
21	разметки I-Task
22	страницы I-Task
23	и O
24	далее O
25	её O
26	уже O
27	заполнить O
28	. O

# sent_id = 33
# text =   В финале я могу его редактировать путем Drag & Drop.
# relations = ""
1	В O
2	финале O
3	я O
4	могу O
5	его O
6	редактировать O
7	путем O
8	Drag B-Method
9	& I-Method
10	Drop I-Method
11	. O

# sent_id = 34
# text =   Некоторое время назад к нам обратился заказчик с не совсем обычной задачей — воспроизвести сервис IBM Watson Personality Insights, который анализировал текст, написанный человеком и определял по нему ряд личностных характеристик.
# relations = "Application_isAppliedTo_Object 0 0, Application_isUsedForSolving_Task 0 0"
1	Некоторое O
2	время O
3	назад O
4	к O
5	нам O
6	обратился O
7	заказчик O
8	с O
9	не O
10	совсем O
11	обычной O
12	задачей O
13	— O
14	воспроизвести O
15	сервис O
16	IBM B-Technology
17	Watson I-Technology
18	Personality I-Technology
19	Insights I-Technology
20	, O
21	который O
22	анализировал B-Task
23	текст I-Task
24	, O
25	написанный O
26	человеком O
27	и O
28	определял O
29	по O
30	нему O
31	ряд O
32	личностных B-Object
33	характеристик I-Object
34	. O

# sent_id = 35
# text =   Основная идея данного сервиса состояла в том, что он получает на вход текст написанный определенным человеком и определяет по этому тексту четыре группы характеристик личности.
# relations = "Object_isUsedInSolving_Task 0 0, Object_isUsedInSolving_Task 1 0"
1	Основная O
2	идея O
3	данного O
4	сервиса O
5	состояла O
6	в O
7	том O
8	, O
9	что O
10	он O
11	получает O
12	на O
13	вход O
14	текст O
15	написанный O
16	определенным O
17	человеком O
18	и O
19	определяет B-Task
20	по O
21	этому O
22	тексту B-Object
23	четыре O
24	группы B-Object
25	характеристик I-Object
26	личности I-Object
27	. O

# sent_id = 36
# text =   Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.
# relations = "Task_isSolvedIn_Science 1 1, Task_isSolvedIn_Science 0 0, Application_isUsedForSolving_Task 0 2, Application_isUsedForSolving_Task 0 1, Application_isUsedIn_Science 0 1, Application_isUsedForSolving_Task 0 0, Application_isUsedIn_Science 0 0"
1	Например O
2	, O
3	Personality B-Technology
4	Insights I-Technology
5	использовался O
6	в O
7	психотерапии B-Science
8	для O
9	оценки B-Task
10	состояния I-Task
11	пациентов I-Task
12	[ O
13	5 O
14	] O
15	, O
16	в O
17	искусстве B-Science
18	( O
19	оценка B-Task
20	личности I-Task
21	персонажей I-Task
22	пьес I-Task
23	Шекспира I-Task
24	) O
25	[ O
26	6 O
27	] O
28	, O
29	определении B-Task
30	спама I-Task
31	[ O
32	7 O
33	] O
34	а O
35	также O
36	в O
37	научных O
38	исследованиях O
39	. O

# sent_id = 37
# text =   Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.
# relations = "Task_isSolvedIn_Science 1 1, Task_isSolvedIn_Science 0 0, Application_isUsedForSolving_Task 0 2, Application_isUsedForSolving_Task 0 1, Application_isUsedIn_Science 0 1, Application_isUsedForSolving_Task 0 0, Application_isUsedIn_Science 0 0"
1	Personality B-Technology
2	Insights I-Technology
3	был O
4	применен O
5	в O
6	психотерапии B-Science
7	для O
8	оценки B-Task
9	состояния I-Task
10	пациентов I-Task
11	, O
12	в O
13	искусстве B-Science
14	( O
15	анализ B-Task
16	личности I-Task
17	персонажей I-Task
18	пьес I-Task
19	Шекспира I-Task
20	) O
21	, O
22	выявлении B-Task
23	спама I-Task
24	, O
25	а O
26	также O
27	в O
28	научных O
29	исследованиях O
30	. O

# sent_id = 38
# text =   На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.
# relations = "Metric_isUsedFor_Model 1 0, Metric_isUsedFor_Model 2 0, Metric_isUsedFor_Model 0 0, Metric_isAlternativeNameFor_Metric 1 0"
1	На O
2	сайте O
3	Personality B-InfoResource
4	Insights I-InfoResource
5	качество O
6	моделей O
7	Watson B-Model
8	оценивалось O
9	с O
10	помощью O
11	двух O
12	показателей O
13	— O
14	средней B-Metric
15	абсолютной I-Metric
16	ошибки I-Metric
17	( O
18	MAE B-Metric
19	) O
20	и O
21	коэффициента B-Metric
22	корреляции I-Metric
23	. O

# sent_id = 39
# text = На платформе Personality Insights модели Watson оценивались по двум метрикам — средней абсолютной ошибке (MAE) и коэффициенту корреляции.
# relations = "Metric_isUsedFor_Model 1 0, Metric_isUsedFor_Model 2 0, Metric_isUsedFor_Model 0 0, Metric_isAlternativeNameFor_Metric 1 0"
1	На O
2	платформе O
3	Personality B-InfoResource
4	Insights I-InfoResource
5	модели O
6	Watson B-Model
7	оценивались O
8	по O
9	двум O
10	метрикам O
11	— O
12	средней B-Metric
13	абсолютной I-Metric
14	ошибке I-Metric
15	( O
16	MAE B-Metric
17	) O
18	и O
19	коэффициенту B-Metric
20	корреляции I-Metric
21	. O

# sent_id = 40
# text =   В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 1 0, Method_solves_Task 0 0, Method_solves_Task 1 0, Method_solves_Task 2 0, Method_solves_Task 3 0"
1	В O
2	литературе O
3	для O
4	предсказания B-Task
5	характеристик I-Task
6	Big O
7	5 O
8	использовались O
9	различные O
10	методы O
11	линейная B-Method
12	регрессия I-Method
13	с O
14	использованием O
15	признаков O
16	полученных O
17	латентным B-Method
18	семантическим I-Method
19	анализом I-Method
20	[ O
21	11 O
22	] O
23	, O
24	ридж B-Method
25	- I-Method
26	регрессия I-Method
27	по O
28	большому O
29	набору O
30	собранных O
31	вручную O
32	признаков O
33	[ O
34	12 O
35	] O
36	, O
37	SVM B-Method
38	с O
39	признаками O
40	TF B-Metric
41	/ O
42	IDF B-Metric
43	[ O
44	13 O
45	] O
46	, O
47	word2vec B-Model
48	и O
49	doc2vec B-Model
50	[ O
51	14 O
52	] O
53	. O

# sent_id = 41
# text =   В более современных работах присутствуют сверточные нейронные сети [15, 16], а также предобученные модели BERT [17]
# relations = ""
1	В O
2	более O
3	современных O
4	работах O
5	присутствуют O
6	сверточные B-Model
7	нейронные I-Model
8	сети I-Model
9	[ O
10	15 O
11	, O
12	16 O
13	] O
14	, O
15	а O
16	также O
17	предобученные O
18	модели O
19	BERT B-Model
20	[ O
21	17 O
22	] O

# sent_id = 42
# text =  Модель, которую построил заказчик использовала вектора слов word2vec и рекуррентную нейронную сеть на базе GRU (gated recurrent unit) (Рис 1а).
# relations = "Model_isAlternativeNameFor_Model 3 4, Model_isModificationOf_Model 2 3"
1	Модель B-Model
2	, O
3	которую O
4	построил O
5	заказчик O
6	использовала O
7	вектора O
8	слов O
9	word2vec B-Model
10	и O
11	рекуррентную B-Model
12	нейронную I-Model
13	сеть I-Model
14	на O
15	базе O
16	GRU B-Model
17	( O
18	gated B-Model
19	recurrent I-Model
20	unit I-Model
21	) O
22	( O
23	Рис O
24	1а O
25	) O
26	. O

# sent_id = 43
# text =   Обучалась модель с функцией ошибки MSE (среднеквадратичное отклонение).
# relations = "Metric_isAlternativeNameFor_Metric 1 0, Metric_isUsedFor_Model 0 0, Metric_isUsedFor_Model 1 0"
1	Обучалась O
2	модель B-Model
3	с O
4	функцией O
5	ошибки O
6	MSE B-Metric
7	( O
8	среднеквадратичное B-Metric
9	отклонение I-Metric
10	) O
11	. O

# sent_id = 44
# text =   Сигмоидная функция активации обычно не очень хорошо подходит для задачи регрессии.
# relations = ""
1	Сигмоидная B-Method
2	функция I-Method
3	активации I-Method
4	обычно O
5	не O
6	очень O
7	хорошо O
8	подходит O
9	для O
10	задачи O
11	регрессии B-Task
12	. O

# sent_id = 45
# text =   В литературе для регрессии рекомендуют использовать линейную активацию или RelU.
# relations = "Method_solves_Task 0 0, Method_solves_Task 1 0"
1	В O
2	литературе O
3	для O
4	регрессии B-Task
5	рекомендуют O
6	использовать O
7	линейную B-Method
8	активацию I-Method
9	или O
10	RelU B-Method
11	. O

# sent_id = 46
# text =   Вычислив MAE отдельно для характеристики личности и отдельно для потребительских предпочтений получили значения 0.11 и 0.148 соответственно, т. е. потребительские предпочтения сильно портят общую картину.
# relations = "Metric_hasValue_Value 0 0, Metric_hasValue_Value 0 1"
1	Вычислив O
2	MAE B-Metric
3	отдельно O
4	для O
5	характеристики O
6	личности O
7	и O
8	отдельно O
9	для O
10	потребительских O
11	предпочтений O
12	получили O
13	значения O
14	0.11 B-Value
15	и O
16	0.148 B-Value
17	соответственно O
18	, O
19	т O
20	. O
21	е O
22	. O
23	потребительские O
24	предпочтения O
25	сильно O
26	портят O
27	общую O
28	картину O
29	. O

# sent_id = 47
# text =   Замена BERT на более современную модель XLM RoBERTa large позволило улучшить результаты (эта модель более ресурсозатратная и медленная, но заказчик сказал, что скорость работы не критична).
# relations = ""
1	Замена O
2	BERT B-Model
3	на O
4	более O
5	современную O
6	модель O
7	XLM B-Model
8	RoBERTa I-Model
9	large I-Model
10	позволило O
11	улучшить O
12	результаты O
13	( O
14	эта O
15	модель O
16	более O
17	ресурсозатратная O
18	и O
19	медленная O
20	, O
21	но O
22	заказчик O
23	сказал O
24	, O
25	что O
26	скорость O
27	работы O
28	не O
29	критична O
30	) O
31	. O

# sent_id = 48
# text =   Итоговый MAE составил 0.073 для характеристик личности и 0.098 для потребительских предпочтений.
# relations = "Metric_hasValue_Value 0 0, Metric_hasValue_Value 0 1"
1	Итоговый O
2	MAE B-Metric
3	составил O
4	0.073 B-Value
5	для O
6	характеристик O
7	личности O
8	и O
9	0.098 B-Value
10	для O
11	потребительских O
12	предпочтений O
13	. O

# sent_id = 49
# text =   Получились немного разные цифры, но средний коэффициент корреляции по всем параметрам составил 0.68, что говорит о том, что характеристики, выдаваемые с разных переводов одного текста должны быть весьма похожи.
# relations = "Metric_hasValue_Value 0 0"
1	Получились O
2	немного O
3	разные O
4	цифры O
5	, O
6	но O
7	средний O
8	коэффициент B-Metric
9	корреляции I-Metric
10	по O
11	всем O
12	параметрам O
13	составил O
14	0.68 B-Value
15	, O
16	что O
17	говорит O
18	о O
19	том O
20	, O
21	что O
22	характеристики O
23	, O
24	выдаваемые O
25	с O
26	разных O
27	переводов O
28	одного O
29	текста O
30	должны O
31	быть O
32	весьма O
33	похожи O
34	. O

# sent_id = 50
# text =   Надо сказать, что признаки, формируемые верхними слоями подобных моделей не всегда являются самыми лучшими, точнее даже сказать, как правило, не являются — в классических задачах, таких как поиск именованных сущностей или ответы на вопросы по тексту, признаки верхних уровней работают хуже, чем признаки промежуточных [18].
# relations = "Object_isUsedInSolving_Task 0 0"
1	Надо O
2	сказать O
3	, O
4	что O
5	признаки B-Object
6	, O
7	формируемые O
8	верхними O
9	слоями O
10	подобных O
11	моделей O
12	не O
13	всегда O
14	являются O
15	самыми O
16	лучшими O
17	, O
18	точнее O
19	даже O
20	сказать O
21	, O
22	как O
23	правило O
24	, O
25	не O
26	являются O
27	— O
28	в O
29	классических O
30	задачах O
31	, O
32	таких O
33	как O
34	поиск B-Task
35	именованных I-Task
36	сущностей I-Task
37	или O
38	ответы O
39	на O
40	вопросы O
41	по O
42	тексту O
43	, O
44	признаки O
45	верхних O
46	уровней O
47	работают O
48	хуже O
49	, O
50	чем O
51	признаки O
52	промежуточных O
53	[ O
54	18 O
55	] O
56	. O

# sent_id = 51
# text =   Veridical Data Science — программная статья о методологии верификации моделей.
# relations = ""
1	Veridical B-InfoResource
2	Data I-InfoResource
3	Science I-InfoResource
4	— O
5	программная O
6	статья O
7	о O
8	методологии O
9	верификации B-Task
10	моделей I-Task
11	. O

# sent_id = 52
# text =  Чтобы обеспечить надежную проверку и разработать механизмы проверки и пополнения знаний, нужны специалисты смежных областей, одновременно обладающие компетенциями в ML и в предметной области (медицине, лингвистике, нейробиологии, образовании и т.д.).
# relations = ""
1	Чтобы O
2	обеспечить O
3	надежную O
4	проверку O
5	и O
6	разработать O
7	механизмы O
8	проверки O
9	и O
10	пополнения O
11	знаний O
12	, O
13	нужны O
14	специалисты O
15	смежных O
16	областей O
17	, O
18	одновременно O
19	обладающие O
20	компетенциями O
21	в O
22	ML O
23	и O
24	в O
25	предметной O
26	области O
27	( O
28	медицине B-Science
29	, O
30	лингвистике B-Science
31	, O
32	нейробиологии B-Science
33	, O
34	образовании B-Science
35	и O
36	т.д. O
37	) O
38	. O

# sent_id = 53
# text =   В частности, развивается causal inference и commonsense reasoning.
# relations = ""
1	В O
2	частности O
3	, O
4	развивается O
5	causal B-Method
6	inference I-Method
7	и O
8	commonsense B-Method
9	reasoning I-Method
10	. O

# sent_id = 54
# text =   Часть докладов посвящена мета-обучению (о том, как учиться учиться) и соединению DL-технологий с логикой 1 и 2 порядка — термин Artificial General Intelligence (AGI) становится обычным термином в выступлениях спикеров.
# relations = ""
1	Часть O
2	докладов O
3	посвящена O
4	мета O
5	- O
6	обучению O
7	( O
8	о O
9	том O
10	, O
11	как O
12	учиться O
13	учиться O
14	) O
15	и O
16	соединению O
17	DL B-Technology
18	- I-Technology
19	технологий I-Technology
20	с O
21	логикой O
22	1 O
23	и O
24	2 O
25	порядка O
26	— O
27	термин O
28	Artificial B-Application
29	General I-Application
30	Intelligence I-Application
31	( O
32	AGI B-Application
33	) O
34	становится O
35	обычным O
36	термином O
37	в O
38	выступлениях O
39	спикеров O
40	. O

# sent_id = 55
# text =   Google запускает Coral ai – аналог raspberry pi, мини-компьютер для внедрения нейросетей в экспериментальные установки.
# relations = "Application_hasAuthor_Organization 0 0"
1	Google B-Organization
2	запускает B-Application_hasAuthor_Organization
3	Coral B-Technology
4	ai I-Technology
5	– O
6	аналог O
7	raspberry B-Technology
8	pi I-Technology
9	, O
10	мини O
11	- O
12	компьютер O
13	для O
14	внедрения O
15	нейросетей B-Method
16	в O
17	экспериментальные O
18	установки O
19	. O

# sent_id = 56
# text =   Federated learning – направление ML, в котором отдельные модели учатся независимо друг от друга, а затем объединяются в единую модель (без централизации исходных данных), с поправками на редкие события, аномалии, персонализацию и т.д.
# relations = "Method_includes_Method 1 0"
1	Federated B-Method
2	learning I-Method
3	– O
4	направление O
5	ML B-Method
6	, O
7	в O
8	котором O
9	отдельные O
10	модели O
11	учатся O
12	независимо O
13	друг O
14	от O
15	друга O
16	, O
17	а O
18	затем O
19	объединяются O
20	в O
21	единую O
22	модель O
23	( O
24	без O
25	централизации O
26	исходных O
27	данных O
28	) O
29	, O
30	с O
31	поправками O
32	на O
33	редкие O
34	события O
35	, O
36	аномалии O
37	, O
38	персонализацию O
39	и O
40	т.д. O

# sent_id = 57
# text =   Генеративные модели на основании federated learning – будущее перспективное направление по мнению Google, которое находится “в ранних стадиях экспоненциального роста”.
# relations = "Method_isUsedForTraining_Model 0 0"
1	Генеративные B-Model
2	модели I-Model
3	на O
4	основании O
5	federated B-Method
6	learning I-Method
7	– O
8	будущее O
9	перспективное O
10	направление O
11	по O
12	мнению O
13	Google B-Organization
14	, O
15	которое O
16	находится O
17	“ O
18	в O
19	ранних O
20	стадиях O
21	экспоненциального O
22	роста O
23	” O
24	. O

# sent_id = 58
# text =   Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.
# relations = "Task_isAlternativeNameFor_Task 1 0, Task_isAlternativeNameFor_Task 2 0, Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 0 1, Application_isUsedForSolving_Task 0 2, Application_isUsedForSolving_Task 1 0, Application_isUsedForSolving_Task 1 1, Application_isUsedForSolving_Task 1 2"
1	Чатботы B-Application
2	и O
3	искусственный B-Application
4	интеллект I-Application
5	для O
6	понимания B-Task
7	естественного I-Task
8	языка I-Task
9	( O
10	NLU B-Task
11	– O
12	Natural B-Task
13	Language I-Task
14	Understanding I-Task
15	) O
16	тема O
17	достаточно O
18	горячая O
19	, O
20	про O
21	нее O
22	не O
23	раз O
24	говорилось O
25	на O
26	Хабре O
27	. O

# sent_id = 59
# text =   Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.
# relations = "Task_isSolvedIn_Science 3 0, Task_isSolvedIn_Science 4 0, Task_isAlternativeNameFor_Task 4 3, Task_isAlternativeNameFor_Task 2 1, Task_isSolvedIn_Science 2 0, Task_isSolvedIn_Science 0 0, Task_isSolvedIn_Science 1 0, Method_isUsedIn_Science 0 0"
1	Хотя O
2	AI B-Science
3	— O
4	это O
5	достаточно O
6	широкая O
7	область O
8	, O
9	включающая B-Science_includes_Science
10	в O
11	себя O
12	машинное B-Science
13	зрение I-Science
14	, O
15	предиктивный B-Method
16	анализ I-Method
17	, O
18	машинный B-Task
19	перевод I-Task
20	и O
21	другие O
22	области O
23	– O
24	понимание B-Task
25	естественного I-Task
26	языка I-Task
27	( O
28	NLU B-Task
29	) O
30	и O
31	его O
32	генерация B-Task
33	( O
34	NLG B-Task
35	) O
36	является O
37	значительной O
38	и O
39	быстрорастущей O
40	его O
41	частью O
42	. O

# sent_id = 60
# text =   Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.
# relations = "Application_isUsedIn_Science 0 0, Application_isUsedIn_Science 1 0, Application_hasAuthor_Person 1 1, Application_hasAuthor_Person 1 2, Method_isUsedIn_Application 0 1, Method_isUsedIn_Application 1 1, Method_hasAuthor_Person 0 1, Method_hasAuthor_Person 0 2, Method_hasAuthor_Person 1 1, Method_hasAuthor_Person 1 2, Date_isDateOf_Method 0 0, Date_isDateOf_Method 0 1, Method_isAlternativeNameFor_Method 1 0, Method_isUsedIn_Science 0 0, Method_isUsedIn_Science 1 0"
1	Опуская O
2	историю O
3	, O
4	начавшуюся O
5	еще O
6	в O
7	50-е O
8	годы O
9	с O
10	Алана B-Person
11	Тьюринга I-Person
12	и O
13	программы O
14	Элиза B-Application
15	в O
16	60-е O
17	годы O
18	, O
19	а O
20	также O
21	научные O
22	исследования O
23	в O
24	области O
25	лингвистики O
26	и O
27	машинного B-Science
28	обучения I-Science
29	90-х O
30	годов O
31	, O
32	значимым O
33	событием O
34	более O
35	новой O
36	истории O
37	стало O
38	появление O
39	языка O
40	разметки O
41	AIML B-Method
42	( O
43	Artificial B-Method
44	Intelligence I-Method
45	Markup I-Method
46	Language I-Method
47	) O
48	, O
49	разработанной O
50	в O
51	2001-м B-Date
52	году O
53	Ричардом B-Person
54	Уэлсом I-Person
55	( O
56	Richard B-Person
57	Wallace I-Person
58	) O
59	и O
60	созданным O
61	на O
62	его O
63	основе O
64	чатботом O
65	A.L.I.C.E. B-Application

# sent_id = 61
# text =   В течение последующих десяти лет подходы к написанию чатботов во многом представляли из себя переработки или улучшения этой методологии, получившей название «rule-based подход» или «подход на основе формальных правил».
# relations = ""
1	В O
2	течение O
3	последующих O
4	десяти O
5	лет O
6	подходы O
7	к O
8	написанию O
9	чатботов O
10	во O
11	многом O
12	представляли O
13	из O
14	себя O
15	переработки O
16	или O
17	улучшения O
18	этой O
19	методологии O
20	, O
21	получившей O
22	название O
23	« O
24	rule B-Method
25	- I-Method
26	based I-Method
27	подход O
28	» O
29	или O
30	« O
31	подход B-Method
32	на I-Method
33	основе I-Method
34	формальных I-Method
35	правил I-Method
36	» O
37	. O

# sent_id = 62
# text =   Именно эти технологии, вместе с заметным продвижением в области технологий синтеза и распознавания речи, а также распространением мессенджеров и вебчатов – обусловили стремительный рост количества внедрений NLU-технологий в 2015-2018-м годах.
# relations = "Method_solves_Task 0 0, Date_isDateOf_Method 0 0"
1	Именно O
2	эти O
3	технологии O
4	, O
5	вместе O
6	с O
7	заметным O
8	продвижением O
9	в O
10	области O
11	технологий O
12	синтеза B-Task
13	и I-Task
14	распознавания I-Task
15	речи I-Task
16	, O
17	а O
18	также O
19	распространением O
20	мессенджеров O
21	и O
22	вебчатов O
23	– O
24	обусловили O
25	стремительный O
26	рост O
27	количества O
28	внедрений O
29	NLU B-Method
30	- I-Method
31	технологий I-Method
32	в O
33	2015 B-Date
34	- I-Date
35	2018-м I-Date
36	годах O
37	. O

# sent_id = 63
# text =   Продвижение в области технологий синтеза и распознавания речи, а также расширение использования мессенджеров и веб-чатов, в сочетании с этими технологиями, существенно способствовали быстрому распространению NLU-технологий в период с 2015 по 2018 год.
# relations = "Date_isDateOf_Method 0 0, Date_isDateOf_Method 1 0"
1	Продвижение O
2	в O
3	области O
4	технологий O
5	синтеза O
6	и O
7	распознавания O
8	речи O
9	, O
10	а O
11	также O
12	расширение O
13	использования O
14	мессенджеров O
15	и O
16	веб O
17	- O
18	чатов O
19	, O
20	в O
21	сочетании O
22	с O
23	этими O
24	технологиями O
25	, O
26	существенно O
27	способствовали O
28	быстрому O
29	распространению O
30	NLU B-Method
31	- I-Method
32	технологий I-Method 
33	в O
34	период O
35	с O
36	2015 B-Date
37	по O
38	2018 B-Date
39	год O
40	. O

# sent_id = 64
# text =   Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.
# relations = "Application_isAppliedTo_Object 6 0, Application_isAppliedTo_Object 5 0, Application_isAppliedTo_Object 4 0, Application_isAppliedTo_Object 3 0, Application_isAppliedTo_Object 2 0, Application_isAppliedTo_Object 6 1, Application_isAppliedTo_Object 5 1, Application_isAppliedTo_Object 4 1, Application_isAppliedTo_Object 3 1, Application_isAppliedTo_Object 2 1, Application_hasAuthor_Organization 6 4, Application_hasAuthor_Organization 5 3, Application_hasAuthor_Organization 4 2, Application_hasAuthor_Organization 3 1, Application_hasAuthor_Organization 2 0, Application_isAlternativeNameFor_Application 1 0"
1	Голосовые B-Application
2	ассистенты I-Application
3	( O
4	IVA B-Application
5	) O
6	: O
7	Alexa B-Application
8	от O
9	Amazon B-Organization
10	, O
11	Google B-Application
12	Assistant I-Application
13	от O
14	Google B-Organization
15	, O
16	Siri B-Application
17	от O
18	Apple B-Organization
19	, O
20	Cortana B-Application
21	от O
22	Microsoft B-Organization
23	, O
24	Алиса B-Application
25	от O
26	Яндекса B-Organization
27	– O
28	они O
29	определяют O
30	интенты B-Object
31	( O
32	намерения B-Object
33	) O
34	пользователей O
35	и O
36	исполняют O
37	команды O
38	. O

# sent_id = 65
# text =   Голосовые ассистенты (ГА, IVA) определяют интенты пользователей и исполняют команды.
# relations = "Application_isAlternativeNameFor_Application 1 0, Application_isAlternativeNameFor_Application 2 0, Application_isAlternativeNameFor_Application 2 1"
1	Голосовые B-Application
2	ассистенты I-Application
3	( O
4	ГА B-Application
5	, O
6	IVA B-Application
7	) O
8	определяют O
9	интенты O
10	пользователей O
11	и O
12	исполняют O
13	команды O
14	. O

# sent_id = 66
# text =   В качестве каналов могут выступать умные устройства, ассистенты, встроенные в устройства или мобильные телефоны, привычный звонок на номер телефона, мессенджеры или вебчаты, подобные популярным в России Livetex, Jivosite или Webim.
# relations = ""
1	В O
2	качестве O
3	каналов O
4	могут O
5	выступать O
6	умные O
7	устройства O
8	, O
9	ассистенты O
10	, O
11	встроенные O
12	в O
13	устройства O
14	или O
15	мобильные O
16	телефоны O
17	, O
18	привычный O
19	звонок O
20	на O
21	номер O
22	телефона O
23	, O
24	мессенджеры O
25	или O
26	вебчаты O
27	, O
28	подобные O
29	популярным O
30	в O
31	России O
32	Livetex B-Application
33	, O
34	Jivosite B-Application
35	или O
36	Webim B-Application
37	. O

# sent_id = 67
# text =   За эту конвертацию отвечают платформы ASR (распознавание речи), TTS (синтез речи), системы интеграции с телефонией.
# relations = "Task_isAlternativeNameFor_Task 1 0, Method_isAlternativeNameFor_Method 1 0"
1	За O
2	эту O
3	конвертацию O
4	отвечают O
5	платформы O
6	ASR B-Task
7	( O
8	распознавание B-Task
9	речи I-Task
10	) O
11	, O
12	TTS B-Method
13	( O
14	синтез B-Method
15	речи I-Method
16	) O
17	, O
18	системы O
19	интеграции O
20	с O
21	телефонией O
22	. O

# sent_id = 68
# text =   Наличие развитого rule-based синтаксиса может ускорить разработку чатботов в разы.
# relations = ""
1	Наличие O
2	развитого O
3	rule B-Method
4	- I-Method
5	based I-Method
6	синтаксиса O
7	может O
8	ускорить O
9	разработку O
10	чатботов O
11	в O
12	разы O
13	. O

# sent_id = 69
# text =   Анализ эмоций, богатая и глубокая аналитика, специальные фильтры (например, на использование ненормативной лексики), языковая поддержка, хранение контекста, как и собственно, точность работы используемых нейросетевых алгоритмов, а также производительность, масштабируемость и стабильность – все это также важные, хотя и не всегда очевидные со стороны, особенности диалоговых платформ.
# relations = ""
1	Анализ B-Task
2	эмоций I-Task
3	, O
4	богатая O
5	и O
6	глубокая B-Task
7	аналитика I-Task
8	, O
9	специальные O
10	фильтры O
11	( O
12	например O
13	, O
14	на O
15	использование O
16	ненормативной O
17	лексики O
18	) O
19	, O
20	языковая O
21	поддержка O
22	, O
23	хранение O
24	контекста O
25	, O
26	как O
27	и O
28	собственно O
29	, O
30	точность O
31	работы O
32	используемых O
33	нейросетевых O
34	алгоритмов O
35	, O
36	а O
37	также O
38	производительность O
39	, O
40	масштабируемость O
41	и O
42	стабильность O
43	– O
44	все O
45	это O
46	также O
47	важные O
48	, O
49	хотя O
50	и O
51	не O
52	всегда O
53	очевидные O
54	со O
55	стороны O
56	, O
57	особенности O
58	диалоговых B-Application
59	платформ I-Application
60	. O

# sent_id = 70
# text =   Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.
# relations = "Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 0 1, Application_isUsedForSolving_Task 0 2, Application_hasAuthor_Organization 0 0, Task_isAlternativeNameFor_Task 2 1"
1	Алгоритм O
2	понимания B-Task
3	естественного I-Task
4	языка I-Task
5	( O
6	Natural B-Task
7	Language I-Task
8	Understanding I-Task
9	, O
10	NLU B-Task
11	) O
12	Microsoft B-Organization
13	DeBERTa B-Application
14	превзошел O
15	человеческие O
16	возможности O
17	в O
18	одном O
19	из O
20	самых O
21	сложных O
22	тестов O
23	для O
24	подобных O
25	алгоритмов O
26	SuperGLUE B-Method
27	. O

# sent_id = 71
# text =   На данный момент модель занимает первое место в рейтинге с показателем в 90,3, в то время как среднее значение человеческих возможностей составляет 89,8 баллов.
# relations = ""
1	На O
2	данный O
3	момент O
4	модель O
5	занимает O
6	первое O
7	место O
8	в O
9	рейтинге O
10	с O
11	показателем O
12	в O
13	90,3 B-Value
14	, O
15	в O
16	то O
17	время O
18	как O
19	среднее O
20	значение O
21	человеческих O
22	возможностей O
23	составляет O
24	89,8 B-Value
25	баллов O
26	. O

# sent_id = 72
# text =  Тест SuperGLUE включает в себя ряд задач, которые разработаны для оценки способности ИИ-моделей распознавать и понимать естественный язык, например, дать правильный ответ на вопрос на базе прочитанного абзаца, определить, правильно ли используется многозначное слово в определенном контексте и т.д.
# relations = "Method_solves_Task 0 0"
1	Тест O
2	SuperGLUE B-Method
3	включает O
4	в O
5	себя O
6	ряд O
7	задач O
8	, O
9	которые O
10	разработаны O
11	для O
12	оценки O
13	способности O
14	ИИ O
15	- O
16	моделей O
17	распознавать O
18	и O
19	понимать O
20	естественный O
21	язык O
22	, O
23	например O
24	, O
25	дать B-Task
26	правильный I-Task
27	ответ I-Task
28	на I-Task
29	вопрос I-Task
30	на I-Task
31	базе I-Task
32	прочитанного I-Task
33	абзаца I-Task
34	, O
35	определить O
36	, O
37	правильно O
38	ли O
39	используется O
40	многозначное B-Object
41	слово I-Object
42	в O
43	определенном O
44	контексте O
45	и O
46	т.д. O

# sent_id = 73
# text =   Тест был разработан группой исследователей в 2019 году.
# relations = "Date_isDateOf_Method 0 0"
1	Тест B-Method
2	был O
3	разработан O
4	группой O
5	исследователей O
6	в O
7	2019 B-Date
8	году I-Date
9	. O

# sent_id = 74
# text =  Исследовательская группа разработала тест в 2019 году.
# relations = "Date_isDateOf_Method 0 0"
1	Исследовательская O
2	группа O
3	разработала O
4	тест B-Method
5	в O
6	2019 B-Date
7	году I-Date
8	. O

# sent_id = 75
# text =  Для того чтобы добиться текущего результата в 90,3 балла, DeBERTa получила масштабное обновление архитектуры: теперь она состоит из 48 слоев и имеет 1,5 млрд параметров.
# relations = ""
1	Для O
2	того O
3	чтобы O
4	добиться O
5	текущего O
6	результата O
7	в O
8	90,3 B-Value
9	балла O
10	, O
11	DeBERTa B-Application
12	получила O
13	масштабное O
14	обновление O
15	архитектуры O
16	: O
17	теперь O
18	она O
19	состоит O
20	из O
21	48 B-Value
22	слоев O
23	и O
24	имеет O
25	1,5 O
26	млрд O
27	параметров O
28	. O

# sent_id = 76
# text =   Кроме того, DeBERTa будет интегрирована в следующую версию Тьюринговой модели Microsoft Turing (Turing NLRv4).
# relations = "Model_isModificationOf_Model 2 1"
1	Кроме O
2	того O
3	, O
4	DeBERTa B-Model
5	будет O
6	интегрирована O
7	в O
8	следующую O
9	версию O
10	Тьюринговой B-Model
11	модели I-Model
12	Microsoft I-Model
13	Turing I-Model
14	( O
15	Turing B-Model
16	NLRv4 I-Model
17	) O
18	. O

# sent_id = 77
# text =   Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.
# relations = "Model_isModificationOf_Model 2 1, Model_hasAuthor_Organization 1 0, Model_hasAuthor_Organization 0 0, Model_hasAuthor_Organization 2 0"
1	Дополнительно O
2	, O
3	DeBERTa B-Model
4	будет O
5	включена O
6	в O
7	следующую O
8	версию O
9	модели O
10	Microsoft B-Model
11	Turing I-Model
12	( O
13	Turing B-Model
14	NLRv4 I-Model
15	) O
16	от B-Model_hasAuthor_Organization
17	Microsoft B-Organization
18	. O

# sent_id = 78
# text =   Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedIn_Application 0 0, Model_isUsedIn_Application 0 1, Model_isUsedIn_Application 0 2, Model_isUsedIn_Application 0 3, Application_hasAuthor_Organization 0 0, Application_hasAuthor_Organization 1 0, Application_hasAuthor_Organization 2 0, Application_hasAuthor_Organization 3 0, Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 1 0, Application_isUsedForSolving_Task 2 0, Application_isUsedForSolving_Task 3 0, Application_isUsedForSolving_Task 4 0"
1	Тьюринговые B-Model
2	модели I-Model
3	используются O
4	в O
5	таких O
6	продуктах O
7	Microsoft B-Organization
8	, O
9	как O
10	Bing B-Application
11	, O
12	Office B-Application
13	, O
14	Dynamics B-Application
15	и O
16	Azure B-Application
17	Cognitive I-Application
18	Services I-Application
19	, O
20	чтобы O
21	совершенствовать O
22	, O
23	к O
24	примеру O
25	, O
26	взаимодействие O
27	с O
28	чат B-Application
29	- I-Application
30	ботами I-Application
31	, O
32	предоставление O
33	рекомендаций O
34	и O
35	ответов O
36	на O
37	вопросы O
38	, O
39	поиск O
40	, O
41	автоматизацию O
42	поддержки O
43	клиентов O
44	, O
45	создание B-Task
46	контента I-Task
47	и O
48	решение O
49	многих O
50	других O
51	задач O
52	на O
53	пользу O
54	сотен O
55	миллионов O
56	пользователей O
57	. O

# sent_id = 79
# text = Тьюринговые модели применяются в продуктах, таких как Bing, Office, Dynamics и Azure Cognitive Services.
# relations = "Model_isUsedIn_Application 0 0, Model_isUsedIn_Application 0 1, Model_isUsedIn_Application 0 2, Model_isUsedIn_Application 0 3"
1	Тьюринговые B-Model
2	модели I-Model
3	применяются O
4	в O
5	продуктах O
6	, O
7	таких O
8	как O
9	Bing B-Application
10	, O
11	Office B-Application
12	, O
13	Dynamics B-Application
14	и O
15	Azure B-Application
16	Cognitive I-Application
17	Services I-Application
18	. O

# sent_id = 80
# text =   В отличии от машин, люди хорошо умеют использовать знания, ранее полученные при выполнении различных задач, для решения новых – это называется композиционным обобщением (англ. compositional generalization).
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	В O
2	отличии O
3	от O
4	машин O
5	, O
6	люди O
7	хорошо O
8	умеют O
9	использовать O
10	знания O
11	, O
12	ранее O
13	полученные O
14	при O
15	выполнении O
16	различных O
17	задач O
18	, O
19	для O
20	решения O
21	новых O
22	– O
23	это O
24	называется O
25	композиционным B-Method
26	обобщением I-Method
27	( O
28	англ O
29	. O
30	compositional B-Method
31	generalization I-Method
32	) O
33	. O

# sent_id = 81
# text =   МТИ Technology Review протестировали два инструмента — MyInterview и Curious Thing.
# relations = ""
1	МТИ B-Organization
2	Technology I-Organization
3	Review I-Organization
4	протестировали O
5	два O
6	инструмента O
7	— O
8	MyInterview B-Technology
9	и O
10	Curious B-Technology
11	Thing I-Technology
12	. O

# sent_id = 82
# text =  Как отличить хороший ремонт от плохого, или как мы в SRG сделали из Томита-парсера многопоточную Java-библиотеку. 
# relations = "Application_hasAuthor_Organization 0 0"
1	Как O
2	отличить O
3	хороший O
4	ремонт O
5	от O
6	плохого O
7	, O
8	или O
9	как O
10	мы O
11	в O
12	SRG B-Organization
13	сделали O
14	из O
15	Томита B-Technology
16	- I-Technology
17	парсера I-Technology
18	многопоточную O
19	Java B-Library
20	- I-Library
21	библиотеку I-Library
22	. O

# sent_id = 83
# text =  В этой статье речь пойдет о том, как мы интегрировали разработанный Яндексом Томита-парсер в нашу систему, превратили его в динамическую библиотеку, подружили с Java, сделали многопоточной и решили с её помощью задачу классификации текста для оценки недвижимости.
# relations = "Application_hasAuthor_Organization 0 0, Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 0 1, Environment_isUsedIn_Application 0 0"
1	В O
2	этой O
3	статье O
4	речь O
5	пойдет O
6	о O
7	том O
8	, O
9	как O
10	мы O
11	интегрировали O
12	разработанный O
13	Яндексом B-Organization
14	Томита B-Technology
15	- I-Technology
16	парсер I-Technology
17	в O
18	нашу O
19	систему O
20	, O
21	превратили O
22	его O
23	в O
24	динамическую O
25	библиотеку O
26	, O
27	подружили O
28	с O
29	Java B-Environment
30	, O
31	сделали O
32	многопоточной O
33	и O
34	решили O
35	с O
36	её O
37	помощью O
38	задачу O
39	классификации B-Task
40	текста O
41	для O
42	оценки B-Task
43	недвижимости I-Task
44	. O

# sent_id = 84
# text =   Итак, у нас есть текст объявления, который необходимо классифицировать в одну из категорий согласно состоянию ремонта в квартире (без отделки, чистовой, средний, хороший, отличный, эксклюзивный).
# relations = ""
1	Итак O
2	, O
3	у O
4	нас O
5	есть O
6	текст B-Object
7	объявления I-Object
8	, O
9	который O
10	необходимо O
11	классифицировать O
12	в O
13	одну O
14	из O
15	категорий O
16	согласно O
17	состоянию O
18	ремонта O
19	в O
20	квартире O
21	( O
22	без O
23	отделки O
24	, O
25	чистовой O
26	, O
27	средний O
28	, O
29	хороший O
30	, O
31	отличный O
32	, O
33	эксклюзивный O
34	) O
35	. O

# sent_id = 85
# text =   Таким образом, по мере решения сформировалась вторая большая и интересная задача — научиться извлекать всю достаточную и необходимую информацию о ремонте из объявления, а именно обеспечить быстрый синтаксический и морфологический анализ текста, который сможет работать параллельно под нагрузкой в режиме библиотеки.
# relations = ""
1	Таким O
2	образом O
3	, O
4	по O
5	мере O
6	решения O
7	сформировалась O
8	вторая O
9	большая O
10	и O
11	интересная O
12	задача O
13	— O
14	научиться O
15	извлекать B-Task
16	всю I-Task
17	достаточную I-Task
18	и I-Task
19	необходимую I-Task
20	информацию I-Task
21	о O
22	ремонте O
23	из O
24	объявления O
25	, O
26	а O
27	именно O
28	обеспечить O
29	быстрый O
30	синтаксический O
31	и O
32	морфологический B-Method
33	анализ I-Method
34	текста I-Method
35	, O
36	который O
37	сможет O
38	работать O
39	параллельно O
40	под O
41	нагрузкой O
42	в O
43	режиме O
44	библиотеки O
45	. O

# sent_id = 86
# text =   Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.
# relations = "Library_isAppliedTo_Object 0 0, Method_isUsedIn_Library 0 0, Application_isAppliedTo_Object 0 0, Method_isUsedIn_Application 0 0, Method_solves_Task 0 0, Object_isUsedInSolving_Task 0 0, Application_isUsedForSolving_Task 0 0, Method_isAppliedTo_Object 0 0"
1	Из O
2	доступных O
3	средств O
4	для O
5	извлечения B-Task
6	фактов I-Task
7	из O
8	текста B-Object
9	на O
10	основе O
11	контекстно B-Method
12	- I-Method
13	свободных I-Method
14	грамматик I-Method
15	, O
16	способных O
17	работать O
18	с O
19	русским O
20	языком O
21	, O
22	наше O
23	внимание O
24	привлекли O
25	Томита B-Technology
26	- I-Technology
27	парсер I-Technology
28	и O
29	библиотека O
30	Yagry B-Library
31	на O
32	питоне O
33	. O

# sent_id = 87
# text =   Многопоточный вариант Томиты — TomitaPooledParser использует для парсинга пул объектов TomitaParser, одинаковым образом сконфигурированных.
# relations = "Application_isUsedForSolving_Task 1 0, Application_isUsedForSolving_Task 0 0"
1	Многопоточный O
2	вариант O
3	Томиты B-Technology
4	— O
5	TomitaPooledParser B-Technology
6	использует O
7	для O
8	парсинга B-Task
9	пул O
10	объектов O
11	TomitaParser B-Technology
12	, O
13	одинаковым O
14	образом O
15	сконфигурированных O
16	. O

# sent_id = 88
# text =   Приведу только показатели качества классификации, которые были нами получены на тестах: Accuracy = 95% F1 score = 93%
# relations = "Metric_isUsedIn_Task 0 0, Metric_isUsedIn_Task 1 0, Metric_hasValue_Value 0 0, Metric_hasValue_Value 1 1"
1	Приведу O
2	только O
3	показатели O
4	качества O
5	классификации B-Task
6	, O
7	которые O
8	были O
9	нами O
10	получены O
11	на O
12	тестах O
13	: O
14	Accuracy B-Metric
15	= O
16	95 B-Value
17	% I-Value
18	F1 B-Metric
19	score I-Metric
20	= O
21	93 B-Value
22	% I-Value

# sent_id = 89
# text =  JavaScript-библиотека для обработки текстов на русском языке
# relations = "Library_isUsedForSolving_Task 0 0"
1	JavaScript B-Library
2	- I-Library
3	библиотека I-Library
4	для O
5	обработки B-Task
6	текстов I-Task
7	на O
8	русском O
9	языке O

# sent_id = 90
# text =   Бессвязность текстов в нынешней версии «Генератора» вызвана тем, что на самом деле никакого анализа он производить не умеет.
# relations = ""
1	Бессвязность O
2	текстов O
3	в O
4	нынешней O
5	версии O
6	« O
7	Генератора B-Technology
8	» O
9	вызвана O
10	тем O
11	, O
12	что O
13	на O
14	самом O
15	деле O
16	никакого O
17	анализа B-Method
18	он O
19	производить O
20	не O
21	умеет O
22	. O

# sent_id = 91
# text =   На данный момент библиотека умеет две вещи: токенизацию и анализ морфологии.
# relations = "Method_isUsedIn_Library 1 0, Method_isUsedIn_Library 0 0"
1	На O
2	данный O
3	момент O
4	библиотека B-Library
5	умеет O
6	две O
7	вещи O
8	: O
9	токенизацию B-Method
10	и O
11	анализ B-Method
12	морфологии I-Method
13	. O

# sent_id = 92
# text = В настоящее время библиотека обладает двумя функциональностями: выполнением токенизации и проведением анализа морфологии.
# relations = "Method_isUsedIn_Library 1 0, Method_isUsedIn_Library 0 0"
1	В O
2	настоящее O
3	время O
4	библиотека B-Library
5	обладает O
6	двумя O
7	функциональностями O
8	: O
9	выполнением O
10	токенизации B-Method
11	и O
12	проведением O
13	анализа B-Method
14	морфологии I-Method
15	. O

# sent_id = 93
# text =   Полный список граммем можно найти на странице проекта OpenCorpora.
# relations = ""
1	Полный O
2	список O
3	граммем O
4	можно O
5	найти O
6	на O
7	странице O
8	проекта O
9	OpenCorpora B-InfoResource
10	. O

# sent_id = 94
# text =   Кроме того, для анализа используется словарь OpenCorpora, упакованный в специальном формате, но об этом ниже.
# relations = ""
1	Кроме O
2	того O
3	, O
4	для O
5	анализа B-Task
6	используется O
7	словарь O
8	OpenCorpora B-Corpus
9	, O
10	упакованный O
11	в O
12	специальном O
13	формате O
14	, O
15	но O
16	об O
17	этом O
18	ниже O
19	. O

# sent_id = 95
# text =   Вообще создатели проекта OpenCorpora большие молодцы и я вам рекомендую не только ознакомиться с ним, но и принять участие в коллаборативной разметке корпуса — это также поможет и другим опенсорсным проектам.
# relations = ""
1	Вообще O
2	создатели O
3	проекта O
4	OpenCorpora B-Activity
5	большие O
6	молодцы O
7	и O
8	я O
9	вам O
10	рекомендую O
11	не O
12	только O
13	ознакомиться O
14	с O
15	ним O
16	, O
17	но O
18	и O
19	принять O
20	участие O
21	в O
22	коллаборативной O
23	разметке B-Task
24	корпуса I-Task
25	— O
26	это O
27	также O
28	поможет O
29	и O
30	другим O
31	опенсорсным O
32	проектам O
33	. O

# sent_id = 96
# text =   По сути эта часть библиотеки — порт замечательного морфологического анализатора pymorphy2 за авторством kmike (на Хабре была пара статей об этой библиотеке).
# relations = "Library_hasAuthor_Person 0 0"
1	По O
2	сути O
3	эта O
4	часть O
5	библиотеки O
6	— O
7	порт O
8	замечательного O
9	морфологического B-Application
10	анализатора I-Application
11	pymorphy2 B-Library
12	за O
13	авторством O
14	kmike B-Person
15	( O
16	на O
17	Хабре B-InfoResource
18	была O
19	пара O
20	статей O
21	об O
22	этой O
23	библиотеке O
24	) O
25	. O

# sent_id = 97
# text = Эта часть библиотеки по сути является переносом выдающегося морфологического анализатора pymorphy2, созданного kmike (о котором было написано несколько статей на Хабре).
# relations = "Library_hasAuthor_Person 0 0"
1	Эта O
2	часть O
3	библиотеки O
4	по O
5	сути O
6	является O
7	переносом O
8	выдающегося O
9	морфологического B-Application
10	анализатора I-Application
11	pymorphy2 B-Library
12	, O
13	созданного O
14	kmike B-Person
15	( O
16	о O
17	котором O
18	было O
19	написано O
20	несколько O
21	статей O
22	на O
23	Хабре B-InfoResource
24	) O
25	. O

# sent_id = 98
# text =   Потом появилась нейросеть GPT-2, которая была как минимум в 10 раз мощнее и была способна обрабатывать 1,5 миллиарда параметров (переменных, определяющих возможности машинного обучения).
# relations = ""
1	Потом O
2	появилась O
3	нейросеть O
4	GPT-2 B-Model
5	, O
6	которая O
7	была O
8	как O
9	минимум O
10	в O
11	10 O
12	раз O
13	мощнее O
14	и O
15	была O
16	способна O
17	обрабатывать O
18	1,5 O
19	миллиарда O
20	параметров O
21	( O
22	переменных O
23	, O
24	определяющих O
25	возможности O
26	машинного B-Science
27	обучения I-Science
28	) O
29	. O

# sent_id = 99
# text =   Анализируем тональность текстов с помощью Fast.ai
# relations = ""
1	Анализируем O
2	тональность O
3	текстов O
4	с O
5	помощью O
6	Fast.ai B-Technology

# sent_id = 100
# text =  В статье пойдет речь о классификации тональности текстовых сообщений на русском языке (а по сути любой классификации текстов, используя те же технологии).
# relations = ""
1	В O
2	статье O
3	пойдет O
4	речь O
5	о O
6	классификации B-Task
7	тональности I-Task
8	текстовых I-Task
9	сообщений I-Task
10	на O
11	русском B-Lang
12	языке O
13	( O
14	а O
15	по O
16	сути O
17	любой O
18	классификации O
19	текстов O
20	, O
21	используя O
22	те O
23	же O
24	технологии O
25	) O
26	. O

# sent_id = 101
# text =   За основу возьмем данную статью, в которой была рассмотрена классификация тональности на архитектуре CNN с использованием Word2vec модели.
# relations = "Method_solves_Task 0 0, Model_isUsedForSolving_Task 0 0, Method_uses_Model 0 0"
1	За O
2	основу O
3	возьмем O
4	данную O
5	статью O
6	, O
7	в O
8	которой O
9	была O
10	рассмотрена O
11	классификация B-Task
12	тональности I-Task
13	на O
14	архитектуре O
15	CNN B-Method
16	с O
17	использованием O
18	Word2vec B-Model
19	модели O
20	. O

# sent_id = 102
# text =   В нашем примере будем решать ту же самую задачу разделения твитов на позитивные и негативные на том же самом датасете с использованием модели ULMFit.
# relations = "Model_isUsedForSolving_Task 0 0, Object_isUsedInSolving_Task 0 0, Object_isUsedInSolving_Task 1 0"
1	В O
2	нашем O
3	примере O
4	будем O
5	решать O
6	ту O
7	же O
8	самую O
9	задачу O
10	разделения B-Task
11	твитов I-Task
12	на O
13	позитивные B-Object
14	и O
15	негативные B-Object
16	на O
17	том O
18	же O
19	самом O
20	датасете O
21	с O
22	использованием O
23	модели O
24	ULMFit B-Model
25	. O

# sent_id = 103
# text =   Результат из статьи (average F1-score = 0.78142) примем в качестве baseline.
# relations = "Metric_hasValue_Value 0 0"
1	Результат O
2	из O
3	статьи O
4	( O
5	average O
6	F1-score B-Metric
7	= O
8	0.78142 B-Value
9	) O
10	примем O
11	в O
12	качестве O
13	baseline O
14	. O

# sent_id = 104
# text =   Модель ULMFIT была представлена разработчиками fast.ai (Jeremy Howard, Sebastian Ruder) в 2018 году.
# relations = "Date_isDateOf_Model 0 0, Model_hasAuthor_Person 0 0, Model_hasAuthor_Person 0 1, Model_hasAuthor_Organization 0 0"
1	Модель O
2	ULMFIT B-Model
3	была O
4	представлена O
5	разработчиками O
6	fast.ai B-Organization
7	( O
8	Jeremy B-Person
9	Howard I-Person
10	, O
11	Sebastian B-Person
12	Ruder I-Person
13	) O
14	в O
15	2018 B-Date
16	году O
17	. O

# sent_id = 105
# text =   Суть подхода состоит в использовании transfer learning в задачах NLP, когда вы используете предобученные модели, сокращая время на обучение своих моделей и снижая требования к размерам размеченной тестовой выборки.
# relations = "Method_solves_Task 0 0"
1	Суть O
2	подхода O
3	состоит O
4	в O
5	использовании B-Method_solves_Task
6	transfer B-Method
7	learning I-Method
8	в O
9	задачах B-Task
10	NLP I-Task
11	, O
12	когда O
13	вы O
14	используете O
15	предобученные O
16	модели O
17	, O
18	сокращая O
19	время O
20	на O
21	обучение O
22	своих O
23	моделей O
24	и O
25	снижая O
26	требования O
27	к O
28	размерам O
29	размеченной O
30	тестовой O
31	выборки O
32	. O

# sent_id = 106
# text =   Для задачи моделирования языка ULMFit использует архитектуру AWD-LSTM, которая предполагает активное использование dropout везде, где только можно и имеет смысл.
# relations = "Model_isUsedForSolving_Task 1 0, Model_includes_Model 0 1"
1	Для O
2	задачи O
3	моделирования B-Task
4	языка O
5	ULMFit B-Model
6	использует O
7	архитектуру O
8	AWD B-Model
9	- I-Model
10	LSTM I-Model
11	, O
12	которая O
13	предполагает O
14	активное O
15	использование O
16	dropout O
17	везде O
18	, O
19	где O
20	только O
21	можно O
22	и O
23	имеет O
24	смысл O
25	. O

# sent_id = 107
# text =   Результат, показанный на тестовой выборке average F1-score = 0,80064.
# relations = "Metric_hasValue_Value 0 0"
1	Результат O
2	, O
3	показанный O
4	на O
5	тестовой O
6	выборке O
7	average O
8	F1-score B-Metric
9	= O
10	0,80064 B-Value
11	. O

# sent_id = 108
# text =   Добавьте возможности IBM Watson платформы в ваши приложения, разработанные на платформе IBM Cloud, или в сторонние приложения!
# relations = ""
1	Добавьте O
2	возможности O
3	IBM B-Technology
4	Watson I-Technology
5	платформы O
6	в O
7	ваши O
8	приложения O
9	, O
10	разработанные O
11	на O
12	платформе O
13	IBM B-Technology
14	Cloud I-Technology
15	, O
16	или O
17	в O
18	сторонние O
19	приложения O
20	! O

# sent_id = 109
# text =   IBM Automation Platform для цифрового бизнеса — это интегрированная платформа с пятью возможностями автоматизации, которая помогает бизнесу быстро и масштабно управлять практически всеми типами проектов автоматизации — от повторяющихся и административных до работы на уровне экспертов.
# relations = "Application_isUsedIn_Science 0 0"
1	IBM B-Technology
2	Automation I-Technology
3	Platform I-Technology
4	для O
5	цифрового B-Science
6	бизнеса I-Science
7	— O
8	это O
9	интегрированная O
10	платформа O
11	с O
12	пятью O
13	возможностями O
14	автоматизации O
15	, O
16	которая O
17	помогает O
18	бизнесу O
19	быстро O
20	и O
21	масштабно O
22	управлять O
23	практически O
24	всеми O
25	типами O
26	проектов O
27	автоматизации O
28	— O
29	от O
30	повторяющихся O
31	и O
32	административных O
33	до O
34	работы O
35	на O
36	уровне O
37	экспертов O
38	. O

# sent_id = 110
# text =   Платформа IBM Automation для цифрового бизнеса представляет собой интегрированную платформу с пятью функциями автоматизации, которая обеспечивает быстрое и масштабное управление практически любыми проектами автоматизации — от повторяющихся и административных до задач на уровне экспертов.
# relations = "Application_isUsedIn_Science 0 0"
1	Платформа O
2	IBM B-Technology
3	Automation I-Technology
4	для O
5	цифрового B-Science
6	бизнеса I-Science
7	представляет O
8	собой O
9	интегрированную O
10	платформу O
11	с O
12	пятью O
13	функциями O
14	автоматизации O
15	, O
16	которая O
17	обеспечивает O
18	быстрое O
19	и O
20	масштабное O
21	управление O
22	практически O
23	любыми O
24	проектами O
25	автоматизации O
26	— O
27	от O
28	повторяющихся O
29	и O
30	административных O
31	до O
32	задач O
33	на O
34	уровне O
35	экспертов O
36	. O

# sent_id = 111
# text =   HuggingArtists | Генерируем текст песен с трансформером за 5 минут 
# relations = "Application_isAppliedTo_Object 0 0"
1	HuggingArtists B-Technology
2	| O
3	Генерируем O
4	текст B-Object
5	песен I-Object
6	с O
7	трансформером O
8	за O
9	5 O
10	минут O

# sent_id = 112
# text =   В HuggingArtists, мы можем создавать тексты песен на основе конкретного исполнителя.
# relations = "Application_isUsedForSolving_Task 0 0"
1	В O
2	HuggingArtists B-Technology
3	, O
4	мы O
5	можем O
6	создавать B-Task
7	тексты I-Task
8	песен O
9	на O
10	основе O
11	конкретного O
12	исполнителя O
13	. O

# sent_id = 113
# text =   Это было сделано путем fine-tune (точной настройки) предварительно обученного трансформера HuggingFace  на собранных данных Genius.
# relations = "Model_isTrainedOn_Dataset 0 0, Method_isAlternativeNameFor_Method 1 0, Method_isUsedForTraining_Model 0 0, Method_isUsedForTraining_Model 1 0"
1	Это O
2	было O
3	сделано O
4	путем O
5	fine B-Method
6	- I-Method
7	tune I-Method
8	( O
9	точной B-Method
10	настройки I-Method
11	) O
12	предварительно O
13	обученного O
14	трансформера B-Model
15	HuggingFace I-Model
16	на O
17	собранных O
18	данных O
19	Genius B-Dataset
20	. O

# sent_id = 114
# text =   Кроме того, мы используем интеграцию Weights & Biases для автоматического учета производительности и прогнозов модели.
# relations = ""
1	Кроме O
2	того O
3	, O
4	мы O
5	используем O
6	интеграцию O
7	Weights B-Library
8	& I-Library
9	Biases I-Library
10	для O
11	автоматического O
12	учета O
13	производительности O
14	и O
15	прогнозов O
16	модели O
17	. O

# sent_id = 115
# text =  Анализ тональности текста с использованием фреймворка Lightautoml 
# relations = "Application_isUsedForSolving_Task 0 0"
1	Анализ B-Task
2	тональности I-Task
3	текста I-Task
4	с O
5	использованием O
6	фреймворка O
7	Lightautoml B-Technology

# sent_id = 116
# text =  Сентиментный анализ (анализ тональности) – это область компьютерной лингвистики, занимающаяся изучением эмоций в текстовых документах, в основе которой лежит машинное обучение.
# relations = "Science_isAlternativeNameFor_Science 1 0"
1	Сентиментный B-Science
2	анализ I-Science
3	( O
4	анализ B-Science
5	тональности I-Science
6	) O
7	– O
8	это O
9	область O
10	компьютерной B-Science
11	лингвистики I-Science
12	, O
13	занимающаяся O
14	изучением O
15	эмоций O
16	в O
17	текстовых O
18	документах O
19	, O
20	в O
21	основе O
22	которой O
23	лежит O
24	машинное O
25	обучение O
26	. O

# sent_id = 117
# text =  Сентиментный анализ, также известный как анализ тональности, представляет собой сферу компьютерной лингвистики, которая занимается изучением эмоций в текстовых документах, применяя методы машинного обучения.
# relations = "Method_isUsedIn_Science 0 0, Method_isUsedIn_Science 0 1, Method_isUsedIn_Science 0 2, Science_isAlternativeNameFor_Science 1 0"
1	Сентиментный B-Science
2	анализ I-Science
3	, O
4	также O
5	известный O
6	как O
7	анализ B-Science
8	тональности I-Science
9	, O
10	представляет O
11	собой O
12	сферу O
13	компьютерной B-Science
14	лингвистики I-Science
15	, O
16	которая O
17	занимается O
18	изучением O
19	эмоций O
20	в O
21	текстовых O
22	документах O
23	, O
24	применяя B-Method_isUsedIn_Science
25	методы B-Method
26	машинного I-Method
27	обучения I-Method
28	. O

# sent_id = 118
# text =  Сентимент-анализ, или анализ тональности, является разделом компьютерной лингвистики, в которой занимаются изучением эмоций в текстах с помощью методов машинного обучения.
# relations = "Method_isUsedIn_Science 0 0, Method_isUsedIn_Science 0 1, Method_isUsedIn_Science 0 2, Science_isAlternativeNameFor_Science 1 0"
1	Сентимент-анализ B-Science
2	, O
3	или O
4	анализ B-Science
5	тональности I-Science
6	, O
7	является O
8	разделом O
9	компьютерной B-Science
10	лингвистики I-Science
11	, O
12	в O
13	которой O
14	занимаются O
15	изучением O
16	эмоций O
17	в O
18	текстах O
19	с O
20	помощью O
21	методов B-Method
22	машинного I-Method
23	обучения I-Method
24	. O

# sent_id = 119
# text =  В этой статье я покажу, как мы использовали для этих целей внутреннюю разработку компании – фреймворк LightAutoML, в котором имеется всё для решения поставленной задачи – предобученные готовые векторные представления слов FastText и готовые текстовые пресеты, в которых необходимо только указать гиперпараметры.
# relations = "Application_isAppliedTo_Object 0 0"
1	В O
2	этой O
3	статье O
4	я O
5	покажу O
6	, O
7	как O
8	мы O
9	использовали O
10	для O
11	этих O
12	целей O
13	внутреннюю O
14	разработку O
15	компании O
16	– O
17	фреймворк O
18	LightAutoML B-Technology
19	, O
20	в O
21	котором O
22	имеется O
23	всё O
24	для O
25	решения O
26	поставленной O
27	задачи O
28	– O
29	предобученные B-Object
30	готовые I-Object
31	векторные I-Object
32	представления I-Object
33	слов I-Object
34	FastText B-Model
35	и O
36	готовые O
37	текстовые O
38	пресеты O
39	, O
40	в O
41	которых O
42	необходимо O
43	только O
44	указать O
45	гиперпараметры O
46	. O

# sent_id = 120
# text =   При обучении модели значение метрики F1-score достигло 0.894, соответственно можно сделать вывод о том, что модель хорошо справляется с задачей определения нейтральных и негативных обращений.
# relations = "Metric_isUsedIn_Task 0 0, Metric_hasValue_Value 0 0"
1	При O
2	обучении O
3	модели O
4	значение O
5	метрики O
6	F1-score B-Metric
7	достигло O
8	0.894 B-Value
9	, O
10	соответственно O
11	можно O
12	сделать O
13	вывод O
14	о O
15	том O
16	, O
17	что O
18	модель O
19	хорошо O
20	справляется O
21	с O
22	задачей O
23	определения B-Task
24	нейтральных I-Task
25	и I-Task
26	негативных I-Task
27	обращений I-Task
28	. O

# sent_id = 121
# text =   Также одним из способов оценить работу модели в целом можно по кривой ROC-AUC, которая описывает площадь под кривой (Area Under Curve – Receiver Operating Characteristic).
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	Также O
2	одним O
3	из O
4	способов O
5	оценить O
6	работу O
7	модели O
8	в O
9	целом O
10	можно O
11	по O
12	кривой O
13	ROC B-Metric
14	- I-Metric
15	AUC I-Metric
16	, O
17	которая O
18	описывает O
19	площадь O
20	под O
21	кривой O
22	( O
23	Area B-Metric
24	Under I-Metric
25	Curve I-Metric
26	– I-Metric
27	Receiver I-Metric
28	Operating I-Metric
29	Characteristic I-Metric
30	) O
31	. O

# sent_id = 122
# text =   В качестве подтверждения вышесказанного можно привести работу встроенного в LAMA модуля – LIME, который раскрывает работу модели окрашивая слова в тот или иной цвет, в зависимости от их эмоционального окраса.
# relations = ""
1	В O
2	качестве O
3	подтверждения O
4	вышесказанного O
5	можно O
6	привести O
7	работу O
8	встроенного O
9	в O
10	LAMA B-Application
11	модуля O
12	– O
13	LIME B-Technology
14	, O
15	который O
16	раскрывает O
17	работу O
18	модели O
19	окрашивая O
20	слова O
21	в O
22	тот O
23	или O
24	иной O
25	цвет O
26	, O
27	в O
28	зависимости O
29	от O
30	их O
31	эмоционального O
32	окраса O
33	. O

# sent_id = 123
# text =  Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.
# relations = "Library_isUsedForSolving_Task 0 1, Library_isUsedForSolving_Task 0 2, Library_isUsedForSolving_Task 0 0"
1	Также O
2	фреймворк B-Library
3	может B-Application_isUsedForSolving_Task
4	решать I-Application_isUsedForSolving_Task
5	задачи O
6	регрессионного B-Task
7	анализа I-Task
8	, O
9	целью O
10	которого O
11	является O
12	определение B-Task
13	зависимости I-Task
14	между I-Task
15	переменными I-Task
16	и O
17	оценкой B-Task
18	функции I-Task
19	регрессии I-Task
20	. O

# sent_id = 124
# text =   Работа с текстомВ LightAutoML имеется большое количество вариантов разработки той или иной модели, работающей с текстом.
# relations = ""
1	Работа O
2	с O
3	текстомВ O
4	LightAutoML B-Technology
5	имеется O
6	большое O
7	количество O
8	вариантов O
9	разработки O
10	той O
11	или O
12	иной O
13	модели O
14	, O
15	работающей O
16	с O
17	текстом O
18	. O

# sent_id = 125
# text =   Библиотека предоставляет не только получение стандартных признаков на основе TF-IDF, но и на основе эмбеддингов:1) На основе встроенного FastText, который можно тренировать на том или ином корпусе2) Предобученных моделей Gensim3) Любой другой объект, который имеет вид словаря, где на вход подается слово, а на выходе его эмбеддинги
# relations = "Model_isIncludedIn_Library 0 0, Model_isIncludedIn_Library 1 0, Library_isAppliedTo_Object 0 0"
1	Библиотека B-Library
2	предоставляет O
3	не O
4	только O
5	получение O
6	стандартных O
7	признаков O
8	на O
9	основе O
10	TF B-Metric
11	- I-Metric
12	IDF I-Metric
13	, O
14	но O
15	и O
16	на O
17	основе O
18	эмбеддингов B-Object
19	: O
20	1 O
21	) O
22	На O
23	основе O
24	встроенного O
25	FastText B-Model
26	, O
27	который O
28	можно O
29	тренировать O
30	на O
31	том O
32	или O
33	ином O
34	корпусе O
35	2 O
36	) O
37	Предобученных O
38	моделей O
39	Gensim3 B-Model
40	) O
41	Любой O
42	другой O
43	объект O
44	, O
45	который O
46	имеет O
47	вид O
48	словаря O
49	, O
50	где O
51	на O
52	вход O
53	подается O
54	слово O
55	, O
56	а O
57	на O
58	выходе O
59	его O
60	эмбеддинги O

# sent_id = 126
# text = Среди используемых стратегий извлечения представлений текстов из эмбеддингов слов, можно выделить:1) Weighted Average Transformer (WAT) – взвешивается каждое слово с некоторым весом
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Среди O
2	используемых O
3	стратегий O
4	извлечения O
5	представлений O
6	текстов O
7	из O
8	эмбеддингов O
9	слов O
10	, O
11	можно O
12	выделить O
13	: O
14	1 O
15	) O
16	Weighted B-Method
17	Average I-Method
18	Transformer I-Method
19	( O
20	WAT B-Method
21	) O
22	– O
23	взвешивается O
24	каждое O
25	слово O
26	с O
27	некоторым O
28	весом O

# sent_id = 127
# text =  Bag of Random Embedding Projections (BOREP) – строится линейная модель со случайными весами  
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Bag B-Method
2	of I-Method
3	Random I-Method
4	Embedding I-Method
5	Projections I-Method
6	( O
7	BOREP B-Method
8	) O
9	– O
10	строится O
11	линейная O
12	модель O
13	со O
14	случайными O
15	весами O

# sent_id = 128
# text =  Bert Pooling – получение эмбеддинга с последнего выхода модели Transformer  
# relations = ""
1	Bert B-Method
2	Pooling I-Method
3	– O
4	получение O
5	эмбеддинга O
6	с O
7	последнего O
8	выхода O
9	модели B-Model
10	Transformer I-Model

# sent_id = 129
# text =  За препроцессинг текста отвечает класс токенайзера, по умолчанию применяется только для TF-IDF.
# relations = ""
1	За O
2	препроцессинг O
3	текста O
4	отвечает O
5	класс O
6	токенайзера O
7	, O
8	по O
9	умолчанию O
10	применяется O
11	только O
12	для O
13	TF B-Metric
14	- I-Metric
15	IDF I-Metric
16	. O

# sent_id = 130
# text =  Подводя итоги стоит сказать, что LightAutoML благодаря встроенному инструментарию способен показывать достаточно хорошие результаты в задачах бинарной или мультиклассовой классификации и регрессии.
# relations = "Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 0 1"
1	Подводя O
2	итоги O
3	стоит O
4	сказать O
5	, O
6	что O
7	LightAutoML B-Technology
8	благодаря O
9	встроенному O
10	инструментарию O
11	способен O
12	показывать O
13	достаточно O
14	хорошие O
15	результаты O
16	в O
17	задачах O
18	бинарной B-Task
19	или I-Task
20	мультиклассовой I-Task
21	классификации I-Task
22	и O
23	регрессии B-Task
24	. O

# sent_id = 131
# text =  Конкретно в нашем случае нам удалось создать модель сентиментного анализа, которая с 89% точностью определяет эмоциональный окрас обращения и слова, которые оказывают на это наибольшее влияние.
# relations = "Metric_hasValue_Value 0 0"
1	Конкретно O
2	в O
3	нашем O
4	случае O
5	нам O
6	удалось O
7	создать O
8	модель O
9	сентиментного O
10	анализа O
11	, O
12	которая O
13	с O
14	89 B-Value
15	% I-Value
16	точностью B-Metric
17	определяет O
18	эмоциональный O
19	окрас O
20	обращения O
21	и O
22	слова O
23	, O
24	которые O
25	оказывают O
26	на O
27	это O
28	наибольшее O
29	влияние O
30	. O

# sent_id = 132
# text =   Яндекс открывает датасеты Беспилотных автомобилей, Погоды и Переводчика, чтобы помочь решить проблему сдвига данных в ML       
# relations = "Task_isSolvedIn_Science 0 0"
1	Яндекс B-Organization
2	открывает O
3	датасеты B-Dataset
4	Беспилотных O
5	автомобилей O
6	, O
7	Погоды O
8	и O
9	Переводчика O
10	, O
11	чтобы O
12	помочь O
13	решить O
14	проблему O
15	сдвига B-Task
16	данных I-Task
17	в O
18	ML B-Science

# sent_id = 133
# text =   Для современных моделей, которые используются в машинном переводе, такой язык представляет серьезную проблему, так как большинство переводчиков обучаются на чуть более формальном языке: классической литературе, юридических документах или статьях Википедии.
# relations = ""
1	Для O
2	современных O
3	моделей O
4	, O
5	которые O
6	используются O
7	в O
8	машинном O
9	переводе O
10	, O
11	такой O
12	язык O
13	представляет O
14	серьезную O
15	проблему O
16	, O
17	так O
18	как O
19	большинство O
20	переводчиков O
21	обучаются O
22	на O
23	чуть O
24	более O
25	формальном O
26	языке O
27	: O
28	классической B-InfoResource
29	литературе I-InfoResource
30	, O
31	юридических B-InfoResource
32	документах I-InfoResource
33	или O
34	статьях B-InfoResource
35	Википедии B-InfoResource
36	. O

# sent_id = 134
# text =   В треке перевода мы использовали для обучения англо-русский корпус WMT’20, который в основном состоит из государственных и новостных текстов.
# relations = ""
1	В O
2	треке O
3	перевода O
4	мы O
5	использовали O
6	для O
7	обучения O
8	англо O
9	- O
10	русский O
11	корпус O
12	WMT’20 B-Corpus
13	, O
14	который O
15	в O
16	основном O
17	состоит O
18	из O
19	государственных O
20	и O
21	новостных B-InfoResource
22	текстов I-InfoResource
23	. O

# sent_id = 135
# text =   Данные без сдвига взяты из англо-русского корпуса Newstest’19, а также из корпуса новостных текстов, собранных службой Global Voices и переведенных Яндексом.
# relations = ""
1	Данные O
2	без O
3	сдвига O
4	взяты O
5	из O
6	англо B-Lang
7	- O
8	русского B-Lang
9	корпуса O
10	Newstest’19 B-Corpus
11	, O
12	а O
13	также O
14	из O
15	корпуса B-Corpus
16	новостных I-Corpus
17	текстов I-Corpus
18	, O
19	собранных O
20	службой O
21	Global B-Organization
22	Voices I-Organization
23	и O
24	переведенных O
25	Яндексом B-Organization
26	. O

# sent_id = 136
# text =   Данные со сдвигом для отладки взяты из подготовленного для WMT Robustness Challenge корпуса Reddit и также переведены Яндексом.
# relations = ""
1	Данные O
2	со O
3	сдвигом O
4	для O
5	отладки O
6	взяты O
7	из O
8	подготовленного O
9	для O
10	WMT O
11	Robustness O
12	Challenge O
13	корпуса O
14	Reddit B-Corpus
15	и O
16	также O
17	переведены O
18	Яндексом B-Organization
19	. O

# sent_id = 137
# text =   Для проверки модели на данных со сдвигом мы также собрали, перевели и разметили дополнительные данные с Reddit.
# relations = ""
1	Для O
2	проверки O
3	модели O
4	на O
5	данных O
6	со O
7	сдвигом O
8	мы O
9	также O
10	собрали O
11	, O
12	перевели O
13	и O
14	разметили O
15	дополнительные O
16	данные O
17	с O
18	Reddit B-Corpus
19	. O

# sent_id = 138
# text =   Парсить комментарии мы будем с помощью официального API ВКонтакте для Python
# relations = "Environment_isUsedIn_Application 0 0"
1	Парсить O
2	комментарии O
3	мы O
4	будем O
5	с O
6	помощью O
7	официального O
8	API B-Application
9	ВКонтакте I-Application
10	для O
11	Python B-Environment

# sent_id = 139
# text =   Необходимо убрать из комментария направление, чтобы при поиске расстояния Левенштейна меньше ошибаться.
# relations = ""
1	Необходимо O
2	убрать O
3	из O
4	комментария O
5	направление O
6	, O
7	чтобы O
8	при O
9	поиске O
10	расстояния B-Metric
11	Левенштейна I-Metric
12	меньше O
13	ошибаться O
14	. O

# sent_id = 140
# text =   Небольшая справка: расстояние Левенштейна — минимальное количество операций вставки одного символа, удаления одного символа и замены одного символа на другой, необходимых для превращения одной строки в другую.
# relations = ""
1	Небольшая O
2	справка O
3	: O
4	расстояние B-Metric
5	Левенштейна I-Metric
6	— O
7	минимальное O
8	количество O
9	операций O
10	вставки O
11	одного O
12	символа O
13	, O
14	удаления O
15	одного O
16	символа O
17	и O
18	замены O
19	одного O
20	символа O
21	на O
22	другой O
23	, O
24	необходимых O
25	для O
26	превращения O
27	одной O
28	строки O
29	в O
30	другую O
31	. O

# sent_id = 141
# text =   Его мы будем находить с помощью библиотеки fuzzywuzzy.
# relations = ""
1	Его O
2	мы O
3	будем O
4	находить O
5	с O
6	помощью O
7	библиотеки O
8	fuzzywuzzy B-Library
9	. O

# sent_id = 142
# text =   Для ускорения работы авторы библиотеки советуют также установить библиотеку python-Levenshtein.
# relations = ""
1	Для O
2	ускорения O
3	работы O
4	авторы O
5	библиотеки O
6	советуют O
7	также O
8	установить O
9	библиотеку O
10	python B-Library
11	- I-Library
12	Levenshtein I-Library
13	. O

# sent_id = 143
# text =   Его мне любезно предоставил разработчик приложения GoTrans, Александр Козлов.
# relations = "Application_hasAuthor_Person 0 0"
1	Его O
2	мне O
3	любезно O
4	предоставил O
5	разработчик O
6	приложения O
7	GoTrans B-Technology
8	, O
9	Александр B-Person
10	Козлов I-Person
11	. O

# sent_id = 144
# text =   Александр Козлов, разработчик приложения GoTrans, любезно предоставил его мне.
# relations = "Application_hasAuthor_Person 0 0"
1	Александр B-Person
2	Козлов I-Person
3	, O
4	разработчик O
5	приложения O
6	GoTrans B-Technology
7	, O
8	любезно O
9	предоставил O
10	его O
11	мне O
12	. O

# sent_id = 145
# text =   Самый сложный кроссворд, составленный компьютером
# relations = ""
1	Самый O
2	сложный O
3	кроссворд B-Object
4	, O
5	составленный O
6	компьютером O

# sent_id = 145
# text =   Пример Deep Blue показывает, что программы ИИ могут участвовать в викторинах и обыгрывать людей.
# relations = ""
1	Пример O
2	Deep B-Technology
3	Blue I-Technology
4	показывает O
5	, O
6	что O
7	программы O
8	ИИ O
9	могут O
10	участвовать O
11	в O
12	викторинах B-Object
13	и O
14	обыгрывать O
15	людей O
16	. O

# sent_id = 146
# text =   Американский разработчик Мэтью Гинсберг (Matthew Ginsberg) создал программу под названием Dr Fill, которая справляется с кроссвордами гораздо лучше, чем абсолютное большинство людей, пишет New Scientist.
# relations = "Application_isAppliedTo_Object 0 0, Application_hasAuthor_Person 0 0, Application_hasAuthor_Person 0 1"
1	Американский O
2	разработчик O
3	Мэтью B-Person
4	Гинсберг I-Person
5	( O
6	Matthew B-Person
7	Ginsberg I-Person
8	) O
9	создал O
10	программу O
11	под O
12	названием O
13	Dr B-Technology
14	Fill I-Technology
15	, O
16	которая O
17	справляется O
18	с O
19	кроссвордами B-Object
20	гораздо O
21	лучше O
22	, O
23	чем O
24	абсолютное O
25	большинство O
26	людей O
27	, O
28	пишет O
29	New B-Organization
30	Scientist I-Organization
31	. O

# sent_id = 147
# text = Программа Dr Fill, разработанная американским специалистом Мэтью Гинсбергом (Matthew Ginsberg), согласно информации из издания New Scientist, проявляет более выдающуюся эффективность в решении кроссвордов по сравнению с абсолютным большинством людей.
# relations = "Application_isAppliedTo_Object 0 0, Application_hasAuthor_Person 0 0, Application_hasAuthor_Person 0 1"
1	Программа O
2	Dr B-Technology
3	Fill I-Technology
4	, O
5	разработанная O
6	американским O
7	специалистом O
8	Мэтью B-Person
9	Гинсбергом I-Person
10	( O
11	Matthew B-Person
12	Ginsberg I-Person
13	) O
14	, O
15	согласно O
16	информации O
17	из O
18	издания O
19	New B-Organization
20	Scientist I-Organization
21	, O
22	проявляет O
23	более O
24	выдающуюся O
25	эффективность O
26	в O
27	решении O
28	кроссвордов B-Object
29	по O
30	сравнению O
31	с O
32	абсолютным O
33	большинством O
34	людей O
35	. O

# sent_id = 148
# text =   Анализ тональности текстов с помощью сверточных нейронных сетей 
# relations = "Method_solves_Task 0 0"
1	Анализ B-Task
2	тональности I-Task
3	текстов I-Task
4	с O
5	помощью O
6	сверточных B-Method
7	нейронных I-Method
8	сетей I-Method

# sent_id = 149
# text =   Есть много способов решать такую задачу, и один из них — свёрточные нейронные сети (Convolutional Neural Networks).
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Есть O
2	много O
3	способов O
4	решать O
5	такую O
6	задачу O
7	, O
8	и O
9	один O
10	из O
11	них O
12	— O
13	свёрточные B-Method
14	нейронные I-Method
15	сети I-Method
16	( O
17	Convolutional B-Method
18	Neural I-Method
19	Networks I-Method
20	) O
21	. O

# sent_id = 150
# text =   CNN изначально были разработаны для обработки изображений, однако они успешно справляются с решением задач в сфере автоматической обработки текстов.
# relations = "Method_solves_Task 0 0, Method_isUsedIn_Science 0 0"
1	CNN B-Method
2	изначально O
3	были O
4	разработаны O
5	для O
6	обработки B-Task
7	изображений I-Task
8	, O
9	однако O
10	они O
11	успешно O
12	справляются O
13	с O
14	решением O
15	задач O
16	в O
17	сфере O
18	автоматической B-Science
19	обработки I-Science
20	текстов I-Science
21	. O

# sent_id = 151
# text =   Я познакомлю вас с бинарным анализом тональности русскоязычных текстов с помощью свёрточной нейронной сети, для которой векторные представления слов были сформированы на основе обученной Word2Vec модели.
# relations = "Method_isAppliedTo_Object 0 0, Method_uses_Model 0 0, Method_uses_Model 0 1"
1	Я O
2	познакомлю O
3	вас O
4	с O
5	бинарным B-Method
6	анализом I-Method
7	тональности I-Method
8	русскоязычных I-Method
9	текстов I-Method
10	с O
11	помощью O
12	свёрточной B-Model
13	нейронной I-Model
14	сети I-Model
15	, O
16	для O
17	которой O
18	векторные B-Object
19	представления I-Object
20	слов I-Object
21	были O
22	сформированы O
23	на O
24	основе O
25	обученной O
26	Word2Vec B-Model
27	модели O
28	. O

# sent_id = 152
# text =   Для обучения я выбрал корпус коротких текстов Юлии Рубцовой, сформированный на основе русскоязычных сообщений из Twitter [4].
# relations = ""
1	Для O
2	обучения O
3	я O
4	выбрал O
5	корпус B-Corpus
6	коротких I-Corpus
7	текстов I-Corpus
8	Юлии I-Corpus
9	Рубцовой I-Corpus
10	, O
11	сформированный O
12	на O
13	основе O
14	русскоязычных B-Lang
15	сообщений B-Object
16	из O
17	Twitter B-Technology
18	[ O
19	4 O
20	] O
21	. O

# sent_id = 153
# text =   Визуализация кластеров похожих слов с использование t-SNE.
# relations = "Method_isAppliedTo_Object 0 0"
1	Визуализация O
2	кластеров B-Object
3	похожих O
4	слов O
5	с O
6	использование O
7	t B-Method
8	- I-Method
9	SNE I-Method
10	. O

# sent_id = 154
# text =   На следующем этапе каждый текст был отображен в массив идентификаторов токенов.
# relations = ""
1	На O
2	следующем O
3	этапе O
4	каждый O
5	текст B-Object
6	был O
7	отображен O
8	в O
9	массив O
10	идентификаторов O
11	токенов B-Object
12	. O

# sent_id = 155
# text =   Вот пусть комментаторы поправят, но кроме модуля LanguageTool для Open Office (о нём мы ещё поговорим) даже в голову ничего не приходит.
# relations = ""
1	Вот O
2	пусть O
3	комментаторы O
4	поправят O
5	, O
6	но O
7	кроме O
8	модуля O
9	LanguageTool B-Technology
10	для O
11	Open B-Technology
12	Office I-Technology
13	( O
14	о O
15	нём O
16	мы O
17	ещё O
18	поговорим O
19	) O
20	даже O
21	в O
22	голову O
23	ничего O
24	не O
25	приходит O
26	. O

# sent_id = 156
# text =   Было бы здорово составить базу с инструкциями не для людей, а для роботов, подумали инженеры из Института искусственного интеллекта при Бременском университете (Германия), авторы проекта RoboHow.
# relations = "Activity_hasAuthor_Organization 0 0, Activity_hasAuthor_Organization 0 1"
1	Было O
2	бы O
3	здорово O
4	составить O
5	базу O
6	с O
7	инструкциями B-Object
8	не O
9	для O
10	людей O
11	, O
12	а O
13	для O
14	роботов O
15	, O
16	подумали O
17	инженеры O
18	из O
19	Института B-Organization
20	искусственного I-Organization
21	интеллекта I-Organization
22	при O
23	Бременском B-Organization
24	университете I-Organization
25	( O
26	Германия O
27	) O
28	, O
29	авторы O
30	проекта O
31	RoboHow B-Activity
32	. O

# sent_id = 157
# text =   Инженеры из Института искусственного интеллекта при Бременском университете (Германия), участники проекта RoboHow, рассматривают возможность создания базы данных с инструкциями, предназначенными не для людей, а для роботов.
# relations = "Activity_hasAuthor_Organization 0 0, Activity_hasAuthor_Organization 0 1"
1	Инженеры O
2	из O
3	Института B-Organization
4	искусственного I-Organization
5	интеллекта I-Organization
6	при O
7	Бременском B-Organization
8	университете I-Organization
9	( O
10	Германия O
11	) O
12	, O
13	участники O
14	проекта O
15	RoboHow B-Activity
16	, O
17	рассматривают O
18	возможность O
19	создания O
20	базы O
21	данных O
22	с O
23	инструкциями B-Object
24	, O
25	предназначенными O
26	не O
27	для O
28	людей O
29	, O
30	а O
31	для O
32	роботов O
33	. O

# sent_id = 158
# text =   С такой базой wiki-инструкций роботы смогут передавать информацию друг другу.
# relations = ""
1	С O
2	такой O
3	базой O
4	wiki B-InfoResource
5	- I-InfoResource
6	инструкций I-InfoResource
7	роботы O
8	смогут O
9	передавать O
10	информацию O
11	друг O
12	другу O
13	. O

# sent_id = 159
# text =   Созданный в Бременском университете робот PR2 (на фото вверху) учится понимать и выполнять «человеческие» инструкции из базы WikiHow.
# relations = "Application_hasAuthor_Organization 0 0, Application_isAppliedTo_Object 0 0"
1	Созданный O
2	в O
3	Бременском B-Organization
4	университете I-Organization
5	робот O
6	PR2 B-Application
7	( O
8	на O
9	фото O
10	вверху O
11	) O
12	учится O
13	понимать O
14	и O
15	выполнять O
16	« O
17	человеческие O
18	» O
19	инструкции B-Object
20	из O
21	базы O
22	WikiHow B-InfoResource
23	. O

# sent_id = 161
# text =   Успешно выполнив задачу, то есть усвоив урок, робот делится приобретёнными знаниями со своими собратьями через онлайновую базу Open Ease.
# relations = ""
1	Успешно O
2	выполнив O
3	задачу O
4	, O
5	то O
6	есть O
7	усвоив O
8	урок O
9	, O
10	робот O
11	делится O
12	приобретёнными O
13	знаниями O
14	со O
15	своими O
16	собратьями O
17	через O
18	онлайновую O
19	базу O
20	Open B-InfoResource
21	Ease I-InfoResource
22	. O

# sent_id = 162
# text =   Здесь инструкции записаны в машиночитаемом виде, на языке, похожем на язык Семантической сети.
# relations = ""
1	Здесь O
2	инструкции B-Object
3	записаны O
4	в O
5	машиночитаемом O
6	виде O
7	, O
8	на O
9	языке O
10	, O
11	похожем O
12	на O
13	язык O
14	Семантической B-Application
15	сети I-Application
16	. O

# sent_id = 163
# text =   Это очень сложная задача, которая сочетает в себе тесную интеграцию распознавания речи, интерпретации команд на естественном языке, машинного зрения и планирования сложных действий через алгоритмы осуществления отдельных манипуляций.
# relations = ""
1	Это O
2	очень O
3	сложная O
4	задача O
5	, O
6	которая O
7	сочетает O
8	в O
9	себе O
10	тесную O
11	интеграцию O
12	распознавания B-Task
13	речи I-Task
14	, O
15	интерпретации B-Task
16	команд I-Task
17	на I-Task
18	естественном I-Task
19	языке I-Task
20	, O
21	машинного O
22	зрения O
23	и O
24	планирования O
25	сложных O
26	действий O
27	через O
28	алгоритмы O
29	осуществления O
30	отдельных O
31	манипуляций O
32	. O

# sent_id = 164
# text =   «М.видео-Эльдорадо» внедряет нейросеть для ответов на вопросы покупателей 
# relations = "Model_isUsedForSolving_Task 0 0, Model_hasAuthor_Organization 0 0"
1	« O
2	М.видео B-Organization
3	- I-Organization
4	Эльдорадо I-Organization
5	» O
6	внедряет O
7	нейросеть B-Model
8	для O
9	ответов B-Task
10	на I-Task
11	вопросы I-Task
12	покупателей O

# sent_id = 165
# text =   Президент Ассоциации больших данных Анна Серебряникова отметила, что ИИ в ретейле может применяться для прогнозирования открытия новых торговых точек, а также для персонализации предложений для клиентов и создания чат-ботов для службы поддержки.
# relations = ""
1	Президент O
2	Ассоциации B-Organization
3	больших I-Organization
4	данных I-Organization
5	Анна B-Person
6	Серебряникова I-Person
7	отметила O
8	, O
9	что O
10	ИИ O
11	в O
12	ретейле O
13	может O
14	применяться O
15	для O
16	прогнозирования O
17	открытия O
18	новых O
19	торговых O
20	точек O
21	, O
22	а O
23	также O
24	для O
25	персонализации B-Task
26	предложений I-Task
27	для O
28	клиентов O
29	и O
30	создания B-Task
31	чат I-Task
32	- I-Task
33	ботов I-Task
34	для O
35	службы O
36	поддержки O
37	. O

# sent_id = 166
# text =   В Facebook AI продемонстрировали прямой машинный перевод с одного языка на другой
# relations = ""
1	В O
2	Facebook B-Organization
3	AI I-Organization
4	продемонстрировали O
5	прямой O
6	машинный O
7	перевод O
8	с O
9	одного O
10	языка O
11	на O
12	другой O

# sent_id = 167
# text =  Facebook AI представила новую систему машинного перевода M2M-100 с 15 млрд параметров.
# relations = "Model_hasAuthor_Organization 0 0"
1	Facebook B-Organization
2	AI I-Organization
3	представила B-Model_hasAuthor_Organization
4	новую O
5	систему O
6	машинного O
7	перевода O
8	M2M-100 B-Model
9	с O
10	15 O
11	млрд O
12	параметров O
13	. O

# sent_id = 168
# text =   Она способна переводить с одного языка на другой напрямую, не используя английский в качестве промежуточного.
# relations = ""
1	Она O
2	способна O
3	переводить B-Task
4	с I-Task
5	одного I-Task
6	языка I-Task
7	на I-Task
8	другой I-Task
9	напрямую O
10	, O
11	не O
12	используя O
13	английский O
14	в O
15	качестве O
16	промежуточного O
17	. O

# sent_id = 169
# text =   Она способна осуществлять переводы между парами из ста языков.
# relations = ""
1	Она O
2	способна O
3	осуществлять O
4	переводы B-Task
5	между O
6	парами O
7	из O
8	ста O
9	языков O
10	. O

# sent_id = 170
# text =   Модель обучали на наборе данных из более чем 7,5 млрд предложений как из базы Facebook, так и из других источников.
# relations = ""
1	Модель B-Model
2	обучали O
3	на O
4	наборе O
5	данных O
6	из O
7	более O
8	чем O
9	7,5 O
10	млрд O
11	предложений O
12	как O
13	из O
14	базы O
15	Facebook B-Organization
16	, O
17	так O
18	и O
19	из O
20	других O
21	источников O
22	. O

# sent_id = 171
# text =   При разработке использовали инструмент CommonCrawl, который поддерживает открытый репозиторий данных веб-сканирования, и систему классификации текстов FastText, которую в Facebook представили несколько лет назад.
# relations = "Application_hasAuthor_Organization 1 0"
1	При O
2	разработке O
3	использовали O
4	инструмент O
5	CommonCrawl B-Technology
6	, O
7	который O
8	поддерживает O
9	открытый O
10	репозиторий O
11	данных O
12	веб O
13	- O
14	сканирования O
15	, O
16	и O
17	систему O
18	классификации O
19	текстов O
20	FastText B-App_system
21	, O
22	которую O
23	в O
24	Facebook B-Organization
25	представили B-Application_hasAuthor_Organization
26	несколько O
27	лет O
28	назад O
29	. O

# sent_id = 172
# text =   Согласно метрикам BLEU, M2M-100 на 10 баллов опережает предшественника, где английский язык был промежуточным.
# relations = "Metric_isUsedFor_Model 0 0"
1	Согласно O
2	метрикам O
3	BLEU B-Metric
4	, O
5	M2M-100 B-Model
6	на O
7	10 O
8	баллов O
9	опережает O
10	предшественника O
11	, O
12	где O
13	английский O
14	язык O
15	был O
16	промежуточным O
17	. O

# sent_id = 173
# text =   Facebook AI отмечает, что эта модель может быть полезной не только при машинном переводе, но и при изучении языков.
# relations = "Model_isUsedForSolving_Task 0 0"
1	Facebook B-Organization
2	AI I-Organization
3	отмечает O
4	, O
5	что O
6	эта O
7	модель B-Model
8	может O
9	быть O
10	полезной O
11	не O
12	только O
13	при O
14	машинном B-Task
15	переводе I-Task
16	, O
17	но O
18	и O
19	при O
20	изучении O
21	языков O
22	. O

# sent_id = 174
# text =   Я тестировала Google Translate на одних и тех же текстах в марте и декабре 2011, январе 2016 и декабре 2017 года.
# relations = ""
1	Я O
2	тестировала O
3	Google B-Technology
4	Translate I-Technology
5	на O
6	одних O
7	и O
8	тех O
9	же O
10	текстах O
11	в O
12	марте O
13	и O
14	декабре O
15	2011 O
16	, O
17	январе O
18	2016 O
19	и O
20	декабре O
21	2017 O
22	года O
23	. O

# sent_id = 175
# text =   Брала одни и те же отрывки на английском, русском, немецком, французском, украинском и польском языках и переводила каждый на остальные пять языков из выборки.
# relations = ""
1	Брала O
2	одни O
3	и O
4	те O
5	же O
6	отрывки O
7	на O
8	английском B-Lang
9	, O
10	русском B-Lang
11	, O
12	немецком B-Lang
13	, O
14	французском B-Lang
15	, O
16	украинском B-Lang
17	и O
18	польском B-Lang
19	языках O
20	и O
21	переводила O
22	каждый O
23	на O
24	остальные O
25	пять O
26	языков O
27	из O
28	выборки O
29	. O

# sent_id = 176
# text =   Результаты cross-verification в целом совпали с тенденциями в первоначальной выборке.
# relations = ""
1	Результаты O
2	cross B-Method
3	- I-Method
4	verification I-Method
5	в O
6	целом O
7	совпали O
8	с O
9	тенденциями O
10	в O
11	первоначальной O
12	выборке O
13	. O

# sent_id = 177
# text =   С марта 2017 года нейросеть стали использовать для перевода на русский.
# relations = "Model_isUsedForSolving_Task 0 0, Model_Language_Lang 0 0"
1	С O
2	марта O
3	2017 B-Date
4	года O
5	нейросеть B-Model
6	стали O
7	использовать O
8	для O
9	перевода B-Task
10	на O
11	русский B-Lang
12	. O

# sent_id = 178
# text =   Сервис не переводит дословно, результат стал более свободным: адекватная перефразировка, перегруппировка слов, перестановка слов из начала в конец предложения, если того требуют правила языка (в немецком это реализовано великолепно).
# relations = ""
1	Сервис O
2	не O
3	переводит O
4	дословно O
5	, O
6	результат O
7	стал O
8	более O
9	свободным O
10	: O
11	адекватная O
12	перефразировка B-Task
13	, O
14	перегруппировка B-Task
15	слов I-Task
16	, O
17	перестановка B-Task
18	слов I-Task
19	из O
20	начала O
21	в O
22	конец O
23	предложения O
24	, O
25	если O
26	того O
27	требуют O
28	правила O
29	языка O
30	( O
31	в O
32	немецком B-Lang
33	это O
34	реализовано O
35	великолепно O
36	) O
37	. O

# sent_id = 179
# text =   В отличие от предыдущего уровня (phrase-based translation– однократное нахождение соответствий отдельных слов и фраз), нейронный переводчик в какой-то степени трансформирует предложения, анализирует их как единое целое и устанавливает соответствия «из конца в конец» в несколько стадий(end-to-end mapping – сквозное преобразование, полного цикла, непрерывная трансформация многообразия данных со входа на выход).
# relations = "Method_isAlternativeNameFor_Method 3 2, Method_isAlternativeNameFor_Method 1 0"
1	В O
2	отличие O
3	от O
4	предыдущего O
5	уровня O
6	( O
7	phrase B-Method
8	- I-Method
9	based I-Method
10	translation I-Method
11	– O
12	однократное B-Method
13	нахождение I-Method
14	соответствий I-Method
15	отдельных I-Method
16	слов I-Method
17	и O
18	фраз O
19	) O
20	, O
21	нейронный O
22	переводчик O
23	в O
24	какой O
25	- O
26	то O
27	степени O
28	трансформирует O
29	предложения O
30	, O
31	анализирует O
32	их O
33	как O
34	единое O
35	целое O
36	и O
37	устанавливает O
38	соответствия O
39	« O
40	из O
41	конца O
42	в O
43	конец O
44	» O
45	в O
46	несколько O
47	стадий O
48	( O
49	end B-Method
50	- I-Method
51	to I-Method
52	- I-Method
53	end I-Method
54	mapping I-Method
55	– O
56	сквозное B-Method
57	преобразование I-Method
58	, O
59	полного O
60	цикла O
61	, O
62	непрерывная O
63	трансформация B-Method
64	многообразия I-Method
65	данных I-Method
66	со O
67	входа O
68	на O
69	выход O
70	) O
71	. O

# sent_id = 180
# text =   Сейчас в Яндексе мой основной проект это Алиса, голосовой помощник, который Яндекс запустил в октябре прошлого года, и моя группа отвечает за то, что можно условно назвать мозгами Алисы.
# relations = "Application_hasAuthor_Organization 0 0"
1	Сейчас O
2	в O
3	Яндексе B-Organization
4	мой O
5	основной O
6	проект O
7	это O
8	Алиса B-Technology
9	, O
10	голосовой B-Application
11	помощник I-Application
12	, O
13	который O
14	Яндекс B-Organization
15	запустил O
16	в O
17	октябре O
18	прошлого O
19	года O
20	, O
21	и O
22	моя O
23	группа O
24	отвечает O
25	за O
26	то O
27	, O
28	что O
29	можно O
30	условно O
31	назвать O
32	мозгами O
33	Алисы B-Technology
34	. O

# sent_id = 181
# text =   Мы интерпретируем то, что сказал пользователь на естественном языке и превращаем это в некоторое структурированное представление.
# relations = ""
1	Мы O
2	интерпретируем O
3	то O
4	, O
5	что O
6	сказал O
7	пользователь O
8	на O
9	естественном B-Object
10	языке I-Object
11	и O
12	превращаем O
13	это O
14	в O
15	некоторое O
16	структурированное B-Object
17	представление B-Object
18	. O

# sent_id = 182
# text =   Есть Siri, единственный голосовой помощник, который тоже понимает русский язык, но он работает только на iOS и MacOS, это как бы не самая популярная платформа в России, и к Siri как к продукту тоже есть определенные вопросы.
# relations = "Environment_isUsedIn_Application 0 0, Environment_isUsedIn_Application 1 0"
1	Есть O
2	Siri B-Technology
3	, O
4	единственный O
5	голосовой B-Application
6	помощник I-Application
7	, O
8	который O
9	тоже O
10	понимает O
11	русский B-Lang
12	язык O
13	, O
14	но O
15	он O
16	работает O
17	только O
18	на O
19	iOS B-Environment
20	и O
21	MacOS B-Environment
22	, O
23	это O
24	как O
25	бы O
26	не O
27	самая O
28	популярная O
29	платформа O
30	в O
31	России O
32	, O
33	и O
34	к O
35	Siri B-Technology
36	как O
37	к O
38	продукту O
39	тоже O
40	есть O
41	определенные O
42	вопросы O
43	. O

# sent_id = 183
# text =   На самом деле у нас уже есть модель которая оценивает градацию этой оскорбительности, и если бы возникла продуктовая необходимость, мы уже могли бы сделать такой ползунок который делает ответы более или менее дерзкими.
# relations = ""
1	На O
2	самом O
3	деле O
4	у O
5	нас O
6	уже O
7	есть O
8	модель O
9	которая O
10	оценивает B-Task
11	градацию I-Task
12	этой I-Task
13	оскорбительности I-Task
14	, O
15	и O
16	если O
17	бы O
18	возникла O
19	продуктовая O
20	необходимость O
21	, O
22	мы O
23	уже O
24	могли O
25	бы O
26	сделать O
27	такой O
28	ползунок O
29	который O
30	делает O
31	ответы O
32	более O
33	или O
34	менее O
35	дерзкими O
36	. O

# sent_id = 184
# text =   Это генеративная нейронная сеть, способная решать множество задач по обработке естествнного языка (NLP).
# relations = "Method_solves_Task 0 0, Method_solves_Task 0 1, Task_isAlternativeNameFor_Task 1 0"
1	Это O
2	генеративная B-Method
3	нейронная I-Method
4	сеть I-Method
5	, O
6	способная O
7	решать O
8	множество O
9	задач B-Task
10	по I-Task
11	обработке I-Task
12	естествнного I-Task
13	языка I-Task
14	( O
15	NLP B-Task
16	) O
17	. O

# sent_id = 185
# text =   Это такие задачи как суммаризация (сделать из большого текста его резюме), понимание текста (NLU), вопросно-ответные системы, генерация (например, стихов, — на Хабре была хорошая статья) и другие.
# relations = "Task_isAlternativeNameFor_Task 2 1"
1	Это O
2	такие O
3	задачи O
4	как O
5	суммаризация B-Task
6	( O
7	сделать O
8	из O
9	большого O
10	текста O
11	его O
12	резюме O
13	) O
14	, O
15	понимание B-Task
16	текста I-Task
17	( O
18	NLU B-Task
19	) O
20	, O
21	вопросно B-App_system
22	- I-App_system
23	ответные I-App_system
24	системы I-App_system
25	, O
26	генерация B-Task
27	( O
28	например O
29	, O
30	стихов O
31	, O
32	— O
33	на O
34	Хабре B-Organization
35	была O
36	хорошая O
37	статья O
38	) O
39	и O
40	другие O
41	. O

# sent_id = 186
# text =   Используя новый алгоритм упаковки, в Graphcore ускорили обработку естественного языка более чем в 2 раза при обучении BERT-Large.
# relations = "Method_isUsedForTraining_Model 0 0, Method_hasAuthor_Organization 0 0"
1	Используя B-Method_isUsedIn_Activity
2	новый O
3	алгоритм B-Method
4	упаковки I-Method
5	, O
6	в O
7	Graphcore B-Organization
8	ускорили B-Activity
9	обработку I-Activity
10	естественного B-Object
11	языка I-Object
12	более O
13	чем O
14	в O
15	2 O
16	раза O
17	при O
18	обучении O
19	BERT B-Model
20	- I-Model
21	Large I-Model
22	. O

# sent_id = 187
# text =   В Graphcore предполагают, что алгоритм упаковки также может применяться в геномике, в моделях фолдинга белков и других моделях с перекошенным распределением длины, оказывая гораздо более широкое влияние на различные отрасли и приложения.
# relations = "Method_isUsedIn_Science 0 0"
1	В O
2	Graphcore B-Organization
3	предполагают O
4	, O
5	что O
6	алгоритм B-Method
7	упаковки I-Method
8	также O
9	может B-Method_isUsedIn_Science
10	применяться I-Method_isUsedIn_Science
11	в O
12	геномике B-Science
13	, O
14	в O
15	моделях B-Model
16	фолдинга I-Model
17	белков O
18	и O
19	других O
20	моделях O
21	с O
22	перекошенным O
23	распределением O
24	длины O
25	, O
26	оказывая O
27	гораздо O
28	более O
29	широкое O
30	влияние O
31	на O
32	различные O
33	отрасли O
34	и O
35	приложения O
36	. O

# sent_id = 188
# text = В Graphcore считают, что алгоритм упаковки может быть успешно применен не только в области геномики, но и в моделях фолдинга белков и других моделях с неравномерным распределением длины. 
# relations = "Method_isUsedIn_Science 0 0, Method_hasAuthor_Organization 0 0"
1	В O
2	Graphcore B-Organization
3	считают O
4	, O
5	что O
6	алгоритм B-Method
7	упаковки I-Method
8	может O
9	быть O
10	успешно O
11	применен B-Method_isUsedIn_Science
12	не O
13	только O
14	в O
15	области O
16	геномики B-Science
17	, O
18	но O
19	и O
20	в O
21	моделях B-Model
22	фолдинга I-Model
23	белков I-Model
24	и O
25	других O
26	моделях O
27	с O
28	неравномерным O
29	распределением O
30	длины O
31	. O

# sent_id = 189
# text =   В новой работе Graphcore представили высокоэффективный алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами (или NNLSHP), а также алгоритм BERT, применяемый к упакованным последовательностям.
# relations = "Method_isAlternativeNameFor_Method 1 0, Method_hasAuthor_Organization 0 0, Method_hasAuthor_Organization 1 0"
1	В O
2	новой O
3	работе O
4	Graphcore B-Organization
5	представили B-Method_hasAuthor_Organization
6	высокоэффективный O
7	алгоритм B-Method
8	гистограммной I-Method
9	упаковки I-Method
10	с I-Method
11	неотрицательными I-Method
12	наименьшими I-Method
13	квадратами I-Method
14	( O
15	или O
16	NNLSHP B-Method
17	) O
18	, O
19	а O
20	также O
21	алгоритм O
22	BERT B-Model
23	, O
24	применяемый O
25	к O
26	упакованным O
27	последовательностям O
28	. O

# sent_id = 190
# text = В последнем исследовании от Graphcore был представлен эффективный алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов (NNLSHP), а также алгоритм BERT, примененный к упакованным последовательностям.
# relations = "Method_isAlternativeNameFor_Method 1 0, Method_hasAuthor_Organization 0 0, Method_hasAuthor_Organization 1 0"
1	В O
2	последнем O
3	исследовании O
4	от O
5	Graphcore B-Organization
6	был B-Method_hasAuthor_Organization
7	представлен I-Method_hasAuthor_Organization
8	эффективный O
9	алгоритм B-Method
10	гистограммной I-Method
11	упаковки I-Method
12	с I-Method
13	использованием I-Method
14	неотрицательных I-Method
15	наименьших I-Method
16	квадратов I-Method
17	( O
18	NNLSHP B-Method
19	) O
20	, O
21	а O
22	также O
23	алгоритм O
24	BERT B-Model
25	, O
26	примененный O
27	к O
28	упакованным O
29	последовательностям O
30	. O

# sent_id = 191
# text =   В Яндекс.Браузер внедрили машинный перевод видеороликов 
# relations = "Method_isUsedIn_Application 0 0"
1	В O
2	Яндекс B-Technology
3	. I-Technology
4	Браузер I-Technology
5	внедрили O
6	машинный B-Method
7	перевод I-Method
8	видеороликов O

# sent_id = 192
# text =  Алгоритм отслеживает темп речи говорящего, за счет чего переводчик делает паузы, замедляет или ускоряет речь, чтобы закадровый голос совпадал с картинкой.
# relations = ""
1	Алгоритм O
2	отслеживает O
3	темп B-Object
4	речи I-Object
5	говорящего O
6	, O
7	за O
8	счет O
9	чего O
10	переводчик O
11	делает O
12	паузы B-Object
13	, O
14	замедляет O
15	или O
16	ускоряет O
17	речь B-Object
18	, O
19	чтобы O
20	закадровый O
21	голос B-Object
22	совпадал O
23	с O
24	картинкой O
25	. O

# sent_id = 193
# text =  Перевод доступен в Яндекс.Браузере для Windows и macOS.
# relations = "Environment_isUsedIn_Application 0 0, Environment_isUsedIn_Application 1 0"
1	Перевод O
2	доступен O
3	в O
4	Яндекс B-Application
5	. I-Application
6	Браузере I-Application
7	для O
8	Windows B-Environment
9	и O
10	macOS B-Environment
11	. O

# sent_id = 194
# text =   Тогда к статистической модели, которая была в «Переводчике» с момента запуска, добавили технологию перевода с помощью нейросети.
# relations = "Application_isUsedForSolving_Task 0 0"
1	Тогда O
2	к O
3	статистической O
4	модели O
5	, O
6	которая O
7	была O
8	в O
9	« O
10	Переводчике B-Application
11	» O
12	с O
13	момента O
14	запуска O
15	, O
16	добавили O
17	технологию O
18	перевода B-Task
19	с O
20	помощью O
21	нейросети O
22	. O

# sent_id = 195
# text = "В июне Яндекс открыл доступ к нейросети «Балабоба» для всех пользователей."
# relations = "Application_hasAuthor_Organization 0 0"
1	В O
2	июне O
3	Яндекс B-Organization
4	открыл O
5	доступ O
6	к O
7	нейросети O
8	« O
9	Балабоба B-Technology
10	» O
11	для O
12	всех O
13	пользователей O
14	. O

# sent_id = 196
# text =   Она работает на языковой модели из семейства YaLM (Yet another Language Model).
# relations = "Model_isAlternativeNameFor_Model 1 0"
1	Она O
2	работает O
3	на O
4	языковой O
5	модели O
6	из O
7	семейства O
8	YaLM B-Model
9	( O
10	Yet B-Model
11	another I-Model
12	Language I-Model
13	Model I-Model
14	) O
15	. O

# sent_id = 197
# text =   Она использует языковую модель из семейства YaLM (Yet another Language Model).
# relations = "Model_isAlternativeNameFor_Model 1 0"
1	Она O
2	использует O
3	языковую O
4	модель O
5	из O
6	семейства O
7	YaLM B-Model
8	( O
9	Yet B-Model
10	another I-Model
11	Language I-Model
12	Model I-Model
13	) O
14	. O

# sent_id = 198
# text =   Эта модель помогает нейросети запоминать правила языка, выбирать подходящие слова и связывать их по смыслу.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1"
1	Эта O
2	модель B-Model
3	помогает O
4	нейросети O
5	запоминать B-Task
6	правила I-Task
7	языка I-Task
8	, O
9	выбирать B-Task
10	подходящие I-Task
11	слова I-Task
12	и O
13	связывать O
14	их O
15	по O
16	смыслу O
17	. O

# sent_id = 199
# text =   У «Балабобы» нет своего мнения, она выдает случайные продолжения и может закончить историю, придумать подпись или написать небольшой рассказ.
# relations = "Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 0 1"
1	У O
2	« O
3	Балабобы B-Technology
4	» O
5	нет O
6	своего O
7	мнения O
8	, O
9	она O
10	выдает O
11	случайные O
12	продолжения O
13	и O
14	может O
15	закончить O
16	историю O
17	, O
18	придумать B-Task
19	подпись I-Task
20	или O
21	написать B-Task
22	небольшой I-Task
23	рассказ I-Task
24	. O

# sent_id = 200
# text =   AntiToxicBot — бот, распознающий токсичных пользователей в телеграм чатах.
# relations = "Application_isUsedForSolving_Task 0 0"
1	AntiToxicBot B-Technology
2	— O
3	бот O
4	, O
5	распознающий B-Task
6	токсичных I-Task
7	пользователей I-Task
8	в O
9	телеграм O
10	чатах O
11	. O

# sent_id = 201
# text =   Почему же выбрано CNN+GRU, а не просто GRU или CNN?
# relations = ""
1	Почему O
2	же O
3	выбрано O
4	CNN+GRU B-Method
5	, O
6	а O
7	не O
8	просто O
9	GRU B-Method
10	или O
11	CNN B-Method
12	? O

# sent_id = 202
# text =   Нейросеть состоит из 3-х основных частей(CNN, GRU, Linear).
# relations = ""
1	Нейросеть O
2	состоит O
3	из O
4	3-х O
5	основных O
6	частей O
7	( O
8	CNN B-Method
9	, O
10	GRU B-Method
11	, O
12	Linear B-Method
13	) O
14	. O

# sent_id = 203
# text =   Как и в классификации картинок, свёрточный слой выделяет “признаки”, но в нашем случае векторизированный текст.
# relations = ""
1	Как O
2	и O
3	в O
4	классификации O
5	картинок O
6	, O
7	свёрточный O
8	слой O
9	выделяет O
10	“ O
11	признаки O
12	” O
13	, O
14	но O
15	в O
16	нашем O
17	случае O
18	векторизированный B-Object
19	текст I-Object
20	. O

# sent_id = 204
# text =   То-есть данная часть сети учится выделять признаки токсичных и позитивных сообщений.
# relations = ""
1	То O
2	- O
3	есть O
4	данная O
5	часть O
6	сети O
7	учится O
8	выделять B-Task
9	признаки I-Task
10	токсичных I-Task
11	и I-Task
12	позитивных I-Task
13	сообщений I-Task
14	. O

# sent_id = 205
# text =   GRU - Recurrent Neural Network
# relations = "Method_includes_Method 1 0"
1	GRU B-Method
2	- O
3	Recurrent B-Method
4	Neural I-Method
5	Network I-Method

# sent_id = 206
# text =   Чтобы обрабатывать последовательности произвольной длины, используют рекуррентные слои.
# relations = "Method_solves_Task 0 0"
1	Чтобы O
2	обрабатывать B-Task
3	последовательности I-Task
4	произвольной I-Task
5	длины I-Task
6	, O
7	используют B-Method_solves_Task
8	рекуррентные B-Method
9	слои I-Method
10	. O

# sent_id = 207
# text =   В архитектуре используется рекуррентный слой GRU.
# relations = ""
1	В O
2	архитектуре O
3	используется O
4	рекуррентный O
5	слой O
6	GRU B-Method
7	. O

# sent_id = 208
# text =  Данный слой учится делать заключительное решение по определению тональности текста на основе предыдущих слоёв.
# relations = ""
1	Данный O
2	слой O
3	учится O
4	делать O
5	заключительное O
6	решение O
7	по O
8	определению B-Task
9	тональности I-Task
10	текста I-Task
11	на O
12	основе O
13	предыдущих O
14	слоёв O
15	. O

# sent_id = 209
# text =   Датасет был взят с сайта kaggle.
# relations = ""
1	Датасет B-Dataset
2	был O
3	взят O
4	с O
5	сайта O
6	kaggle B-InfoResource
7	. O

# sent_id = 210
# text =   Около 14000 комментариев с разметкой токсичное сообщение или нет.
# relations = ""
1	Около O
2	14000 O
3	комментариев O
4	с O
5	разметкой B-Method
6	токсичное B-Object
7	сообщение I-Object
8	или O
9	нет O
10	. O

# sent_id = 211
# text =   Для решения данной проблемы была использована библиотека Yandex Speller, которая исправляет орфографические ошибки.
# relations = "Library_isUsedForSolving_Task 0 0"
1	Для O
2	решения O
3	данной O
4	проблемы O
5	была O
6	использована O
7	библиотека O
8	Yandex B-Library
9	Speller I-Library
10	, O
11	которая O
12	исправляет B-Task
13	орфографические I-Task
14	ошибки I-Task
15	. O

# sent_id = 212
# text =   Можно было обучить собственный Word2Vec на основе данного набора данных, но лучше взять уже обученный.
# relations = ""
1	Можно O
2	было O
3	обучить O
4	собственный O
5	Word2Vec B-Model
6	на O
7	основе O
8	данного O
9	набора O
10	данных O
11	, O
12	но O
13	лучше O
14	взять O
15	уже O
16	обученный O
17	. O

# sent_id = 213
# text =   Например: Navec.
# relations = ""
1	Например O
2	: O
3	Navec B-Model
4	. O

# sent_id = 214
# text =   Модель обучали на русской литературе (~150gb), что говорит о качественной векторизации текста.
# relations = ""
1	Модель B-Model
2	обучали O
3	на O
4	русской B-Science
5	литературе I-Science
6	( O
7	~150 O
8	gb O
9	) O
10	, O
11	что O
12	говорит O
13	о O
14	качественной O
15	векторизации O
16	текста O
17	. O

# sent_id = 215
# text =  Для классификации используется обыкновенная функция потерь – кросс энтропия.
# relations = "Method_solves_Task 0 0"
1	Для O
2	классификации B-Task
3	используется O
4	обыкновенная O
5	функция B-Method
6	потерь I-Method
7	– I-Method
8	кросс I-Method
9	энтропия I-Method
10	. O

# sent_id = 216
# text =  При обучении сети надо обращать внимание на основные параметры такие, как loss, precision и accuracy.
# relations = ""
1	При O
2	обучении O
3	сети O
4	надо O
5	обращать O
6	внимание O
7	на O
8	основные O
9	параметры O
10	такие O
11	, O
12	как O
13	loss B-Metric
14	, O
15	precision B-Metric
16	и O
17	accuracy B-Metric
18	. O

# sent_id = 217
# text =   В ~80% случаев нейросеть классифицирует тональность текста правильно.
# relations = ""
1	В O
2	~80 B-Value
3	% I-Value
4	случаев O
5	нейросеть O
6	классифицирует O
7	тональность O
8	текста O
9	правильно O
10	. O

# sent_id = 218
# text =   Теперь нейронная сеть указала конкретные сцены, написанные не Шекспиром, и определила, кто на самом деле их написал.
# relations = ""
1	Теперь O
2	нейронная B-Model
3	сеть I-Model
4	указала O
5	конкретные O
6	сцены O
7	, O
8	написанные O
9	не O
10	Шекспиром O
11	, O
12	и O
13	определила O
14	, O
15	кто O
16	на O
17	самом O
18	деле O
19	их O
20	написал O
21	. O

# sent_id = 219
# text =   Плехач обучил алгоритм распознавать стиль Шекспира на пьесах «Кориолан», «Цимбелин», «Зимняя сказка» и «Буря».
# relations = ""
1	Плехач B-Person
2	обучил O
3	алгоритм O
4	распознавать B-Task
5	стиль I-Task
6	Шекспира O
7	на O
8	пьесах B-Object
9	« O
10	Кориолан O
11	» O
12	, O
13	« O
14	Цимбелин O
15	» O
16	, O
17	« O
18	Зимняя O
19	сказка O
20	» O
21	и O
22	« O
23	Буря O
24	» O
25	. O

# sent_id = 220
# text =   В результате искусственный интеллект согласился с анализом Спеддинга.
# relations = ""
1	В O
2	результате O
3	искусственный O
4	интеллект O
5	согласился O
6	с O
7	анализом B-Method
8	Спеддинга O
9	. O

# sent_id = 221
# text =   В прошлом году учёные из Университета Торонто, Мельбурнского Университета и подразделения IBM в Австралии научили искусственный интеллект генерировать сонеты в шекспировском стиле.
# relations = ""
1	В O
2	прошлом O
3	году O
4	учёные O
5	из O
6	Университета B-Organization
7	Торонто I-Organization
8	, O
9	Мельбурнского B-Organization
10	Университета I-Organization
11	и O
12	подразделения O
13	IBM B-Organization
14	в O
15	Австралии O
16	научили O
17	искусственный O
18	интеллект O
19	генерировать O
20	сонеты O
21	в O
22	шекспировском O
23	стиле O
24	. O

# sent_id = 222
# text =   Алгоритм под названием Deepspeare обучали на 2,7 тыс. сонетов Шекспира, после чего он научился писать собственные, придерживаясь похожего стиля.
# relations = ""
1	Алгоритм O
2	под O
3	названием O
4	Deepspeare B-Method
5	обучали O
6	на O
7	2,7 O
8	тыс. O 
9	сонетов B-Object
10	Шекспира O
11	, O
12	после O
13	чего O
14	он O
15	научился O
16	писать O
17	собственные O
18	, O
19	придерживаясь O
20	похожего O
21	стиля O
22	. O

# sent_id = 223
# text =   Как научить свою нейросеть генерировать стихи
# relations = ""
1	Как O
2	научить O
3	свою O
4	нейросеть O
5	генерировать B-Task
6	стихи I-Task

# sent_id = 224
# text =   Языковые модели определяют вероятность появления последовательности слов  в данном языке: .
# relations = ""
1	Языковые O
2	модели O
3	определяют B-Task
4	вероятность I-Task
5	появления I-Task
6	последовательности I-Task
7	слов I-Task
8	в O
9	данном O
10	языке B-Object
11	: O
12	. O

# sent_id = 225
# text =   Кажется, самым простым способом построить такую модель является использование N-граммной статистики.
# relations = "Method_isUsedForTraining_Model 0 0"
1	Кажется O
2	, O
3	самым O
4	простым O
5	способом O
6	построить O
7	такую O
8	модель B-Model
9	является O
10	использование O
11	N B-Method
12	- I-Method
13	граммной I-Method
14	статистики I-Method
15	. O

# sent_id = 226
# text =   Для решения такой проблемы используют обычно сглаживание Kneser-Ney или Katz’s backing-off.
# relations = ""
1	Для O
2	решения O
3	такой O
4	проблемы O
5	используют O
6	обычно O
7	сглаживание B-Method
8	Kneser I-Method
9	- I-Method
10	Ney I-Method
11	или O
12	Katz B-Method
13	’s I-Method
14	backing I-Method
15	- I-Method
16	off I-Method
17	. O

# sent_id = 227
# text =   За более подробной информацией про методы сглаживания N-грамм стоит обратиться к известной книге Кристофера Маннинга “Foundations of Statistical Natural Language Processing”.
# relations = "Method_hasAuthor_Person 0 0"
1	За O
2	более O
3	подробной O
4	информацией O
5	про O
6	методы O
7	сглаживания B-Method
8	N I-Method
9	- I-Method
10	грамм I-Method
11	стоит O
12	обратиться O
13	к O
14	известной O
15	книге O
16	Кристофера B-Person
17	Маннинга I-Person
18	“ O
19	Foundations B-InfoResource
20	of I-InfoResource
21	Statistical I-InfoResource
22	Natural I-InfoResource
23	Language I-InfoResource
24	Processing I-InfoResource
25	” O
26	. O

# sent_id = 228
# text =   Хочу заметить, что 5-граммы слов я назвал не просто так: именно их (со сглаживанием, конечно) Google демонстрирует в статье “One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling” — и показывает результаты, весьма сопоставимые с результатами у рекуррентных нейронных сетей — о которых, собственно, и пойдет далее речь.
# relations = "Method_hasAuthor_Organization 0 0"
1	Хочу O
2	заметить O
3	, O
4	что O
5	5-граммы O
6	слов O
7	я O
8	назвал O
9	не O
10	просто O
11	так O
12	: O
13	именно O
14	их O
15	( O
16	со O
17	сглаживанием O
18	, O
19	конечно O
20	) O
21	Google B-Organization
22	демонстрирует O
23	в O
24	статье O
25	“ B-InfoResource
26	One I-InfoResource
27	Billion I-InfoResource
28	Word I-InfoResource
29	Benchmark I-InfoResource
30	for I-InfoResource
31	Measuring I-InfoResource
32	Progress I-InfoResource
33	in I-InfoResource
34	Statistical I-InfoResource
35	Language I-InfoResource
36	Modeling I-InfoResource
37	” I-InfoResource
38	— O
39	и O
40	показывает O
41	результаты O
42	, O
43	весьма O
44	сопоставимые O
45	с O
46	результатами O
47	у O
48	рекуррентных B-Method
49	нейронных I-Method
50	сетей I-Method
51	— O
52	о O
53	которых O
54	, O
55	собственно O
56	, O
57	и O
58	пойдет O
59	далее O
60	речь O
61	. O

# sent_id = 229
# text =   Преимущество рекуррентных нейронных сетей — в возможности использовать неограниченно длинный контекст.
# relations = ""
1	Преимущество O
2	рекуррентных B-Method
3	нейронных I-Method
4	сетей I-Method
5	— O
6	в O
7	возможности O
8	использовать O
9	неограниченно B-Object
10	длинный I-Object
11	контекст I-Object
12	. O

# sent_id = 230
# text =   На практике классические RNN страдают от затухания градиента — по сути, отсутствия возможности помнить контекст дальше, чем на несколько слов.
# relations = ""
1	На O
2	практике O
3	классические O
4	RNN B-Method
5	страдают O
6	от O
7	затухания O
8	градиента O
9	— O
10	по O
11	сути O
12	, O
13	отсутствия O
14	возможности O
15	помнить O
16	контекст O
17	дальше O
18	, O
19	чем O
20	на O
21	несколько O
22	слов O
23	. O

# sent_id = 231
# text =   Самыми популярными являются LSTM и GRU.
# relations = ""
1	Самыми O
2	популярными O
3	являются O
4	LSTM B-Method
5	и O
6	GRU B-Method
7	. O

# sent_id = 232
# text =   В дальнейшем, говоря о рекуррентном слое, я всегда буду подразумевать LSTM.
# relations = ""
1	В O
2	дальнейшем O
3	, O
4	говоря O
5	о O
6	рекуррентном O
7	слое O
8	, O
9	я O
10	всегда O
11	буду O
12	подразумевать O
13	LSTM B-Method
14	. O

# sent_id = 233
# text =   Вспомним теперь, что для нашей задачи языковая модель нужна для выбора наиболее подходящего следующего слова по уже сгенерированной последовательности.
# relations = "Object_isUsedInSolving_Task 0 0, Model_isUsedForSolving_Task 0 0"
1	Вспомним O
2	теперь O
3	, O
4	что O
5	для O
6	нашей O
7	задачи O
8	языковая O
9	модель B-Model
10	нужна O
11	для O
12	выбора B-Task
13	наиболее I-Task
14	подходящего I-Task
15	следующего I-Task
16	слова I-Task
17	по O
18	уже O
19	сгенерированной B-Object
20	последовательности I-Object
21	. O

# sent_id = 234
# text =   Метрические правила определяют последовательность ударных и безударных слогов в строке.
# relations = ""
1	Метрические B-Object
2	правила I-Object
3	определяют O
4	последовательность O
5	ударных O
6	и O
7	безударных O
8	слогов B-Object
9	в O
10	строке O
11	. O

# sent_id = 235
# text =   Для решения этой проблемы мы делаем лучевой поиск (beam search), выбирая на каждом шаге вместо одного сразу N путей с наивысшими вероятностями.
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Для O
2	решения O
3	этой O
4	проблемы O
5	мы O
6	делаем O
7	лучевой B-Method
8	поиск I-Method
9	( O
10	beam B-Method
11	search I-Method
12	) O
13	, O
14	выбирая O
15	на O
16	каждом O
17	шаге O
18	вместо O
19	одного O
20	сразу O
21	N O
22	путей O
23	с O
24	наивысшими O
25	вероятностями O
26	. O

# sent_id = 236
# text =  Автоматическое определение эмоций в текстовых беседах с использованием нейронных сетей
# relations = "Method_isAppliedTo_Object 0 0, Method_solves_Task 0 0, Object_isUsedInSolving_Task 0 0"
1	Автоматическое B-Task
2	определение I-Task
3	эмоций I-Task
4	в O
5	текстовых B-Object
6	беседах I-Object
7	с O
8	использованием O
9	нейронных B-Method
10	сетей I-Method

# sent_id = 237
# text = Одна из основных задач диалоговых систем состоит не только в предоставлении нужной пользователю информации, но и в генерации как можно более человеческих ответов.
# relations = "Application_isUsedForSolving_Task 0 1, Application_isUsedForSolving_Task 0 0"
1	Одна O
2	из O
3	основных O
4	задач O
5	диалоговых B-Application
6	систем I-Application
7	состоит O
8	не O
9	только O
10	в O
11	предоставлении B-Task
12	нужной I-Task
13	пользователю I-Task
14	информации I-Task
15	, O
16	но O
17	и O
18	в O
19	генерации B-Task
20	как O
21	можно O
22	более O
23	человеческих O
24	ответов O
25	. O

# sent_id = 238
# text =   В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.
# relations = "Task_isSolvedIn_Science 0 0, Method_isUsedIn_Science 0 0, Object_isUsedInSolving_Task 0 0, Method_isAppliedTo_Object 0 0, Method_solves_Task 0 0"
1	В O
2	этой O
3	статье O
4	мы O
5	рассмотрим O
6	архитектуру O
7	рекуррентной B-Method
8	нейросети I-Method
9	для O
10	определения B-Task
11	эмоций I-Task
12	в O
13	текстовых B-Object
14	беседах I-Object
15	, O
16	которая O
17	принимала O
18	участие O
19	в O
20	SemEval-2019 O
21	Task O
22	3 O
23	“ O
24	EmoContext O
25	” O
26	, O
27	ежегодном O
28	соревновании O
29	по O
30	компьютерной B-Science
31	лингвистике I-Science
32	. O

# sent_id = 239
# text =   Задача состояла в классификации эмоций (“happy”, “sad”, “angry” и “others”) в беседе из трех реплик, в которой участвовали чат-бот и человек.
# relations = ""
1	Задача O
2	состояла O
3	в O
4	классификации B-Task
5	эмоций I-Task
6	( O
7	“ O
8	happy O
9	” O
10	, O
11	“ O
12	sad O
13	” O
14	, O
15	“ O
16	angry O
17	” O
18	и O
19	“ O
20	others O
21	” O
22	) O
23	в O
24	беседе O
25	из O
26	трех O
27	реплик O
28	, O
29	в O
30	которой O
31	участвовали O
32	чат O
33	- O
34	бот O
35	и O
36	человек O
37	. O

# sent_id = 240
# text =   В четвёртой части мы опишем архитектуру LSTM, которую мы использовали в соревновании.
# relations = ""
1	В O
2	четвёртой O
3	части O
4	мы O
5	опишем O
6	архитектуру O
7	LSTM B-Method
8	, O
9	которую O
10	мы O
11	использовали O
12	в O
13	соревновании O
14	. O

# sent_id = 241
# text =   Код написан на языке Python с использованием библиотеки Keras.
# relations = ""
1	Код O
2	написан O
3	на O
4	языке O
5	Python B-Environment
6	с O
7	использованием O
8	библиотеки O
9	Keras B-Library
10	. O

# sent_id = 242
# text =   Подробное описание представлено здесь: (Chatterjee et al., 2019).
# relations = ""
1	Подробное O
2	описание O
3	представлено O
4	здесь O
5	: O
6	( O
7	Chatterjee B-InfoResource
8	et I-InfoResource
9	al I-InfoResource
10	. I-InfoResource
11	, I-InfoResource
12	2019 I-InfoResource
13	) O
14	. O

# sent_id = 243
# text =   Примеры из датасета EmoContext (Chatterjee et al., 2019)
# relations = ""
1	Примеры O
2	из O
3	датасета O
4	EmoContext B-Dataset
5	( O
6	Chatterjee B-InfoResource
7	et I-InfoResource
8	al I-InfoResource
9	. I-InfoResource
10	, I-InfoResource
11	2019 I-InfoResource
12	) O

# sent_id = 244
# text =   Данные предоставлены Microsoft, скачать их можно в официальной группе в LinkedIn.
# relations = "Application_hasAuthor_Organization 0 0"
1	Данные O
2	предоставлены O
3	Microsoft B-Organization
4	, O
5	скачать O
6	их O
7	можно O
8	в O
9	официальной O
10	группе O
11	в O
12	LinkedIn B-Application
13	. O

# sent_id = 245
# text =   В дополнение к этим данным мы собрали 900 тыс. англоязычных сообщений из Twitter, чтобы создать Distant-датасет (300 тыс. твитов на каждую эмоцию).
# relations = ""
1	В O
2	дополнение O
3	к O
4	этим O
5	данным O
6	мы O
7	собрали O
8	900 O
9	тыс. O
10	англоязычных O
11	сообщений O
12	из O
13	Twitter B-Organization
14	, O
15	чтобы O
16	создать O
17	Distant B-Dataset
18	- O
19	датасет O
20	( O
21	300 O
22	тыс. O
23	твитов O
24	на O
25	каждую O
26	эмоцию O
27	) O
28	. O

# sent_id = 246
# text =   При его создании мы придерживались стратегии Go et al. (2009), в рамках которой просто ассоциировали сообщения с наличием относящихся к эмоциям слов, таких как #angry, #annoyed, #happy, #sad, #surprised и так далее.
# relations = ""
1	При O
2	его O
3	создании O
4	мы O
5	придерживались O
6	стратегии O
7	Go B-InfoResource
8	et I-InfoResource
9	al I-InfoResource
10	. I-InfoResource
11	( I-InfoResource
12	2009 I-InfoResource
13	) I-InfoResource
14	, O
15	в O
16	рамках O
17	которой O
18	просто O
19	ассоциировали B-Task
20	сообщения I-Task
21	с I-Task
22	наличием I-Task
23	относящихся I-Task
24	к I-Task
25	эмоциям I-Task
26	слов I-Task
27	, O
28	таких O
29	как O
# O
30	angry O
31	, O
# O
32	annoyed O
33	, O
# O
34	happy O
35	, O
# O
36	sad O
37	, O
# O
38	surprised O
39	и O
40	так O
41	далее O
42	. O

# sent_id = 247
# text =   Список терминов основан на терминах из SemEval-2018 AIT DISC (Duppada et al., 2018).
# relations = ""
1	Список O
2	терминов B-Object
3	основан O
4	на O
5	терминах B-Object
6	из O
7	SemEval-2018 B-Dataset
8	AIT I-Dataset
9	DISC I-Dataset
10	( O
11	Duppada B-InfoResource
12	et I-InfoResource
13	al I-InfoResource
14	. I-InfoResource
15	, I-InfoResource
16	2018 I-InfoResource
17	) O
18	. O

# sent_id = 248
# text =   Главной метрикой качества в соревновании EmoContext является усредненная F1-мера для трёх классов эмоций, то есть для классов «happy», «sad» и «angry».
# relations = ""
1	Главной O
2	метрикой O
3	качества O
4	в O
5	соревновании O
6	EmoContext O
7	является O
8	усредненная O
9	F1-мера B-Metric
10	для O
11	трёх O
12	классов O
13	эмоций O
14	, O
15	то O
16	есть O
17	для O
18	классов O
19	« O
20	happy O
21	» O
22	, O
23	« O
24	sad O
25	» O
26	и O
27	« O
28	angry O
29	» O
30	. O

# sent_id = 249
# text =   Перед обучением мы предварительно обработали тексты с помощью инструмента Ekphrasis (Baziotis et al., 2017).
# relations = ""
1	Перед O
2	обучением O
3	мы O
4	предварительно O
5	обработали O
6	тексты B-Object
7	с O
8	помощью O
9	инструмента O
10	Ekphrasis B-Application
11	( O
12	Baziotis B-InfoResource
13	et I-InfoResource
14	al I-InfoResource
15	. I-InfoResource
16	, I-InfoResource
17	2017 I-InfoResource
18	) O
19	. O

# sent_id = 250
# text =   Он помогает исправить орфографию, нормализовать слова, сегментировать, а также определить, какие токены следует отбросить, нормализовать или аннотировать с помощью специальных тегов.
# relations = "Object_isUsedInSolving_Task 0 1, Object_isUsedInSolving_Task 0 2, Object_isUsedInSolving_Task 0 0"
1	Он O
2	помогает O
3	исправить B-Task
4	орфографию I-Task
5	, O
6	нормализовать B-Task
7	слова I-Task
8	, O
9	сегментировать B-Task
10	, O
11	а O
12	также O
13	определить O
14	, O
15	какие O
16	токены B-Object
17	следует O
18	отбросить O
19	, O
20	нормализовать O
21	или O
22	аннотировать O
23	с O
24	помощью O
25	специальных O
26	тегов B-Object
27	. O

# sent_id = 251
# text =   Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.
# relations = "Method_solves_Task 0 0, Application_isUsedForSolving_Task 0 0, Method_isAppliedTo_Object 0 0, Object_isUsedInSolving_Task 0 0, Method_isAppliedTo_Object 0 1, Object_isUsedInSolving_Task 1 0, Method_isAppliedTo_Object 0 2, Object_isUsedInSolving_Task 2 0, Method_isAppliedTo_Object 0 3, Object_isUsedInSolving_Task 3 0, Method_isAppliedTo_Object 0 4, Object_isUsedInSolving_Task 4 0, Method_isAppliedTo_Object 0 5, Object_isUsedInSolving_Task 5 0, Method_isAppliedTo_Object 0 6, Object_isUsedInSolving_Task 6 0, Method_isUsedIn_Application 0 0"
1	Кроме O
2	того O
3	, O
4	Emphasis B-Application
5	содержит O
6	токенизатор B-Method
7	, O
8	который O
9	может O
10	идентифицировать B-Task
11	большинство O
12	эмодзи B-Object
13	, O
14	эмотиконов B-Object
15	и O
16	сложных B-Object
17	выражений I-Object
18	, O
19	а O
20	также O
21	даты B-Object
22	, O
23	время B-Object
24	, O
25	валюты B-Object
26	и O
27	акронимы B-Object
28	. O

# sent_id = 252
# text =   Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.
# relations = "Object_includes_Object 0 1, Object_includes_Object 0 2, Method_includes_Method 0 1, Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 1 0"
1	Типичным O
2	методом B-Method
3	обучения I-Method
4	без I-Method
5	учителя I-Method
6	является O
7	кластеризация B-Method
8	, O
9	благодаря O
10	которому O
11	обучающая B-Object
12	выборка I-Object
13	разбивается O
14	на O
15	устойчивые B-Object
16	группы I-Object
17	или O
18	кластеры B-Object
19	. O

# sent_id = 253
# text =   Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.
# relations = "Object_isUsedInSolving_Task 0 0, Method_includes_Method 0 1, Method_isAppliedTo_Object 1 0, Method_isAppliedTo_Object 2 0, Method_isAppliedTo_Object 0 0, Method_solves_Task 1 0, Method_solves_Task 0 0, Method_solves_Task 2 0, Method_isAppliedTo_Object 1 0, Method_isAppliedTo_Object 0 0, Method_isAlternativeNameFor_Method 2 1"
1	Другой O
2	подход B-Method
3	обучения I-Method
4	без I-Method
5	учителя I-Method
6	для B-Method_isAppliedTo_Object
7	текстов B-Object
8	называется O
9	тематическим B-Method
10	моделированием I-Method
11	( O
12	topic B-Method
13	modeling I-Method
14	) O
15	, O
16	позволяющим B-Method_solves_Task
17	выявить B-Task
18	в I-Task
19	неразмеченных I-Task
20	текстах I-Task
21	основные I-Task
22	тематики I-Task
23	. O

# sent_id = 254
# text =   Если отказываемся от методов unsupervised learning, то логично обратиться к методам обучения с учителем (supervised learning) и в частности к классификации.
# relations = "Method_includes_Method 1 3"
1	Если O
2	отказываемся O
3	от O
4	методов O
5	unsupervised B-Method
6	learning I-Method
7	, O
8	то O
9	логично O
10	обратиться O
11	к O
12	методам B-Method
13	обучения I-Method
14	с I-Method
15	учителем I-Method
16	( O
17	supervised B-Method
18	learning I-Method
19	) O
20	и O
21	в O
22	частности O
23	к O
24	классификации B-Method
25	. O

# sent_id = 255
# text =   Результатом работы языковой модели являются эмбеддинги — это отображение из пространства слов в пространство векторов конкретной фиксированной длины, причем векторы, соответствующие близким по смыслу словам, будут расположены в новом пространстве рядом, а далекие по смыслу — далеко.
# relations = ""
1	Результатом O
2	работы O
3	языковой B-Model
4	модели I-Model
5	являются O
6	эмбеддинги B-Object
7	— O
8	это O
9	отображение O
10	из O
11	пространства O
12	слов B-Object
13	в O
14	пространство O
15	векторов O
16	конкретной O
17	фиксированной O
18	длины O
19	, O
20	причем O
21	векторы O
22	, O
23	соответствующие O
24	близким O
25	по O
26	смыслу B-Object
27	словам I-Object
28	, O
29	будут O
30	расположены O
31	в O
32	новом O
33	пространстве O
34	рядом O
35	, O
36	а O
37	далекие O
38	по O
39	смыслу O
40	— O
41	далеко O
42	. O

# sent_id = 256
# text =   При использовании TF-IDF (например, вот) подхода с фильтром по частотам и логистической регрессии уже можно получить прекрасные результаты: изначально в краулер отправлялись очень разные тексты, и модель прекрасно справляется.
# relations = "Metric_isAppliedTo_Method 0 0"
1	При O
2	использовании B-Metric_isAppliedTo_Method
3	TF B-Metric
4	- I-Metric
5	IDF I-Metric
6	( O
7	например O
8	, O
9	вот O
10	) O
11	подхода O
12	с O
13	фильтром O
14	по O
15	частотам O
16	и O
17	логистической B-Method
18	регрессии I-Method
19	уже O
20	можно O
21	получить O
22	прекрасные O
23	результаты O
24	: O
25	изначально O
26	в O
27	краулер O
28	отправлялись O
29	очень O
30	разные O
31	тексты O
32	, O
33	и O
34	модель O
35	прекрасно O
36	справляется O
37	. O

# sent_id = 257
# text =   Используя TF-IDF с фильтром по частотам и логистической регрессией, уже можно достичь отличных результатов.
# relations = "Metric_isAppliedTo_Method 0 0"
1	Используя B-Metric_isAppliedTo_Method
2	TF B-Metric
3	- I-Metric
4	IDF I-Metric
5	с O
6	фильтром O
7	по O
8	частотам O
9	и O
10	логистической B-Method
11	регрессией I-Method
12	, O
13	уже O
14	можно O
15	достичь O
16	отличных O
17	результатов O
18	. O

# sent_id = 258
# text =   Для каждой из популяций рассчитаем word2vec расстояние до центра положительной обучающей выборки.
# relations = ""
1	Для O
2	каждой O
3	из O
4	популяций O
5	рассчитаем O
6	word2vec B-Model
7	расстояние O
8	до O
9	центра O
10	положительной O
11	обучающей O
12	выборки B-Object
13	. O

# sent_id = 259
# text =   Распределения можно разделить, и для оценки расстояния между распределениями в первую очередь логично обратиться к Дивергенции Кульбака-Лейблера (ДКЛ).
# relations = ""
1	Распределения O
2	можно O
3	разделить O
4	, O
5	и O
6	для B-Metric_isUsed_in_Activity
7	оценки B-Activity
8	расстояния I-Activity
9	между O
10	распределениями O
11	в O
12	первую O
13	очередь O
14	логично O
15	обратиться O
16	к O
17	Дивергенции B-Metric
18	Кульбака I-Metric
19	- I-Metric
20	Лейблера I-Metric
21	( O
22	ДКЛ B-Metric
23	) O
24	. O

# sent_id = 260
# text =  Они отличаются хорошей сбалансированностью: достаточно высокий уровень чувствительности одновременно с хорошим соотношением сигнал/шум и уровнем AOP (Acoustic Overload Point — это такой аналог максимального звукового давления для цифровых микрофонов). 
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	Они O
2	отличаются O
3	хорошей O
4	сбалансированностью O
5	: O
6	достаточно O
7	высокий O
8	уровень O
9	чувствительности O
10	одновременно O
11	с O
12	хорошим O
13	соотношением O
14	сигнал O
15	/ O
16	шум O
17	и O
18	уровнем O
19	AOP B-Metric
20	( O
21	Acoustic B-Metric
22	Overload I-Metric
23	Point I-Metric
24	— O
25	это O
26	такой O
27	аналог O
28	максимального O
29	звукового O
30	давления O
31	для O
32	цифровых O
33	микрофонов O
34	) O
35	. O

# sent_id = 261
# text =  Пожалуй, самое важное: мы отказались от моделей на базе DNN-HMM и перешли на архитектуру e2e-распознавания с использованием тяжёлых нейросетей-трансформеров. 
# relations = ""
1	Пожалуй O
2	, O
3	самое O
4	важное O
5	: O
6	мы O
7	отказались O
8	от O
9	моделей O
10	на O
11	базе O
12	DNN B-Method
13	- I-Method
14	HMM I-Method
15	и O
16	перешли O
17	на O
18	архитектуру O
19	e2e B-Method
20	- O
21	распознавания O
22	с O
23	использованием O
24	тяжёлых O
25	нейросетей O
26	- O
27	трансформеров O
28	. O

# sent_id = 262
# text =  В обоих случаях они от Texas Instruments, но в Станции Макс используется более свежая и мощная модель TAS5825M. 
# relations = "Model_isUsedIn_Application 0 0"
1	В O
2	обоих O
3	случаях O
4	они O
5	от O
6	Texas B-Organization
7	Instruments I-Organization
8	, O
9	но O
10	в O
11	Станции B-Technology
12	Макс I-Technology
13	используется O
14	более O
15	свежая O
16	и O
17	мощная O
18	модель O
19	TAS5825M B-Model
20	. O

# sent_id = 263
# text =  В конкурсе приняли участие представители ведущих команд рынка компьютерной обработки текстов, в том числе «Антиплагиат», «Наносемантика», DeepPavlov. 
# relations = ""
1	В O
2	конкурсе O
3	приняли O
4	участие O
5	представители O
6	ведущих O
7	команд O
8	рынка O
9	компьютерной O
10	обработки O
11	текстов O
12	, O
13	в O
14	том O
15	числе O
16	« O
17	Антиплагиат B-App_system
18	» O
19	, O
20	« O
21	Наносемантика B-App_system
22	» O
23	, O
24	DeepPavlov B-Library
25	. O

# sent_id = 264
# text =  Руководитель проекта FirstTry Артём Щеголев пришел на конкурс в команде со своей супругой. 
# relations = ""
1	Руководитель O
2	проекта O
3	FirstTry B-Activity
4	Артём B-Person
5	Щеголев I-Person
6	пришел O
7	на O
8	конкурс O
9	в O
10	команде O
11	со O
12	своей O
13	супругой O
14	. O

# sent_id = 265
# text =  TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста. 
# relations = "Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 0 1, Application_isUsedForSolving_Task 0 2, Application_isUsedForSolving_Task 0 3, Application_isUsedForSolving_Task 0 4"
1	TextIT B-Application
2	API I-Application
3	включает O
4	в O
5	себя O
6	функции O
7	проверки B-Task
8	орфографии I-Task
9	и O
10	исправления B-Task
11	ошибок I-Task
12	, O
13	формирования B-Task
14	текстовой I-Task
15	формы I-Task
16	числительных I-Task
17	( O
18	например O
19	, O
20	преобразовать O
21	“ O
22	102 O
23	рубль O
24	” O
25	в O
26	“ O
27	сто O
28	два O
29	рубля O
30	” O
31	) O
32	, O
33	подсказки B-Task
34	следующего I-Task
35	слова I-Task
36	по O
37	ранее O
38	введенному O
39	тексту O
40	, O
41	постановки B-Task
42	слова I-Task
43	в I-Task
44	нужную I-Task
45	словоформу I-Task
46	( O
47	число O
48	, O
49	род O
50	, O
51	падеж O
52	, O
53	лицо O
54	и O
55	время O
56	) O
57	и O
58	другие O
59	полезные O
60	функции O
61	обработки O
62	и O
63	формирования O
64	текста O
65	. O

# sent_id = 266
# text = В данной статье я бы хотел познакомить читателей с одним из проектов Apache Software Foundation сообщества — NlpCraft. 
# relations = "Activity_hasAuthor_Organization 0 0"
1	В O
2	данной O
3	статье O
4	я O
5	бы O
6	хотел O
7	познакомить O
8	читателей O
9	с O
10	одним O
11	из O
12	проектов O
13	Apache B-Organization
14	Software I-Organization
15	Foundation I-Organization
16	сообщества O
17	— O
18	NlpCraft B-Activity
19	. O

# sent_id = 267
# text = В этой статье я планирую представить читателям один из проектов сообщества Apache Software Foundation — NlpCraft.
# relations = "Activity_hasAuthor_Organization 0 0"
1	В O
2	этой O
3	статье O
4	я O
5	планирую O
6	представить O
7	читателям O
8	один O
9	из O
10	проектов O
11	сообщества O
12	Apache B-Organization
13	Software I-Organization
14	Foundation I-Organization
15	— O
16	NlpCraft B-Activity
17	. O

# sent_id = 268
# text =  NlpCraft — библиотека с открытым исходным кодом, предназначенная для интеграции языкового интерфейса в пользовательские приложения. 
# relations = ""
1	NlpCraft B-Library
2	— O
3	библиотека O
4	с O
5	открытым O
6	исходным O
7	кодом O
8	, O
9	предназначенная O
10	для O
11	интеграции B-Task
12	языкового I-Task
13	интерфейса I-Task
14	в O
15	пользовательские O
16	приложения O
17	. O

# sent_id = 269
# text =  Подход Model-as-a-Code, позволяющий создавать и редактировать модели с помощью привычных разработчикам инструментов. 
# relations = ""
1	Подход O
2	Model B-Method
3	- I-Method
4	as I-Method
5	- I-Method
6	a I-Method
7	- I-Method
8	Code I-Method
9	, O
10	позволяющий O
11	создавать O
12	и O
13	редактировать O
14	модели O
15	с O
16	помощью O
17	привычных O
18	разработчикам O
19	инструментов O
20	. O

# sent_id = 270
# text =  Интеграция со множеством провайдеров NER компонентов (Apache OpenNlp, Stanford NLP, Google Natural Language API, Spacy) 
# relations = ""
1	Интеграция O
2	со O
3	множеством O
4	провайдеров O
5	NER B-Task
6	компонентов O
7	( O
8	Apache B-Library
9	OpenNlp I-Library
10	, O
11	Stanford B-Library
12	NLP I-Library
13	, O
14	Google B-Library
15	Natural I-Library
16	Language I-Library
17	API I-Library
18	, O
19	Spacy B-Library
20	) O

# sent_id = 271
# text = Named Entity — именованная сущность. 
# relations = ""
1	Named B-Object
2	Entity I-Object
3	— O
4	именованная B-Object
5	сущность I-Object
6	. O

# sent_id = 272
# text =  В большинстве случаев процесс конфигурации сводится к созданию и поддержке простого Json или Yaml файла. 
# relations = ""
1	В O
2	большинстве O
3	случаев O
4	процесс O
5	конфигурации O
6	сводится O
7	к O
8	созданию O
9	и O
10	поддержке O
11	простого O
12	Json B-Environment
13	или O
14	Yaml B-Environment
15	файла O
16	. O

# sent_id = 273
# text =  Ближайшие и наиболее известные “аналоги“ Amazon Alexa и Google DialogFlow имеют целый ряд существенных отличий от данной системы. 
# relations = ""
1	Ближайшие O
2	и O
3	наиболее O
4	известные O
5	“ O
6	аналоги O
7	“ O
8	Amazon B-Technology
9	Alexa I-Technology
10	и O
11	Google B-Technology
12	DialogFlow I-Technology
13	имеют O
14	целый O
15	ряд O
16	существенных O
17	отличий O
18	от O
19	данной O
20	системы O
21	. O

# sent_id = 274
# text = Онлайн-энциклопедия Wikipedia получила новый инструмент — сервис с элементами ИИ, который поможет автоматически определять некорректные правки материалов ресурса. 
# relations = ""
1	Онлайн O
2	- O
3	энциклопедия O
4	Wikipedia B-InfoResource
5	получила O
6	новый O
7	инструмент O
8	— O
9	сервис O
10	с O
11	элементами O
12	ИИ O
13	, O
14	который O
15	поможет O
16	автоматически O
17	определять B-Task
18	некорректные I-Task
19	правки I-Task
20	материалов I-Task
21	ресурса O
22	. O

# sent_id = 275
# text =  Сервис ORES (Objective Revision Evaluation Service) будет проверять все правки на наличие спама или троллинга. 
# relations = "Application_isAlternativeNameFor_Application 1 0"
1	Сервис O
2	ORES B-Application
3	( O
4	Objective B-Application
5	Revision I-Application
6	Evaluation I-Application
7	Service I-Application
8	) O
9	будет O
10	проверять O
11	все O
12	правки O
13	на O
14	наличие O
15	спама O
16	или O
17	троллинга O
18	. O

# sent_id = 276
# text =  Сервис ORES (Objective Revision Evaluation Service) будет осуществлять проверку всех изменений на предмет наличия спама или троллинга.
# relations = "Application_isAlternativeNameFor_Application 1 0"
1	Сервис O
2	ORES B-Application
3	( O
4	Objective B-Application
5	Revision I-Application
6	Evaluation I-Application
7	Service I-Application
8	) O
9	будет O
10	осуществлять O
11	проверку O
12	всех O
13	изменений O
14	на O
15	предмет O
16	наличия O
17	спама O
18	или O
19	троллинга O
20	. O

# sent_id = 277
# text =  Создателем ORES является Wikimedia Foundation. 
# relations = "Application_hasAuthor_Organization 0 0"
1	Создателем O
2	ORES B-Application
3	является O
4	Wikimedia B-Organization
5	Foundation I-Organization
6	. O

# sent_id = 278
# text = ORES (Objective Revision Evaluation Service) был разработан Wikimedia Foundation.
# relations = "Application_isAlternativeNameFor_Application 1 0, Application_hasAuthor_Organization 0 0, Application_hasAuthor_Organization 1 0"
1	ORES B-Application
2	( O
3	Objective B-Application
4	Revision I-Application
5	Evaluation I-Application
6	Service I-Application
7	) O
8	был O
9	разработан B-Application_hasAuthor_Organization
10	Wikimedia B-Organization
11	Foundation I-Organization
12	. O

# sent_id = 279
# text =  Вероятность того, что текст нормальный, составляет 0,0837. 
# relations = ""
# relations = ""
1	Вероятность O
2	того O
3	, O
4	что O
5	текст O
6	нормальный O
7	, O
8	составляет O
9	0,0837 B-Value
10	. O

# sent_id = 280
# text =  Вероятность умышленной порчи текста — 0,9163. 
# relations = ""
1	Вероятность O
2	умышленной O
3	порчи O
4	текста O
5	— O
6	0,9163 B-Value
7	. O

# sent_id = 281
# text =  Точность распознавания естественного языка сейчас у лидеров когнитивных систем (IBM Watson, Google, ABBYY, Microsoft, Наносемантика) позволяет в общем понять смысл и ответить на письменный вопрос при заранее определенной предметной базы знаний, но разговор даже с 90% точностью распознавания фраз на самом деле очень утомителен. 
# relations = "Metric_hasValue_Value 0 0"
1	Точность O
2	распознавания O
3	естественного O
4	языка O
5	сейчас O
6	у O
7	лидеров O
8	когнитивных O
9	систем O
10	( O
11	IBM B-Technology
12	Watson I-Technology
13	, O
14	Google B-Technology
15	, O
16	ABBYY B-Technology
17	, O
18	Microsoft B-Technology
19	, O
20	Наносемантика B-Technology
21	) O
22	позволяет O
23	в O
24	общем O
25	понять O
26	смысл O
27	и O
28	ответить O
29	на O
30	письменный O
31	вопрос O
32	при O
33	заранее O
34	определенной O
35	предметной O
36	базы O
37	знаний O
38	, O
39	но O
40	разговор O
41	даже O
42	с O
43	90 B-Value
44	% I-Value
45	точностью B-Metric
46	распознавания O
47	фраз O
48	на O
49	самом O
50	деле O
51	очень O
52	утомителен O
53	. O

# sent_id = 282
# text =  Кластерный анализ корпуса текстов 
# relations = ""
1	Кластерный B-Method
2	анализ I-Method
3	корпуса O
4	текстов O

# sent_id = 283
# text =  В качестве тестовых данных был взят фрагмент новостного датасета от РИА, из которого в обработке участвовали только заголовки новостей. 
# relations = ""
1	В O
2	качестве O
3	тестовых O
4	данных O
5	был O
6	взят O
7	фрагмент O
8	новостного O
9	датасета B-Dataset
10	от I-Dataset
11	РИА I-Dataset
12	, O
13	из O
14	которого O
15	в O
16	обработке O
17	участвовали O
18	только O
19	заголовки O
20	новостей O
21	. O

# sent_id = 284
# text =  Для векторизации текста использовалась модель LaBSE от @cointegrated. 
# relations = "Model_hasAuthor_Person 0 0"
1	Для O
2	векторизации O
3	текста O
4	использовалась O
5	модель O
6	LaBSE B-Model
7	от O
8	@cointegrated B-Person
9	. O

# sent_id = 285
# text =  Я использовал для этого модель ruT5 за авторством @cointegrated. 
# relations = "Model_hasAuthor_Person 0 0"
1	Я O
2	использовал O
3	для O
4	этого O
5	модель O
6	ruT5 B-Model
7	за O
8	авторством O
9	@cointegrated B-Person
10	. O

# sent_id = 286
# text =  После изучения мы поняли, что Дана (так мы называем нашего чат-бота) — это кнопочный и сценарный чат-бот. 
# relations = ""
1	После O
2	изучения O
3	мы O
4	поняли O
5	, O
6	что O
7	Дана B-Technology
8	( O
9	так O
10	мы O
11	называем O
12	нашего O
13	чат O
14	- O
15	бота O
16	) O
17	— O
18	это O
19	кнопочный O
20	и O
21	сценарный O
22	чат O
23	- O
24	бот O
25	. O

# sent_id = 287
# text =  Среднее количество слов в запросе — четыре, поэтому мы собрали n-grams (словосочетания из 3-5 слов) и решили кластеризовать их разными методами типа тематического моделирования – agglomerative clustering поверх sentence embedding. 
# relations = "Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 1 0"
1	Среднее O
2	количество O
3	слов O
4	в O
5	запросе O
6	— O
7	четыре O
8	, O
9	поэтому O
10	мы O
11	собрали O
12	n B-Object
13	- I-Object
14	grams I-Object
15	( O
16	словосочетания O
17	из O
18	3 O
19	- O
20	5 O
21	слов O
22	) O
23	и O
24	решили O
25	кластеризовать O
26	их O
27	разными O
28	методами O
29	типа O
30	тематического O
31	моделирования O
32	– O
33	agglomerative B-Method
34	clustering I-Method
35	поверх O
36	sentence B-Method
37	embedding I-Method
38	. O

# sent_id = 288
# text =  Решили использовать стандартные метрики: precision, recall, f1 score, accuracy. 
# relations = ""
1	Решили O
2	использовать O
3	стандартные O
4	метрики O
5	: O
6	precision B-Metric
7	, O
8	recall B-Metric
9	, O
10	f1 B-Metric
11	score I-Metric
12	, O
13	accuracy B-Metric
14	. O

# sent_id = 289
# text =  На всех классах accuracy = 0.65. 
# relations = "Metric_hasValue_Value 0 0"
1	На O
2	всех O
3	классах O
4	accuracy B-Metric
5	= O
6	0.65 B-Value
7	. O

# sent_id = 290
# text =  Рассчитаем macro f1 score (0.72 + 0.28 + 0.66 + 0.66)/4 ~ 0.6, weighted f1 score (0.720.85+0.280.05+0.660.05+0.660.05) ~ 0.69. 
# relations = "Metric_hasValue_Value 0 0, Metric_hasValue_Value 1 1"
1	Рассчитаем O
2	macro B-Metric
3	f1 I-Metric
4	score I-Metric
5	( O
6	0.72 O
7	+ O
8	0.28 O
9	+ O
10	0.66 O
11	+ O
12	0.66)/4 O
13	~ O
14	0.6 B-Value
15	, O
16	weighted B-Metric
17	f1 I-Metric
18	score I-Metric
19	( O
20	0.720.85 O
21	+ O
22	0.280.05 O
23	+ O
24	0.660.05 O
25	+ O
26	0.660.05 O
27	) O
28	~ O
29	0.69 B-Value
30	. O

# sent_id = 291
# text =  Только на одном классе accuracy = 0.85. 
# relations = "Metric_hasValue_Value 0 0"
1	Только O
2	на O
3	одном O
4	классе O
5	accuracy B-Metric
6	= O
7	0.85 B-Value
8	. O

# sent_id = 292
# text =  Рассчитаем macro f1 score (0.92 + 0 + 0 + 0)/4 ~ 0.23, weighted f1 score (0.920.85+00.05+00.05+00.05) ~ 0.78. 
# relations = "Metric_hasValue_Value 0 0, Metric_hasValue_Value 1 1"
1	Рассчитаем O
2	macro B-Metric
3	f1 I-Metric
4	score I-Metric
5	( O
6	0.92 O
7	+ O
8	0 O
9	+ O
10	0 O
11	+ O
12	0)/4 O
13	~ O
14	0.23 B-Value
15	, O
16	weighted B-Metric
17	f1 I-Metric
18	score I-Metric
19	( O
20	0.920.85 O
21	+ O
22	00.05 O
23	+ O
24	00.05 O
25	+ O
26	00.05 O
27	) O
28	~ O
29	0.78 B-Value
30	. O

# sent_id = 293
# text =  TCR (Task completed rate) — процент диалогов, в которых частично или полностью решили проблему абонента. 
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	TCR B-Metric
2	( O
3	Task B-Metric
4	completed I-Metric
5	rate I-Metric
6	) O
7	— O
8	процент O
9	диалогов O
10	, O
11	в O
12	которых O
13	частично O
14	или O
15	полностью O
16	решили O
17	проблему O
18	абонента O
19	. O

# sent_id = 294
# text =  CSI (Customer Satisfaction Index) — средняя оценка, которую поставили клиенты боту. 
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	CSI B-Metric
2	( O
3	Customer B-Metric
4	Satisfaction I-Metric
5	Index I-Metric
6	) I-Metric
7	— O
8	средняя O
9	оценка O
10	, O
11	которую O
12	поставили O
13	клиенты O
14	боту O
15	. O

# sent_id = 295
# text =  AR (Automation rate) — процент диалогов, в которых клиент не перешел на оператора. 
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	AR B-Metric
2	( O
3	Automation B-Metric
4	rate I-Metric
5	) O
6	— O
7	процент O
8	диалогов O
9	, O
10	в O
11	которых O
12	клиент O
13	не O
14	перешел O
15	на O
16	оператора O
17	. O

# sent_id = 296
# text =  Мы попробовали разные предобученные модели с ресурса Hugging Face. 
# relations = ""
1	Мы O
2	попробовали O
3	разные O
4	предобученные O
5	модели B-Model
6	с O
7	ресурса O
8	Hugging B-InfoResource
9	Face I-InfoResource
10	. O

# sent_id = 297
# text =  Лучший результат показала модель DeepPavlov/rubert-base-cased. 
# relations = ""
1	Лучший O
2	результат O
3	показала O
4	модель O
5	DeepPavlov B-Model
6	/ I-Model
7	rubert I-Model
8	- I-Model
9	base I-Model
10	- I-Model
11	cased I-Model
12	. O

# sent_id = 298
# text =  Методы, реализованные с помощью библиотеки nlpaugMask insert. 
# relations = ""
1	Методы O
2	, O
3	реализованные O
4	с O
5	помощью O
6	библиотеки O
7	nlpaugMask B-Library
8	insert I-Library
9	. O

# sent_id = 299
# text =  Популярный способ аугментации через NMT-модели. 
# relations = ""
1	Популярный O
2	способ O
3	аугментации O
4	через O
5	NMT B-Model
6	- I-Model
7	модели I-Model
8	. O

# sent_id = 300
# text =  В результате переразметки и разделение моделей качество получилось следующее:Chain-model, sentiment, spamТак как в нашей задаче пространство всех интетов неопределенное (мы не знаем, сколько их), нужно было отделять имеющийся список интентов в чат-боте и остальную лексику, в которой могут содержаться и остальные интенты. 
# relations = ""
1	В O
2	результате O
3	переразметки O
4	и O
5	разделение O
6	моделей O
7	качество O
8	получилось O
9	следующее O
10	: O
11	Chain B-Model
12	- I-Model
13	model I-Model
14	, O
15	sentiment B-Model
16	, O
17	spamТак B-Model
18	как O
19	в O
20	нашей O
21	задаче O
22	пространство O
23	всех O
24	интетов O
25	неопределенное O
26	( O
27	мы O
28	не O
29	знаем O
30	, O
31	сколько O
32	их O
33	) O
34	, O
35	нужно O
36	было O
37	отделять O
38	имеющийся O
39	список O
40	интентов O
41	в O
42	чат O
43	- O
44	боте O
45	и O
46	остальную O
47	лексику O
48	, O
49	в O
50	которой O
51	могут O
52	содержаться O
53	и O
54	остальные O
55	интенты O
56	. O

# sent_id = 301
# text = Новая версия GPT-3, InstructGPT, лучше выполняет инструкции и выдает меньше оскорбительных выражений, дезинформации и ошибок в целом. 
# relations = "Model_isModificationOf_Model 1 0"
1	Новая O
2	версия O
3	GPT-3 B-Model
4	, O
5	InstructGPT B-Model
6	, O
7	лучше O
8	выполняет O
9	инструкции O
10	и O
11	выдает O
12	меньше O
13	оскорбительных O
14	выражений O
15	, O
16	дезинформации O
17	и O
18	ошибок O
19	в O
20	целом O
21	. O

# sent_id = 302
# text =  В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM. 
# relations = "Metric_hasValue_Value 1 0, Metric_hasValue_Value 1 1, Model_isAlternativeNameFor_Model 1 0"
1	В O
2	ходе O
3	тестирования O
4	модель O
5	китайских O
6	ученых O
7	показала O
8	улучшение O
9	на O
10	2,74 O
11	% O
12	по O
13	шкале O
14	F1 B-Metric
15	( O
16	оценка O
17	классификатора O
18	) O
19	сравнению O
20	с O
21	HFM B-Model
22	( O
23	Hierarchical B-Model
24	Fusion I-Model
25	Model I-Model
26	) O
27	, O
28	представленной O
29	в O
30	прошлом O
31	году O
32	: O
33	новая O
34	нейросеть B-Model
35	достигла O
36	86 B-Value
37	% I-Value
38	точности B-Metric
39	по O
40	сравнению O
41	с O
42	83 B-Value
43	% I-Value
44	у O
45	HFM B-Model
46	. O

# sent_id = 303
# text =  Тем не менее, в Facebook признали, что алгоритмы пока не готовы к широкому развертыванию — точность их работы составляет около 65-70%. 
# relations = "Metric_hasValue_Value 0 0"
1	Тем O
2	не O
3	менее O
4	, O
5	в O
6	Facebook B-Organization
7	признали O
8	, O
9	что O
10	алгоритмы O
11	пока O
12	не O
13	готовы O
14	к O
15	широкому O
16	развертыванию O
17	— O
18	точность B-Metric
19	их O
20	работы O
21	составляет O
22	около O
23	65 B-Value
24	- I-Value
25	70 I-Value
26	% I-Value
27	. O

# sent_id = 304
# text =  Несмотря на все свои недостатки, библиотека (неожиданно) оказалась довольно востребованной — например, нагуглил, что pymorphy был слегка использован при разработке системы Speech-to-Text для русского языка в рамках французского проекта Quaero, и рекомендуется в качестве учебного материала в некоторых ВУЗах. 
# relations = ""
1	Несмотря O
2	на O
3	все O
4	свои O
5	недостатки O
6	, O
7	библиотека B-Library
8	( O
9	неожиданно O
10	) O
11	оказалась O
12	довольно O
13	востребованной O
14	— O
15	например O
16	, O
17	нагуглил O
18	, O
19	что O
20	pymorphy B-Library
21	был O
22	слегка O
23	использован O
24	при O
25	разработке O
26	системы O
27	Speech B-App_system
28	- I-App_system
29	to I-App_system
30	- I-App_system
31	Text I-App_system
32	для O
33	русского B-Lang
34	языка I-Lang
35	в O
36	рамках O
37	французского O
38	проекта O
39	Quaero B-Activity
40	, O
41	и O
42	рекомендуется O
43	в O
44	качестве O
45	учебного O
46	материала O
47	в O
48	некоторых O
49	ВУЗах O
50	. O

# sent_id = 305
# text =  Решающим толчком к написанию pymorphy2 послужил проект OpenCorpora — ребята оттуда, кроме всего прочего (а там много «всего прочего»), взяли словарь из aot.ru, полностью переделали его структуру и занялись пополнением и прочими улучшениями. 
# relations = ""
1	Решающим O
2	толчком O
3	к O
4	написанию O
5	pymorphy2 B-Library
6	послужил O
7	проект O
8	OpenCorpora B-Activity
9	— O
10	ребята O
11	оттуда O
12	, O
13	кроме O
14	всего O
15	прочего O
16	( O
17	а O
18	там O
19	много O
20	« O
21	всего O
22	прочего O
23	» O
24	) O
25	, O
26	взяли O
27	словарь O
28	из O
29	aot.ru B-InfoResource
30	, O
31	полностью O
32	переделали O
33	его O
34	структуру O
35	и O
36	занялись O
37	пополнением O
38	и O
39	прочими O
40	улучшениями O
41	. O

# sent_id = 306
# text =  Что меня тут смутило: а) в статье ипользовалась C++ библиотека OpenFST (вроде самый популярный способ реализации конечных автоматов), но заставлять пользователей ставить ее вручную — не вариант; б) даже с использованием C++ библиотеки результаты, судя по статье, были достаточно скромные (2 тыс слов/сек против 100+ тыс слов/сек у mystem или lemmatizer); понятное дело, что эту цифру можно было бы, скорее всего, значительно улучшить (да и lightcaster пишет, что ничего не оптимизировал) — но все же; в) это один из тех подходов, который (по моему мнению) повышает порог вхождения — я считаю, что это скорее минус. 
# relations = ""
1	Что O
2	меня O
3	тут O
4	смутило O
5	: O
6	а O
7	) O
8	в O
9	статье O
10	ипользовалась O
11	C++ B-Environment
12	библиотека O
13	OpenFST B-Library
14	( O
15	вроде O
16	самый O
17	популярный O
18	способ O
19	реализации O
20	конечных O
21	автоматов O
22	) O
23	, O
24	но O
25	заставлять O
26	пользователей O
27	ставить O
28	ее O
29	вручную O
30	— O
31	не O
32	вариант O
33	; O
34	б O
35	) O
36	даже O
37	с O
38	использованием O
39	C++ B-Environment
40	библиотеки O
41	результаты O
42	, O
43	судя O
44	по O
45	статье O
46	, O
47	были O
48	достаточно O
49	скромные O
50	( O
51	2 O
52	тыс O
53	слов O
54	/ O
55	сек O
56	против O
57	100 O
58	+ O
59	тыс O
60	слов O
61	/ O
62	сек O
63	у O
64	mystem O
65	или O
66	lemmatizer O
67	) O
68	; O
69	понятное O
70	дело O
71	, O
72	что O
73	эту O
74	цифру O
75	можно O
76	было O
77	бы O
78	, O
79	скорее O
80	всего O
81	, O
82	значительно O
83	улучшить O
84	( O
85	да O
86	и O
87	lightcaster O
88	пишет O
89	, O
90	что O
91	ничего O
92	не O
93	оптимизировал O
94	) O
95	— O
96	но O
97	все O
98	же O
99	; O
100	в O
101	) O
102	это O
103	один O
104	из O
105	тех O
106	подходов O
107	, O
108	который O
109	( O
110	по O
111	моему O
112	мнению O
113	) O
114	повышает O
115	порог O
116	вхождения O
117	— O
118	я O
119	считаю O
120	, O
121	что O
122	это O
123	скорее O
124	минус O
125	. O

# sent_id = 307
# text =  В итоге получалось, что мне нужно было бы: разобраться, как оптимизировать код и почему даже с C++ библиотекой получается так медленно; написать более простую в установке обертку для OpenFST (или использовать другую реализацию FST — например, сделать свою) + сделать реализацию небольшой части OpenFST (или просто реализацию FST) на Python (чтоб pymorphy можно было использовать без компилятора), ну и формулировать все алгоритмы в терминах конечных автоматов. 
# relations = "Environment_isUsedIn_Library 0 2"
1	В O
2	итоге O
3	получалось O
4	, O
5	что O
6	мне O
7	нужно O
8	было O
9	бы O
10	: O
11	разобраться O
12	, O
13	как O
14	оптимизировать O
15	код O
16	и O
17	почему O
18	даже O
19	с O
20	C++ B-Environment
21	библиотекой O
22	получается O
23	так O
24	медленно O
25	; O
26	написать O
27	более O
28	простую O
29	в O
30	установке O
31	обертку O
32	для O
33	OpenFST B-Library
34	( O
35	или O
36	использовать O
37	другую O
38	реализацию O
39	FST B-Library
40	— O
41	например O
42	, O
43	сделать O
44	свою O
45	) O
46	+ O
47	сделать O
48	реализацию O
49	небольшой O
50	части O
51	OpenFST B-Library
52	( O
53	или O
54	просто O
55	реализацию O
56	FST B-Library
57	) O
58	на O
59	Python B-Environment
60	( O
61	чтоб O
62	pymorphy O
63	можно O
64	было O
65	использовать O
66	без O
67	компилятора O
68	) O
69	, O
70	ну O
71	и O
72	формулировать O
73	все O
74	алгоритмы O
75	в O
76	терминах O
77	конечных O
78	автоматов O
79	. O

# sent_id = 308
# text =  Сперва мне приглянулась библиотека libdatrie, про обертку для нее писал тут: habrahabr.ru/post/147963. 
# relations = ""
1	Сперва O
2	мне O
3	приглянулась O
4	библиотека O
5	libdatrie B-Library
6	, O
7	про O
8	обертку O
9	для O
10	нее O
11	писал O
12	тут O
13	: O
14	habrahabr.ru/post/147963 O
15	. O

# sent_id = 309
# text =  Но и этот второй вариант оставался узким местом, даже переписанный на Cython — что с ним делать, я не знал. 
# relations = ""
1	Но O
2	и O
3	этот O
4	второй O
5	вариант O
6	оставался O
7	узким O
8	местом O
9	, O
10	даже O
11	переписанный O
12	на O
13	Cython B-Environment
14	— O
15	что O
16	с O
17	ним O
18	делать O
19	, O
20	я O
21	не O
22	знал O
23	. O

# sent_id = 310
# text =  Выбор пал на C++ библиотеку marisa-trie, которую написал гуру структур данных Susumu Yata. 
# relations = "Library_hasAuthor_Person 0 0, Environment_isUsedIn_Library 0 0"
1	Выбор O
2	пал O
3	на O
4	C++ B-Environment
5	библиотеку O
6	marisa B-Library
7	- I-Library
8	trie I-Library
9	, O
10	которую O
11	написал O
12	гуру O
13	структур O
14	данных O
15	Susumu B-Person
16	Yata I-Person
17	. O

# sent_id = 311
# text = Было решено использовать библиотеку marisa-trie на C++, созданную экспертом в области структур данных Сусуму Ята.
# relations = "Library_hasAuthor_Person 0 0, Environment_isUsedIn_Library 0 0"
1	Было O
2	решено O
3	использовать O
4	библиотеку O
5	marisa B-Library
6	- I-Library
7	trie I-Library
8	на O
9	C++ B-Environment
10	, O
11	созданную O
12	экспертом O
13	в O
14	области O
15	структур O
16	данных O
17	Сусуму B-Person
18	Ята I-Person
19	. O

# sent_id = 312
# text =  С другой стороны, ускорить версию под CPython понятно как — переписать еще что-нибудь на Cython (к слову: делать я этого не планирую); с PyPy это не так очевидно. 
# relations = ""
1	С O
2	другой O
3	стороны O
4	, O
5	ускорить O
6	версию O
7	под O
8	CPython B-Environment
9	понятно O
10	как O
11	— O
12	переписать O
13	еще O
14	что O
15	- O
16	нибудь O
17	на O
18	Cython B-Environment
19	( O
20	к O
21	слову O
22	: O
23	делать O
24	я O
25	этого O
26	не O
27	планирую O
28	) O
29	; O
30	с O
31	PyPy B-Environment
32	это O
33	не O
34	так O
35	очевидно O
36	. O

# sent_id = 313
# text =  Если не использовать ни PyPy, ни C++ реализацию DAWG, pymorphy2 все равно будет работать во много раз быстрее (по прикидкам — в пару десятков раз), чем pymorphy1 cо всеми включенными ускорениями — ну и разбирать лучше. 
# relations = "Environment_isUsedIn_Library 1 0"
1	Если O
2	не O
3	использовать O
4	ни O
5	PyPy B-Environment
6	, O
7	ни O
8	C++ B-Environment
9	реализацию O
10	DAWG B-Library
11	, O
12	pymorphy2 B-Library
13	все O
14	равно O
15	будет O
16	работать O
17	во O
18	много O
19	раз O
20	быстрее O
21	( O
22	по O
23	прикидкам O
24	— O
25	в O
26	пару O
27	десятков O
28	раз O
29	) O
30	, O
31	чем O
32	pymorphy1 B-Library
33	cо O
34	всеми O
35	включенными O
36	ускорениями O
37	— O
38	ну O
39	и O
40	разбирать O
41	лучше O
42	. O

# sent_id = 314
# text =  Там сейчас есть фичи, которых нет в pymorphy2 (например, интеграция с django, согласование слов с цифрами и склонение фамилий), но в версии на битбакете я поломал обратную совместимость. 
# relations = ""
1	Там O
2	сейчас O
3	есть O
4	фичи O
5	, O
6	которых O
7	нет O
8	в O
9	pymorphy2 B-Library
10	( O
11	например O
12	, O
13	интеграция O
14	с O
15	django B-Library
16	, O
17	согласование O
18	слов O
19	с O
20	цифрами O
21	и O
22	склонение O
23	фамилий O
24	) O
25	, O
26	но O
27	в O
28	версии O
29	на O
30	битбакете O
31	я O
32	поломал O
33	обратную O
34	совместимость O
35	. O

# sent_id = 315
# text =  К примеру, одна из наиболее известных систем такого типа Grammarly выступает против использования пассивного залога. 
# relations = ""
1	К O
2	примеру O
3	, O
4	одна O
5	из O
6	наиболее O
7	известных O
8	систем O
9	такого O
10	типа O
11	Grammarly B-App_system
12	выступает O
13	против O
14	использования O
15	пассивного O
16	залога O
17	. O

# sent_id = 316
# text =  Например, сервис Textly.AI разрешает использовать свои плагины для Chrome и Firefox без создания аккаунта, а в их веб-приложении есть режим, похожий на секретный чат в браузере – после выхода из него, весь откорректированный алгоритмом контент удаляется. 
# relations = ""
1	Например O
2	, O
3	сервис O
4	Textly B-App_system
5	. I-App_system
6	AI I-App_system
7	разрешает O
8	использовать O
9	свои O
10	плагины O
11	для O
12	Chrome B-Technology
13	и O
14	Firefox B-Technology
15	без O
16	создания O
17	аккаунта O
18	, O
19	а O
20	в O
21	их O
22	веб O
23	- O
24	приложении O
25	есть O
26	режим O
27	, O
28	похожий O
29	на O
30	секретный O
31	чат O
32	в O
33	браузере O
34	– O
35	после O
36	выхода O
37	из O
38	него O
39	, O
40	весь O
41	откорректированный O
42	алгоритмом O
43	контент O
44	удаляется O
45	. O

# sent_id = 317
# text =  Еще пример: сервис Ginger предлагает инструмент для перефразирования предложений – пользователь может написать совсем простое, а ему дадут чуть более сложный вариант (не совсем то, что нужно, но хоть что-то). 
# relations = ""
1	Еще O
2	пример O
3	: O
4	сервис O
5	Ginger B-App_system
6	предлагает O
7	инструмент O
8	для O
9	перефразирования O
10	предложений O
11	– O
12	пользователь O
13	может O
14	написать O
15	совсем O
16	простое O
17	, O
18	а O
19	ему O
20	дадут O
21	чуть O
22	более O
23	сложный O
24	вариант O
25	( O
26	не O
27	совсем O
28	то O
29	, O
30	что O
31	нужно O
32	, O
33	но O
34	хоть O
35	что O
36	- O
37	то O
38	) O
39	. O

# sent_id = 318
# text =  Например, на NLP-progress публикуются последние достижения в области commonsense reasoning. 
# relations = ""
1	Например O
2	, O
3	на O
4	NLP B-InfoResource
5	- O
6	progress O
7	публикуются O
8	последние O
9	достижения O
10	в O
11	области O
12	commonsense B-Science
13	reasoning I-Science
14	. O

# sent_id = 319
# text =  В этом посте мы расскажем, как мы создали датасет для задачи Common Sense Reasoning в одной из ее возможных формулировок, предложенной в статье event2mind, а также адаптировали английскую модель event2mind от AllenNLP для русского языка. 
# relations = "Model_isUsedForSolving_Task 0 0, Model_Language_Lang 0 0, Model_hasAuthor_Organization 0 0"
1	В O
2	этом O
3	посте O
4	мы O
5	расскажем O
6	, O
7	как O
8	мы O
9	создали O
10	датасет O
11	для O
12	задачи O
13	Common B-Task
14	Sense I-Task
15	Reasoning I-Task
16	в O
17	одной O
18	из O
19	ее O
20	возможных O
21	формулировок O
22	, O
23	предложенной O
24	в O
25	статье O
26	event2mind O
27	, O
28	а O
29	также O
30	адаптировали O
31	английскую O
32	модель O
33	event2mind B-Model
34	от O
35	AllenNLP B-Organization
36	для O
37	русского B-Lang
38	языка I-Lang
39	. O

# sent_id = 320
# text =  Тексты из SynTagRus, который является частью Русского Национального корпуса и содержит художественные тексты вместе с новостями. 
# relations = ""
1	Тексты O
2	из O
3	SynTagRus B-Corpus
4	, O
5	который O
6	является O
7	частью O
8	Русского B-Corpus
9	Национального I-Corpus
10	корпуса I-Corpus
11	и O
12	содержит O
13	художественные O
14	тексты O
15	вместе O
16	с O
17	новостями O
18	. O

# sent_id = 321
# text =  Для поиска подобных паттернов был использован синтаксический парсер UdPipe, с помощью которого мы выделяли в текстах паттерны вида глагол + зависимые слова в синтаксическом дереве, как например на рисунке 2, которые удовлетворяли одному из следующих правил: 
# relations = ""
1	Для O
2	поиска O
3	подобных O
4	паттернов O
5	был O
6	использован O
7	синтаксический O
8	парсер O
9	UdPipe B-Technology
10	, O
11	с O
12	помощью O
13	которого O
14	мы O
15	выделяли O
16	в O
17	текстах O
18	паттерны O
19	вида O
20	глагол O
21	+ O
22	зависимые O
23	слова O
24	в O
25	синтаксическом O
26	дереве O
27	, O
28	как O
29	например O
30	на O
31	рисунке O
32	2 O
33	, O
34	которые O
35	удовлетворяли O
36	одному O
37	из O
38	следующих O
39	правил O

# sent_id = 322
# text =  Однако уже при 30000 примеров, loss и recall практически не отличаются от результатов на полном объеме данных. 
# relations = ""
1	Однако O
2	уже O
3	при O
4	30000 O
5	примеров O
6	, O
7	loss B-Metric
8	и O
9	recall B-Metric
10	практически O
11	не O
12	отличаются O
13	от O
14	результатов O
15	на O
16	полном O
17	объеме O
18	данных O
19	. O

# sent_id = 323
# text =  Изначально английский корпус собран из нескольких источников: ROC Story training set, the GoogleSyntactic N-grams, the Spinn3r corpus и idioms. 
# relations = ""
1	Изначально O
2	английский O
3	корпус O
4	собран O
5	из O
6	нескольких O
7	источников O
8	: O
9	ROC B-Corpus
10	Story I-Corpus
11	training I-Corpus
12	set I-Corpus
13	, O
14	the B-Corpus
15	GoogleSyntactic I-Corpus
16	N I-Corpus
17	- I-Corpus
18	grams I-Corpus
19	, O
20	the B-Corpus
21	Spinn3r I-Corpus
22	corpus I-Corpus
23	и O
24	idioms B-Corpus
25	. O

# sent_id = 324
# text =  Поэтому мы взяли только примеры из ROC-story. 
# relations = ""
1	Поэтому O
2	мы O
3	взяли O
4	только O
5	примеры O
6	из O
7	ROC B-Corpus
8	- I-Corpus
9	story I-Corpus
10	. O

# sent_id = 325
# text =  таблицу 2), у этого источника коэффициент согласованности аннотаторов (Cohen's kappa coefficient), равный 0.57. 
# relations = "Metric_hasValue_Value 0 0, Metric_hasValue_Value 1 0, Metric_isAlternativeNameFor_Metric 1 0"
1	таблицу O
2	2 O
3	) O
4	, O
5	у O
6	этого O
7	источника O
8	коэффициент B-Metric
9	согласованности I-Metric
10	аннотаторов I-Metric
11	( O
12	Cohen B-Metric
13	's I-Metric
14	kappa I-Metric
15	coefficient I-Metric
16	) O
17	, O
18	равный O
19	0.57 B-Value
20	. O

# sent_id = 326
# text =  При этом fasttext embeddings, обученные на ruscorpora показали себя лучше обученных на araneum. 
# relations = "Model_isTrainedOn_Dataset 0 0, Model_isTrainedOn_Dataset 0 1"
1	При O
2	этом O
3	fasttext B-Model
4	embeddings I-Model
5	, O
6	обученные O
7	на O
8	ruscorpora B-Dataset
9	показали O
10	себя O
11	лучше O
12	обученных O
13	на O
14	araneum B-Dataset
15	. O

# sent_id = 327
# text =  Сегодня мы расскажем, как помогли НПО Энергомаш создать корпоративную интеллектуальную информационно-поисковую систему (КИИПС) на базе ABBYY Intelligent Search – такую же удобную и быструю, как популярные поисковики. 
# relations = "Application_hasAuthor_Organization 0 0, Application_hasAuthor_Organization 1 0, Application_isAlternativeNameFor_Application 1 0"
1	Сегодня O
2	мы O
3	расскажем O
4	, O
5	как O
6	помогли O
7	НПО B-Organization
8	Энергомаш I-Organization
9	создать O
10	корпоративную B-App_system
11	интеллектуальную I-App_system
12	информационно I-App_system
13	- I-App_system
14	поисковую I-App_system
15	систему I-App_system
16	( O
17	КИИПС B-App_system
18	) O
19	на O
20	базе O
21	ABBYY B-App_system
22	Intelligent I-App_system
23	Search I-App_system
24	– O
25	такую O
26	же O
27	удобную O
28	и O
29	быструю O
30	, O
31	как O
32	популярные O
33	поисковики O
34	. O

# sent_id = 328
# text =  Сегодня мы расскажем о том, как мы содействовали НПО "Энергомаш" в разработке и внедрении их корпоративной интеллектуальной информационно-поисковой системы (КИИПС).
# relations = "Application_hasAuthor_Organization 0 0, Application_hasAuthor_Organization 1 0, Application_isAlternativeNameFor_Application 1 0"
1	Сегодня O
2	мы O
3	расскажем O
4	о O
5	том O
6	, O
7	как O
8	мы O
9	содействовали O
10	НПО B-Organization
11	" I-Organization
12	Энергомаш I-Organization
13	" I-Organization
14	в O
15	разработке O
16	и O
17	внедрении O
18	их O
19	корпоративной B-App_system
20	интеллектуальной I-App_system
21	информационно I-App_system
22	- I-App_system
23	поисковой I-App_system
24	системы I-App_system
25	( O
26	КИИПС B-App_system
27	) O
28	. O

# sent_id = 329
# text =  Энергомаш рассматривал несколько поисковых систем, но в итоге решил попробовать ABBYY Intelligent Search. 
# relations = ""
1	Энергомаш B-Organization
2	рассматривал O
3	несколько O
4	поисковых O
5	систем O
6	, O
7	но O
8	в O
9	итоге O
10	решил O
11	попробовать O
12	ABBYY B-App_system
13	Intelligent I-App_system
14	Search I-App_system
15	. O

# sent_id = 330
# text =  Энергомаш подключил к поиску 7 корпоративных источников: систему электронного документооборота LanDocs, файловое хранилище, ИБД, систему поддержки жизненного цикла изделия TeamCenter, систему управления ресурсами Галактика ERP и AMM, информационную систему управления проектами. 
# relations = ""
1	Энергомаш B-Organization
2	подключил O
3	к O
4	поиску O
5	7 O
6	корпоративных O
7	источников O
8	: O
9	систему B-App_system
10	электронного I-App_system
11	документооборота I-App_system
12	LanDocs I-App_system
13	, O
14	файловое O
15	хранилище O
16	, O
17	ИБД B-Dataset
18	, O
19	систему O
20	поддержки O
21	жизненного O
22	цикла O
23	изделия O
24	TeamCenter B-App_system
25	, O
26	систему O
27	управления O
28	ресурсами O
29	Галактика B-App_system
30	ERP I-App_system
31	и O
32	AMM B-App_system
33	, O
34	информационную O
35	систему O
36	управления O
37	проектами O
38	. O

# sent_id = 331
# text =  Доступ в Систему корпоративного поиска организован через внутренний портал предприятия на главной странице. 
# relations = ""
1	Доступ O
2	в O
3	Систему B-App_system
4	корпоративного I-App_system
5	поиска I-App_system
6	организован O
7	через O
8	внутренний O
9	портал O
10	предприятия O
11	на O
12	главной O
13	странице O
14	. O

# sent_id = 332
# text =  По данным Google Books Ngram Viewer — поискового онлайн-сервиса Google, который строит графики частоты упоминания языковых единиц на основе огромного количества печатных источников, популярность и интерес к NLP стремительно растет последние 20 лет. 
# relations = "Application_isUsedIn_Science 0 0, Application_hasAuthor_Organization 0 0"
1	По O
2	данным O
3	Google B-App_system
4	Books I-App_system
5	Ngram I-App_system
6	Viewer I-App_system
7	— O
8	поискового O
9	онлайн O
10	- O
11	сервиса O
12	Google B-Organization
13	, O
14	который O
15	строит O
16	графики O
17	частоты O
18	упоминания O
19	языковых O
20	единиц O
21	на O
22	основе O
23	огромного O
24	количества O
25	печатных O
26	источников O
27	, O
28	популярность O
29	и O
30	интерес O
31	к O
32	NLP B-Science
33	стремительно O
34	растет O
35	последние O
36	20 O
37	лет O
38	. O

# sent_id = 333
# text =  Heliograf способен генерировать новостные, финансовые и подобные им отчеты, и даже посты для социальных медиа. 
# relations = ""
1	Heliograf B-Technology
2	способен O
3	генерировать O
4	новостные O
5	, O
6	финансовые O
7	и O
8	подобные O
9	им O
10	отчеты O
11	, O
12	и O
13	даже O
14	посты O
15	для O
16	социальных O
17	медиа O
18	. O

# sent_id = 334
# text =  Так же, как Wordsmith, эта система используется репортерами при подготовке тысяч корпоративных финансовых отчетов, помогая Bloomberg News в нелегкой конкурентной борьбе с агентством Reuters, а также с новыми участниками информационной гонки – продвинутыми хедж-фондами, которые также используют системы на базе ИИ для поставки свежих новостей и аналитики своим клиентам. 
# relations = ""
1	Так O
2	же O
3	, O
4	как O
5	Wordsmith B-App_system
6	, O
7	эта O
8	система O
9	используется O
10	репортерами O
11	при O
12	подготовке O
13	тысяч O
14	корпоративных O
15	финансовых O
16	отчетов O
17	, O
18	помогая O
19	Bloomberg B-Organization
20	News I-Organization
21	в O
22	нелегкой O
23	конкурентной O
24	борьбе O
25	с O
26	агентством O
27	Reuters B-Organization
28	, O
29	а O
30	также O
31	с O
32	новыми O
33	участниками O
34	информационной O
35	гонки O
36	– O
37	продвинутыми O
38	хедж O
39	- O
40	фондами O
41	, O
42	которые O
43	также O
44	используют O
45	системы O
46	на O
47	базе O
48	ИИ O
49	для O
50	поставки O
51	свежих O
52	новостей O
53	и O
54	аналитики O
55	своим O
56	клиентам O
57	. O

# sent_id = 335
# text = Наконец, компания Forbes недавно сообщила, что тестирует собственную систему Bertie, которая помогает журналистам с написанием черновых вариантов и шаблонов статей. 
# relations = "Application_hasAuthor_Organization 0 0"
1	Наконец O
2	, O
3	компания O
4	Forbes B-Organization
5	недавно O
6	сообщила O
7	, O
8	что O
9	тестирует O
10	собственную O
11	систему O
12	Bertie B-App_system
13	, O
14	которая O
15	помогает O
16	журналистам O
17	с O
18	написанием O
19	черновых O
20	вариантов O
21	и O
22	шаблонов O
23	статей O
24	. O

# sent_id = 336
# text =  Так как например модель «wiki_ru», содержит в своем корпусе 1,88 млн слов в словаре, и 2 млн n-грамм токенов, (300 мерных) векторов. 
# relations = ""
1	Так O
2	как O
3	например O
4	модель O
5	« O
6	wiki_ru B-Model
7	» O
8	, O
9	содержит O
10	в O
11	своем O
12	корпусе O
13	1,88 O
14	млн O
15	слов O
16	в O
17	словаре O
18	, O
19	и O
20	2 O
21	млн O
22	n O
23	- O
24	грамм O
25	токенов O
26	, O
27	( O
28	300 O
29	мерных O
30	) O
31	векторов O
32	. O

# sent_id = 337
# text =  Мы в Badoo и Bumble стараемся оградить пользователей от неприятных ситуаций, поэтому внедрили инструмент Rude Message Detector. 
# relations = ""
1	Мы O
2	в O
3	Badoo B-Organization
4	и O
5	Bumble B-Organization
6	стараемся O
7	оградить O
8	пользователей O
9	от O
10	неприятных O
11	ситуаций O
12	, O
13	поэтому O
14	внедрили O
15	инструмент O
16	Rude B-App_system
17	Message I-App_system
18	Detector I-App_system
19	. O

# sent_id = 338
# text =  Она очень похожа на SentencePiece, но выполняет чуть больше действий над некоторыми токенами 
# relations = ""
1	Она O
2	очень O
3	похожа O
4	на O
5	SentencePiece B-Library
6	, O
7	но O
8	выполняет O
9	чуть O
10	больше O
11	действий O
12	над O
13	некоторыми O
14	токенами O

# sent_id = 339
# text = Нативная TensorFlow-реализация токенизатора требуется для XLM-RoBERTa. 
# relations = ""
1	Нативная O
2	TensorFlow B-Library
3	- O
4	реализация O
5	токенизатора O
6	требуется O
7	для O
8	XLM B-Model
9	- I-Model
10	RoBERTa I-Model
11	. O

# sent_id = 340
# text =  Данные: 30 GB русского текста, в котором была Википедия, новости, часть корпуса Taiga и немного книг. 
# relations = ""
1	Данные O
2	: O
3	30 O
4	GB O
5	русского O
6	текста O
7	, O
8	в O
9	котором O
10	была O
11	Википедия B-InfoResource
12	, O
13	новости O
14	, O
15	часть O
16	корпуса O
17	Taiga B-Corpus
18	и O
19	немного O
20	книг O
21	. O

# sent_id = 341
# text =  Основным из них был SberSQUAD. 
# relations = ""
1	Основным O
2	из O
3	них O
4	был O
5	SberSQUAD B-Model
6	. O

# sent_id = 342
# text =  Позднее, на RussianSuperGLUE, она показала себя чуть лучше. 
# relations = ""
1	Позднее O
2	, O
3	на O
4	RussianSuperGLUE B-Library
5	, O
6	она O
7	показала O
8	себя O
9	чуть O
10	лучше O
11	. O

# sent_id = 343
# text =  В последствии эта модель легла в основу модели SBERT наших коллег из смежной команды SberDevices, которую они выложили в открытый доступ. 
# relations = "Model_hasAuthor_Organization 0 0"
1	В O
2	последствии O
3	эта O
4	модель O
5	легла O
6	в O
7	основу O
8	модели O
9	SBERT B-Model
10	наших O
11	коллег O
12	из O
13	смежной O
14	команды O
15	SberDevices B-Organization
16	, O
17	которую O
18	они O
19	выложили O
20	в O
21	открытый O
22	доступ O
23	. O

# sent_id = 344
# text =  Детали: немного переделали код для обучения из библиотеки Transformers. 
# relations = ""
1	Детали O
2	: O
3	немного O
4	переделали O
5	код O
6	для O
7	обучения O
8	из O
9	библиотеки O
10	Transformers B-Library
11	. O

# sent_id = 345
# text =  Обучали на всём русском корпусе, что у нас был для ruGPT-3 (Википедия, книги, новости, русский Common Crawl и т.д.). 
# relations = "Model_isTrainedOn_Corpus 0 0"
1	Обучали O
2	на O
3	всём O
4	русском O
5	корпусе O
6	, O
7	что O
8	у O
9	нас O
10	был O
11	для O
12	ruGPT-3 B-Model
13	( O
14	Википедия B-InfoResource
15	, O
16	книги O
17	, O
18	новости O
19	, O
20	русский O
21	Common B-Corpus
22	Crawl I-Corpus
23	и O
24	т O
25	. O
26	д. O
27	) O
28	. O

# sent_id = 346
# text =  На разных заданиях топовые метрики далеко не только у ruT5-large: лучшие single-model решения также есть у ruRoBERTa-large (задача TERRa и DaNetQA). 
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1, Model_isUsedForSolving_Task 1 0, Model_isUsedForSolving_Task 1 1"
1	На O
2	разных O
3	заданиях O
4	топовые O
5	метрики O
6	далеко O
7	не O
8	только O
9	у O
10	ruT5-large B-Model
11	: O
12	лучшие O
13	single O
14	- O
15	model O
16	решения O
17	также O
18	есть O
19	у O
20	ruRoBERTa B-Model
21	- I-Model
22	large I-Model
23	( O
24	задача O
25	TERRa B-Task
26	и O
27	DaNetQA B-Task
28	) O
29	. O

# sent_id = 347
# text =  А на некоторых заданиях лучших результатов удалось достичь на few-shot, т. е. без дообучения модели (задача RCB и RuCoS, YaLM от Яндекса). 
# relations = "Model_hasAuthor_Organization 0 0, Dataset_isTrainedForSolving_Task 0 0, Model_isTrainedOn_Dataset 0 0"
1	А O
2	на O
3	некоторых O
4	заданиях O
5	лучших O
6	результатов O
7	удалось O
8	достичь O
9	на O
10	few B-Task
11	- I-Task
12	shot I-Task
13	, O
14	т O
15	. O
16	е O
17	. O
18	без O
19	дообучения O
20	модели O
21	( O
22	задача O
23	RCB B-Task
24	и O
25	RuCoS B-Dataset
26	, O
27	YaLM B-Model
28	от O
29	Яндекса B-Organization
30	) O
31	. O

# sent_id = 348
# text =  Модели ALBERT, RoBERTa и DistilBERT из библиотеки Hugging Face — самые популярные на сегодняшний день. 
# relations = "Model_isIncludedIn_Library 0 0, Model_isIncludedIn_Library 1 0, Model_isIncludedIn_Library 2 0"
1	Модели O
2	ALBERT B-Model
3	, O
4	RoBERTa B-Model
5	и O
6	DistilBERT B-Model
7	из O
8	библиотеки O
9	Hugging B-Library
10	Face I-Library
11	— O
12	самые O
13	популярные O
14	на O
15	сегодняшний O
16	день O
17	. O

# sent_id = 349
# text =  Есть стандартная задача извлечения именованных сущностей из текста (NER). 
# relations = ""
1	Есть O
2	стандартная O
3	задача O
4	извлечения O
5	именованных O
6	сущностей O
7	из O
8	текста O
9	( O
10	NER B-Task
11	) O
12	. O

# sent_id = 350
# text =  Задача старая и хорошо изученная, для английского языка существует масса коммерческих и открытых решений: Spacy, Stanford NER, OpenNLP, NLTK, MITIE, Google Natural Language API, ParallelDots, Aylien, Rosette, TextRazor. 
# relations = ""
1	Задача O
2	старая O
3	и O
4	хорошо O
5	изученная O
6	, O
7	для O
8	английского B-Lang
9	языка I-Lang
10	существует O
11	масса O
12	коммерческих O
13	и O
14	открытых O
15	решений O
16	: O
17	Spacy B-Library
18	, O
19	Stanford B-Library
20	NER I-Library
21	, O
22	OpenNLP B-Library
23	, O
24	NLTK B-Library
25	, O
26	MITIE B-Library
27	, O
28	Google B-Library
29	Natural I-Library
30	Language I-Library
31	API I-Library
32	, O
33	ParallelDots B-Library
34	, O
35	Aylien B-Library
36	, O
37	Rosette B-Library
38	, O
39	TextRazor B-Library
40	. O

# sent_id = 351
# text =  Для русского тоже есть хорошие решения, но они в основном закрытые: DaData, Pullenti, Abbyy Infoextractor, Dictum, Eureka, Promt, RCO, AOT, Ahunter. 
# relations = ""
1	Для O
2	русского O
3	тоже O
4	есть O
5	хорошие O
6	решения O
7	, O
8	но O
9	они O
10	в O
11	основном O
12	закрытые O
13	: O
14	DaData B-App_system
15	, O
16	Pullenti B-Library
17	, O
18	Abbyy B-Technology
19	Infoextractor I-Technology
20	, O
21	Dictum B-Library
22	, O
23	Eureka B-Library
24	, O
25	Promt B-Library
26	, O
27	RCO B-Library
28	, O
29	AOT B-App_system
30	, O
31	Ahunter B-Library
32	. O

# sent_id = 352
# text =  Из открытого мне известен только Томита-парсер и свежий Deepmipt NER. 
# relations = ""
1	Из O
2	открытого O
3	мне O
4	известен O
5	только O
6	Томита B-Technology
7	- I-Technology
8	парсер I-Technology
9	и O
10	свежий O
11	Deepmipt B-Library
12	NER I-Library
13	. O

# sent_id = 353
# text =  Год назад Дима Веселов начал проект Natasha. 
# relations = ""
1	Год O
2	назад O
3	Дима B-Person
4	Веселов I-Person
5	начал O
6	проект O
7	Natasha B-Activity
8	. O

# sent_id = 354
# text =  Natasha — это аналог Томита-парсера для Python (Yargy-парсер) плюс набор готовых правил для извлечения имён, адресов, дат, сумм денег и других сущностей. 
# relations = "Environment_isUsedIn_Application 0 1"
1	Natasha B-Library
2	— O
3	это O
4	аналог O
5	Томита B-Technology
6	- I-Technology
7	парсера I-Technology
8	для O
9	Python B-Environment
10	( O
11	Yargy B-Technology
12	- I-Technology
13	парсер I-Technology
14	) O
15	плюс O
16	набор O
17	готовых O
18	правил O
19	для O
20	извлечения O
21	имён O
22	, O
23	адресов O
24	, O
25	дат O
26	, O
27	сумм O
28	денег O
29	и O
30	других O
31	сущностей O
32	. O

# sent_id = 355
# text =  У топовых решений F1-мера для имён была 0.9+. 
# relations = "Metric_hasValue_Value 0 0"
1	У O
2	топовых O
3	решений O
4	F1-мера B-Metric
5	для O
6	имён O
7	была O
8	0.9 B-Value
9	+ O
10	. O

# sent_id = 356
# text =  У Natasha результат хуже — 0.78. 
# relations = ""
1	У O
2	Natasha B-Model
3	результат O
4	хуже O
5	— O
6	0.78 B-Value
7	. O

# sent_id = 357
# text =  Yargy — сложная и интересная библиотека, в этой статье мы рассмотрим только простые примеры использования. 
# relations = ""
1	Yargy B-Library
2	— O
3	сложная O
4	и O
5	интересная O
6	библиотека O
7	, O
8	в O
9	этой O
10	статье O
11	мы O
12	рассмотрим O
13	только O
14	простые O
15	примеры O
16	использования O
17	. O

# sent_id = 358
# text =  В словаре Opencorpora, который использует pymorphy2, для имён ставится метка Name, для фамилий — метка Surn. 
# relations = ""
1	В O
2	словаре O
3	Opencorpora B-Corpus
4	, O
5	который O
6	использует O
7	pymorphy2 B-Library
8	, O
9	для O
10	имён O
11	ставится O
12	метка O
13	Name O
14	, O
15	для O
16	фамилий O
17	— O
18	метка O
19	Surn O
20	. O

# sent_id = 359
# text =  Например, качество извлечения имён у Natasha очень далеко от SOTA. 
# relations = ""
1	Например O
2	, O
3	качество O
4	извлечения O
5	имён O
6	у O
7	Natasha B-Library
8	очень O
9	далеко O
10	от O
11	SOTA B-Library
12	. O

# sent_id = 360
# text =  В начале 2018 года исследователи из OpenAI, университета Сан-Франциско, Алленовского института искусственного интеллекта и Вашингтонского университета одновременно вывели хитроумный способ приблизиться к этому. 
# relations = ""
1	В O
2	начале O
3	2018 B-Date
4	года O
5	исследователи O
6	из O
7	OpenAI B-Organization
8	, O
9	университета O
10	Сан O
11	- O
12	Франциско O
13	, O
14	Алленовского B-Organization
15	института I-Organization
16	искусственного I-Organization
17	интеллекта I-Organization
18	и O
19	Вашингтонского B-Organization
20	университета I-Organization
21	одновременно O
22	вывели O
23	хитроумный O
24	способ O
25	приблизиться O
26	к O
27	этому O
28	. O

# sent_id = 361
# text =  Набор данных назвали Гансом (Heuristic Analysis for Natural-Language-Inference Systems, HANS) [эвристический анализ систем, делающих заключения на основе естественного языка]. 
# relations = "Dataset_isAlternativeNameFor_Dataset 1 0, Dataset_isAlternativeNameFor_Dataset 2 0, Dataset_isAlternativeNameFor_Dataset 2 1"
1	Набор O
2	данных O
3	назвали O
4	Гансом B-Dataset
5	( O
6	Heuristic B-Dataset
7	Analysis I-Dataset
8	for I-Dataset
9	Natural I-Dataset
10	- I-Dataset
11	Language I-Dataset
12	- I-Dataset
13	Inference I-Dataset
14	Systems I-Dataset
15	, O
16	HANS B-Dataset
17	) O
18	[ O
19	эвристический O
20	анализ O
21	систем O
22	, O
23	делающих O
24	заключения O
25	на O
26	основе O
27	естественного O
28	языка O
29	] O
30	. O

# sent_id = 363
# text =  Рады представить вам PyCaret – библиотеку машинного обучения с открытым исходным кодом на Python для обучения и развертывания моделей с учителем и без учителя в low-code среде. 
# relations = "Environment_isUsedIn_Library 0 0"
1	Рады O
2	представить O
3	вам O
4	PyCaret B-Library
5	– O
6	библиотеку O
7	машинного O
8	обучения O
9	с O
10	открытым O
11	исходным O
12	кодом O
13	на O
14	Python B-Environment
15	для O
16	обучения O
17	и O
18	развертывания O
19	моделей O
20	с O
21	учителем O
22	и O
23	без O
24	учителя O
25	в O
26	low O
27	- O
28	code O
29	среде O
30	. O

# sent_id = 364
# text =  PyCaret позволит вам пройти путь от подготовки данных до развертывания модели за несколько секунд в той notebook-среде, которую вы выберете. 
# relations = ""
1	PyCaret B-Library
2	позволит O
3	вам O
4	пройти O
5	путь O
6	от O
7	подготовки O
8	данных O
9	до O
10	развертывания O
11	модели O
12	за O
13	несколько O
14	секунд O
15	в O
16	той O
17	notebook B-App_system
18	- O
19	среде O
20	, O
21	которую O
22	вы O
23	выберете O
24	. O

# sent_id = 365
# text =  PyCaret – это, по сути, оболочка Python над несколькими библиотеками машинного обучения, такими как scikit-learn, XGBoost, Microsoft LightGBM, spaCy и многими другими. 
# relations = "Environment_isUsedIn_Library 0 0"
1	PyCaret B-Library
2	– O
3	это O
4	, O
5	по O
6	сути O
7	, O
8	оболочка O
9	Python B-Environment
10	над O
11	несколькими O
12	библиотеками O
13	машинного O
14	обучения O
15	, O
16	такими O
17	как O
18	scikit B-Library
19	- I-Library
20	learn I-Library
21	, O
22	XGBoost B-Library
23	, O
24	Microsoft B-Library
25	LightGBM I-Library
26	, O
27	spaCy O
28	и O
29	многими O
30	другими O
31	. O

# sent_id = 366
# text =  Первый стабильный релиз PyCaret версии 1.0.0 можно установить с помощью pip. 
# relations = ""
1	Первый O
2	стабильный O
3	релиз O
4	PyCaret B-Library
5	версии O
6	1.0.0 O
7	можно O
8	установить O
9	с O
10	помощью O
11	pip B-Environment
12	. O

# sent_id = 367
# text =  Этот датасет доступен на GitHub-репозитории PyCaret. 
# relations = ""
1	Этот O
2	датасет O
3	доступен O
4	на O
5	GitHub B-InfoResource
6	- O
7	репозитории O
8	PyCaret B-Library
9	. O

# sent_id = 368
# text =  Для классификации: Accuracy, AUC, Recall, Precision, F1, Kappa. 
# relations = ""
1	Для O
2	классификации B-Task
3	: O
4	Accuracy B-Metric
5	, O
6	AUC B-Metric
7	, O
8	Recall B-Metric
9	, O
10	Precision B-Metric
11	, O
12	F1 B-Metric
13	, O
14	Kappa B-Metric
15	. O

# sent_id = 369
# text =  Для регрессии: MAE, MSE, RMSE, R2, RMSLE, MAPE 
1	Для O
2	регрессии B-Task
3	: O
4	MAE B-Metric
5	, O
6	MSE B-Metric
7	, O
8	RMSE B-Metric
9	, O
10	R2 B-Metric
11	, O
12	RMSLE B-Metric
13	, O
14	MAPE B-Metric
15	. O

# sent_id = 370
# text =  Стэнфордская нейросеть определяет тональность текста с точностью 85% 
# relations = "Metric_hasValue_Value 0 0, Metric_isUsedFor_Model 0 0"
1	Стэнфордская B-Model
2	нейросеть I-Model
3	определяет O
4	тональность O
5	текста O
6	с O
7	точностью B-Metric
8	85 B-Value
9	% I-Value

# sent_id = 371
# text =  Нейросеть от Стэнфорда демонстрирует точность в 85% при определении тональности текста. 
# relations = "Metric_isUsedFor_Model 0 0, Model_hasAuthor_Organization 0 0, Metric_hasValue_Value 0 0"
1	Нейросеть B-Model
2	от O
3	Стэнфорда B-Organization
4	демонстрирует O
5	точность B-Metric
6	в O
7	85 B-Value
8	% I-Value
9	при O
10	определении O
11	тональности O
12	текста O
13	. O

# sent_id = 372
# text =  Для англоязычного nlp-сообщества задача поиска сложного слова в тексте называется так: CWI – complex word identification. 
# relations = "Task_isAlternativeNameFor_Task 1 0"
1	Для O
2	англоязычного O
3	nlp O
4	- O
5	сообщества O
6	задача O
7	поиска O
8	сложного O
9	слова O
10	в O
11	тексте O
12	называется O
13	так O
14	: O
15	CWI B-Task
16	– O
17	complex B-Task
18	word I-Task
19	identification I-Task
20	. O

# sent_id = 373
# text =  Примеры обучения LDA часто демонстрируются на "образцовых" датасетах, например "20 newsgroups dataset", который есть в sklearn. 
# relations = "Model_isTrainedOn_Dataset 0 0"
1	Примеры O
2	обучения O
3	LDA B-Model
4	часто O
5	демонстрируются O
6	на O
7	" O
8	образцовых O
9	" O
10	датасетах O
11	, O
12	например O
13	" O
14	20 B-Dataset
15	newsgroups I-Dataset
16	dataset I-Dataset
17	" O
18	, O
19	который O
20	есть O
21	в O
22	sklearn B-Library
23	. O

# sent_id = 374
# text =  Для стемминга использовался pymystem3. 
# relations = ""
1	Для O
2	стемминга O
3	использовался O
4	pymystem3 B-Library
5	. O

# sent_id = 375
# text = Объединенная команда специалистов Пенсильванского и Шеффилдского университетов создала слабую форму искусственного интеллекта, которая способна предсказывать решения Европейского суда по правам человека (European Court of Human Rights, ECtHR, ЕСПЧ) с точностью в 79%. 
# relations = "Metric_hasValue_Value 0 0"
1	Объединенная O
2	команда O
3	специалистов O
4	Пенсильванского B-Organization
5	и O
6	Шеффилдского B-Organization
7	университетов I-Organization
8	создала O
9	слабую O
10	форму O
11	искусственного O
12	интеллекта O
13	, O
14	которая O
15	способна O
16	предсказывать O
17	решения O
18	Европейского O
19	суда O
20	по O
21	правам O
22	человека O
23	( O
24	European O
25	Court O
26	of O
27	Human O
28	Rights O
29	, O
30	ECtHR O
31	, O
32	ЕСПЧ O
33	) O
34	с O
35	точностью B-Metric
36	в O
37	79 B-Value
38	% I-Value
39	. O

# sent_id = 376
# text =  Он демонстрирует точность 95%. 
# relations = "Metric_hasValue_Value 0 0"
1	Он O
2	демонстрирует O
3	точность B-Metric
4	95 B-Value
5	% I-Value
6	. O

# sent_id = 377
# text =  На данный момент подход дает прогноз с accuracy 0,64, что выше случайного предсказания. 
# relations = "Metric_isAppliedTo_Method 0 0, Metric_hasValue_Value 0 0"
1	На O
2	данный O
3	момент O
4	подход B-Method
5	дает O
6	прогноз O
7	с O
8	accuracy B-Metric
9	0,64 B-Value
10	, O
11	что O
12	выше O
13	случайного O
14	предсказания O
15	. O

# sent_id = 378
# text =  Таким образом, хоть и удается достигнуть высокой точности, но результат не всегда стабилен и в моем случае колеблется в промежутке 75-80%. 
# relations = "Metric_hasValue_Value 0 0"
1	Таким O
2	образом O
3	, O
4	хоть O
5	и O
6	удается O
7	достигнуть O
8	высокой O
9	точности B-Metric
10	, O
11	но O
12	результат O
13	не O
14	всегда O
15	стабилен O
16	и O
17	в O
18	моем O
19	случае O
20	колеблется O
21	в O
22	промежутке O
23	75 B-Value
24	- I-Value
25	80 I-Value
26	% I-Value
27	. O

# sent_id = 379
# text =  Видно, что при перестановках качество падает, но это падение не критично и точность остается в диапазоне 69-80%. 
# relations = "Metric_hasValue_Value 0 0"
1	Видно O
2	, O
3	что O
4	при O
5	перестановках O
6	качество O
7	падает O
8	, O
9	но O
10	это O
11	падение O
12	не O
13	критично O
14	и O
15	точность B-Metric
16	остается O
17	в O
18	диапазоне O
19	69 B-Value
20	- I-Value
21	80 I-Value
22	% I-Value
23	. O

# sent_id = 380
# text =  ЗаключениеВ итоге, моделью RuBioRoBERTa в задаче RuMedDaNet мне удалось добиться качества 73.24% на закрытой тестовой части данных (хотя на dev метрика Accuracy вообще была 81.64%). 
# relations = "Metric_hasValue_Value 0 0, Metric_isUsedIn_Task 0 0, Metric_isUsedFor_Model 0 0, Model_isUsedForSolving_Task 0 0"
1	ЗаключениеВ O
2	итоге O
3	, O
4	моделью O
5	RuBioRoBERTa B-Model
6	в O
7	задаче O
8	RuMedDaNet B-Task
9	мне O
10	удалось O
11	добиться O
12	качества O
13	73.24 O
14	% O
15	на O
16	закрытой O
17	тестовой O
18	части O
19	данных O
20	( O
21	хотя O
22	на O
23	dev O
24	метрика O
25	Accuracy B-Metric
26	вообще O
27	была O
28	81.64 B-Value
29	% I-Value
30	) O
31	. O

# sent_id = 381
# text =  Точность модели составила 58%, если учитывать все слот. 
# relations = "Metric_hasValue_Value 0 0"
1	Точность B-Metric
2	модели O
3	составила O
4	58 B-Value
5	% I-Value
6	, O
7	если O
8	учитывать O
9	все O
10	слот O
11	. O

# sent_id = 382
# text =  После тонкой настройки модель показала примерно 63%-ю точность как на учебном, так и на контрольном наборах данных. 
# relations = "Metric_hasValue_Value 0 0"
1	После O
2	тонкой O
3	настройки O
4	модель O
5	показала O
6	примерно O
7	63%-ю B-Value
8	точность B-Metric
9	как O
10	на O
11	учебном O
12	, O
13	так O
14	и O
15	на O
16	контрольном O
17	наборах O
18	данных O
19	. O

# sent_id = 383
# text =  Самые интересные для нас сущности – судья и прокурор – быстро идентифицируются из более чем 200 миллионов документов с точностью выше 92%».
# relations = "Metric_hasValue_Value 0 0"
1	Самые O
2	интересные O
3	для O
4	нас O
5	сущности O
6	– O
7	судья O
8	и O
9	прокурор O
10	– O
11	быстро O
12	идентифицируются O
13	из O
14	более O
15	чем O
16	200 O
17	миллионов O
18	документов O
19	с O
20	точностью B-Metric
21	выше O
22	92 B-Value
23	% I-Value
24	» O
25	. O

# sent_id = 384
# text =  В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно. 
# relations = "Metric_isUsedFor_Model 1 0, Metric_isUsedFor_Model 1 1, Metric_isUsedFor_Model 0 0, Metric_isUsedFor_Model 0 1, Metric_isAlternativeNameFor_Metric 1 0, Metric_hasValue_Value 0 0, Metric_hasValue_Value 0 1, Metric_hasValue_Value 1 0, Metric_hasValue_Value 1 1"
1	В O
2	сравнении O
3	показываются O
4	FriendBERT B-Model
5	и O
6	ChatBERT B-Model
7	, O
8	которые O
9	по O
10	итогу O
11	исследования O
12	представили O
13	точность B-Metric
14	( O
15	MacroAVG B-Metric
16	F I-Metric
17	- I-Metric
18	меру I-Metric
19	) O
20	, O
21	равную O
22	73 B-Value
23	% I-Value
24	для O
25	первой O
26	и O
27	69,5 B-Value
28	% I-Value
29	для O
30	второй O
31	модели O
32	соответственно O
33	. O

# sent_id = 385
# text =  Разработал систему компьютерной алгебры Mathematica и систему извлечения знаний WolframAlpha. 
# relations = ""
1	Разработал O
2	систему O
3	компьютерной O
4	алгебры O
5	Mathematica B-App_system
6	и O
7	систему O
8	извлечения O
9	знаний O
10	WolframAlpha B-App_system
11	. O

# sent_id = 386
# text =  В чем проблема Пролога, да и любой системы / языка программирования, назначение которых анализировать факты и искать ответы на вопросы? 
# relations = ""
1	В O
2	чем O
3	проблема O
4	Пролога B-App_system
5	, O
6	да O
7	и O
8	любой O
9	системы O
10	/ O
11	языка O
12	программирования O
13	, O
14	назначение O
15	которых O
16	анализировать O
17	факты O
18	и O
19	искать O
20	ответы O
21	на O
22	вопросы O
23	? O

# sent_id = 387
# text =  Интерес представляют и системы DeepMind, которые в дополнение к нейросети имеют внешнюю память фактов (или опыта), что позволяет им обучаться без учителя «правилам игры», просто проявляя активность в среде и записывая ее результат. 
# relations = ""
1	Интерес O
2	представляют O
3	и O
4	системы O
5	DeepMind B-App_system
6	, O
7	которые O
8	в O
9	дополнение O
10	к O
11	нейросети O
12	имеют O
13	внешнюю O
14	память O
15	фактов O
16	( O
17	или O
18	опыта O
19	) O
20	, O
21	что O
22	позволяет O
23	им O
24	обучаться O
25	без O
26	учителя O
27	« O
28	правилам O
29	игры O
30	» O
31	, O
32	просто O
33	проявляя O
34	активность O
35	в O
36	среде O
37	и O
38	записывая O
39	ее O
40	результат O
41	. O

# sent_id = 388
# text =  В заглавии упомянута и на картинке представлена ELIZA — диалоговая система-психоаналитик (сейчас, ее назвали бы чат-бот), родом из 60-ых годов. 
# relations = ""
1	В O
2	заглавии O
3	упомянута O
4	и O
5	на O
6	картинке O
7	представлена O
8	ELIZA B-App_system
9	— O
10	диалоговая O
11	система O
12	- O
13	психоаналитик O
14	( O
15	сейчас O
16	, O
17	ее O
18	назвали O
19	бы O
20	чат O
21	- O
22	бот O
23	) O
24	, O
25	родом O
26	из O
27	60-ых O
28	годов O
29	. O

# sent_id = 389
# text = GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate. 
# relations = "Application_hasAuthor_Organization 2 0, Model_isUsedIn_Application 0 0, Application_hasAuthor_Organization 0 0"
1	GNMT B-App_system
2	есть O
3	система O
4	нейронного O
5	машинного O
6	перевода O
7	( O
8	NMT B-App_system
9	) O
10	компании O
11	Google B-Organization
12	, O
13	которая O
14	использует O
15	нейросеть O
16	( O
17	ANN B-Model
18	) O
19	для O
20	повышения O
21	точности O
22	и O
23	скорости O
24	перевода O
25	, O
26	и O
27	в O
28	частности O
29	для O
30	создания O
31	лучших O
32	, O
33	более O
34	естественных O
35	вариантов O
36	перевода O
37	текста O
38	в O
39	Google B-App_system
40	Translate I-App_system
41	. O

# sent_id = 390
# text =  Его обучали с помощью большого количества текстов из Интернета и системы Reinforcement Learning from Human Feedback. 
# relations = ""
1	Его O
2	обучали O
3	с O
4	помощью O
5	большого O
6	количества O
7	текстов O
8	из O
9	Интернета O
10	и O
11	системы O
12	Reinforcement B-App_system
13	Learning I-App_system
14	from I-App_system
15	Human I-App_system
16	Feedback I-App_system
17	. O

# sent_id = 391
# text =  Во-вторых, даже перевод между русским и эрзянским ещё расти и расти: у SOTA систем для высокоресурсных языков BLEU обычно где-то между 40 и 80. 
# relations = "Environment_isUsedIn_Application 0 0"
1	Во O
2	- O
3	вторых O
4	, O
5	даже O
6	перевод O
7	между O
8	русским O
9	и O
10	эрзянским O
11	ещё O
12	расти O
13	и O
14	расти O
15	: O
16	у O
17	SOTA B-App_system
18	систем O
19	для O
20	высокоресурсных O
21	языков O
22	BLEU B-Environment
23	обычно O
24	где O
25	- O
26	то O
27	между O
28	40 O
29	и O
30	80 O
31	. O

# sent_id = 392
# text =  Insertions – вставки слов, которых нет в исходной аудиозаписи Substitutions – замены слов на некорректные Deletions – система слово не распознала и сделала пропуск
# relations = ""
1	Insertions O
2	– O
3	вставки O
4	слов O
5	, O
6	которых O
7	нет O
8	в O
9	исходной O
10	аудиозаписи O
11	Substitutions O
12	– O
13	замены O
14	слов O
15	на O
16	некорректные O
18	Deletions B-App_system
19	– O
20	система O
21	слово O
22	не O
23	распознала O
24	и O
25	сделала O
26	пропуск O

# sent_id = 393
# text = “Вам курицу или рыбу?” – Рекомендательная система на “Своем Родном” знает ответ / Habr 
# relations = ""
1	“ O
2	Вам O
3	курицу O
4	или O
5	рыбу O
6	? O
7	” O
8	– O
9	Рекомендательная O
10	система O
11	на O
12	“ O
13	Своем B-App_system
14	Родном I-App_system
15	” O
16	знает O
17	ответ O

# sent_id = 394
# text =  Его обучали с помощью большого количества текстов из Интернета и системы Reinforcement Learning from Human Feedback. 
# relations = ""
1	Его O
2	обучали O
3	с O
4	помощью O
5	большого O
6	количества O
7	текстов O
8	из O
9	Интернета O
10	и O
11	системы O
12	Reinforcement B-App_system
13	Learning I-App_system
14	from I-App_system
15	Human I-App_system
16	Feedback I-App_system
17	. O

# sent_id = 395
# text =  Система Kaldi, разработанная британским специалистом по нейросетям Даниэлем Повеем, предоставляет пользователю наиболее широкий выбор алгоритмов для разных задач и удобна в использовании. 
# relations = "Application_hasAuthor_Person 0 0"
1	Система O
2	Kaldi B-App_system
3	, O
4	разработанная O
5	британским O
6	специалистом O
7	по O
8	нейросетям O
9	Даниэлем B-Person
10	Повеем I-Person
11	, O
12	предоставляет O
13	пользователю O
14	наиболее O
15	широкий O
16	выбор O
17	алгоритмов O
18	для O
19	разных O
20	задач O
21	и O
22	удобна O
23	в O
24	использовании O
25	. O

# sent_id = 396
# text =  Британский специалист по нейросетям Даниэль Пове создал систему Kaldi, которая предоставляет пользователю разнообразные алгоритмы для решения различных задач и отличается удобством в использовании.
# relations = "Application_hasAuthor_Person 0 0"
1	Британский O
2	специалист O
3	по O
4	нейросетям O
5	Даниэль B-Person
6	Пове I-Person
7	создал O
8	систему O
9	Kaldi B-App_system
10	, O
11	которая O
12	предоставляет O
13	пользователю O
14	разнообразные O
15	алгоритмы O
16	для O
17	решения O
18	различных O
19	задач O
20	и O
21	отличается O
22	удобством O
23	в O
24	использовании O
25	. O

# sent_id = 397
# text =  А AI позволяет извлекать из данных нужную информацию, что делает системы IoT намного более интеллектуальными. 
# relations = ""
1	А O
2	AI O
3	позволяет O
4	извлекать O
5	из O
6	данных O
7	нужную O
8	информацию O
9	, O
10	что O
11	делает O
12	системы O
13	IoT B-App_system
14	намного O
15	более O
16	интеллектуальными O
17	. O

# sent_id = 398
# text =  После того, как данные загружены в систему, CLI позволяет осуществить её тонкую настройку, в том числе — воспользоваться специальной опцией для двоичной классификации. 
# relations = ""
1	После O
2	того O
3	, O
4	как O
5	данные O
6	загружены O
7	в O
8	систему O
9	, O
10	CLI B-App_system
11	позволяет O
12	осуществить O
13	её O
14	тонкую O
15	настройку O
16	, O
17	в O
18	том O
19	числе O
20	— O
21	воспользоваться O
22	специальной O
23	опцией O
24	для O
25	двоичной O
26	классификации O
27	. O

# sent_id = 399
# text = Google представила систему искусственного интеллекта MusicLM, которая способна генерировать музыку в любом жанре по текстовому описанию. 
# relations = "Application_hasAuthor_Organization 0 0"
1	Google B-Organization
2	представила O
3	систему O
4	искусственного O
5	интеллекта O
6	MusicLM B-App_system
7	, O
8	которая O
9	способна O
10	генерировать O
11	музыку O
12	в O
13	любом O
14	жанре O
15	по O
16	текстовому O
17	описанию O
18	. O

# sent_id = 400
# text =  Ниже показаны примеры генерации кода с использованием сервиса CodeWhisperer на всех трёх перечисленных выше языках программирования. 
# relations = ""
1	Ниже O
2	показаны O
3	примеры O
4	генерации O
5	кода O
6	с O
7	использованием O
8	сервиса O
9	CodeWhisperer B-App_system
10	на O
11	всех O
12	трёх O
13	перечисленных O
14	выше O
15	языках O
16	программирования O
17	. O

# sent_id = 401
# text = Аналогичный описанному выше сервис был запущен Microsoft в прошлом, 2021 году, и получил название Copilot. 
# relations = "Date_isDateOf_Application 0 0, Application_hasAuthor_Organization 0 0"
1	Аналогичный O
2	описанному O
3	выше O
4	сервис O
5	был O
6	запущен O
7	Microsoft B-Organization
8	в O
9	прошлом O
10	, O
11	2021 B-Date
12	году O
13	, O
14	и O
15	получил O
16	название O
17	Copilot B-App_system
18	. O

# sent_id = 402
# text =  Система может быть подключена в виде расширения для сред разработки: Visual Studio Code, Visual Studio, Neovim, набора IDE от JetBrains. 
# relations = "Application_hasAuthor_Organization 3 0"
1	Система O
2	может O
3	быть O
4	подключена O
5	в O
6	виде O
7	расширения O
8	для O
9	сред O
10	разработки O
11	: O
12	Visual B-App_system
13	Studio I-App_system
14	Code I-App_system
15	, O
16	Visual B-App_system
17	Studio I-App_system
18	, O
19	Neovim B-App_system
20	, O
21	набора O
22	IDE B-App_system
23	от O
24	JetBrains B-Organization
25	. O

# sent_id = 403
# text =  Процент роботов среди трафика относительно низок, при этом самый высокий показатель приходится на трафик поисковых систем (Baidu) и составляет 1,0%. 
# relations = ""
1	Процент O
2	роботов O
3	среди O
4	трафика O
5	относительно O
6	низок O
7	, O
8	при O
9	этом O
10	самый O
11	высокий O
12	показатель O
13	приходится O
14	на O
15	трафик O
16	поисковых O
17	систем O
18	( O
19	Baidu B-App_system
20	) O
21	и O
22	составляет O
23	1,0 O
24  % O
25  . O

# sent_id = 404
# text =  Поддерживается система рекомендаций для разработки приложений на языках Java, Javascript и Python. 
# relations = ""
1	Поддерживается O
2	система O
3	рекомендаций O
4	для O
5	разработки O
6	приложений O
7	на O
8	языках O
9	Java B-Environment
10	, O
11	Javascript B-Environment
12	и O
13	Python B-Environment
14	. O

# sent_id = 405
# text =  Ниже показаны примеры генерации кода с использованием сервиса CodeWhisperer на всех трёх перечисленных выше языках программирования. 
# relations = ""
1	Ниже O
2	показаны O
3	примеры O
4	генерации O
5	кода O
6	с O
7	использованием O
8	сервиса O
9	CodeWhisperer B-App_system
10	на O
11	всех O
12	трёх O
13	перечисленных O
14	выше O
15	языках O
16	программирования O
17	. O

# sent_id = 406
# text = Одним из самых известных датасетов по задаче модерации является датасет с соревнования на Kaggle Toxic Comment Classification Challenge. 
# relations = ""
1	Одним O
2	из O
3	самых O
4	известных O
5	датасетов O
6	по O
7	задаче O
8	модерации O
9	является O
10	датасет B-Dataset
11	с O
12	соревнования O
13	на O
14	Kaggle B-Activity
15	Toxic I-Activity
16	Comment I-Activity
17	Classification I-Activity
18	Challenge I-Activity
19	. O

# sent_id = 407
# text =  Для обучения модели был использован гигантский датасет mC4, включающий в себя 6,6 млрд веб-страниц на 101 языке. 
# relations = "Model_isTrainedOn_Dataset 0 0"
1	Для O
2	обучения B-Model_isTrainedOn_Dataset
3	модели B-Model
4	был O
5	использован O
6	гигантский O
7	датасет O
8	mC4 B-Dataset
9	, O
10	включающий O
11	в O
12	себя O
13	6,6 O
14	млрд O
15	веб O
16	- O
17	страниц O
18	на O
19	101 O
20	языке O
21	. O

# sent_id = 408
# text =  Есть множество датасетов, таких как:Paraphraser Plus; корпус парафраз, собранных Давидом Дале;корпус парафраз из новостных заголовков, собранный Екатериной Пронозой;корпус парафраз-заголовков, собранный командой Вадима Гудкова. 
# relations = ""
1	Есть O
2	множество O
3	датасетов O
4	, O
5	таких O
6	как O
7	: O
8	Paraphraser B-Dataset
9	Plus I-Dataset
10	; O
11	корпус B-Corpus
12	парафраз I-Corpus
13	, O
14	собранных O
15	Давидом B-Person
16	Дале I-Person
17	; O
18	корпус B-Corpus
19	парафраз I-Corpus
20	из I-Corpus
21	новостных I-Corpus
22	заголовков I-Corpus
23	, O
24	собранный O
25	Екатериной B-Person
26	Пронозой I-Person
27	; O
28	корпус B-Corpus
29	парафраз I-Corpus
30	- I-Corpus
31	заголовков I-Corpus
32	, O
33	собранный O
34	командой O
35	Вадима B-Person
36	Гудкова I-Person
37	. O

# sent_id = 409
# text =  На базе этих корпусов есть также обученные модели в том числе на основе ruT5 и ruGPT3 (например, несколько моделей находятся в библиотеке russian_paraphrases, или например мультитасковая модель). 
# relations = "Model_isTrainedOn_Corpus 2 0"
1	На O
2	базе O
3	этих O
4	корпусов B-Corpus
5	есть O
6	также O
7	обученные O
8	модели O
9	в O
10	том O
11	числе O
12	на O
13	основе O
14	ruT5 B-Model
15	и O
16	ruGPT3 B-Model
17	( O
18	например O
19	, O
20	несколько O
21	моделей O
22	находятся O
23	в O
24	библиотеке O
25	russian_paraphrases B-Library
26	, O
27	или O
28	например O
29	мультитасковая B-Model
30	модель I-Model
31	) O
32	. O

# sent_id = 410
# text =  Прежде всего, стоит выделить Dialog State Tracking Challenge, в этом году он, кстати, будет проводиться уже в шестой раз. 
# relations = ""
1	Прежде O
2	всего O
3	, O
4	стоит O
5	выделить O
6	Dialog B-Activity
7	State I-Activity
8	Tracking I-Activity
9	Challenge I-Activity
10	, O
11	в O
12	этом O
13	году O
14	он O
15	, O
16	кстати O
17	, O
18	будет O
19	проводиться O
20	уже O
21	в O
22	шестой O
23	раз O
24	. O

# sent_id = 411
# text = Текстах аудиокниг, будем использовать датасет caito, в котором как раз есть тексты на всех языках, на которых обучалась модель (20,000 случайных предложений на каждый язык); 
# relations = ""
1	Текстах O
2	аудиокниг O
3	, O
4	будем O
5	использовать O
6	датасет O
7	caito B-Dataset
8	, O
9	в O
10	котором O
11	как O
12	раз O
13	есть O
14	тексты O
15	на O
16	всех O
17	языках O
18	, O
19	на O
20	которых O
21	обучалась O
22	модель O
23	( O
24	20,000 O
25	случайных O
26	предложений O
27	на O
28	каждый O
29	язык O
30	) O
31	; O

# sent_id = 412
# text =  Это не упоминалось ранее, однако исходные вопросы для сбора демонстраций и генерации пар на сравнение (в RL/RM частях) были выбраны из датасета ELI5. 
# relations = ""
1	Это O
2	не O
3	упоминалось O
4	ранее O
5	, O
6	однако O
7	исходные O
8	вопросы O
9	для O
10	сбора O
11	демонстраций O
12	и O
13	генерации O
14	пар O
15	на O
16	сравнение O
17	( O
18	в O
19	RL O
20	/ O
21	RM O
22	частях O
23	) O
24	были O
25	выбраны O
26	из O
27	датасета O
28	ELI5 B-Dataset
29	. O

# sent_id = 413
# text =  Пары предложений новых языков с русским я взял из датасета CCMatrix, и по ходу дообучения дополнял их эрзянскими переводами из своей русско-эрзянской модели, чтобы потом учить другую модель переводить эти эрзянские тексты на иностранный. 
# relations = ""
1	Пары O
2	предложений O
3	новых O
4	языков O
5	с O
6	русским O
7	я O
8	взял O
9	из O
10	датасета O
11	CCMatrix B-Dataset
12	, O
13	и O
14	по O
15	ходу O
16	дообучения O
17	дополнял O
18	их O
19	эрзянскими O
20	переводами O
21	из O
22	своей O
23	русско O
24	- O
25	эрзянской O
26	модели O
27	, O
28	чтобы O
29	потом O
30	учить O
31	другую O
32	модель O
33	переводить O
34	эти O
35	эрзянские O
36	тексты O
37	на O
38	иностранный O
39	. O

# sent_id = 414
# text =  Вот несколько примеров из тренировочного датасета:ContextQuestionAnswer 
# relations = ""
1	Вот O
2	несколько O
3	примеров O
4	из O
5	тренировочного O
6	датасета O
7	: O
8	ContextQuestionAnswer B-Dataset

# sent_id = 415
# text =  Например, в наборе данных CRD3 использовались стенограммы шоу Critical Role.
# relations = ""
1	Например O
2	, O
3	в O
4	наборе O
5	данных O
6	CRD3 B-Dataset
7	использовались O
8	стенограммы O
9	шоу O
10	Critical O
11	Role O
12	. O

# sent_id = 416
# text =  Проверим этот метод на практике, обучив модель на табличном датасете California Housing, в котором нужно предсказывать цену недвижимости в разных районах Калифорнии, имея 8 исходных признаков. 
# relations = "Model_isTrainedOn_Dataset 0 0"
1	Проверим O
2	этот O
3	метод O
4	на O
5	практике O
6	, O
7	обучив B-Model_isTrainedOn_Dataset
8	модель B-Model
9	на O
10	табличном O
11	датасете O
12	California B-Dataset
13	Housing I-Dataset
14	, O
15	в O
16	котором O
17	нужно O
18	предсказывать O
19	цену O
20	недвижимости O
21	в O
22	разных O
23	районах O
24	Калифорнии O
25	, O
26	имея O
27	8 O
28	исходных O
29	признаков O
30	. O

# sent_id = 417
# text =  Давайте протестируем данную методику, обучив модель на датасете California Housing.
# relations = "Model_isTrainedOn_Dataset 0 0"
1	Давайте O
2	протестируем O
3	данную O
4	методику O
5	, O
6	обучив B-Model_isTrainedOn_Dataset
7	модель B-Model
8	на O
9	датасете O
10	California B-Dataset
11	Housing I-Dataset
12	. O

# sent_id = 418
# text = Чтобы оценить точность регрессора, мы будем использовать наборы данных Medical Cost Personal Datasets | Kaggle. 
# relations = "Dataset_isTrainedForSolving_Task 0 0"
1	Чтобы O
2	оценить B-Task
3	точность I-Task
4	регрессора I-Task
5	, O
6	мы O
7	будем O
8	использовать O
9	наборы O
10	данных O
11	Medical B-Dataset
12	Cost I-Dataset
13	Personal I-Dataset
14	Datasets I-Dataset
15  | O
15	Kaggle B-InfoResource
16	. O

# sent_id = 419
# text = В задаче классификации на 10%, 20%, 30%, 40%, 50% от общего датасета тестовой выборки DatRet показал лучшие результаты. 
# relations = ""
1	В O
2	задаче O
3	классификации O
4	на O
5	10 O
6	% O
7	, O
8	20 O
9	% O
10	, O
11	30 O
12	% O
13	, O
14	40 O
15	% O
16	, O
17	50 O
18	% O
19	от O
20	общего O
21	датасета O
22	тестовой O
23	выборки O
24	DatRet B-Dataset
25	показал O
26	лучшие O
27	результаты O
28	. O

# sent_id = 420
# text =  И речь здесь даже не о том, что метрики качества оцениваются в первую очередь на общих датасетах вроде COCO, а в том, что сами метрики заточены под исследовательские цели. 
# relations = ""
1	И O
2	речь O
3	здесь O
4	даже O
5	не O
6	о O
7	том O
8	, O
9	что O
10	метрики O
11	качества O
12	оцениваются O
13	в O
14	первую O
15	очередь O
16	на O
17	общих O
18	датасетах O
19	вроде O
20	COCO B-Dataset
21	, O
22	а O
23	в O
24	том O
25	, O
26	что O
27	сами O
28	метрики O
29	заточены O
30	под O
31	исследовательские O
32	цели O
33	. O

# sent_id = 421
# text =  TAPE является логичным развитием проекта Russian SuperGLUE, где на вопросно-ответных датасетах RuCoS, MuSeRC и DaNetQA решения участников уже достигли уровня человека. 
# relations = ""
1	TAPE B-Technology
2	является O
3	логичным O
4	развитием O
5	проекта O
6	Russian B-Activity
7	SuperGLUE I-Activity
8	, O
9	где O
10	на O
11	вопросно O
12	- O
13	ответных O
14	датасетах O
15	RuCoS B-Dataset
16	, O
17	MuSeRC B-Dataset
18	и O
19	DaNetQA B-Dataset
20	решения O
21	участников O
22	уже O
23	достигли O
24	уровня O
25	человека O
26	. O

# sent_id = 422
# text =  Датасет Ethics состоит из двух частей. 
# relations = ""
1	Датасет O
2	Ethics B-Dataset
3	состоит O
4	из O
5	двух O
6	частей O
7	. O

# sent_id = 423
# text =  Для тестирования были отобраны два класса по две тысячи примеров из датасета интентов нашего чат-бота Смарти, которые показывали высокую и среднюю оценку разнообразия по self-bleu по 3-граммам. 
# relations = ""
1	Для O
2	тестирования O
3	были O
4	отобраны O
5	два O
6	класса O
7	по O
8	две O
9	тысячи O
10	примеров O
11	из O
12	датасета B-Dataset
13	интентов I-Dataset
14	нашего O
15	чат O
16	- O
17	бота O
18	Смарти B-Technology
19	, O
20	которые O
21	показывали O
22	высокую O
23	и O
24	среднюю O
25	оценку O
26	разнообразия O
27	по O
28	self O
29	- O
30	bleu O
31	по O
32	3-граммам O
33	. O

# sent_id = 424
# text =  В рамках этой статьи давайте предположим, что у нас есть датасет для обучения обычного многоклассового классификатора интентов. 
# relations = ""
1	В O
2	рамках O
3	этой O
4	статьи O
5	давайте O
6	предположим O
7	, O
8	что O
9	у O
10	нас O
11	есть O
12	датасет B-Dataset
13	для I-Dataset
14	обучения I-Dataset
15	обычного I-Dataset
16	многоклассового I-Dataset
17	классификатора I-Dataset
18	интентов I-Dataset
19	. O

# sent_id = 425
# text =  Обучались на датасете открытого кода с Гитхаба, больше всего в выборке было питона.
# relations = ""
1	Обучались O
2	на O
3	датасете B-Dataset
4	открытого I-Dataset
5	кода I-Dataset
6	с I-Dataset
7	Гитхаба I-Dataset
8	, O
9	больше O
10	всего O
11	в O
12	выборке O
13	было O
14	питона O
15	. O

# sent_id = 426
# text =  Данные для обучения включали в себя отфильтрованный датасет CommonCrawl (составляет большую пропорцию всех текстов, которые присутствовали в обучении), а также корпус книжных текстов и текстов Википедии. 
# relations = ""
1	Данные O
2	для O
3	обучения O
4	включали O
5	в O
6	себя O
7	отфильтрованный O
8	датасет O
9	CommonCrawl B-Dataset
10	( O
11	составляет O
12	большую O
13	пропорцию O
14	всех O
15	текстов O
16	, O
17	которые O
18	присутствовали O
19	в O
20	обучении O
21	) O
22	, O
23	а O
24	также O
25	корпус O
26	книжных O
27	текстов O
28	и O
29	текстов O
30	Википедии B-InfoResource
31	. O

# sent_id = 427
# text =  Dusha: самый большой открытый датасет для распознавания эмоций в устной речи на русском языке. 
# relations = "Dataset_isTrainedForSolving_Task 0 0, Dataset_isTrainedForSolving_Task 1 0, Dataset_Language_Lang 0 0, Dataset_Language_Lang 1 0"
1	Dusha B-Dataset
2	: O
3	самый O
4	большой O
5	открытый O
6	датасет B-Dataset
7	для O
8	распознавания B-Task
9	эмоций I-Task
10	в O
11	устной O
12	речи O
13	на O
14	русском B-Lang
15	языке I-Lang
16	. O

# sent_id = 428
# text =  Dusha - это крупнейший открытый набор данных на русском языке для распознавания эмоций в речи.
# relations = "Dataset_isTrainedForSolving_Task 0 0, Dataset_isTrainedForSolving_Task 1 0, Dataset_Language_Lang 0 0, Dataset_Language_Lang 1 0"
1	Dusha B-Dataset
2	- O
3	это O
4	крупнейший O
5	открытый O
6	набор B-Dataset
7	данных I-Dataset
8	на O
9	русском B-Lang
10	языке I-Lang
11	для O
12	распознавания B-Task
13	эмоций I-Task
14	в I-Task
15	речи I-Task
16	. O

# sent_id = 429
# text =  Де-факто, в подавляющем большинстве случаев, бенчмарком для новых моделей распознавания эмоций является англоязычный датасет IEMOCAP с игрой профессиональных актёров. 
# relations = "Dataset_isTrainedForSolving_Task 0 0, Dataset_Language_Lang 0 0"
1	Де O
2	- O
3	факто O
4	, O
5	в O
6	подавляющем O
7	большинстве O
8	случаев O
9	, O
10	бенчмарком O
11	для O
12	новых O
13	моделей O
14	распознавания B-Task
15	эмоций I-Task
16	является O
17	англоязычный B-Lang
18	датасет O
19	IEMOCAP B-Dataset
20	с O
21	игрой O
22	профессиональных O
23	актёров O
24	. O

# sent_id = 430
# text =  IEMOCAP, англоязычный набор данных, служит стандартом для распознавания эмоций.
# relations = "Dataset_isTrainedForSolving_Task 0 0, Dataset_Language_Lang 0 0"
1	IEMOCAP B-Dataset
2	, O
3	англоязычный B-Lang
4	набор O
5	данных O
6	, O
7	служит O
8	стандартом O
9	для O
10	распознавания B-Task
11	эмоций I-Task
12	. O

# sent_id = 431
# text =  Если датасеты с большим количеством семплов и находятся (к примеру, CMU-MOSEI, MURCO), то у них очень ярко проявляется проблема из п1. 
# relations = ""
1	Если O
2	датасеты O
3	с O
4	большим O
5	количеством O
6	семплов O
7	и O
8	находятся O
9	( O
10	к O
11	примеру O
12	, O
13	CMU B-Dataset
14	- I-Dataset
15	MOSEI I-Dataset
16	, O
17	MURCO B-Dataset
18	) O
19	, O
20	то O
21	у O
22	них O
23	очень O
24	ярко O
25	проявляется O
26	проблема O
27	из O
28	п1 O
29  . O

# sent_id = 432
# text =  Столкнувшись с описанными выше проблемами, мы решили собрать свой датасет для распознавания эмоций и назвали его Dusha, по аналогии с датасетом для распознавания речи — Golos. 
# relations = "Dataset_isTrainedForSolving_Task 0 0, Dataset_isTrainedForSolving_Task 1 1"
1	Столкнувшись O
2	с O
3	описанными O
4	выше O
5	проблемами O
6	, O
7	мы O
8	решили O
9	собрать O
10	свой O
11	датасет O
12	для O
13	распознавания B-Task
14	эмоций I-Task
15	и O
16	назвали O
17	его O
18	Dusha B-Dataset
19	, O
20	по O
21	аналогии O
22	с O
23	датасетом O
24	для O
25	распознавания B-Task
26	речи I-Task
27	— O
28	Golos B-Dataset
29	. O

# sent_id = 433
# text =  Эту часть датасета мы назвали Crowd. 
# relations = ""
1	Эту O
2	часть O
3	датасета O
4	мы O
5	назвали O
6	Crowd B-Dataset
7	. O

# sent_id = 434
# text =  Мы обучали движок Amazon Translate, используя «Active Custom Translation», который позволяет выполнять перевод на лету с использованием двуязычного корпуса. 
# relations = "Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 1 0, Corpus_isTrainedForSolving_Task 0 0"
1	Мы O
2	обучали O
3	движок O
4	Amazon B-Technology
5	Translate I-Technology
6	, O
7	используя O
8	« O
9	Active B-Technology
10	Custom I-Technology
11	Translation I-Technology
12	» O
13	, O
14	который O
15	позволяет O
16	выполнять O
17	перевод B-Task
18	на O
19	лету O
20	с O
21	использованием O
22	двуязычного B-Corpus
23	корпуса I-Corpus
24	. O

# sent_id = 435
# text = Та статья была написана совместно с Ильей Гусевым, у которого есть библиотека для анализа и генерации стихов на русском языке и поэтический корпус русского языка. 
# relations = "Corpus_Language_Lang 0 1, Library_hasAuthor_Person 0 0"
1	Та O
2	статья O
3	была O
4	написана O
5	совместно O
6	с O
7	Ильей B-Person
8	Гусевым I-Person
9	, O
10	у O
11	которого O
12	есть O
13	библиотека B-Library
14	для I-Library
15	анализа I-Library
16	и I-Library
17	генерации I-Library
18	стихов I-Library
19	на O
20	русском B-Lang
21	языке I-Lang
22	и O
23	поэтический B-Corpus
24	корпус I-Corpus
25	русского B-Lang
26	языка I-Lang
27	. O

# sent_id = 436
# text = Этот материал был создан совместно с Ильей Гусевым, у которого имеется библиотека для анализа и генерации стихов на русском языке, а также поэтический корпус русского языка.
# relations = "Corpus_Language_Lang 0 1, Library_hasAuthor_Person 0 0"
1	Этот O
2	материал O
3	был O
4	создан O
5	совместно O
6	с O
7	Ильей B-Person
8	Гусевым I-Person
9	, O
10	у O
11	которого O
12	имеется O
13	библиотека B-Library
14	для I-Library
15	анализа I-Library
16	и I-Library
17	генерации I-Library
18	стихов I-Library
19	на O
20	русском B-Lang 
21	языке I-Lang 
22	, O
23	а O
24	также O
25	поэтический B-Corpus
26	корпус I-Corpus
27	русского B-Lang
28	языка I-Lang
29	. O

# sent_id = 437
# text =  Обученный на большом корпусе русской литературы «Порфирьевич» порадовал публику множеством забавных творений. 
# relations = ""
1	Обученный O
2	на O
3	большом O
4	корпусе B-Corpus
5	русской I-Corpus
6	литературы I-Corpus
7	« O
8	Порфирьевич B-Technology
9	» O
10	порадовал O
11	публику O
12	множеством O
13	забавных O
14	творений O
15	. O

# sent_id = 438
# text =  Для обучения использовался корпус объёмом около 750 Гб, получивший название C4 (Colossal Clean Crawled Corpus, Колоссальный очищенный собранный в интернете корпус), являющийся отфильтрованной версией корпуса Common Crawl. 
# relations = "Corpus_isAlternativeNameFor_Corpus 1 0, Corpus_isAlternativeNameFor_Corpus 2 0"
1	Для O
2	обучения O
3	использовался O
4	корпус O
5	объёмом O
6	около O
7	750 O
8	Гб O
9	, O
10	получивший O
11	название O
12	C4 B-Corpus
13	( O
14	Colossal B-Corpus
15	Clean I-Corpus
16	Crawled I-Corpus
17	Corpus I-Corpus
18	, O
19	Колоссальный B-Corpus
20	очищенный I-Corpus
21	собранный I-Corpus
22	в I-Corpus
23	интернете I-Corpus
24	корпус I-Corpus
25	) O
26	, O
27	являющийся O
28	отфильтрованной O
29	версией O
30	корпуса O
31	Common B-Corpus
32	Crawl I-Corpus
33	. O

# sent_id = 439
# text =  Для обучения использовался корпус C4 (Colossal Clean Crawled Corpus, Колоссальный очищенный собранный в интернете корпус). 
# relations = "Corpus_isAlternativeNameFor_Corpus 1 0, Corpus_isAlternativeNameFor_Corpus 2 0"
1	Для O
2	обучения O
3	использовался O
4	корпус O
5	C4 B-Corpus
6	( O
7	Colossal B-Corpus
8	Clean I-Corpus
9	Crawled I-Corpus
10	Corpus I-Corpus
11	, O
12	Колоссальный B-Corpus
13	очищенный I-Corpus
14	собранный I-Corpus
15	в I-Corpus
16	интернете I-Corpus
17	корпус I-Corpus
18	) O
19	. O

# sent_id = 440
# text =  Для ещё двух языков, английского и финского, несколько сотен параллельных предложений нашлось в эрзянском корпусе Universal Dependencies, собранном всё тем же Jack'ом Rueter'ом. 
# relations = "Corpus_Language_Lang 0 2, Corpus_Language_Lang 0 0, Corpus_Language_Lang 0 1"
1	Для O
2	ещё O
3	двух O
4	языков O
5	, O
6	английского B-Lang
7	и O
8	финского B-Lang
9	, O
10	несколько O
11	сотен O
12	параллельных O
13	предложений O
14	нашлось O
15	в O
16	эрзянском B-Lang
17	корпусе O
18	Universal B-Corpus
19	Dependencies I-Corpus
20	, O
21	собранном O
22	всё O
23	тем O
24	же O
25	Jack'ом B-Person
26	Rueter'ом I-Person
27	. O

# sent_id = 441
# text =  В качестве данных используется корпус журналов из области астрономии. 
# relations = ""
1	В O
2	качестве O
3	данных O
4	используется O
5	корпус B-Corpus
6	журналов I-Corpus
7	из O
8	области O
9	астрономии B-Science
10	. O

# sent_id = 442
# text =  Они обнаружили, что логистическая регрессия с содержательными признаками (content-based features), полученными на основе близости тем и слов в корпусе ACL (корпусе научных публикаций на английском языке), даёт наилучший результат. 
# relations = "Corpus_Language_Lang 0 0"
1	Они O
2	обнаружили O
3	, O
4	что O
5	логистическая B-Method
6	регрессия I-Method
7	с O
8	содержательными O
9	признаками O
10	( O
11	content O
12	- O
13	based O
14	features O
15	) O
16	, O
17	полученными O
18	на O
19	основе O
20	близости O
21	тем O
22	и O
23	слов O
24	в O
25	корпусе O
26	ACL B-Corpus
27	( O
28	корпусе B-Corpus
29	научных I-Corpus
30	публикаций I-Corpus
31	на O
32	английском B-Lang
33	языке I-Lang
34	) O
35	, O
36	даёт O
37	наилучший O
38	результат O
39	. O

# sent_id = 443
# text =  Использование логистической регрессии на корпусе ACL (корпусе научных публикаций на английском языке) даёт наилучший результат. 
# relations = "Corpus_Language_Lang 0 0"
1	Использование O
2	логистической B-Method
3	регрессии I-Method
4	на O
5	корпусе O
6	ACL B-Corpus
7	( O
8	корпусе B-Corpus
9	научных I-Corpus
10	публикаций I-Corpus
11	на O
12	английском B-Lang
13	языке I-Lang
14	) O
15	даёт O
16	наилучший O
17	результат O
18	. O

# sent_id = 444
# text =  Например, при изучении развёрнутой модели на 16 итераций на примере корпуса книг о Шерлоке Холмсе после 60 000 итераций (обучение на примерно 1 Мб текста) она выдаёт довольно бессмысленный текст. 
# relations = ""
1	Например O
2	, O
3	при O
4	изучении O
5	развёрнутой O
6	модели O
7	на O
8	16 O
9	итераций O
10	на O
11	примере O
12	корпуса B-Corpus
13	книг I-Corpus
14	о I-Corpus
15	Шерлоке I-Corpus
16	Холмсе I-Corpus
17	после O
18	60 O
19	000 O
20	итераций O
21	( O
22	обучение O
23	на O
24	примерно O
25	1 O
26	Мб O
27	текста O
28	) O
29	она O
30	выдаёт O
31	довольно O
32	бессмысленный O
33	текст O
34	. O

# sent_id = 445
# text =  В нашем случае это был корпус текстов из социальных сетей с 48 млн. 
# relations = ""
1	В O
2	нашем O
3	случае O
4	это O
5	был O
6	корпус B-Corpus
7	текстов I-Corpus
8	из I-Corpus
9	социальных I-Corpus
10	сетей I-Corpus
11	с O
12	48 O
13	млн O
14	. O

# sent_id = 446
# text =  Первое подобное исследование решает задачу автоматической оценки приемлемости в русском языке на основе корпуса предложений из лингвистических статей, что вызывает две проблемы. 
# relations = "Corpus_isTrainedForSolving_Task 0 0"
1	Первое O
2	подобное O
3	исследование O
4	решает O
5	задачу O
6	автоматической B-Task
7	оценки I-Task
8	приемлемости I-Task
9	в O
10	русском B-Lang
11	языке I-Lang
12	на O
13	основе O
14	корпуса B-Corpus
15	предложений I-Corpus
16	из I-Corpus
17	лингвистических I-Corpus
18	статей I-Corpus
19	, O
20	что O
21	вызывает O
22	две O
23	проблемы O
24	. O

# sent_id = 447
# text =  В качестве данных был выбран открытый корпус русскоязычных твитов. 
# relations = ""
1	В O
2	качестве O
3	данных O
4	был O
5	выбран O
6	открытый B-Corpus
7	корпус I-Corpus
8	русскоязычных I-Corpus
9	твитов I-Corpus
10	. O

# sent_id = 448
# text =  Отличием self-bleu от оригинала заключается в том, что вместо референтного корпуса используются все сгенерированные тексты, кроме тестируемого. 
# relations = ""
1	Отличием O
2	self O
3	- O
4	bleu O
5	от O
6	оригинала O
7	заключается O
8	в O
9	том O
10	, O
11	что O
12	вместо O
13	референтного B-Corpus
14	корпуса I-Corpus
15	используются O
16	все O
17	сгенерированные O
18	тексты O
19	, O
20	кроме O
21	тестируемого O
22	. O

# sent_id = 449
# text =  Таким образом, чем больше совпадений н-грамм между референтным корпусом и проверяемым текстом, тем выше значение этой метрики. 
# relations = ""
1	Таким O
2	образом O
3	, O
4	чем O
5	больше O
6	совпадений O
7	н B-Object
8	- I-Object
9	грамм I-Object
10	между O
11	референтным B-Corpus
12	корпусом I-Corpus
13	и O
14	проверяемым O
15	текстом O
16	, O
17	тем O
18	выше O
19	значение O
20	этой O
21	метрики O
22	. O

# sent_id = 450
# text = Хочу показать, как создать мультиязычный параллельный корпус и книги при помощи пет-проекта, которым я занимаюсь несколько лет. 
# relations = ""
1	Хочу O
2	показать O
3	, O
4	как O
5	создать O
6	мультиязычный B-Corpus
7	параллельный I-Corpus
8	корпус I-Corpus
9	и O
10	книги O
11	при O
12	помощи O
13	пет O
14	- O
15	проекта O
16	, O
17	которым O
18	я O
19	занимаюсь O
20	несколько O
21	лет O
22	. O

# sent_id = 451
# text =  Получим параллельный корпус на 10 языках и много красивых книг. 
# relations = ""
1	Получим O
2	параллельный B-Corpus
3	корпус I-Corpus
4	на O
5	10 O
6	языках O
7	и O
8	много O
9	красивых O
10	книг O
11	. O

# sent_id = 452
# text =  Я использовал модель, обученную на Национальном Корпусе Русского Языка (НКРЯ), ее название — ruscorpora_upos_cbow_300_20_2019. 
# relations = "Model_isTrainedOn_Corpus 1 0, Model_isTrainedOn_Corpus 1 1, Corpus_isAlternativeNameFor_Corpus 1 0"
1	Я O
2	использовал O
3	модель B-Model
4	, O
5	обученную B-Model_isTrainedOn_Corpus
6	на O
7	Национальном B-Corpus
8	Корпусе I-Corpus
9	Русского I-Corpus
10	Языка I-Corpus
11	( O
12	НКРЯ B-Corpus
13	) O
14	, O
15	ее O
16	название O
17	— O
18	ruscorpora_upos_cbow_300_20_2019 B-Model
19	. O

# sent_id = 453
# text =  Для наших целей прекрасно подошла модель ruscorpora_upos_cbow_300_20_2019, обученная на Национальном Корпусе Русского Языка (НКРЯ). 
# relations = "Model_isTrainedOn_Corpus 0 0, Model_isTrainedOn_Corpus 0 1, Corpus_isAlternativeNameFor_Corpus 1 0"
1	Для O
2	наших O
3	целей O
4	прекрасно O
5	подошла O
6	модель O
7	ruscorpora_upos_cbow_300_20_2019 B-Model
8	, O
9	обученная B-Model_isTrainedOn_Corpus
10	на O
11	Национальном B-Corpus
12	Корпусе I-Corpus
13	Русского I-Corpus
14	Языка I-Corpus
15	( O
16	НКРЯ B-Corpus
17	) O
18	. O

# sent_id = 454
# text =  Для своих целей я применил модель, обученную на Национальном Корпусе Русского Языка (НКРЯ) под названием ruscorpora_upos_cbow_300_20_2019.
# relations = "Model_isTrainedOn_Corpus 0 0, Model_isTrainedOn_Corpus 0 1, Corpus_isAlternativeNameFor_Corpus 1 0"
1	Для O
2	своих O
3	целей O
4	я O
5	применил O
6	модель O
7	, O
8	обученную O
9	на O
10	Национальном B-Corpus
11	Корпусе I-Corpus
12	Русского I-Corpus
13	Языка I-Corpus
14	( O
15	НКРЯ B-Corpus
16	) O
17	под O
18	названием O
19	ruscorpora_upos_cbow_300_20_2019 B-Model
20	. O

# sent_id = 455
# text =  Основной тип данных для обучения переводчика — это bitext-корпусы, состоящие из пар текстов «оригинал — перевод». 
# relations = ""
1	Основной O
2	тип O
3	данных O
4	для O
5	обучения O
6	переводчика O
7	— O
8	это O
9	bitext B-Corpus
10	- I-Corpus
11	корпусы I-Corpus
12	, O
13	состоящие O
14	из O
15	пар O
16	текстов O
17	« O
18	оригинал O
19	— O
20	перевод O
21	» O
22	. O

# sent_id = 456
# text =  Например, один из крупнейших корпусов UNPC состоит из официальных и юридических текстов. 
# relations = ""
1	Например O
2	, O
3	один O
4	из O
5	крупнейших O
6	корпусов O
7	UNPC B-Corpus
8	состоит O
9	из O
10	официальных O
11	и O
12	юридических O
13	текстов O
14	. O

# sent_id = 457
# text =  Другой полезный источник — это mono-корпусы, состоящие из большого объёма обычных текстов. 
# relations = ""
1	Другой O
2	полезный O
3	источник O
4	— O
5	это O
6	mono B-Corpus
7	- I-Corpus
8	корпусы I-Corpus
9	, O
10	состоящие O
11	из O
12	большого O
13	объёма O
14	обычных O
15	текстов O
16	. O

# sent_id = 458
# text =  На основе mono-корпусов мы предобучаем разные вспомогательные модели, начиная с токенизаторов и заканчивая большими языковыми претрейнами типа BART и T5. 
# relations = "Model_isTrainedOn_Corpus 0 0"
1	На O
2	основе O
3	mono B-Corpus
4	- I-Corpus
5	корпусов I-Corpus
6	мы O
7	предобучаем B-Model_isTrainedOn_Corpus
8	разные O
9	вспомогательные O
10	модели O
11	, O
12	начиная O
13	с O
14	токенизаторов O
15	и O
16	заканчивая O
17	большими O
18	языковыми O
19	претрейнами O
20	типа O
21	BART B-Model
22	и O
23	T5 B-Model
24	. O

# sent_id = 459
# text =  Исходя из моно-корпусов, мы проводим предварительное обучение различных вспомогательных моделей, начиная с токенизаторов и заканчивая обширными языковыми предварительными тренировками, такими как BART и T5.
# relations = "Model_isTrainedOn_Corpus 0 0"
1	Исходя O
2	из O
3	моно B-Corpus
4	- I-Corpus
5	корпусов I-Corpus
6	, O
7	мы O
8	проводим O
9	предварительное O
10	обучение B-Model_isTrainedOn_Corpus
11	различных O
12	вспомогательных O
13	моделей O
14	, O
15	начиная O
16	с O
17	токенизаторов O
18	и O
19	заканчивая O
20	обширными O
21	языковыми O
22	предварительными O
23	тренировками O
24	, O
25	такими O
26	как O
27	BART B-Model
28	и O
29	T5 B-Model
30	. O

# sent_id = 460
# text =  Авторы, предложившие такой подход, делали свой поиск внутри огромного корпуса Common Crawl и снапшотов Википедии, и поделились с нами новыми крупными датасетами CCMatrix и WikiMatrix. 
# relations = ""
1	Авторы O
2	, O
3	предложившие O
4	такой O
5	подход O
6	, O
7	делали O
8	свой O
9	поиск O
10	внутри O
11	огромного O
12	корпуса O
13	Common B-Corpus
14	Crawl I-Corpus
15	и O
16	снапшотов O
17	Википедии B-InfoResource
18	, O
19	и O
20	поделились O
21	с O
22	нами O
23	новыми O
24	крупными O
25	датасетами O
26	CCMatrix B-Dataset
27	и O
28	WikiMatrix B-Dataset
29	. O

# sent_id = 461
# text =  Для сравнения, размер хорошего английского корпуса The Pile составляет более 800Гб. 
# relations = ""
1	Для O
2	сравнения O
3	, O
4	размер O
5	хорошего O
6	английского B-Lang
7	корпуса O
8	The B-Corpus
9	Pile I-Corpus
10	составляет O
11	более O
12	800 O
13	Гб O
14	. O

# sent_id = 462
# text =  В конце концов, основным в обучении GPT был корпус англоязычной литературы. 
# relations = ""
1	В O
2	конце O
3	концов O
4	, O
5	основным O
6	в O
7	обучении O
8	GPT B-Model
9	был O
10	корпус B-Corpus
11	англоязычной I-Corpus
12	литературы I-Corpus
13	. O

# sent_id = 463
# text =  Я решил велосипед не изобретать и собрать свой датасет из готовых дампов Википедии, новостей, выгрузки постов с Habr и корпуса русских книг, отсекая тексты короче 10000 токенов. 
# relations = ""
1	Я O
2	решил O
3	велосипед O
4	не O
5	изобретать O
6	и O
7	собрать O
8	свой O
9	датасет O
10	из O
11	готовых O
12	дампов O
13	Википедии B-InfoResource
14	, O
15	новостей O
16	, O
17	выгрузки O
18	постов O
19	с O
20	Habr B-InfoResource
21	и O
22	корпуса B-Corpus
23	русских I-Corpus
24	книг I-Corpus
25	, O
26	отсекая O
27	тексты O
28	короче O
29	10000 O
30	токенов O
31	. O

# sent_id = 464
# text = После преобразования сообщений в векторы можно использовать любой классический метод для классификации: логистическую регрессию, SVM, случайный лес, бустинг. 
# relations = "Method_solves_Task 0 0, Method_solves_Task 1 0, Method_solves_Task 2 0, Method_solves_Task 3 0"
1	После O
2	преобразования O
3	сообщений O
4	в O
5	векторы O
6	можно O
7	использовать O
8	любой O
9	классический O
10	метод O
11	для O
12	классификации B-Task
13	: O
14	логистическую B-Method
15	регрессию I-Method
16	, O
17	SVM B-Method
18	, O
19	случайный B-Method
20	лес I-Method
21	, O
22	бустинг B-Method
23	. O

# sent_id = 465
# text =  Для сверточных нейросетей хорошо настроенный метод стохастического градиента (SGD) почти всегда немного превосходит Adam, но область оптимальной скорости обучения гораздо более узкая и зависит от задачи. 
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Для O
2	сверточных O
3	нейросетей O
4	хорошо O
5	настроенный O
6	метод B-Method
7	стохастического I-Method
8	градиента I-Method
9	( O
10	SGD B-Method
11	) O
12	почти O
13	всегда O
14	немного O
15	превосходит O
16	Adam B-Method
17	, O
18	но O
19	область O
20	оптимальной O
21	скорости O
22	обучения O
23	гораздо O
24	более O
25	узкая O
26	и O
27	зависит O
28	от O
29	задачи O
30	. O

# sent_id = 466
# text =  После работы Эдсгера Дейкстры «О вреде оператора goto», давшей отправную точку парадигмы "структурного программирования", было немало работ, посвященных "структуре алгоритма": методология ООП, функциональное программирование, паттерны проектирования, принципы SOLID…
# relations = ""
1	После O
2	работы O
3	Эдсгера B-Person
4	Дейкстры I-Person
5	« O
6	О O
7	вреде O
8	оператора O
9	goto O
10	» O
11	, O
12	давшей O
13	отправную O
14	точку O
15	парадигмы O
16	" O
17	структурного O
18	программирования O
19	" O
20	, O
21	было O
22	немало O
23	работ O
24	, O
25	посвященных O
26	" O
27	структуре O
28	алгоритма O
29	" O
30	: O
31	методология O
32	ООП B-Method
33	, O
34	функциональное B-Science
35	программирование I-Science
36	, O
37	паттерны B-Method
38	проектирования I-Method
39	, O
40	принципы B-Method
41	SOLID I-Method
42	… O

# sent_id = 467
# text =  В случае GNMT речь идет о так называемом методе перевода на основе примеров (EBMT), т.е. 
# relations = "Method_isAlternativeNameFor_Method 2 1"
1	В O
2	случае O
3	GNMT B-Method
4	речь O
5	идет O
6	о O
7	так O
8	называемом O
9	методе B-Method
10	перевода I-Method
11	на I-Method
12	основе I-Method
13	примеров I-Method
14	( O
15	EBMT B-Method
16	) O
17	, O
18	т.е. O

# sent_id = 468
# text =  Мы обучаем методологии CRISP-DM, учим постановке гипотез, выбору и аргументации методов исследования, интерпретации и представлению результатов. 
# relations = ""
1	Мы O
2	обучаем O
3	методологии O
4	CRISP B-Method
5	- I-Method
6	DM I-Method
7	, O
8	учим O
9	постановке O
10	гипотез O
11	, O
12	выбору O
13	и O
14	аргументации O
15	методов O
16	исследования O
17	, O
18	интерпретации O
19	и O
20	представлению O
21	результатов O
22	. O

# sent_id = 469
# text =  На момент создания в 2020 году такая модель была наикрупнейшей. 
# relations = "Date_isDateOf_Model 0 0"
1	На O
2	момент O
3	создания O
4	в O
5	2020 B-Date
6	году O
7	такая O
8	модель B-Model
9	была O
10	наикрупнейшей O
11	. O

# sent_id = 470
# text =  В 2020 году появился GPT-3. 
# relations = "Date_isDateOf_Model 0 0"
1	В O
2	2020 B-Date
3	году O
4	появился O
5	GPT-3 B-Model
6	. O

# sent_id = 471
# text =  О своём партнёрстве с Microsoft OpenAI объявила в конце 2019 года. 
# relations = ""
1	О O
2	своём O
3	партнёрстве O
4	с O
5	Microsoft B-Organization
6	OpenAI B-Organization
7	объявила O
8	в O
9	конце O
10	2019 B-Date
11	года O
12	. O

# sent_id = 472
# text = С появлением в 2020 году нейронной сети GPT3 и других архитектур – трансформеров, генерируемые тексты стали невероятно правдоподобными. 
# relations = "Date_isDateOf_Model 0 0, Date_isDateOf_Model 0 1"
1	С O
2	появлением O
3	в O
4	2020 B-Date
5	году O
6	нейронной O
7	сети O
8	GPT3 B-Model
9	и O
10	других O
11	архитектур B-Model
12	– I-Model
13	трансформеров I-Model
14	, O
15	генерируемые O
16	тексты O
17	стали O
18	невероятно O
19	правдоподобными O
20	. O

# sent_id = 473
# text =  В 2020 компания приобрела эксклюзивную лицензию на базовую технологию, лежащую в основе GPT-3. 
# relations = ""
1	В O
2	2020 B-Date
3	компания O
4	приобрела O
5	эксклюзивную O
6	лицензию O
7	на O
8	базовую O
9	технологию O
10	, O
11	лежащую O
12	в O
13	основе O
14	GPT-3 B-Model
15	. O

# sent_id = 474
# text =  6 февраля 2023 года Google представил свой аналог ChatGPT — экспериментальный диалоговый ИИ-сервис под названием Bard. 
# relations = "Application_hasAuthor_Organization 1 0, Date_isDateOf_Application 0 1"
1	6 O
2	февраля O
3	2023 B-Date
4	года O
5	Google B-Organization
6	представил O
7	свой O
8	аналог O
9	ChatGPT B-Technology
10	— O
11	экспериментальный O
12	диалоговый O
13	ИИ O
14	- O
15	сервис O
16	под O
17	названием O
18	Bard B-Technology
19	. O

# sent_id = 475
# text =  Однако, по мере углубления в тему, автор связался с разработчиками и в январе 2023 года получил первую версию ScoreCloud Songwriter на тестирование под Windows 10. 
# relations = "Date_isDateOf_Application 0 0, Environment_isUsedIn_Application 0 0"
1	Однако O
2	, O
3	по O
4	мере O
5	углубления O
6	в O
7	тему O
8	, O
9	автор O
10	связался O
11	с O
12	разработчиками O
13	и O
14	в O
15	январе O
16	2023 B-Date
17	года O
18	получил O
19	первую O
20	версию O
21	ScoreCloud B-Technology
22	Songwriter I-Technology
23	на O
24	тестирование O
25	под O
26	Windows B-Environment
27	10 I-Environment
28	. O

# sent_id = 476
# text =  В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE. 
# relations = "Method_hasAuthor_Organization 1 0, Method_hasAuthor_Organization 1 1, Method_hasAuthor_Organization 1 2, Method_hasAuthor_Organization 0 0, Method_hasAuthor_Organization 0 1, Method_hasAuthor_Organization 0 2, Date_isDateOf_Method 0 0, Date_isDateOf_Method 0 1"
1	В O
2	2020 B-Date
3	нашими O
4	коллегами O
5	из O
6	команды O
7	AGI B-Organization
8	NLP I-Organization
9	Сбербанка I-Organization
10	, O
11	лаборатории O
12	Noah B-Organization
13	’s I-Organization
14	Ark I-Organization
15	Huawei I-Organization
16	и O
17	факультета O
18	компьютерных O
19	наук O
20	ВШЭ B-Organization
21	был O
22	представлен O
23	Russian B-Method
24	SuperGLUE I-Method
25	— O
26	набор O
27	задач O
28	на O
29	понимание O
30	текста O
31	по O
32	аналогии O
33	с O
34	его O
35	английской O
36	версией O
37	SuperGLUE B-Method
38	. O

# sent_id = 477
# text =  Описание технологии появилось в общем доступе в 2020 году.
# relations = ""
1	Описание O
2	технологии O
3	появилось O
4	в O
5	общем O
6	доступе O
8	в O
9	2020 B-Date
10	году O
11	. O

# sent_id = 478
# text =  Обучение языковой модели происходило в 2021 году. 
# relations = ""
1	Обучение O
2	языковой O
3	модели O
4	происходило O
5	в O
6	2021 B-Date
7	году O
8	. O

# sent_id = 479
# text =  Первые нейронные сети были внедрены в кредитный скоринг в 2020-м году. 
# relations = ""
1	Первые O
2	нейронные O
3	сети O
4	были O
5	внедрены O
6	в O
7	кредитный O
8	скоринг O
9	в O
10	2020-м B-Date
11	году O
12	. O

# sent_id = 480
# text =  В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения. 
# relations = "Application_isUsedIn_Science 0 0, Date_isDateOf_Application 0 0, Application_hasAuthor_Organization 0 0"
1	В O
2	2021 B-Date
3	году O
4	Amazon B-Organization
5	запустила O
6	SageMaker B-Technology
7	Studio I-Technology
8	— O
9	первый O
10	IDE B-App_system
11	для O
12	машинного B-Science
13	обучения i-Science
14	. O

# sent_id = 481
# text =  Создана в 2021 году. 
# relations = ""
1	Создана O
2	в O
3	2021 B-Date
4	году O
5	. O

# sent_id = 482
# text =  ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия). 
# relations = "Date_isDateOf_Application 0 0, Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 0 1, Application_isUsedForSolving_Task 0 2, Application_isUsedForSolving_Task 0 3"
1	ChatGPT B-Technology
2	был O
3	запущен O
4	30 B-Date
5	ноября I-Date
6	2022 I-Date
7	года O
8	и O
9	привлек O
10	внимание O
11	своими O
12	широкими O
13	возможностями O
14	: O
15	написание B-Task
16	кода I-Task
17	, O
18	создание B-Task
19	текстов I-Task
20	, O
21	возможности O
22	перевода B-Task
23	, O
24	получения B-Task
25	точных I-Task
26	ответов I-Task
27	и O
28	использование O
29	контекста O
30	диалога O
31	для O
32	ответов O
33	, O
34	хотя O
35	его O
36	фактическая O
37	точность O
38	подверглась O
39	критике O
40	( O
41	источник O
42	— O
43	Википедия B-InfoResource
44	) O
45	. O

# sent_id = 483
# text =  Компания уже давно работает над сложным поисковым ИИ под названием LaMDA: о нем впервые объявили еще в мае 2021 года. 
# relations = "Date_isDateOf_Application 0 0"
1	Компания O
2	уже O
3	давно O
4	работает O
5	над O
6	сложным O
7	поисковым O
8	ИИ O
9	под O
10	названием O
11	LaMDA B-Technology
12	: O
13	о O
14	нем O
15	впервые O
16	объявили O
17	еще O
18	в O
19	мае O
20	2021 B-Date
21	года O
22	. O

# sent_id = 484
# text =  И уже в 2020-2021 годах компании начали запускать альтернативные платформы, а стартапы — внедрять Feature Store в свои проекты. 
# relations = ""
1	И O
2	уже O
3	в O
4	2020 B-Date
5	- O
6	2021 B-Date
7	годах O
8	компании O
9	начали O
10	запускать O
11	альтернативные O
12	платформы O
13	, O
14	а O
15	стартапы O
16	— O
17	внедрять O
18	Feature B-Technology
19	Store I-Technology
20	в O
21	свои O
22	проекты O
23	. O

# sent_id = 485
# text =  На этапе обучения text-davinci-003 используются датасеты текстов и программного кода, собранные OpenAI на момент конца 2021 года. 
# relations = "Model_isTrainedOn_Dataset 0 0"
1	На O
2	этапе O
3	обучения O
4	text B-Model
5	- I-Model
6	davinci-003 I-Model
7	используются O
8	датасеты B-Dataset
9	текстов I-Dataset
10	и O
11	программного O
12	кода O
13	, O
14	собранные O
15	OpenAI B-Organization
16	на O
17	момент O
18	конца O
19	2021 B-Date
20	года O
21	. O

# sent_id = 486
# text =  На этапе обучения ChatGPT используются дополнительные текстовые данные и программный код, собранные на момент конца 2021 года.Reinforcement Learning with Human Feedback (RLHF)В основе лежит сильная предобученная языковая модель (в случае ChatGPT это InstructGPT, но могут быть и другие, например, Gopher от DeepMind). 
# relations = ""
1	На O
2	этапе O
3	обучения O
4	ChatGPT B-Technology
5	используются O
6	дополнительные O
7	текстовые O
8	данные O
9	и O
10	программный O
11	код O
12	, O
13	собранные O
14	на O
15	момент O
16	конца O
17	2021 B-Date
18	года O
19	. O

# sent_id = 487
# text =  Так и появился AIDungeon — уникальная для своего времени (2019 год) вещь, которая не сильно потеряла в популярности и по сей день. 
# relations = "Date_isDateOf_Application 0 0"
1	Так O
2	и O
3	появился O
4	AIDungeon B-Technology
5	— O
6	уникальная O
7	для O
8	своего O
9	времени O
10	( O
11	2019 B-Date
12	год O
13	) O
14	вещь O
15	, O
16	которая O
17	не O
18	сильно O
19	потеряла O
20	в O
21	популярности O
22	и O
23	по O
24	сей O
25	день O
26	. O

# sent_id = 488
# text =  Окончательная версия TACL c достаточно хорошим внешним видом содержит около 150 цитат, связанных с BERT, и нет никаких иллюзий завершённости: в августе 2020 года у нас закончились отведённые для журнала страницы. 
# relations = ""
1	Окончательная O
2	версия O
3	TACL B-Environment
4	c O
5	достаточно O
6	хорошим O
7	внешним O
8	видом O
9	содержит O
10	около O
11	150 O
12	цитат O
13	, O
14	связанных O
15	с O
16	BERT B-Model
17	, O
18	и O
19	нет O
20	никаких O
21	иллюзий O
22	завершённости O
23	: O
24	в O
25	августе O
26	2020 B-Date
27	года O
28	у O
29	нас O
30	закончились O
31	отведённые O
32	для O
33	журнала O
34	страницы O
35	. O

# sent_id = 489
# text =  Чтобы определить, какие проходы и MLP нужно обрезать, мы используем аппроксимацию, основанную на потерях: оценки важности, предложенные Michel, Levy and Neubig (2019) для проходов самонаблюдения, которые мы распространяем на MLP. 
# relations = ""
1	Чтобы O
2	определить O
3	, O
4	какие O
5	проходы O
6	и O
7	MLP B-Method
8	нужно O
9	обрезать O
10	, O
11	мы O
12	используем O
13	аппроксимацию O
14	, O
15	основанную O
16	на O
17	потерях O
18	: O
19	оценки O
20	важности O
21	, O
22	предложенные O
23	Michel B-Person
24	, O
25	Levy B-Person
26	and O
27	Neubig B-Person
28	( O
29	2019 B-Date
30	) O
31	для O
32	проходов O
33	самонаблюдения O
34	, O
35	которые O
36	мы O
37	распространяем O
38	на O
39	MLP B-Method
40	. O

# sent_id = 490
# text =  Например, в 2022 году, помимо ABBYY, это будут МТС, SberDevices, Яндекс и другие. 
# relations = ""
1	Например O
2	, O
3	в O
4	2022 B-Date
5	году O
6	, O
7	помимо O
8	ABBYY B-Organization
9	, O
10	это O
11	будут O
12	МТС B-Organization
13	, O
14	SberDevices B-Organization
15	, O
16	Яндекс B-Organization
17	и O
18	другие O
19	. O

# sent_id = 491
# text =  Первая была в 2019 году, называлась AGRR: Automatic Gapping Resolution for Russian. 
# relations = "Task_isAlternativeNameFor_Task 1 0"
1	Первая O
2	была O
3	в O
4	2019 B-Date
5	году O
6	, O
7	называлась O
8	AGRR B-Task
9	: O
10	Automatic B-Task
11	Gapping I-Task
12	Resolution I-Task
13	for I-Task
14	Russian I-Task
15	. O

# sent_id = 492
# text =  Автор эксперимента может быть простым наблюдателем, однако его результаты сильно влияют на выбор рациональных допущений в исследовании.
# relations = ""
16	Автор O
17	эксперимента B-Activity
18	может O
19	быть O
20	простым O
21	наблюдателем O
22	, O
23	однако O
24	его O
25	результаты O
26	сильно O
27	влияют O
28	на O
29	выбор O
30	рациональных O
31	допущений O
32	в O
33	исследовании O
34	. O

# sent_id = 493
# text =  Для данного эксперимента наилучшими оказались параметры 0.2 и 0.3. 
# relations = ""
1	Для O
2	данного O
3	эксперимента B-Activity
4	наилучшими O
5	оказались O
6	параметры O
7	0.2 O
8	и O
9	0.3 O
10	. O

# sent_id = 494
# text =  После первых экспериментов оказалось, что краткого описания задачи недостаточно и результаты неустойчивы. 
# relations = ""
1	После O
2	первых O
3	экспериментов B-Activity
4	оказалось O
5	, O
6	что O
7	краткого O
8	описания O
9	задачи O
10	недостаточно O
11	и O
12	результаты O
13	неустойчивы O
14	. O

# sent_id = 495
# text =  Техногиганты в зависимости от текущей повестки публикуют разные исследования то за, то против удаленной работы. 
# relations = ""
1	Техногиганты O
2	в O
3	зависимости O
4	от O
5	текущей O
6	повестки O
7	публикуют O
8	разные O
9	исследования B-Activity
10	то O
11	за O
12	, O
13	то O
14	против O
15	удаленной O
16	работы O
17	. O

# sent_id = 496
# text =  Некоторые люди используют его в целях академических исследований. 
# relations = ""
1	Некоторые O
2	люди O
3	используют O
4	его O
5	в O
6	целях O
7	академических B-Activity
8	исследований I-Activity
9	. O

# sent_id = 497
# text =  Если вам также интересно наше исследование, прикладываю ссылку на наш репозиторий с реализацией нашего алгоритма на фреймворке PyTorch. 
# relations = ""
1	Если O
2	вам O
3	также O
4	интересно O
5	наше O
6	исследование B-Activity
7	, O
8	прикладываю O
9	ссылку O
10	на O
11	наш O
12	репозиторий O
13	с O
14	реализацией O
15	нашего O
16	алгоритма O
17	на O
18	фреймворке O
19	PyTorch B-Environment
20	. O

# sent_id = 498
# text =  Проект получил название YaLM 2.0. 
# relations = ""
1	Проект O
2	получил O
3	название O
4	YaLM B-Activity
5	2.0 I-Activity
6	. O

# sent_id = 499
# text =  Важным аспектом здесь является то, что Nearby Share опирается на Google Mobile Services (GMS), а это означает, что разработчик системы заменил доступную в AOSP функцию проприетарной службой, которая не является частью проекта AOSP. 
# relations = "Organization_isAlternativeNameFor_Organization 2 1"
1	Важным O
2	аспектом O
3	здесь O
4	является O
5	то O
6	, O
7	что O
8	Nearby B-Organization
9	Share I-Organization
10	опирается O
11	на O
12	Google B-Organization
13	Mobile I-Organization
14	Services I-Organization
15	( O
16	GMS B-Organization
17	) O
18	, O
19	а O
20	это O
21	означает O
22	, O
23	что O
24	разработчик O
25	системы O
26	заменил O
27	доступную O
28	в O
29	AOSP B-Activity
30	функцию O 
31	проприетарной O
32	службой O
33	, O
34	которая O
35	не O
36	является O
37	частью O
38	проекта O
39	AOSP B-Activity
40	. O

# sent_id = 500
# text =  Nearby Share (NS) повторяют за Google Mobile Services (GMS). 
# relations = "Organization_isAlternativeNameFor_Organization 1 0, Organization_isAlternativeNameFor_Organization 3 2"
1	Nearby B-Organization
2	Share I-Organization
3	( O
4	NS B-Organization
5	) O
6	повторяют O 
7	за O
8	Google B-Organization
9	Mobile I-Organization
10	Services I-Organization
11	( O
12	GMS B-Organization
13	) O
14	. O

# sent_id = 501
# text =  Исходный код проекта GPT-Tokenator на GitHub 
# relations = ""
1	Исходный O
2	код O
3	проекта O
4	GPT B-Activity
5	- I-Activity
6	Tokenator I-Activity
7	на O
8	GitHub B-InfoResource

# sent_id = 502
# text =  В настоящее время проект Angry Email Translator находится на стадии тестирования. 
# relations = ""
1	В O
2	настоящее O
3	время O
4	проект O
5	Angry B-Activity
6	Email I-Activity
7	Translator I-Activity
8	находится O
9	на O
10	стадии O
11	тестирования O
12	. O

# sent_id = 503
# text =  Этот проект называется llamaindex. 
# relations = ""
1	Этот O
2	проект O
3	называется O
4	llamaindex B-Activity
5	. O

# sent_id = 504
# text =  Так появился проект VoiceDock, призванный сделать ИИ доступнее для разработчиков конечных приложений. 
# relations = ""
1	Так O
2	появился O
3	проект O
4	VoiceDock B-Activity
5	, O
6	призванный O
7	сделать O
8	ИИ O
9	доступнее O
10	для O
11	разработчиков O
12	конечных O
13	приложений O
14	. O

# sent_id = 505
# text =  Построен на базе whisper.cpp (Быстрая С++ реализации проекта Whisper от Open AI). 
# relations = ""
1	Построен O
2	на O
3	базе O
4	whisper.cpp B-Activity
5	( O
6	Быстрая O
7	С++ B-Environment
8	реализации O
9	проекта O
10	Whisper B-Activity
11	от O
12	Open B-Organization
13	AI I-Organization
14	) O
15	. O

# sent_id = 506
# text =  Сделана на базе популярного проекта llama.cpp от того же автора, что и whisper.cpp. 
# relations = ""
1	Сделана O
2	на O
3	базе O
4	популярного O
5	проекта O
6	llama.cpp B-Activity
7	от O
8	того O
9	же O
10	автора O
11	, O
12	что O
13	и O
14	whisper.cpp B-Activity
15	. O

# sent_id = 507
# text = Решение основано на проекте Piper и позволяет достаточно качественно и быстро синтезировать голос (демки можно послушать тут). 
# relations = ""
1	Решение O
2	основано O
3	на O
4	проекте O
5	Piper B-Activity
6	и O
7	позволяет O
8	достаточно O
9	качественно O
10	и O
11	быстро O
12	синтезировать O
13	голос O
14	( O
15	демки O
16	можно O
17	послушать O
18	тут O
19	) O
20	. O

# sent_id = 508
# text = Пройдя этот путь, уже не так сложно начать строить свой проект голосового ассистента. 
# relations = ""
1	Пройдя O
2	этот O
3	путь O
4	, O
5	уже O
6	не O
7	так O
8	сложно O
9	начать O
10	строить O
11	свой O
12	проект B-Activity
13	голосового I-Activity
14	ассистента I-Activity
15	. O

# sent_id = 509
# text =  Миллер опубликовал подробное техническое описание всех своих действий по этому проекту под названием Robo Boys в своём блоге. 
# relations = ""
1	Миллер B-Person
2	опубликовал O
3	подробное O
4	техническое O
5	описание O
6	всех O
7	своих O
8	действий O
9	по O
10	этому O
11	проекту O
12	под O
13	названием O
14	Robo B-Activity
15	Boys I-Activity
16	в O
17	своём O
18	блоге O
19	. O

# sent_id = 510
# text =  В начале апреля СМИ сообщили, что подрядчики Google в проекте по оценке ответов чат-бота Bard из-за нехватки времени часто ставили оценки на ответы ИИ по сложным запросам наугад. 
# relations = "Activity_hasAuthor_Organization 0 0"
1	В O
2	начале O
3	апреля O
4	СМИ O
5	сообщили O
6	, O
7	что O
8	подрядчики O
9	Google B-Organization
10	в O
11	проекте B-Activity
12	по I-Activity
13	оценке I-Activity
14	ответов I-Activity
15	чат I-Activity
16	- I-Activity
17	бота I-Activity
18	Bard I-Activity
19	из O
20	- O
21	за O
22	нехватки O
23	времени O
24	часто O
25	ставили O
26	оценки O
27	на O
28	ответы O
29	ИИ O
30	по O
31	сложным O
32	запросам O
33	наугад O
34	. O

# sent_id = 511
# text =  Еще один известный проект подобного типа — Midjourney. 
# relations = ""
1	Еще O
2	один O
3	известный O
4	проект O
5	подобного O
6	типа O
7	— O
8	Midjourney B-Activity
9	. O

# sent_id = 512
# text =  Артур Самуэль тесно сотрудничал с Дональдом Кнутом при создании проекта TeX, и самостоятельно написал часть технической документации для этого стандарта. 
# relations = ""
1	Артур B-Person
2	Самуэль I-Person
3	тесно O
4	сотрудничал O
5	с O
6	Дональдом B-Person
7	Кнутом I-Person
8	при O
9	создании O
10	проекта O
11	TeX B-Activity
12	, O
13	и O
14	самостоятельно O
15	написал O
16	часть O
17	технической O
18	документации O
19	для O
20	этого O
21	стандарта O
22	. O

# sent_id = 513
# text =  Да, на сложных проектах Copilot может иногда и мешать. 
# relations = ""
1	Да O
2	, O
3	на O
4	сложных O
5	проектах O
6	Copilot B-Activity
7	может O
8	иногда O
9	и O
10	мешать O
11	. O

# sent_id = 514
# text =  Во время разработки этой системы я познакомился с другими техническими проектами «Диалектика», о которых хочу рассказать в этом посте. 
# relations = ""
1	Во O
2	время O
3	разработки O
4	этой O
5	системы O
6	я O
7	познакомился O
8	с O
9	другими O
10	техническими O
11	проектами O
12	« O
13	Диалектика B-Activity
14	» O
15	, O
16	о O
17	которых O
18	хочу O
19	рассказать O
20	в O
21	этом O
22	посте O
23	. O

# sent_id = 515
# text = Инфоповоды, которые осветил коллектив проекта “АгитПроп” в своей новостной рубрике. 
# relations = ""
1	Инфоповоды O
2	, O
3	которые O
4	осветил O
5	коллектив O
6	проекта O
7	“ O
8	АгитПроп B-Activity
9	” O
10	в O
11	своей O
12	новостной O
13	рубрике O
14	. O

# sent_id = 516
# text =  Этот датасет используется в проекте Марксизм в цитатах. 
# relations = ""
1	Этот O
2	датасет B-Dataset
3	используется O
4	в O
5	проекте O
6	Марксизм B-Activity
7	в O
8	цитатах O
9	. O

# sent_id = 517
# text =  Стоит ещё понимать, что это MVP, проект совсем молодой, а экспертность у создателей в этой сфере большая - так что я думаю скоро мы будем видеть классные апдейты.WonderSlideСтоимость: 7 дней бесплатный период (можно регистрироваться на почту,ну вы поняли), потом 69 USD в год подпискаРезюме: Отличный сервис по соотношению время/качество для событий, когда не нужен выдающийся дизайн.3. 
# relations = ""
1	Стоит O
2	ещё O
3	понимать O
4	, O
5	что O
6	это O
7	MVP B-Activity
8	, O
9	проект O
10	совсем O
11	молодой O
12	, O
13	а O
14	экспертность O
15	у O
16	создателей O
17	в O
18	этой O
19	сфере O
20	большая O
21	- O
22	так O
23	что O
24	я O
25	думаю O
26	скоро O
27	мы O
28	будем O
29	видеть O
30	классные O
31	апдейты O
32	. O

# sent_id = 518
# text = В 2022 году сообщалось, что в рамках проекта Riffusion разработчики развивают вариант системы машинного обучения Stable Diffusion для генерации музыки вместо изображений. 
# relations = ""
1	В O
2	2022 B-Date
3	году O
4	сообщалось O
5	, O
6	что O
7	в O
8	рамках O
9	проекта O
10	Riffusion B-Activity
11	разработчики O
12	развивают O
13	вариант O
14	системы O
15	машинного O
16	обучения O
17	Stable B-App_system
18	Diffusion I-App_system
19	для O
20	генерации O
21	музыки O
22	вместо O
23	изображений O
24	. O

# sent_id = 519
# text = Бывший президент Google China и китайско-тайваньский венчурный капиталист Ли Кайфу объявил о запуске нового ИИ-проекта под названием Project AI 2.0. 
# relations = ""
1	Бывший O
2	президент O
3	Google B-Organization
4	China I-Organization
5	и O
6	китайско O
7	- O
8	тайваньский O
9	венчурный O
10	капиталист O
11	Ли B-Person
12	Кайфу I-Person
13	объявил O
14	о O
15	запуске O
16	нового O
17	ИИ O
18	- O
19	проекта O
20	под O
21	названием O
22	Project B-Activity
23	AI I-Activity
24	2.0 I-Activity
25	. O

# sent_id = 520
# text =  Например, GPT может предложить идеи для MVP-проекта и помочь с их возможной реализацией. 
# relations = ""
1	Например O
2	, O
3	GPT B-Technology
4	может O
5	предложить O
6	идеи O
7	для O
8	MVP B-Activity
9	- I-Activity
10	проекта I-Activity
11	и O
12	помочь O
13	с O
14	их O
15	возможной O
16	реализацией O
17	. O

# sent_id = 521
# text =   Сбер создал и опубликовал в открытом доступе программную библиотеку PyTorch-LifeStream, содержащую несколько алгоритмов построения эмбеддингов событийных данных.
# relations = "Application_hasAuthor_Organization 0 0"
1	Сбер B-Organization
2	создал B-Application_hasAuthor_Organization
3	и O
4	опубликовал O
5	в O
6	открытом O
7	доступе O
8	программную O
9	библиотеку O
10	PyTorch B-Application
11	- I-Application
12	LifeStream I-Application
13	, O
14	содержащую O
15	несколько O
16	алгоритмов O
17	построения O
18	эмбеддингов O
19	событийных O
20	данных O
21	. O

# sent_id = 522
# text =  Эмбеддинг (Embedding) – преобразования сложноструктурированных данных,  например слов, текстов, атрибутов событий, событий и их последовательностей, в машинно-читаемый набор чисел – числовой вектор.
# relations = "Object_includes_Object 2 3, Object_includes_Object 2 4, Object_includes_Object 2 5, Object_includes_Object 2 6"
1	Эмбеддинг B-Object
2	( O
3	Embedding B-Object
4	) O
5	– O
6	преобразования O
7	сложноструктурированных B-Object
8	данных I-Object
9	, O
10	например O
11	слов B-Object
12	, O
13	текстов B-Object
14	, O
15	атрибутов B-Object
16	событий I-Object
17	, O
18	событий B-Object
19	и O
20	их O
21	последовательностей O
22	, O
23	в O
24	машинно B-Object
25	- I-Object
26	читаемый I-Object
27	набор I-Object
28	чисел I-Object
29	– O
30	числовой B-Object
31	вектор I-Object
32	. O

# sent_id = 523
# text =   Самой популярной из трёх задач соревнования стала главная – Matching.
# relations = ""
1	Самой O
2	популярной O
3	из O
4	трёх O
5	задач O
6	соревнования O
7	стала O
8	главная O
9	– O
10	Matching B-Task
11	. O

# sent_id = 524
# text =   Стоит отметить, что и для них всё было непросто – конкурсная задача матчинга позволила удачно применить разработанный в Лаборатории ИИ метод генерации эмбеддингов транзакционных данных одновременно для двух разных доменов событийных данных (транзакции и кликстрим – атрибуты посещения веб-страниц). 
# relations = "Method_hasAuthor_Organization 0 0, Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 0 1"
1	Стоит O
2	отметить O
3	, O
4	что O
5	и O
6	для O
7	них O
8	всё O
9	было O
10	непросто O
11	– O
12	конкурсная O
13	задача O
14	матчинга O
15	позволила O
16	удачно O
17	применить O
18	разработанный B-Method_hasAuthor_Organization
19	в I-Method_hasAuthor_Organization
20	Лаборатории B-Organization
21	ИИ I-Organization
22	метод B-Method
23	генерации I-Method
24	эмбеддингов I-Method
25	транзакционных I-Method
26	данных I-Method
27	одновременно O
28	для B-Method_isAppliedTo_Object
29	двух O
30	разных O
31	доменов O
32	событийных O
33	данных O
34	( O
35	транзакции B-Object
36	и O
37	кликстрим B-Object
38	– O
39	атрибуты O
40	посещения O
41	веб O
42	- O
43	страниц O
44	) O
45	. O

# sent_id = 525
# text = Однако использование разработанного в Лаборатории ИИ метода генерации эмбеддингов транзакционных данных позволило успешно применить его одновременно к двум различным доменам событийных данных – транзакциям и кликстриму (атрибутам посещения веб-страниц).
# relations = "Method_hasAuthor_Organization 0 0, Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 0 1"
1	Однако O
2	использование O
3	разработанного B-Method_hasAuthor_Organization
4	в I-Method_hasAuthor_Organization
5	Лаборатории B-Organization
6	ИИ I-Organization
7	метода B-Method
8	генерации I-Method
9	эмбеддингов I-Method
10	транзакционных I-Method
11	данных I-Method
12	позволило O
13	успешно O
14	применить B-Method_isAppliedTo_Object
15	его O
16	одновременно O
17	к O
18	двум O
19	различным O
20	доменам O
21	событийных O
22	данных O
23	– O
24	транзакциям B-Object
25	и O
26	кликстриму B-Object
27	( O
28	атрибутам O
29	посещения O
30	веб-страниц O
31	) O
32	. O

# sent_id = 526
# text =   Победители создали лучшее решение благодаря применению собственной библиотеки PyTorch-LifeStream, которая позволила ускорить разработку решения, так как содержит много готовых инструментов для работы с событийными данными, и дала возможность стать фаворитом престижного конкурса. 
# relations = ""
1	Победители O
2	создали O
3	лучшее O
4	решение O
5	благодаря O
6	применению O
7	собственной O
8	библиотеки O
9	PyTorch B-Application
10	- I-Application
11	LifeStream I-Application
12	, O
13	которая O
14	позволила O
15	ускорить O
16	разработку O
17	решения O
18	, O
19	так O
20	как O
21	содержит O
22	много O
23	готовых O
24	инструментов O
25	для O
26	работы O
27	с O
28	событийными O
29	данными O
30	, O
31	и O
32	дала O
33	возможность O
34	стать O
35	фаворитом O
36	престижного O
37	конкурса O

# sent_id = 527
# text =   Фичи для транзакций и кликов объединялись и подавались в алгоритм бустинга.
# relations = "Method_isAppliedTo_Object 0 0"
1	Фичи B-Object
2	для O
3	транзакций O
4	и O
5	кликов O
6	объединялись O
7	и O
8	подавались B-Method_isAppliedTo_Object
9	в I-Method_isAppliedTo_Object
10	алгоритм O
11	бустинга B-Method
12	. O

# sent_id = 528
# text =   Алгоритм обучался как задача бинарной классификации.
# relations = ""
1	Алгоритм O
2	обучался O
3	как O
4	задача B-Task
5	бинарной I-Task
6	классификации I-Task
7	. O

# sent_id = 529
# text =   Команда решила использовать схему обучения, похожую на сиамскую сеть.
# relations = ""
1	Команда O
2	решила O
3	использовать O
4	схему O
5	обучения O
6	, O
7	похожую O
8	на O
9	сиамскую B-Method
10	сеть I-Method
11	. O

# sent_id = 530
# text =   Метки использованы для выборки положительных и отрицательных образцов для функции потерь Softmax Loss.
# relations = ""
1	Метки O
2	использованы O
3	для O
4	выборки O
5	положительных O
6	и O
7	отрицательных O
8	образцов O
9	для O
10	функции O
11	потерь O
12	Softmax B-Method
13	Loss I-Method
14	. O

# sent_id = 531
# text =  SequenceEncoder – рекурентно-нейронная сеть (RNN), совместно используемая для транзакций и кликов.
# relations = "Model_isAlternativeNameFor_Model 2 1, Model_includes_Model 1 0, Model_includes_Model 2 0"
1	SequenceEncoder B-Model
2	– O
3	рекурентно B-Model
4	- I-Model
5	нейронная I-Model
6	сеть I-Model
7	( O
8	RNN B-Model
9	) O
10	, O
11	совместно O
12	используемая O
13	для O
14	транзакций B-Object
15	и O
16	кликов B-Object
17	. O

# sent_id = 532
# text =   В итоге это дало самый большой прирост качества: для ансамбля из пяти моделей метрика качества R1 выросла с 0.2819 до 0.2949.
# relations = "Metric_hasValue_Value 0 0, Metric_hasValue_Value 0 1"
1	В O
2	итоге O
3	это O
4	дало O
5	самый O
6	большой O
7	прирост O
8	качества O
9	: O
10	для O
11	ансамбля O
12	из O
13	пяти O
14	моделей O
15	метрика O
16	качества O
17	R1 B-Metric
18	выросла O
19	с O
20	0.2819 B-Value
21	до O
22	0.2949 B-Value
23	. O

# sent_id = 533
# text = Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.
# relations = "Model_hasAuthor_Person 1 0, Model_hasAuthor_Person 0 0, Model_hasAuthor_Organization 1 0, Model_hasAuthor_Organization 0 0, Model_isAlternativeNameFor_Model 1 0"
1	Основатель O
2	компании O
3	Imagination B-Organization
4	Engines I-Organization
5	, O
6	Stephen B-Person
7	L. I-Person
8	Thaler I-Person
9	продвигает B-Model_hasAuthor_Person
10	свою I-Model_hasAuthor_Person
11	нейронную I-Model_hasAuthor_Person
12	сеть I-Model_hasAuthor_Person
13	по O
14	имени O
15	DABUS B-Model
16	( O
17	Device B-Model
18	for I-Model
19	the I-Model
20	Autonomous I-Model
21	Boot I-Model
22	- I-Model
23	strapping I-Model
24	of I-Model
25	Unified I-Model
26	Sentience I-Model
27	) O
28	, O
29	указывая O
30	ее O
31	в O
32	качестве O
33	автора O
34	изобретения O
35	в O
36	заявках O
37	на O
38	патенты O
39	на O
40	разные O
41	изобретения O
42	, O
43	сгенерированные O
44	этой O
45	сетью O
46	. O

# sent_id = 534
# text = Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).
# relations = "Model_hasAuthor_Person 1 0, Model_hasAuthor_Person 0 0, Model_hasAuthor_Organization 1 0, Model_hasAuthor_Organization 0 0, Model_isAlternativeNameFor_Model 1 0"
1	Стивен B-Person
2	Л I-Person
3	. I-Person
4	Тейлер I-Person
5	, O
6	основатель O
7	компании O
8	Imagination B-Organization
9	Engines I-Organization
10	, O
11	продвигает B-Model_hasAuthor_Person
12	свою I-Model_hasAuthor_Person
13	нейросеть O
14	под O
15	названием O
16	DABUS B-Model
17	( O
18	Device B-Model
19	for I-Model
20	the I-Model
21	Autonomous I-Model
22	Boot I-Model
23	- I-Model
24	strapping I-Model
25	of I-Model
26	Unified I-Model
27	Sentience I-Model
28	) O
29	. O

# sent_id = 535
# text =   Специалисты Data Science часто применяют различные методы получения датасетов.
# relations = "Method_isUsedIn_Science 0 0, Method_isAppliedTo_Object 0 0"
1	Специалисты O
2	Data B-Science
3	Science I-Science
4	часто O
5	применяют B-Method_isUsedIn_Science
6	различные O
7	методы B-Method
8	получения I-Method
9	датасетов B-Object
10	. O

# sent_id = 536
# text = Профессионалы в области Data Science часто используют различные подходы к созданию наборов данных.
# relations = "Method_isUsedIn_Science 0 0, Method_isAppliedTo_Object 0 0"
1	Профессионалы O
2	в O
3	области O
4	Data B-Science
5	Science I-Science
6	часто O
7	используют B-Method_isUsedIn_Science
8	различные O
9	подходы B-Method
10	к I-Method
11	созданию I-Method
12	наборов B-Object
13	данных I-Object
14	. O

# sent_id = 537
# text =   Цель этой статьи — представить краткий обзор трех разных методов извлечения данных с использованием языка Python.
# relations = ""
1	Цель O
2	этой O
3	статьи O
4	— O
5	представить O
6	краткий O
7	обзор O
8	трех O
9	разных O
10	методов O
11	извлечения O
12	данных O
13	с O
14	использованием O
15	языка O
16	Python B-Environment
17	. O

# sent_id = 538
# text =   Я расскажу, как делать это с помощью Jupyter Notebook.
# relations = ""
1	Я O
2	расскажу O
3	, O
4	как O
5	делать O
6	это O
7	с B-Environment_isUsedIn_Activity
8	помощью I-Environment_isUsedIn_Activity
9	Jupyter B-Environment
10	Notebook I-Environment
11	. O

# sent_id = 539
# text =   Библиотека SQLAlchemy позволит связать ваш код в ноутбуке с наиболее распространенными типами баз данных.
# relations = ""
1	Библиотека O
2	SQLAlchemy B-Environment
3	позволит O
4	связать O
5	ваш O
6	код O
7	в O
8	ноутбуке O
9	с O
10	наиболее O
11	распространенными O
12	типами O
13	баз B-InfoResource
14	данных I-InfoResource
15	. O

# sent_id = 540
# text =   Мы собираемся применить Beautiful Soup и библиотеку urllib, чтобы соскрапить названия отелей и цены на них с веб-сайта TripAdvisor.
# relations = ""
1	Мы O
2	собираемся B-Application_isUsedIn_Activity
3	применить I-Application_isUsedIn_Activity
4	Beautiful B-Library
5	Soup I-Library
6	и O
7	библиотеку O
8	urllib B-Library
9	, O
10	чтобы O
11	соскрапить O
12	названия B-Object
13	отелей I-Object
14	и O
15	цены B-Object
16	на O
17	них O
18	с O
19	веб O
20	- O
21	сайта O
22	TripAdvisor B-InfoResource
23	. O

# sent_id = 541
# text =   Я приведу простой пример извлечения данных о погоде с общедоступного API Dark Sky.
# relations = "Object_isUsedInSolving_Task 0 0, Application_isUsedForSolving_Task 0 0"
1	Я O
2	приведу O
3	простой O
4	пример O
5	извлечения B-Task
6	данных B-Object
7	о I-Object
8	погоде I-Object
9	с O
10	общедоступного O
11	API B-Application
12	Dark I-Application
13	Sky I-Application
14	. O

# sent_id = 542
# text =   Для доступа к данным из Dark Sky я воспользуюсь библиотекой requests.
# relations = ""
1	Для O
2	доступа O
3	к O
4	данным O
5	из O
6	Dark B-Application
7	Sky I-Application
8	я O
9	воспользуюсь O
10	библиотекой O
11	requests B-Library
12	. O

# sent_id = 543
# text =   Решать задачу будем с использованием нейронных сетей, но оптимизируемых генетическим алгоритмом (ГА) – такой процесс называют нейроэволюцией.
# relations = "Method_isAlternativeNameFor_Method 1 0, Method_solves_Task 0 0, Method_solves_Task 1 0"
1	Решать B-Method_solves_Task
2	задачу B-Task
3	будем O
4	с B-Method_solves_Task
5	использованием I-Method_solves_Task
6	нейронных O
7	сетей O
8	, O
9	но O
10	оптимизируемых O
11	генетическим B-Method
12	алгоритмом I-Method
13	( O
14	ГА B-Method
15	) O
16	– O
17	такой O
18	процесс O
19	называют O
20	нейроэволюцией O
21	. O

# sent_id = 544
# text =   Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.
# relations = "Method_isAlternativeNameFor_Method 1 0, Method_isUsedIn_Application 2 0, Method_hasAuthor_Person 1 0, Method_hasAuthor_Person 1 1, Method_hasAuthor_Person 0 0, Method_hasAuthor_Person 0 1"
1	Мы O
2	воспользовались O
3	методом O
4	NEAT B-Method
5	( O
6	NeuroEvolution B-Method
7	of I-Method
8	Augmenting I-Method
9	Topologies I-Method
10	) O
11	, O
12	изобретенным B-Method_hasAuthor_Person
13	Кеннетом B-Person
14	Стенли I-Person
15	и O
16	Ристо B-Person
17	Мииккулайненом I-Person
18	в O
19	начале O
20	века O
21	[ O
22	1 O
23	] O
24	: O
25	во O
26	- O
27	первых O
28	, O
29	он O
30	хорошо O
31	зарекомендовал O
32	себя O
33	в O
34	важных O
35	для O
36	народного O
37	хозяйства O
38	проблемах O
39	, O
40	во O
41	- O
42	вторых O
43	, O
44	к O
45	началу O
46	работы O
47	над O
48	проектом B-Activity
49	у O
50	нас O
51	уже O
52	был O
53	свой O
54	фреймворк B-Application
55	, O
56	реализующий B-Method_isUsedIn_Application
57	NEAT B-Method
58	. O

# sent_id = 545
# text =   Речь шла о морфологической разметке (part of speech tagging) современных текстов на русском языке.
# relations = "Method_isAlternativeNameFor_Method 1 0, Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 1 0"
1	Речь O
2	шла O
3	о O
4	морфологической B-Method
5	разметке I-Method
6	( O
7	part B-Method
8	of I-Method
9	speech I-Method
10	tagging I-Method
11	) O
12	современных O
13	текстов B-Object
14	на O
15	русском B-Lang
16	языке I-Lang
17	. O

# sent_id = 546
# text =   Как обычно, результат разметки будет опубликован на условиях лицензии Creative Commons.
# relations = ""
1	Как O
2	обычно O
3	, O
4	результат O
5	разметки B-Method
6	будет O
7	опубликован O
8	на O
9	условиях O
10	лицензии O
11	Creative B-Environment
12	Commons I-Environment
13	. O

# sent_id = 547
# text =   Извлечение именованных сущностей из текста — одна из востребованных функций текстовой аналитики.
# relations = "Task_isSolvedIn_Science 0 0"
1	Извлечение B-Task
2	именованных I-Task
3	сущностей I-Task
4	из O
5	текста O
6	— O
7	одна O
8	из O
9	востребованных O
10	функций O
11	текстовой B-Science
12	аналитики I-Science
13	. O

# sent_id = 548
# text =   Строго говоря, нам нужно получить параллельный корпус из двух текстов.
# relations = ""
1	Строго O
2	говоря O
3	, O
4	нам O
5	нужно O
6	получить O
7	параллельный B-Object
8	корпус I-Object
9	из O
10	двух O
11	текстов O
12	. O

# sent_id = 549
# text =   Для выравнивания воспользуемся библиотекой lingtrain-aligner, над которой я работаю около года и которая родилась из кучи скриптов на python, часть из которых еще ждет своего часа.
# relations = "Library_isUsedForSolving_Task 0 0, Environment_isUsedIn_Library 0 0"
1	Для B-Application_isUsedForSolving_Task
2	выравнивания B-Task
3	воспользуемся I-Application_isUsedForSolving_Task
4	библиотекой O
5	lingtrain B-Library
6	- I-Library
7	aligner I-Library
8	, O
9	над O
10	которой O
11	я O
12	работаю O
13	около O
14	года O
15	и O
16	которая O
17	родилась O
18	из O
19	кучи O
20	скриптов O
21	на O
22	python B-Environment
23	, O
24	часть O
25	из O
26	которых O
27	еще O
28	ждет O
29	своего O
30	часа O
31	. O

# sent_id = 550
# text =   Хорошим решением мне видится регрессия на координаты строк при выравнивании батча и сдвиг окна на конец потока при выравнивании следующего.
# relations = "Method_isAppliedTo_Object 0 0"
1	Хорошим O
2	решением O
3	мне O
4	видится O
5	регрессия B-Method
6	на B-Method_isAppliedTo_Object
7	координаты B-Object
8	строк I-Object
9	при O
10	выравнивании O
11	батча O
12	и O
13	сдвиг O
14	окна O
15	на O
16	конец O
17	потока O
18	при O
19	выравнивании O
20	следующего O
21	. O

# sent_id = 551
# text =   Facebook представила систему распознавания речи wav2vec-U.
# relations = "Application_hasAuthor_Organization 0 0, Application_isUsedForSolving_Task 0 0"
1	Facebook B-Organization
2	представила B-Application_hasAuthor_Organization
3	систему O
4	распознавания B-Task
5	речи I-Task
6	wav2vec B-App_system
7	- I-App_system
8	U I-App_system

# sent_id = 552
# text =   Система разбивает запись на речевые единицы, которые приблизительно соответствуют отдельным звукам.
# relations = "Application_isAppliedTo_Object 0 0"
1	Система B-Application
2	разбивает B-Application_isAppliedTo_Object
3	запись O
4	на O
5	речевые B-Object
6	единицы I-Object
7	, O
8	которые O
9	приблизительно O
10	соответствуют O
11	отдельным O
12	звукам O
13	. O

# sent_id = 553
# text =   Чтобы научиться распознавать слова в аудиозаписи, Facebook обучила генеративную состязательную сеть (GAN).
# relations = "Model_hasAuthor_Organization 0 0, Model_isAlternativeNameFor_Model 1 0"
1	Чтобы O
2	научиться O
3	распознавать O
4	слова O
5	в O
6	аудиозаписи O
7	, O
8	Facebook B-Organization
9	обучила O
10	генеративную B-Model
11	состязательную I-Model
12	сеть I-Model
13	( O
14	GAN B-Model
15	) O
16	. O

# sent_id = 554
# text =   Генератор берет каждый аудиосегмент и предсказывает фонему, соответствующую звуку на языке.
# relations = "Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 0 1"
1	Генератор B-Method
2	берет B-Method_isAppliedTo_Object
3	каждый O
4	аудиосегмент B-Object
5	и O
6	предсказывает B-Method_isAppliedTo_Object
7	фонему B-Object
8	, O
9	соответствующую O
10	звуку O
11	на O
12	языке O
13	. O

# sent_id = 555
# text =   Новая модель распознавания речи Facebook AI — это последняя разработка за несколько лет работы над моделями распознавания речи.
# relations = "Model_hasAuthor_Organization 0 0, Model_isUsedForSolving_Task 0 0"
1	Новая O
2	модель B-Model
3	распознавания I-Model
4	речи I-Model
5	Facebook B-Organization
6	AI I-Organization
7	— O
8	это O
9	последняя O
10	разработка O
11	за O
12	несколько O
13	лет O
14	работы O
15	над O
16	моделями O
17	распознавания B-Task
18	речи I-Task
19	. O

# sent_id = 556
# text =   Ее предшественниками стали wav2letter, wav2vec, Librilight, wav2vec 2.0, XLSR и wav2vec 2.0.
# relations = ""
1	ее O
2	предшественниками O
3	стали O
4	wav2letter B-Model
5	, O
6	wav2vec B-Model
7	, O
8	Librilight B-Model
9	, O
10	wav2vec B-Model
11	2.0 I-Model
12	, O
13	XLSR B-Model
14	и O
15	wav2vec B-Model
16	2.0 I-Model
17	. O

# sent_id = 557
# text =  В этой статье мы расскажем о методе Propensity Score Adjustment, который применим для коррекции смещений и улучшения данных, полученных на онлайн-панелях.
# relations = "Method_solves_Task 0 0, Method_solves_Task 0 1"
1	В O
2	этой O
3	статье O
4	мы O
5	расскажем O
6	о O
7	методе B-Method
8	Propensity I-Method
9	Score I-Method
10	Adjustment I-Method
11	, O
12	который O
13	применим B-Method_solves_Task
14	для I-Method_solves_Task
15	коррекции B-Task
16	смещений I-Task
17	и O
18	улучшения B-Task
19	данных I-Task
20	, O
21	полученных O
22	на O
23	онлайн O
24	- O
25	панелях O
26	. O

# sent_id = 558
# text =  Итоговые коэффициенты, корректирующие смещение онлайн-выборки, можно рассчитать по методу Хорвица-Томпсона.
# relations = "Method_isAppliedTo_Object 0 0"
1	Итоговые O
2	коэффициенты B-Object
3	, O
4	корректирующие O
5	смещение O
6	онлайн O
7	- O
8	выборки O
9	, O
10	можно B-Method_isAppliedTo_Object
11	рассчитать I-Method_isAppliedTo_Object
12	по I-Method_isAppliedTo_Object
13	методу B-Method
14	Хорвица I-Method
15	- I-Method
16	Томпсона I-Method
17	. O

# sent_id = 559
# text =  Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.
# relations = "Method_solves_Task 0 0, Method_solves_Task 1 0, Method_isAppliedTo_Object 0 0, Object_includes_Object 0 1, Object_isUsedInSolving_Task 0 0, Object_isUsedInSolving_Task 1 0"
1	Взвешивание B-Method
2	( O
3	Weighting B-Method
4	) O
5	метод O
6	предназначен B-Method_solves_Task
7	для I-Method_solves_Task
8	коррекции B-Task
9	известных O
10	перекосов B-Object
11	выборок I-Object
12	по O
13	социально B-Object
14	- I-Object
15	демографическим I-Object
16	атрибутам I-Object
17	. O

# sent_id = 560
# text =  Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).
# relations = "Method_solves_Task 0 0, Method_solves_Task 1 0, Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 1 0, Object_isUsedInSolving_Task 0 0"
1	Авторы O
2	оригинального O
3	исследования O
4	Pew B-Activity
5	Research I-Activity
6	рекомендуют O
7	использовать B-Method_solves_Task
8	для O
9	корректировки B-Task
10	онлайн B-Object
11	- I-Object
12	опросов I-Object
13	модели O
14	случайных B-Method
15	лесов I-Method
16	( O
17	random B-Method
18	forest I-Method
19	) O
20	. O

# sent_id = 561
# text =  Сейчас стандарт коррекции онлайн-выборок находится на стадии обсуждения и разработки и метод Propensity Score Adjustment, который мы рассмотрели, может стать общепринятым способом коррекции онлайн-панелей.
# relations = "Method_solves_Task 0 0, Method_isAppliedTo_Object 0 0, Object_isUsedInSolving_Task 0 0"
1	Сейчас O
2	стандарт O
3	коррекции O
4	онлайн O
5	- O
6	выборок O
7	находится O
8	на O
9	стадии O
10	обсуждения O
11	и O
12	разработки O
13	и O
14	метод B-Method
15	Propensity I-Method
16	Score I-Method
17	Adjustment I-Method
18	, O
19	который O
20	мы O
21	рассмотрели O
22	, O
23	может O
24	стать B-Method_solves_Task
25	общепринятым O
26	способом I-Method_solves_Task
27	коррекции B-Task
28	онлайн B-Object
29	- I-Object
30	панелей I-Object
31	. O

# sent_id = 562
# text =   В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).
# relations = "Model_hasAuthor_Organization 1 0, Model_hasAuthor_Organization 2 0, Model_hasAuthor_Organization 1 1, Model_hasAuthor_Organization 2 1, Organization_isAlternativeNameFor_Organization 1 0, Model_isAlternativeNameFor_Model 1 2"
1	В O
2	полку O
3	LLM B-Model
4	прибыло O
5	: O
6	недавно O
7	специалисты O
8	из O
9	Французского B-Organization
10	национального I-Organization
11	центра I-Organization
12	научных I-Organization
13	исследований I-Organization
14	( O
15	French B-Organization
16	National I-Organization
17	Center I-Organization
18	for I-Organization
19	Scientific I-Organization
20	Research I-Organization
21	) O
22	объявили B-Model_hasAuthor_Organization
23	о I-Model_hasAuthor_Organization
24	релизе I-Model_hasAuthor_Organization
25	новой O
26	большой O
27	языковой O
28	модели O
29	под O
30	названием O
31	BLOOM B-Model
32	( O
33	расшифровывается O
34	как O
35	BigScience B-Model
36	Large I-Model
37	Open I-Model
38	- I-Model
39	science I-Model
40	Open I-Model
41	- I-Model
42	access I-Model
43	Multilingual I-Model
44	Language I-Model
45	Model I-Model
46	) O
47	. O

# sent_id = 563
# text = Недавно ученые из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о выходе модели BLOOM.
# relations = "Organization_isAlternativeNameFor_Organization 1 0, Model_hasAuthor_Organization 0 0, Model_hasAuthor_Organization 0 1"
1	Недавно O
2	ученые O
3	из O
4	Французского B-Organization
5	национального I-Organization
6	центра I-Organization
7	научных I-Organization
8	исследований I-Organization
9	( O
10	French B-Organization
11	National I-Organization
12	Center I-Organization
13	for I-Organization
14	Scientific I-Organization
15	Research I-Organization
16	) O
17	объявили O
18	о O
19	выходе O
20	модели O
21	BLOOM B-Model
22	. O

# sent_id = 564
# text = Недавно был релиз модели BLOOM, которую разработала команда из Французского национального центра научных исследований (French National Center for Scientific Research).
# relations = "Organization_isAlternativeNameFor_Organization 1 0, Model_hasAuthor_Organization 0 0, Model_hasAuthor_Organization 0 1"
1	Недавно O
2	был O
3	релиз O
4	модели O
5	BLOOM B-Model
6	, O
7	которую O
8	разработала O
9	команда O
10	из O
11	Французского B-Organization
12	национального I-Organization
13	центра I-Organization
14	научных I-Organization
15	исследований I-Organization
16	( O
17	French B-Organization
18	National I-Organization
19	Center I-Organization
20	for I-Organization
21	Scientific I-Organization
22	Research I-Organization
23	) O
24	. O

# sent_id = 565
# text =   Большие языковые модели или LLM (Large Language Models) — это алгоритмы глубокого обучения, которые обучаются на огромных объемах данных.
# relations = "Model_isAlternativeNameFor_Model 1 0"
1	Большие O
2	языковые O
3	модели O
4	или O
5	LLM B-Model
6	( O
7	Large B-Model
8	Language I-Model
9	Models I-Model
10	) O
11	— O
12	это O
13	алгоритмы O
14	глубокого O
15	обучения O
16	, O
17	которые O
18	обучаются O
19	на O
20	огромных O
21	объемах O
22	данных O
23	. O

# sent_id = 566
# text =   Их можно использовать в качестве чат-ботов, для поиска информации, модерации онлайн-контента, анализа литературы или для создания совершенно новых фрагментов текста на основе подсказок (чем занимается, например, «Порфирьевич», который способен генерировать весьма забавные короткие рассказы).
# relations = "Application_isUsedForSolving_Task 0 0"
1	Их O
2	можно O
3	использовать B-Application_isUsedForSolving_Task
4	в O
5	качестве O
6	чат B-Application
7	- I-Application
8	ботов I-Application
9	, O
10	для B-Application_isUsedForSolving_Task
11	поиска B-Task
12	информации I-Task
13	, O
14	модерации B-Activity
15	онлайн B-Object
16	- I-Object
17	контента I-Object
18	, O
19	анализа B-Activity
20	литературы B-Object
21	или O
22	для O
23	создания B-Activity
24	совершенно O
25	новых B-Object
26	фрагментов I-Object
27	текста I-Object
28	на O
29	основе O
30	подсказок O
31	( O
32	чем O
33	занимается O
34	, O
35	например O
36	, O
37	« O
38	Порфирьевич B-Application
39	» O
40	, O
41	который O
42	способен O
43	генерировать B-Activity
44	весьма I-Activity
45	забавные I-Activity
46	короткие I-Activity
47	рассказы I-Activity
48	) O
49	. O

# sent_id = 567
# text =   Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.
# relations = "Model_hasAuthor_Organization 2 0, Model_hasAuthor_Organization 3 1"
1	Новая O
2	LLM B-Model
3	с O
4	открытым O
5	исходным O
6	кодом O
7	в O
8	отличие O
9	от O
10	таких O
11	известных O
12	LLM B-Model
13	, O
14	как O
15	GPT-3 B-Model
16	от B-Model_hasAuthor_Organization
17	OpenAI B-Organization
18	и O
19	LaMDA B-Model
20	от B-Model_hasAuthor_Organization
21	Google B-Organization
22	, O
23	BLOOM B-Model
24	является O
25	открытой O
26	языковой O
27	моделью O
28	, O
29	а O
30	исследователи O
31	охотно O
32	делятся O
33	подробностями O
34	о O
35	тех O
36	данных O
37	, O
38	на O
39	которых O
40	она O
41	обучалась O
42	, O
43	рассказывают O
44	о O
45	проблемах O
46	в O
47	ее O
48	разработке O
49	и O
50	о O
51	том O
52	, O
53	как O
54	они O
55	оценивали O
56	производительность O
57	BLOOM B-Model
58	. O

# sent_id = 568
# text =   OpenAI и Google не делились своим кодом и не делали свои модели общедоступными.
# relations = ""
1	OpenAI B-Organization
2	и O
3	Google B-Organization
4	не O
5	делились O
6	своим O
7	кодом O
8	и O
9	не O
10	делали O
11	свои O
12	модели O
13	общедоступными O
14	. O

# sent_id = 569
# text =   И уже сейчас над BLOOM работают более тысячи исследователей-добровольцев в рамках проекта под названием BigScience, который координирует стартап Hugging Face, существующий за счет финансовой поддержки французского правительства.
# relations = "Activity_hasAuthor_Organization 0 0"
1	И O
2	уже O
3	сейчас O
4	над O
5	BLOOM B-Model
6	работают O
7	более O
8	тысячи O
9	исследователей O
10	- O
11	добровольцев O
12	в O
13	рамках O
14	проекта O
15	под O
16	названием O
17	BigScience B-Activity
18	, O
19	который B-Activity_hasAuthor_Organization
20	координирует I-Activity_hasAuthor_Organization
21	стартап O
22	Hugging B-Organization
23	Face I-Organization
24	, O
25	существующий O
26	за O
27	счет O
28	финансовой O
29	поддержки O
30	французского O
31	правительства O
32	. O

# sent_id = 570
# text = Более тысячи добровольных исследователей уже вовлечены в работу над моделью BLOOM в рамках проекта BigScience, который управляется стартапом Hugging Face.
# relations = "Activity_hasAuthor_Organization 0 0"
1	Более O
2	тысячи O
3	добровольных O
4	исследователей O
5	уже O
6	вовлечены O
7	в O
8	работу O
9	над O
10	моделью O
11	BLOOM B-Model
12	в O
13	рамках O
14	проекта O
15	BigScience B-Activity
16	, O
17	который B-Activity_hasAuthor_Organization
18	управляется I-Activity_hasAuthor_Organization
19	стартапом O
20	Hugging B-Organization
21	Face I-Organization
22	. O

# sent_id = 571
# text =   BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.
# relations = "Model_Language_Lang 0 0, Model_Language_Lang 0 1, Model_Language_Lang 0 2, Model_Language_Lang 0 3, Model_Language_Lang 0 4, Model_Language_Lang 0 5, Model_Language_Lang 0 6, Model_Language_Lang 0 7, Model_Language_Lang 0 8, Model_Language_Lang 0 9"
1	BLOOM B-Model
2	может O
3	обрабатывать O
4	46 O
5	языков O
6	, O
7	включая O
8	французский B-Lang
9	, O
10	испанский B-Lang
11	, O
12	арабский B-Lang
13	, O
14	вьетнамский B-Lang
15	, O
16	китайский B-Lang
17	, O
18	индонезийский B-Lang
19	, O
20	каталанский B-Lang
21	, O
22	целых O
23	13 O
24	языков O
25	Индии O
26	( O
27	хинди B-Lang
28	, O
29	бенгали B-Lang
30	, O
31	маратхи B-Lang
32	и O
33	ряд O
34	других O
35	) O
36	и O
37	аж O
38	20 O
39	африканских O
40	. O

# sent_id = 572
# text =   На русском BLOOM тоже пишет, но пока довольно вяло.
# relations = "Model_Language_Lang 0 0"
1	На O
2	русском B-Lang
3	BLOOM B-Model
4	тоже O
5	пишет O
6	, O
7	но O
8	пока O
9	довольно O
10	вяло O
11	. O

# sent_id = 573
# text =   Почти треть обучающих данных была введена в модель BLOOM на английском языке: следствие того, что именно английский является наиболее часто используемым языком в интернете.
# relations = "Model_Language_Lang 0 0, Model_Language_Lang 0 1"
1	Почти O
2	треть O
3	обучающих O
4	данных O
5	была O
6	введена O
7	в O
8	модель O
9	BLOOM B-Model
10	на O
11	английском B-Lang
12	языке O
13	: O
14	следствие O
15	того O
16	, O
17	что O
18	именно O
19	английский B-Lang
20	является O
21	наиболее O
22	часто O
23	используемым O
24	языком O
25	в O
26	интернете O
27	. O

# sent_id = 574
# text =   В июне текущего года инженер Google Блейк Лемуан (он на фото выше) ошарашил мировую общественность заявлением, что LLM LaMDA, над которой он работал вместе с другими программистами, может обладать некоторым подобием разума.
# relations = "Model_hasAuthor_Person 0 0, Model_hasAuthor_Organization 0 0"
1	В O
2	июне O
3	текущего O
4	года O
5	инженер O
6	Google B-Organization
7	Блейк B-Person
8	Лемуан I-Person
9	( O
10	он O
11	на O
12	фото O
13	выше O
14	) O
15	ошарашил O
16	мировую O
17	общественность O
18	заявлением O
19	, O
20	что O
21	LLM B-Model
22	LaMDA I-Model
23	, O
24	над B-Model_hasAuthor_Person
25	которой I-Model_hasAuthor_Person
26	он I-Model_hasAuthor_Person
27	работал I-Model_hasAuthor_Person
28	вместе O
29	с O
30	другими O
31	программистами O
32	, O
33	может O
34	обладать O
35	некоторым O
36	подобием O
37	разума O
38	. O

# sent_id = 575
# text =   Американский ученый и исследователь ИИ Гэри Маркус еще до появления в сети откровений Лемуана опубликовал на портале Scientific American материал под названием «Общий ИИ не так неизбежен, как вы думаете».
# relations = ""
1	Американский O
2	ученый O
3	и O
4	исследователь O
5	ИИ O
6	Гэри B-Person
7	Маркус I-Person
8	еще O
9	до O
10	появления O
11	в O
12	сети O
13	откровений O
14	Лемуана B-Person
15	опубликовал O
16	на O
17	портале O
18	Scientific B-InfoResource
19	American I-InfoResource
20	материал O
21	под O
22	названием O
23	« B-InfoResource
24	Общий I-InfoResource
25	ИИ I-InfoResource
26	не I-InfoResource
27	так I-InfoResource
28	неизбежен I-InfoResource
29	, I-InfoResource
30	как I-InfoResource
31	вы I-InfoResource
32	думаете I-InfoResource
33	» I-InfoResource
34	. O 

# sent_id = 576
# text =   В частности, DALL-E 2 от OpenAI провалил тест на различение изображений астронавтов, едущих на лошадях, перепутав их с лошадьми, оседлавшими астронавтов.
# relations = "Model_hasAuthor_Organization 0 0"
1	В O
2	частности O
3	, O
4	DALL B-Model
5	- I-Model
6	E I-Model
7	2 I-Model
8	от B-Model_hasAuthor_Organization
9	OpenAI B-Organization
10	провалил O
11	тест O
12	на O
13	различение O
14	изображений O
15	астронавтов O
16	, O
17	едущих O
18	на O
19	лошадях O
20	, O
21	перепутав O
22	их O
23	с O
24	лошадьми O
25	, O
26	оседлавшими O
27	астронавтов O
28	. O

# sent_id = 577
# text =   Известный учёный Алан Тьюринг в 1950 году усомнился в том, что машина не может мыслить, и для проверки предложил свой знаменитый тест.
# relations = "Method_hasAuthor_Person 0 0, Date_isDateOf_Method 0 0"
1	Известный O
2	учёный O
3	Алан B-Person
4	Тьюринг I-Person
5	в O
6	1950 B-Date
7	году O
8	усомнился O
9	в O
10	том O
11	, O
12	что O
13	машина O
14	не O
15	может O
16	мыслить O
17	, O
18	и O
19	для O
20	проверки O
21	предложил B-Method_hasAuthor_Person
22	свой O
23	знаменитый O
24	тест B-Method
25	. O

# sent_id = 578
# text =  В 1954 году прошёл Джорджтаунский эксперимент.
# relations = ""
1	В O
2	1954 B-Date
3	году O
4	прошёл O
5	Джорджтаунский B-Activity
6	эксперимент I-Activity
7	. O

# sent_id = 579
# text =   В его рамках демонстрировалась система, которая автоматически перевела 60 предложений с русского языка на французский.
# relations = ""
1	В O
2	его O
3	рамках O
4	демонстрировалась O
5	система B-App_system
6	, O
7	которая O
8	автоматически O
9	перевела O
10	60 O
11	предложений B-Object
12	с O
13	русского B-Lang
14	языка B-Object
15	на O
16	французский B-Lang
17	. O

# sent_id = 580
# text =   В 1960-е годы появились первые чат-боты, очень примитивные: в основном они перефразировали то, что говорил им собеседник-человек.
# relations = "Date_isDateOf_Application 0 0"
1	В O
2	1960-е B-Date
3	годы O
4	появились O
5	первые O
6	чат B-Technology
7	- I-Technology
8	боты I-Technology
9	, O
10	очень O
11	примитивные O
12	: O
13	в O
14	основном O
15	они O
16	перефразировали O
17	то O
18	, O
19	что O
20	говорил O
21	им O
22	собеседник O
23	- O
24	человек O
25	. O

# sent_id = 581
# text =   Даже знаменитый чат-бот Женя Густман, который, как считается, прошёл одну из версий теста Тьюринга, сделал это не благодаря хитрым алгоритмам.
# relations = ""
1	Даже O
2	знаменитый O
3	чат B-Technology
4	- I-Technology
5	бот I-Technology
6	Женя I-Technology
7	Густман I-Technology
8	, O
9	который O
10	, O
11	как O
12	считается O
13	, O
14	прошёл O
15	одну O
16	из O
17	версий O
18	теста B-Method
19	Тьюринга I-Method
20	, O
21	сделал O
22	это O
23	не O
24	благодаря O
25	хитрым O
26	алгоритмам O
27	. O

# sent_id = 582
# text =   Учёные пытались всё формализовать, построить формальную модель, онтологию, понятия, связи, общие правила синтаксического разбора и универсальную грамматику.
# relations = ""
1	Учёные O
2	пытались O
3	всё O
4	формализовать O
5	, O
6	построить O
7	формальную B-Model
8	модель I-Model
9	, O
10	онтологию B-InfoResource
11	, O
12	понятия B-Object
13	, O
14	связи B-Object
15	, O
16	общие O
17	правила O
18	синтаксического B-Method
19	разбора I-Method
20	и O
21	универсальную B-Method
22	грамматику I-Method
23	. O

# sent_id = 583
# text =   Тогда возникла теория грамматик Хомского.
# relations = ""
1	Тогда O
2	возникла O
3	теория B-Method
4	грамматик I-Method
5	Хомского I-Method
6	. O

# sent_id = 584
# text =   Поэтому в 1980-е годы внимание переключилось на систему другого класса: на алгоритмы машинного обучения и так называемую корпусную лингвистику.
# relations = "Date_isDateOf_Method 0 0"
1	Поэтому O
2	в O
3	1980-е B-Date
4	годы O
5	внимание O
6	переключилось O
7	на O
8	систему O
9	другого O
10	класса O
11	: O
12	на O
13	алгоритмы B-Method
14	машинного I-Method
15	обучения I-Method
16	и O
17	так O
18	называемую O
19	корпусную B-Science
20	лингвистику I-Science
21	. O

# sent_id = 585
# text =   Поэтому внимание в 1980-х годах было перенаправлено на системы другого типа: на алгоритмы машинного обучения и корпусную лингвистику.
# relations = "Date_isDateOf_Method 0 0"
1	Поэтому O
2	внимание O
3	в O
4	1980 B-Date
5	- I-Date
6	х I-Date
7	годах I-Date
8	было O
9	перенаправлено O
10	на O
11	системы O
12	другого O
13	типа O
14	: O
15	на O
16	алгоритмы B-Method
17	машинного I-Method
18	обучения O
19	и O
20	корпусную B-Science
21	лингвистику I-Science
22	. O

# sent_id = 586
# text =   В 1990-е годы эта область получила очень мощный толчок благодаря развитию Всемирной паутины с большим количеством слабоструктурированного текста, по которому нужно было искать, его требовалось каталогизировать.
# relations = "Date_isDateOf_Application 0 0, Application_isAppliedTo_Object 0 0"
1	В O
2	1990-е B-Date
3	годы O
4	эта O
5	область O
6	получила O
7	очень O
8	мощный O
9	толчок O
10	благодаря O
11	развитию O
12	Всемирной B-Application
13	паутины I-Application
14	с O
15	большим O
16	количеством O
17	слабоструктурированного B-Object
18	текста I-Object
19	, O
20	по O
21	которому O
22	нужно O
23	было O
24	искать O
25	, O
26	его O
27	требовалось O
28	каталогизировать O
29	. O

# sent_id = 587
# text =   В 2000-е анализ естественных языков начал применяться уже не только для поиска в Интернете, но и для решения разнообразных задач.
# relations = "Method_solves_Task 0 0, Application_isUsedForSolving_Task 0 0"
1	В O
2	2000-е O
3	анализ B-Method
4	естественных I-Method
5	языков I-Method
6	начал B-Method_solves_Task
7	применяться I-Method_solves_Task
8	уже O
9	не O
10	только O
11	для B-Method_solves_Task
12	поиска B-Task
13	в O
14	Интернете B-Application
15	, O
16	но O
17	и O
18	для O
19	решения O
20	разнообразных O
21	задач O
22	. O

# sent_id = 588
# text =   Возникли модели, основанные на краудсорсинге: мы не только пытаемся что-то понять с помощью машины, а подключаем людей, которые за небольшую плату определяют, на каком языке написан текст.
# relations = "Method_isUsedForTraining_Model 0 0"
1	Возникли O
2	модели B-Model
3	, O
4	основанные O
5	на O
6	краудсорсинге B-Method
7	: O
8	мы O
9	не O
10	только O
11	пытаемся O
12	что O
13	- O
14	то O
15	понять O
16	с O
17	помощью O
18	машины O
19	, O
20	а O
21	подключаем O
22	людей O
23	, O
24	которые O
25	за O
26	небольшую O
27	плату O
28	определяют O
29	, O
30	на O
31	каком O
32	языке O
33	написан O
34	текст O
35	. O

# sent_id = 589
# text =   В некотором смысле начали возрождаться идеи использования формальных онтологий, но теперь онтологии крутятся вокруг краудсорсинговых баз знаний, в частности баз на основе Linked Open Data.
# relations = ""
1	В O
2	некотором O
3	смысле O
4	начали O
5	возрождаться O
6	идеи O
7	использования O
8	формальных B-InfoResource
9	онтологий I-InfoResource
10	, O
11	но O
12	теперь O
13	онтологии B-InfoResource
14	крутятся O
15	вокруг O
16	краудсорсинговых B-InfoResource
17	баз I-InfoResource
18	знаний I-InfoResource
19	, O
20	в O
21	частности O
22	баз O
23	на O
24	основе O
25	Linked B-InfoResource
26	Open I-InfoResource
27	Data I-InfoResource
28	. O

# sent_id = 590
# text =   Это целый набор баз знаний, его центр — машиночитаемый вариант «Википедии» DBpedia, который тоже наполняется по краудсорсинговой модели.
# relations = ""
1	Это O
2	целый O
3	набор O
4	баз O
5	знаний O
6	, O
7	его O
8	центр O
9	— O
10	машиночитаемый O
11	вариант O
12	« O
13	Википедии B-InfoResource
14	» O
15	DBpedia B-InfoResource
16	, O
17	который O
18	тоже O
19	наполняется O
20	по O
21	краудсорсинговой B-Model
22	модели I-Model
23	. O

# sent_id = 591
# text =   В частности, семантический анализ (о чём документ?), генерация автоматической аннотации и автоматического summary, перевод и создание документов.
# relations = "Method_solves_Task 0 0, Method_solves_Task 0 1, Method_solves_Task 0 2"
1	В O
2	частности O
3	, O
4	семантический B-Method
5	анализ I-Method
6	( O
7	о O
8	чём O
9	документ O
10	? O
11	) O
12	, O
13	генерация B-Task
14	автоматической I-Task
15	аннотации I-Task
16	и I-Task
17	автоматического I-Task
18	summary I-Task
19	, O
20	перевод B-Task
21	и O
22	создание B-Task
23	документов I-Task
24	. O

# sent_id = 592
# text =   Все наверняка слышали об известном генераторе научных статей SCIgen, который создал статью «Корчеватель: Алгоритм типичной унификации точек доступа и избыточности».
# relations = ""
1	Все O
2	наверняка O
3	слышали O
4	об O
5	известном O
6	генераторе O
7	научных O
8	статей O
9	SCIgen B-Technology
10	, O
11	который O
12	создал O
13	статью O
14	« O
15	Корчеватель O
16	: O
17	Алгоритм O
18	типичной O
19	унификации O
20	точек O
21	доступа O
22	и O
23	избыточности O
24	» O
25	. O

# sent_id = 593
# text =   Но в случае с лентой такие рекомендации работают плохо: здесь постоянно возникает ситуация холодного старта.
# relations = ""
1	Но O
2	в O
3	случае O
4	с O
5	лентой O
6	такие O
7	рекомендации O
8	работают O
9	плохо O
10	: O
11	здесь O
12	постоянно O
13	возникает O
14	ситуация B-Object
15	холодного I-Object
16	старта I-Object
17	. O

# sent_id = 594
# text =   Поэтому применим классический воркэраунд для задачи холодного старта и построим систему контентных рекомендаций: попробуем научить машину понимать, о чём написан пост.
# relations = "Method_solves_Task 0 0"
1	Поэтому O
2	применим B-Method_solves_Task
3	классический O
4	воркэраунд B-Method
5	для B-Method_solves_Task
6	задачи I-Method_solves_Task
7	холодного B-Task
8	старта I-Task
9	и O
10	построим O
11	систему O
12	контентных O
13	рекомендаций O
14	: O
15	попробуем O
16	научить O
17	машину O
18	понимать O
19	, O
20	о O
21	чём O
22	написан O
23	пост O
24	. O

# sent_id = 595
# text =   Соответственно, требуется метод семантического анализа.
# relations = ""
1	Соответственно O
2	, O
3	требуется B-Method_solves_Task
4	метод B-Method
5	семантического I-Method
6	анализа I-Method
7	. O

# sent_id = 596
# text =   Тут поможет анализ эмоциональной окраски.
# relations = ""
1	Тут O
2	поможет B-Method_solves_Task
3	анализ B-Method
4	эмоциональной I-Method
5	окраски I-Method
6	. O

# sent_id = 597
# text = В частности, это Apache Tika, японская библиотека language-detection и одна из последних разработок — питоновский пакет Ldig, который как раз работает на инфинитиграммах.
# relations = "Library_isAppliedTo_Object 2 0"
1	В O
2	частности O
3	, O
4	это O
5	Apache B-Library
6	Tika I-Library
7	, O
8	японская O
9	библиотека O
10	language B-Library
11	- I-Library
12	detection I-Library
13	и O
14	одна O
15	из O
16	последних O
17	разработок O
18	— O
19	питоновский O
20	пакет O
21	Ldig B-Library
22	, O
23	который O
24	как O
25	раз O
26	работает B-Application_isAppliedTo_Object
27	на I-Application_isAppliedTo_Object
28	инфинитиграммах B-Object
29	. O

# sent_id = 598
# text = Но если текст короткий, из одного предложения или нескольких слов, то классический подход, основанный на триграммах, очень часто ошибается.
# relations = ""
1	Но O
2	если O
3	текст B-Object
4	короткий O
5	, O
6	из O
7	одного O
8	предложения B-Object
9	или O
10	нескольких O
11	слов B-Object
12	, O
13	то O
14	классический O
15	подход O
16	, O
17	основанный O
18	на O
19	триграммах B-Object
20	, O
21	очень O
22	часто O
23	ошибается O
24	. O

# sent_id = 599
# text =   Исправить ситуацию могут инфинитиграммы, но это новая область, далеко не для всех языков уже есть обученные и готовые классификаторы.
# relations = ""
1	Исправить O
2	ситуацию O
3	могут O
4	инфинитиграммы B-Object
5	, O
6	но O
7	это O
8	новая O
9	область O
10	, O
11	далеко O
12	не O
13	для O
14	всех O
15	языков O
16	уже O
17	есть O
18	обученные O
19	и O
20	готовые O
21	классификаторы O
22	. O

# sent_id = 600
# text =   Первый основан на так называемом фонетическом матчинге.
# relations = ""
1	Первый O
2	основан O
3	на O
4	так O
5	называемом O
6	фонетическом B-Method
7	матчинге I-Method
8	. O

# sent_id = 601
# text =   Альтернативный подход — так называемое редакционное расстояние, с помощью которого мы ищем в словаре максимально похожие слова-аналоги.
# relations = ""
1	Альтернативный O
2	подход O
3	— O
4	так O
5	называемое O
6	редакционное B-Metric
7	расстояние I-Metric
8	, O
9	с O
10	помощью O
11	которого O
12	мы O
13	ищем O
14	в O
15	словаре O
16	максимально O
17	похожие O
18	слова O
19	- O
20	аналоги O
21	. O

# sent_id = 602
# text =   Первая концепция — стемминг, мы пытаемся найти основу слова.
# relations = "Method_isAppliedTo_Object 0 0"
1	Первая O
2	концепция O
3	— O
4	стемминг B-Method
5	, O
6	мы O
7	пытаемся B-Method_isAppliedTo_Object
8	найти I-Method_isAppliedTo_Object
9	основу B-Object
10	слова I-Object
11	. O

# sent_id = 603
# text =   Здесь используется подход affix stripping.
# relations = ""
1	Здесь O
2	используется B-Method_isUsedIn_Activity
3	подход O
4	affix B-Method
5	stripping I-Method
6	. O

# sent_id = 604
# text =   Есть известная реализация, так называемый стеммер Портера, или проект Snowball.
# relations = ""
1	Есть O
2	известная O
3	реализация O
4	, O
5	так O
6	называемый O
7	стеммер B-Method
8	Портера I-Method
9	, O
10	или O
11	проект O
12	Snowball B-Activity
13	. O

# sent_id = 605
# text =   Самый распространённый, наверное, инструмент — реализация в пакете Apache Lucene.
# relations = ""
1	Самый O
2	распространённый O
3	, O
4	наверное O
5	, O
6	инструмент O
7	— O
8	реализация O
9	в B-Method_isUsedIn_Library
10	пакете I-Method_isUsedIn_Library
11	Apache B-Library
12	Lucene I-Library
13	. O

# sent_id = 606
# text =   Вторая концепция, альтернатива стемминга — лемматизация.
# relations = ""
1	Вторая O
2	концепция O
3	, O
4	альтернатива O
5	стемминга B-Method
6	— O
7	лемматизация B-Method
8	. O

# sent_id = 607
# text =   Она пытается привести слово не к основе или корню, а к базовой, словарной форме — т. е. лемме.
# relations = ""
1	Она O
2	пытается O
3	привести O
4	слово B-Object
5	не O
6	к O
7	основе B-Object
8	или O
9	корню B-Object
10	, O
11	а O
12	к O
13	базовой O
14	, O
15	словарной B-Object
16	форме I-Object
17	— O
18	т O
19	. O
20	е O
21	. O
22	лемме B-Object
23	. O

# sent_id = 608
# text =   Существует множество реализаций, и тема очень хорошо проработана именно для user generated текстов, пользовательски зашумлённых текстов.
# relations = ""
1	Существует O
2	множество O
3	реализаций O
4	, O
5	и O
6	тема B-Object
7	очень O
8	хорошо O
9	проработана O
10	именно O
11	для O
12	user B-Object
13	generated I-Object
14	текстов I-Object
15	, O
16	пользовательски B-Object
17	зашумлённых I-Object
18	текстов I-Object
19	. O

# sent_id = 609
# text =   Теперь отобразим это в векторном пространстве, потому что почти все математические модели работают в векторных пространствах больших размерностей.
# relations = ""
1	Теперь O
2	отобразим O
3	это O
4	в O
5	векторном B-Object
6	пространстве I-Object
7	, O
8	потому O
9	что O
10	почти O
11	все O
12	математические B-Method
13	модели I-Method
14	работают B-Method_isAppliedTo_Object
15	в I-Method_isAppliedTo_Object
16	векторных B-Object
17	пространствах I-Object
18	больших O
19	размерностей O
20	. O

# sent_id = 610
# text =   Базовый подход, который используют многие модели, — метод "мешка слов".
# relations = ""
1	Базовый O
2	подход O
3	, O
4	который O
5	используют O
6	многие O
7	модели O
8	, O
9	— O
10	метод B-Method
11	" I-Method
12	мешка I-Method
13	слов I-Method
14	" I-Method
15	. O

# sent_id = 611
# text =   Доминирует так называемый TF-IDF.
# relations = ""
1	Доминирует O
2	так O
3	называемый O
4	TF B-Metric
5	- I-Metric
6	IDF I-Metric
7	. O

# sent_id = 612
# text =   Частоту слова (term frequency, TF) определяют по-разному.
# relations = ""
1	Частоту B-Metric
2	слова I-Metric
3	( O
4	term B-Metric
5	frequency I-Metric
6	, O
7	TF B-Metric
8	) O
9	определяют O
10	по O
11	- O
12	разному O
13	. O

# sent_id = 613
# text =   Определив TF в документе, мы перемножаем её с обратной частотой документа (inverse document frequency, IDF).
# relations = ""
1	Определив O
2	TF B-Metric
3	в O
4	документе O
5	, O
6	мы O
7	перемножаем O
8	её O
9	с O
10	обратной B-Metric
11	частотой I-Metric
12	документа I-Metric
13	( O
14	inverse B-Metric
15	document I-Metric
16	frequency I-Metric
17	, O
18	IDF B-Metric
19	) O
20	. O

# sent_id = 614
# text =   IDF обычно вычисляют как логарифм от числа документов в корпусе, разделённый на количество документов, где это слово представлено.
# relations = ""
1	IDF B-Metric
2	обычно O
3	вычисляют O
4	как O
5	логарифм B-Object
6	от O
7	числа O
8	документов O
9	в O
10	корпусе B-Object
11	, O
12	разделённый O
13	на O
14	количество O
15	документов O
16	, O
17	где O
18	это O
19	слово B-Object
20	представлено O
21	. O

# sent_id = 615
# text =   Например, при анализе эмоциональной окраски очень важно, к чему относилось, условно говоря, слово «хороший» или «нет».
# relations = "Method_isAppliedTo_Object 0 0"
1	Например O
2	, O
3	при O
4	анализе B-Method
5	эмоциональной I-Method
6	окраски I-Method
7	очень O
8	важно O
9	, O
10	к O
11	чему O
12	относилось O
13	, O
14	условно O
15	говоря O
16	, O
17	слово B-Object
18	« O
19	хороший O
20	» O
21	или O
22	« O
23	нет O
24	» O
25	. O

# sent_id = 616
# text =   Тогда наряду с мешком слов поможет мешок N-грамм: мы добавляем в словарь не только слова, но и словосочетания.
# relations = ""
1	Тогда O
2	наряду O
3	с O
4	мешком B-Method
5	слов I-Method
6	поможет O
7	мешок B-Method
8	N I-Method
9	- I-Method
10	грамм I-Method
11	: O
12	мы O
13	добавляем O
14	в O
15	словарь O
16	не O
17	только O
18	слова B-Object
19	, O
20	но O
21	и O
22	словосочетания B-Object
23	. O

# sent_id = 617
# text =   Мы не будем вносить все словосочетания, потому что это приведёт к комбинаторному взрыву, но часто используемые статистически значимые пары или пары, соответствующие именованным сущностям, можно добавить, и это повысит качество работы итоговой модели.
# relations = ""
1	Мы O
2	не O
3	будем O
4	вносить O
5	все O
6	словосочетания B-Object
7	, O
8	потому O
9	что O
10	это O
11	приведёт O
12	к O
13	комбинаторному O
14	взрыву O
15	, O
16	но O
17	часто O
18	используемые O
19	статистически O
20	значимые O
21	пары O
22	или O
23	пары O
24	, O
25	соответствующие O
26	именованным B-Object
27	сущностям I-Object
28	, O
29	можно O
30	добавить O
31	, O
32	и O
33	это O
34	повысит O
35	качество O
36	работы O
37	итоговой O
38	модели B-Model
39	. O

# sent_id = 618
# text =   Отчасти эти ситуации позволяют обработать методы построения "векторных представлений слов", например, знаменитый word2vec или более модные skip-gramm.
# relations = "Method_includes_Method 0 1, Method_includes_Method 0 2, Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 1 0, Method_isAppliedTo_Object 2 0"
1	Отчасти O
2	эти O
3	ситуации O
4	позволяют O
5	обработать O
6	методы B-Method
7	построения I-Method
8	" O
9	векторных B-Object
10	представлений I-Object
11	слов I-Object
12	" O
13	, O
14	например O
15	, O
16	знаменитый O
17	word2vec B-Method
18	или O
19	более O
20	модные O
21	skip B-Method
22	- I-Method
23	gramm I-Method
24	. O

# sent_id = 619
# text =   Стандартные хеш-функции равномерно размазывают данные по пространству хешей.
# relations = ""
1	Стандартные O
2	хеш B-Method
3	- I-Method
4	функции I-Method
5	равномерно O
6	размазывают O
7	данные O
8	по O
9	пространству O
10	хешей O
11	. O

# sent_id = 620
# text =   Локально-чувствительный хеш похожие объекты поместит в пространстве объектов близко.
# relations = ""
1	Локально B-Method
2	- I-Method
3	чувствительный I-Method
4	хеш I-Method
5	похожие O
6	объекты O
7	поместит O
8	в O
9	пространстве O
10	объектов O
11	близко O
12	. O

# sent_id = 621
# text =   Мы выбираем случайный базис из случайных векторов.
# relations = "Object_includes_Object 0 1"
1	Мы O
2	выбираем O
3	случайный O
4	базис B-Object
5	из O
6	случайных B-Object
7	векторов I-Object
8	. O

# sent_id = 622
# text =   Задача семантического анализа достаточно старая.
# relations = ""
1	Задача O
2	семантического B-Task
3	анализа I-Task
4	достаточно O
5	старая O
6	. O

# sent_id = 623
# text =   Современный подход — анализ семантики без учителя, поэтому его называют анализом скрытой (латентной) семантики.
# relations = "Method_includes_Method 0 1"
1	Современный O
2	подход O
3	— O
4	анализ B-Method
5	семантики I-Method
6	без I-Method
7	учителя I-Method
8	, O
9	поэтому O
10	его O
11	называют O
12	анализом B-Method
13	скрытой I-Method
14	( I-Method
15	латентной I-Method
16	) I-Method
17	семантики I-Method
18	. O

# sent_id = 624
# text =   Исторически первый подход к латентно-семантическому анализу — это латентно-семантическое индексирование.
# relations = "Method_includes_Method 0 1"
1	Исторически O
2	первый O
3	подход O
4	к O
5	латентно B-Method
6	- I-Method
7	семантическому I-Method
8	анализу I-Method
9	— O
10	это O
11	латентно B-Method
12	- I-Method
13	семантическое I-Method
14	индексирование I-Method
15	. O

# sent_id = 625
# text =   Мы уже использовали для решения задач коллаборативных рекомендаций хорошо зарекомендовавшие себя техники факторизации матриц.
# relations = "Method_solves_Task 0 0"
1	Мы O
2	уже O
3	использовали O
4	для B-Method_solves_Task
5	решения I-Method_solves_Task
6	задач B-Task
7	коллаборативных I-Task
8	рекомендаций I-Task
9	хорошо O
10	зарекомендовавшие O
11	себя O
12	техники B-Method
13	факторизации I-Method
14	матриц I-Method
15	. O

# sent_id = 626
# text =   В чём суть факторизации?
# relations = ""
1	В O
2	чём O
3	суть O
4	факторизации B-Method
5	? O

# sent_id = 627
# text =   Одной из альтернатив стал так называемый вероятностный латентно-семантический индекс.
# relations = ""
1	Одной O
2	из O
3	альтернатив O
4	стал O
5	так O
6	называемый O
7	вероятностный B-Metric
8	латентно I-Metric
9	- I-Metric
10	семантический I-Metric
11	индекс I-Metric
12	. O

# sent_id = 628
# text =   Важно понять, что техника вероятностного латентно-семантического индекса — это техника факторизации матрицы.
# relations = "Method_includes_Method 1 0"
1	Важно O
2	понять O
3	, O
4	что O
5	техника B-Method
6	вероятностного I-Method
7	латентно I-Method
8	- I-Method
9	семантического I-Method
10	индекса I-Method
11	— O
12	это B-Method_includes_Method
13	техника B-Method
14	факторизации I-Method
15	матрицы I-Method
16	. O

# sent_id = 629
# text =   По сравнению с классической факторизацией на основе сингулярного разложения у вероятностной генерирующей модели есть важное преимущество.
# relations = "Method_includes_Method 0 1"
1	По O
2	сравнению O
3	с O
4	классической B-Method
5	факторизацией I-Method
6	на O
7	основе O
8	сингулярного B-Method
9	разложения I-Method
10	у O
11	вероятностной B-Model
12	генерирующей I-Model
13	модели I-Model
14	есть O
15	важное O
16	преимущество O
17	. O

# sent_id = 630
# text =   Для этого используется перплексия.
# relations = ""
1	Для O
2	этого O
3	используется B-Method_isUsedIn_Activity
4	перплексия B-Method
5	. O

# sent_id = 631
# text =   Есть так называемый EM-алгоритм.
# relations = ""
1	Есть O
2	так O
3	называемый O
4	EM B-Method
5	- I-Method
6	алгоритм I-Method
7	. O

# sent_id = 632
# text =  «Сбер» представил mGPT — версию нейросети GPT-3, способную генерировать тексты на 61 языке 
# relations = "Model_hasAuthor_Organization 0 0, Model_isModificationOf_Model 0 1"
1	« O
2	Сбер B-Organization
3	» O
4	представил B-Model_hasAuthor_Organization
5	mGPT B-Model
6	— O
7	версию O
8	нейросети O
9	GPT-3 B-Model
10	, O
11	способную O
12	генерировать B-Task
13	тексты I-Task
14	на O
15	61 O
16	языке O

# sent_id = 633
# text =   21 апреля 2022 года команда разработчиков SberDevices представила многоязычную версию нейросети GPT-3 под названием mGPT.
# relations = "Model_hasAuthor_Organization 1 0, Date_isDateOf_Model 0 1"
1	21 B-Date
2	апреля I-Date
3	2022 I-Date
4	года O
5	команда O
6	разработчиков O
7	SberDevices B-Organization
8	представила B-Model_hasAuthor_Organization
9	многоязычную O
10	версию O
11	нейросети O
12	GPT-3 B-Model
13	под O
14	названием O
15	mGPT B-Model
16	. O

# sent_id = 634
# text =   21 апреля 2022 года SberDevices представили многоязычную версию нейросети GPT-3 под названием mGPT.
# relations = "Model_hasAuthor_Organization 1 0, Date_isDateOf_Model 0 1"
1	21 B-Date
2	апреля I-Date
3	2022 I-Date
4	года O
5	SberDevices B-Organization
6	представили B-Model_hasAuthor_Organization
7	многоязычную O
8	версию O
9	нейросети O
10	GPT B-Model
11	- I-Model
12	3 I-Model
13	под O
14	названием O
15	mGPT B-Model
16	. O

# sent_id = 635
# text =   «Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.
# relations = "Task_isSolvedIn_Science 0 0, Model_isUsedForSolving_Task 0 0, Model_hasAuthor_Organization 0 0, Method_isUsedIn_Science 0 0, Method_uses_Model 0 0"
1	« O
2	Сбер B-Organization
3	» O
4	рассказал O
5	, O
6	что O
7	модель O
8	mGPT B-Model
9	может O
10	использоваться B-Model_isUsedForSolving_Task
11	как O
12	просто O
13	для B-Model_isUsedForSolving_Task
14	генерации B-Task
15	текста I-Task
16	, O
17	так O
18	и O
19	для O
20	решения O
21	различных O
22	задач O
23	в B-Task_isSolvedIn_Science
24	области I-Task_isSolvedIn_Science
25	обработки B-Science
26	естественного I-Science
27	языка I-Science
28	на O
29	одном O
30	из O
31	поддерживаемых O
32	языков O
33	путем O
34	дообучения O
35	или O
36	в O
37	составе O
38	ансамблей B-Method
39	моделей I-Method
40	. O

# sent_id = 636
# text =   Разработчики уточнили, что модель mGPT показывает выдающиеся результаты на многих задачах few-shot и zero-shot learning: в этой области машинного обучения не требуется отдельно доучивать модель, достаточно сформулировать задачу текстом и привести несколько примеров, после чего mGPT научится выполнять новую задачу.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1, Model_isUsedForSolving_Task 0 0, Model_isUsedIn_Science 0 0, Task_isSolvedIn_Science 0 0, Task_isSolvedIn_Science 1 0"
1	Разработчики O
2	уточнили O
3	, O
4	что O
5	модель O
6	mGPT B-Model
7	показывает O
8	выдающиеся O
9	результаты O
10	на B-Model_isUsedForSolving_Task
11	многих I-Model_isUsedForSolving_Task
12	задачах I-Model_isUsedForSolving_Task
13	few B-Task
14	- I-Task
15	shot I-Task
16	и O
17	zero B-Task
18	- I-Task
19	shot I-Task
20	learning I-Task
21	: O
22	в O
23	этой O
24	области O
25	машинного B-Science
26	обучения I-Science
27	не O
28	требуется O
29	отдельно O
30	доучивать O
31	модель O
32	, O
33	достаточно O
34	сформулировать O
35	задачу O
36	текстом O
37	и O
38	привести O
39	несколько O
40	примеров O
41	, O
42	после O
43	чего O
44	mGPT B-Model
45	научится O
46	выполнять O
47	новую O
48	задачу O
49	. O

# sent_id = 637
# text =   Это может использоваться для того, чтобы научить автоматизированную систему отвечать на вопросы, определять эмоциональную окраску текста, извлекать из текста имена, фамилии, названия компаний и тому подобное.
# relations = ""
1	Это O
2	может O
3	использоваться B-Method_solves_Task
4	для O
5	того O
6	, O
7	чтобы O
8	научить O
9	автоматизированную O
10	систему O
11	отвечать B-Task
12	на I-Task
13	вопросы I-Task
14	, O
15	определять B-Task
16	эмоциональную I-Task
17	окраску I-Task
18	текста I-Task
19	, O
20	извлекать B-Task
21	из O
22	текста O
23	имена B-Object
24	, O
25	фамилии B-Object
26	, O
27	названия B-Object
28	компаний I-Object
29	и O
30	тому O
31	подобное O
32	. O

# sent_id = 638
# text =   «Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1, Model_hasAuthor_Organization 0 0, Task_isSolvedIn_Science 0 0, Task_isSolvedIn_Science 1 0"
1	« O
2	Сбер B-Organization
3	» O
4	раскрыл O
5	, O
6	что O
7	модель O
8	mGPT B-Model
9	может O
10	также O
11	использоваться B-Model_isUsedForSolving_Task
12	как O
13	компонент O
14	различных O
15	речевых B-Science
16	технологий I-Science
17	— O
18	например O
19	, O
20	для O
21	улучшения B-Task
22	качества I-Task
23	распознавания I-Task
24	речи I-Task
25	, O
26	генерации B-Task
27	сценариев I-Task
28	диалоговых I-Task
29	систем I-Task
30	и O
31	других O
32	задачах O
33	. O

# sent_id = 639
# text =   Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.
# relations = "Model_Language_Lang 0 0, Model_Language_Lang 0 1, Model_Language_Lang 0 2, Model_Language_Lang 0 3, Model_Language_Lang 0 4, Model_Language_Lang 0 5, Model_Language_Lang 0 6, Model_Language_Lang 0 7, Model_Language_Lang 0 8, Model_Language_Lang 0 9, Model_Language_Lang 0 10, Model_Language_Lang 0 11, Model_Language_Lang 0 12, Model_Language_Lang 0 13, Model_Language_Lang 0 14, Model_Language_Lang 0 15, Model_Language_Lang 0 16, Model_Language_Lang 0 17, Model_Language_Lang 0 18, Model_Language_Lang 0 19, Model_Language_Lang 0 20, Model_Language_Lang 0 21, Model_Language_Lang 0 22, Model_Language_Lang 0 23, Model_Language_Lang 0 24, Model_Language_Lang 0 25, Model_Language_Lang 0 26, Model_Language_Lang 0 27, Model_Language_Lang 0 28, Model_Language_Lang 0 29, Model_Language_Lang 0 30, Model_Language_Lang 0 31, Model_Language_Lang 0 32, Model_Language_Lang 0 33, Model_Language_Lang 0 34, Model_Language_Lang 0 35, Model_Language_Lang 0 36, Model_Language_Lang 0 37, Model_Language_Lang 0 38, Model_Language_Lang 0 39, Model_Language_Lang 0 40, Model_Language_Lang 0 41, Model_Language_Lang 0 42, Model_Language_Lang 0 43, Model_Language_Lang 0 44, Model_Language_Lang 0 45, Model_Language_Lang 0 46, Model_Language_Lang 0 47, Model_Language_Lang 0 48, Model_Language_Lang 0 49, Model_Language_Lang 0 50, Model_Language_Lang 0 51, Model_Language_Lang 0 52, Model_Language_Lang 0 53, Model_Language_Lang 0 54, Model_Language_Lang 0 55, Model_Language_Lang 0 56, Model_Language_Lang 0 57, Model_Language_Lang 0 58, Model_Language_Lang 0 59, Model_Language_Lang 0 60"
1	Полный O
2	перечень O
3	языков O
4	, O
5	доступный O
6	в O
7	модели O
8	mGPT B-Model
9	: O
10	азербайджанский B-Lang
11	, O
12	английский B-Lang
13	, O
14	арабский B-Lang
15	, O
16	армянский B-Lang
17	, O
18	африкаанс B-Lang
19	, O
20	баскский B-Lang
21	, O
22	башкирский B-Lang
23	, O
24	белорусский B-Lang
25	, O
26	бенгали B-Lang
27	, O
28	бирманский B-Lang
29	, O
30	болгарский B-Lang
31	, O
32	бурятский B-Lang
33	, O
34	венгерский B-Lang
35	, O
36	вьетнамский B-Lang
37	, O
38	голландский B-Lang
39	, O
40	греческий B-Lang
41	, O
42	грузинский B-Lang
43	, O
44	датский B-Lang
45	, O
46	иврит B-Lang
47	, O
48	индонезийский B-Lang
49	, O
50	испанский B-Lang
51	, O
52	итальянский B-Lang
53	, O
54	йоруба B-Lang
55	, O
56	казахский B-Lang
57	, O
58	калмыцкий B-Lang
59	, O
60	киргизский B-Lang
61	, O
62	китайский B-Lang
63	, O
64	корейский B-Lang
65	, O
66	латышский B-Lang
67	, O
68	литовский B-Lang
69	, O
70	малайский B-Lang
71	, O
72	малаялам B-Lang
73	, O
74	маратхи B-Lang
75	, O
76	молдавский B-Lang
77	, O
78	монгольский B-Lang
79	, O
80	немецкий B-Lang
81	, O
82	осетинский B-Lang
83	, O
84	персидский B-Lang
85	, O
86	польский B-Lang
87	, O
88	португальский B-Lang
89	, O
90	румынский B-Lang
91	, O
92	русский B-Lang
93	, O
94	суахили B-Lang
95	, O
96	таджикский B-Lang
97	, O
98	тайский B-Lang
99	, O
100	тамильский B-Lang
101	, O
102	татарский B-Lang
103	, O
104	телугу B-Lang
105	, O
106	тувинский B-Lang
107	, O
108	турецкий B-Lang
109	, O
110	туркменский B-Lang
111	, O
112	узбекский B-Lang
113	, O
114	украинский B-Lang
115	, O
116	урду B-Lang
117	, O
118	финский B-Lang
119	, O
120	французский B-Lang
121	, O
122	хинди B-Lang
123	, O
124	чувашский B-Lang
125	, O
126	шведский B-Lang
127	, O
128	якутский B-Lang
129	, O
130	японский B-Lang
131	. O

# sent_id = 640
# text =   В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».
# relations = "Application_hasAuthor_Organization 0 0, Model_Language_Lang 0 0, Date_isDateOf_Model 0 0, Model_hasAuthor_Organization 0 0, Model_isUsedIn_Application 0 0"
1	В O
2	2020 B-Date
3	году O
4	« O
5	Сбер B-Organization
6	» O
7	представил B-Model_hasAuthor_Organization
8	русскоязычную B-Lang
9	версию B-Model
10	нейросети I-Model
11	GPT-3 I-Model
12	, O
13	именно O
14	она O
15	используется B-Model_isUsedIn_Application
16	в O
17	двух O
18	виртуальных O
19	ассистентах O
20	семейства O
21	« O
22	Салют B-Application
23	» O
24	от O
25	« O
26	Сбера B-Organization
27	» O
28	. O

# sent_id = 641
# text =   Русскоязычная версия GPT-3, разработанная «Сбером», доступна на платформе SmartMarket.
# relations = "Model_Language_Lang 0 0, Model_hasAuthor_Organization 0 0"
1	Русскоязычная B-Lang
2	версия B-Model
3	GPT-3 I-Model
4	, O
5	разработанная B-Model_hasAuthor_Organization
6	« O
7	Сбером B-Organization
8	» O
9	, O
10	доступна B-Model_isOn_InfoResource
11	на O
12	платформе O
13	SmartMarket B-InfoResource
14	. O

# sent_id = 642
# text =   В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.
# relations = "Date_isDateOf_Method 0 0, Method_hasAuthor_Organization 0 0, Model_hasAuthor_Organization 0 0, Date_isDateOf_Model 0 0, Method_isUsedForTraining_Model 0 0"
1	В O
2	ноябре B-Date
3	2021 I-Date
4	года I-Date
5	« O
6	Сбер B-Organization
7	» O
8	обучил B-Model_hasAuthor_Organization
9	нейросеть O
10	ruGPT-3 B-Model
11	автоматически O
12	писать O
13	код O
14	и O
15	назвал O
16	эту O
17	функцию O
18	JARVIS B-Method
19	. O

# sent_id = 643
# text = В ноябре 2021 года компания "Сбер" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.
# relations = "Date_isDateOf_Method 0 0, Method_hasAuthor_Organization 0 0, Model_hasAuthor_Organization 0 0, Date_isDateOf_Model 0 0, Method_isUsedForTraining_Model 0 0"
1	В O
2	ноябре B-Date
3	2021 I-Date
4	года I-Date
5	компания O
6	" O
7	Сбер B-Organization
8	" O
9	провела B-Model_hasAuthor_Organization
10	обучение I-Model_hasAuthor_Organization
11	нейросети O
12	ruGPT-3 B-Model
13	для O
14	автоматического O
15	написания O
16	кода O
17	, O
18	представив O
19	эту O
20	функцию O
21	под O
22	названием O
23	JARVIS B-Method
24	. O

# sent_id = 644
# text =   Не заблокированы: Sber AI — на GitHub; ruDALL-E — на GitHub; Russian GPT-3 models — GitHub.
# relations = ""
1	Не O
2	заблокированы O
3	: O
4	Sber B-Model
5	AI I-Model
6	— O
7	на B-Model_isOn_InfoResource
8	GitHub B-InfoResource
9	; O
10	ruDALL B-Model
11	- I-Model
12	E I-Model
13	— O
14	на B-Model_isOn_InfoResource
15	GitHub B-InfoResource
16	; O
17	Russian B-Model
18	GPT-3 I-Model
19	models I-Model
20	— O
21	GitHub B-InfoResource
22	. O

# sent_id = 645
# text =   Заблокированы: большая часть ссылок на открытом портале Open Source от разработчиков «Сбера»; SberDevices.
# relations = "Application_hasAuthor_Organization 0 0"
1	Заблокированы O
2	: O
3	большая O
4	часть O
5	ссылок O
6	на O
7	открытом O
8	портале O
9	Open B-InfoResource
10	Source I-InfoResource
11	от O
12	разработчиков O
13	« O
14	Сбера B-Organization
15	» O
16	; O
17	SberDevices B-Application
18	. O

# sent_id = 646
# text =  Как поясняет сам Томас Димсон, This Word Does Not Exist является вариацией нейросети GPT-2.
# relations = ""
1	Как O
2	поясняет O
3	сам O
4	Томас B-Person
5	Димсон I-Person
6	, O
7	This B-Model
8	Word I-Model
9	Does I-Model
10	Not I-Model
11	Exist I-Model
12	является O
13	вариацией O
14	нейросети O
15	GPT-2 B-Model
16	. O

# sent_id = 647
# text =   Существует также твиттер-бот проекта.
# relations = ""
1	Существует O
2	также O
3	твиттер B-Technology
4	- I-Technology
5	бот I-Technology
6	проекта O
7	. O

# sent_id = 648
# text =   Чтобы натренировать свою нейросеть на основе загруженных файлов, Димсон рекомендует воспользоваться контентом Apple Dictionary или Urban Dictionary.
# relations = ""
1	Чтобы O
2	натренировать O
3	свою O
4	нейросеть O
5	на O
6	основе O
7	загруженных O
8	файлов O
9	, O
10	Димсон B-Person
11	рекомендует O
12	воспользоваться O
13	контентом O
14	Apple B-InfoResource
15	Dictionary I-InfoResource
16	или O
17	Urban B-InfoResource
18	Dictionary I-InfoResource
19	. O

# sent_id = 649
# text =  Правда, пользователи YCombinator уже заметили, что This Word Does Not Exist иногда предлагает уже существующие слова — например, refactoring.
# relations = ""
1	Правда O
2	, O
3	пользователи O
4	YCombinator B-Application
5	уже O
6	заметили O
7	, O
8	что O
9	This B-Model
10	Word I-Model
11	Does I-Model
12	Not I-Model
13	Exist I-Model
14	иногда O
15	предлагает O
16	уже O
17	существующие O
18	слова O
19	— O
20	например O
21	, O
22	refactoring O
23	. O

# sent_id = 650
# text =  После выхода учебника я читал курс на его основе в УрФУ, ШАДе, ИТМО и СПбГУ и убедился, что наличие перевода очень помогает.
# relations = ""
1	После O
2	выхода O
3	учебника O
4	я O
5	читал O
6	курс O
7	на O
8	его O
9	основе O
10	в O
11	УрФУ B-Organization
12	, O
13	ШАДе B-Organization
14	, O
15	ИТМО B-Organization
16	и O
17	СПбГУ B-Organization
18	и O
19	убедился O
20	, O
21	что O
22	наличие O
23	перевода O
24	очень O
25	помогает O
26	. O

# sent_id = 651
# text =   В случае NLP потребность в «локализованных» учебных материалах еще заметнее, чем в информационном поиске.
# relations = "Science_includes_Science 0 1"
1	В O
2	случае O
3	NLP B-Science
4	потребность O
5	в O
6	« O
7	локализованных O
8	» O
9	учебных O
10	материалах O
11	еще O
12	заметнее O
13	, O
14	чем O
15	в O
16	информационном B-Science
17	поиске I-Science
18	. O

# sent_id = 652
# text =   Слушателям предлагается самостоятельно реализовать методы морфологического анализа, определения тональности текста, автоматического реферирования документов, извлечения именованных сущностей и машинного перевода.
# relations = ""
1	Слушателям O
2	предлагается O
3	самостоятельно O
4	реализовать O
5	методы B-Method
6	морфологического I-Method
7	анализа I-Method
8	, O
9	определения B-Task
10	тональности I-Task
11	текста I-Task
12	, O
13	автоматического B-Task
14	реферирования I-Task
15	документов I-Task
16	, O
17	извлечения B-Task
18	именованных I-Task
19	сущностей I-Task
20	и O
21	машинного B-Task
22	перевода I-Task
23	. O

# sent_id = 653
# text =   Желательно, чтобы слушатели обладали базовыми знаниями линейной алгебры, теории вероятностей, математической статистики и машинного обучения, а также навыками программирования (необходимы для решения практических заданий).
# relations = ""
1	Желательно O
2	, O
3	чтобы O
4	слушатели O
5	обладали O
6	базовыми O
7	знаниями O
8	линейной B-Science
9	алгебры I-Science
10	, O
11	теории B-Science
12	вероятностей I-Science
13	, O
14	математической B-Science
15	статистики I-Science
16	и O
17	машинного B-Method
18	обучения I-Method
19	, O
20	а O
21	также O
22	навыками O
23	программирования B-Science
24	( O
25	необходимы O
26	для O
27	решения O
28	практических O
29	заданий O
30	) O
31	. O

# sent_id = 654
# text =   Он опубликовал программу (репозиторий на гитхабе), которая делает именно это: генерирует политические речи, удивительно похожие на настоящие.
# relations = "Application_isUsedForSolving_Task 0 0"
1	Он O
2	опубликовал B-Application_hasAuthor_Person
3	программу B-Application
4	( O
5	репозиторий O
6	на O
7	гитхабе O
8	) O
9	, O
10	которая B-Application_isUsedForSolving_Task
11	делает I-Application_isUsedForSolving_Task
12	именно O
13	это O
14	: O
15	генерирует B-Task
16	политические I-Task
17	речи I-Task
18	, O
19	удивительно O
20	похожие O
21	на O
22	настоящие O
23	. O

# sent_id = 655
# text =   В данной статье мы будем использовать модель трансформера для бинарной классификации текста.
# relations = "Model_isUsedForSolving_Task 0 0"
24	В O
25	данной O
26	статье O
27	мы O
28	будем O
29	использовать O
30	модель B-Model
31	трансформера I-Model
32	для B-Model_isUsedForSolving_Task
33	бинарной B-Task
34	классификации I-Task
35	текста I-Task
36	. O

# sent_id = 656
# text =   Самая простая и популярная связка – TF-IDF + линейная модель.
# relations = "Metric_isUsedFor_Model 0 0"
1	Самая O
2	простая O
3	и O
4	популярная O
5	связка O
6	– O
7	TF B-Metric
8	- I-Metric
9	IDF I-Metric
10	+ O
11	линейная B-Model
12	модель I-Model
13	. O

# sent_id = 657
# text =   В случае с BERT можно (даже нужно) опустить препроцессинг и сразу перейти к токенизации и обучению.
# relations = ""
1	В O
2	случае O
3	с O
4	BERT B-Model
5	можно O
6	( O
7	даже O
8	нужно O
9	) O
10	опустить O
11	препроцессинг B-Method
12	и O
13	сразу O
14	перейти O
15	к O
16	токенизации B-Method
17	и O
18	обучению O
19	. O

# sent_id = 658
# text =   Необходимо обучить модель находить обращения с жалобой на сотрудника или другими словами – бинарная классификация.
# relations = ""
1	Необходимо O
2	обучить O
3	модель O
4	находить O
5	обращения O
6	с O
7	жалобой O
8	на O
9	сотрудника O
10	или O
11	другими O
12	словами O
13	– O
14	бинарная B-Task
15	классификация I-Task
16	. O

# sent_id = 659
# text =  Для решения описанной задачи используется модель от DeepPavlov rubert-base-cased-sentence.
# relations = "Model_hasAuthor_Organization 0 0"
1	Для B-Model_isUsedForSolving_Task
2	решения I-Model_isUsedForSolving_Task
3	описанной O
4	задачи O
5	используется B-Model_isUsedForSolving_Task
6	модель O
7	от B-Model_hasAuthor_Organization
8	DeepPavlov B-Organization
9	rubert B-Model
10	- I-Model
11	base I-Model
12	- I-Model
13	cased I-Model
14	- I-Model
15	sentence I-Model
16	. O

# sent_id = 660
# text =   На выходе мы получаем метрику f1 = 0.91.
# relations = "Metric_hasValue_Value 0 0"
1	На O
2	выходе O
3	мы O
4	получаем O
5	метрику O
6	f1 B-Metric
7	= O
8	0.91 B-Value
9	. O

# sent_id = 661
# text =   Обученные модели можно найти на сайтах HuggingFace и DeepPavlov.
# relations = ""
1	Обученные O
2	модели O
3	можно B-Model_isOn_InfoResource
4	найти I-Model_isOn_InfoResource
5	на O
6	сайтах O
7	HuggingFace B-InfoResource
8	и O
9	DeepPavlov B-InfoResource
10	. O

# sent_id = 662
# text =   Соответственно, мы приходим к стандартной задаче Machine Learning (ML) – «многоклассовая классификация».
# relations = "Science_isAlternativeNameFor_Science 1 0, Task_isSolvedIn_Science 0 0, Task_isSolvedIn_Science 0 1"
1	Соответственно O
2	, O
3	мы O
4	приходим O
5	к O
6	стандартной O
7	задаче O
8	Machine B-Science
9	Learning I-Science
10	( O
11	ML B-Science
12	) O
13	– O
14	« O
15	многоклассовая B-Task
16	классификация I-Task
17	» O
18	. O

# sent_id = 663
# text = Стандартной задачей Machine Learning (ML)  является многоклассовая классификация.
# relations = "Science_isAlternativeNameFor_Science 1 0, Task_isSolvedIn_Science 0 0, Task_isSolvedIn_Science 0 1"
1	Стандартной O
2	задачей O
3	Machine B-Science
4	Learning I-Science
5	( O
6	ML B-Science
7	) O
8	является O
9	многоклассовая B-Task
10	классификация I-Task
11	. O

# sent_id = 664
# text = Многоклассовая классификация - это известная задача Machine Learning (ML).
# relations = "Science_isAlternativeNameFor_Science 1 0, Task_isSolvedIn_Science 0 0, Task_isSolvedIn_Science 0 1"
1	Многоклассовая B-Task
2	классификация I-Task
3	- O
4	это O
5	известная O
6	задача O
7	Machine B-Science
8	Learning I-Science
9	( O
10	ML B-Science
11	) O
12	. O

# sent_id = 665
# text =   В результате данного анализа решается задача — сбор сводной аналитики по организации.
# relations = "Method_solves_Task 0 0"
1	В O
2	результате O
3	данного O
4	анализа B-Method
5	решается B-Method_solves_Task
6	задача O
7	— O
8	сбор B-Task
9	сводной I-Task
10	аналитики I-Task
11	по I-Task
12	организации I-Task
13	. O

# sent_id = 666
# text =   В случае многоклассовой классификации число классов должно быть более 2 и может достигать даже многих тысяч.
# relations = "Object_isUsedInSolving_Task 0 0"
1	В O
2	случае O
3	многоклассовой B-Task
4	классификации I-Task
5	число O
6	классов B-Object
7	должно O
8	быть O
9	более O
10	2 O
11	и O
12	может O
13	достигать O
14	даже O
15	многих O
16	тысяч O
17	. O

# sent_id = 667
# text =   Во-вторых, такого разброса тематик, связанных с техническими текстами, у нас еще не было: нейросети, переиспользование контента, автоматическое тестирование документации, встраивание текста в интерфейс, мастерство технических коммуникаций, построение процессов перевода и принципы написания документов с расчетом на их последующую локализацию.
# relations = ""
1	Во O
2	- O
3	вторых O
4	, O
5	такого O
6	разброса O
7	тематик O
8	, O
9	связанных O
10	с O
11	техническими B-Object
12	текстами I-Object
13	, O
14	у O
15	нас O
16	еще O
17	не O
18	было O
19	: O
20	нейросети O
21	, O
22	переиспользование B-Task
23	контента I-Task
24	, O
25	автоматическое B-Task
26	тестирование I-Task
27	документации I-Task
28	, O
29	встраивание B-Task
30	текста I-Task
31	в I-Task
32	интерфейс I-Task
33	, O
34	мастерство B-Task
35	технических I-Task
36	коммуникаций I-Task
37	, O
38	построение B-Task
39	процессов I-Task
40	перевода I-Task
41	и O
42	принципы B-Task
43	написания I-Task
44	документов I-Task
45	с O
46	расчетом O
47	на O
48	их O
49	последующую O
50	локализацию O
51	. O

# sent_id = 668
# text =   Зачастую суммаризация предполагает работу с большими генеративными текстовыми моделями, куда надо «положить» все отзывы.
# relations = "Method_isAppliedTo_Object 0 0"
1	Зачастую O
2	суммаризация B-Method
3	предполагает B-Method_isAppliedTo_Object
4	работу I-Method_isAppliedTo_Object
5	с I-Method_isAppliedTo_Object
6	большими O
7	генеративными B-Object
8	текстовыми I-Object
9	моделями I-Object
10	, O
11	куда O
12	надо O
13	« O
14	положить O
15	» O
16	все O
17	отзывы O
18	. O

# sent_id = 669
# text =   То есть какие аспекты искать; выделять эти аспекты в отзывах; оценивать тональность высказываний.
# relations = ""
1	То O
2	есть O
3	какие O
4	аспекты O
5	искать O
6	; O
7	выделять O
8	эти O
9	аспекты O
10	в O
11	отзывах O
12	; O
13	оценивать O
14	тональность B-Object
15	высказываний I-Object
16	. O

# sent_id = 670
# text =   Мы начали со внутреннего инструмента Яндекса — библиотеки регулярных выражений под названием Remorph.
# relations = "Application_hasAuthor_Organization 0 0, Application_hasAuthor_Organization 1 0"
1	Мы O
2	начали O
3	со O
4	внутреннего O
5	инструмента O
6	Яндекса B-Organization
7	— O
8	библиотеки B-Application
9	регулярных I-Application
10	выражений I-Application
11	под O
12	названием O
13	Remorph B-Application
14	. O

# sent_id = 671
# text =   Исследователи Массачусетского технологического университета разработали систему искусственного интеллекта, которая способна переписывать устаревшие предложения в статьях «Википедии».
# relations = "Object_isUsedInSolving_Task 0 0, Application_isAppliedTo_Object 0 0, Application_isUsedForSolving_Task 0 0, Application_hasAuthor_Organization 0 0"
1	Исследователи O
2	Массачусетского B-Organization
3	технологического I-Organization
4	университета I-Organization
5	разработали B-Application_hasAuthor_Organization
6	систему B-Application
7	искусственного I-Application
8	интеллекта I-Application
9	, O
10	которая O
11	способна B-Application_isUsedForSolving_Task
12	переписывать B-Task
13	устаревшие I-Task
14	предложения I-Task
15	в B-Application_isAppliedTo_Object
16	статьях B-Object
17	« O
18	Википедии B-InfoResource
19	» O
20	. O

# sent_id = 672
# text =   Расширение статей, серьезные переписывания или другие рутинные изменения, такие как обновление номеров, дат, имен и местоположений в настоящее время добровольно выполняются пользователями из разных стран.
# relations = ""
1	Расширение B-Task
2	статей I-Task
3	, O
4	серьезные O
5	переписывания B-Task
6	или O
7	другие O
8	рутинные O
9	изменения O
10	, O
11	такие O
12	как O
13	обновление O
14	номеров O
15	, O
16	дат O
17	, O
18	имен O
19	и O
20	местоположений O
21	в O
22	настоящее O
23	время O
24	добровольно O
25	выполняются O
26	пользователями O
27	из O
28	разных O
29	стран O
30	. O

# sent_id = 673
# text =   Если она видит какие-либо противоречия между этими двумя высказываниями, то использует «маску нейтральности», чтобы определить те противоречивые слова, которые нужно удалить, и те, которые обязательно нужно сохранить.
# relations = ""
1	Если O
2	она O
3	видит O
4	какие O
5	- O
6	либо O
7	противоречия O
8	между O
9	этими O
10	двумя O
11	высказываниями O
12	, O
13	то O
14	использует O
15	« O
16	маску B-Object
17	нейтральности I-Object
18	» O
19	, O
20	чтобы O
21	определить O
22	те O
23	противоречивые O
24	слова O
25	, O
26	которые O
27	нужно O
28	удалить O
29	, O
30	и O
31	те O
32	, O
33	которые O
34	обязательно O
35	нужно O
36	сохранить O
37	. O

# sent_id = 674
# text =   Отмечается, что систему также можно использовать для дополнения наборов данных, предназначенных для обучения детекторов фейкньюс, что потенциально снижает предвзятость и повышает точность информации.
# relations = "Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 0 1"
1	Отмечается O
2	, O
3	что O
4	систему B-Application
5	также O
6	можно O
7	использовать B-Application_isUsedForSolving_Task
8	для I-Application_isUsedForSolving_Task
9	дополнения B-Task
10	наборов I-Task
11	данных I-Task
12	, O
13	предназначенных O
14	для O
15	обучения B-Task
16	детекторов I-Task
17	фейкньюс I-Task
18	, O
19	что O
20	потенциально O
21	снижает O
22	предвзятость O
23	и O
24	повышает O
25	точность B-Metric
26	информации O
27	. O

# sent_id = 675
# text =  Наше выработанное решение – обучить нейронную сеть, которая способна по тексту обращения автоматически распознавать заранее ранжированные по классам проблемы, извлекать сущность (номер заказа и телефон клиента) и по определённым классам сделать автоматизацию решения.
# relations = "Method_solves_Task 0 0, Method_solves_Task 0 1"
1	Наше O
2	выработанное O
3	решение O
4	– O
5	обучить O
6	нейронную B-Method
7	сеть I-Method
8	, O
9	которая O
10	способна B-Method_solves_Task
11	по O
12	тексту O
13	обращения O
14	автоматически B-Task
15	распознавать I-Task
16	заранее I-Task
17	ранжированные I-Task
18	по I-Task
19	классам I-Task
20	проблемы I-Task
21	, O
22	извлекать B-Task
23	сущность I-Task
24	( O
25	номер O
26	заказа O
27	и O
28	телефон O
29	клиента O
30	) O
31	и O
32	по O
33	определённым O
34	классам O
35	сделать O
36	автоматизацию O
37	решения O
38	. O

# sent_id = 676
# text =   На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).
# relations = "Model_isAlternativeNameFor_Model 2 1, Model_isUsedForSolving_Task 2 0, Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 1 0"
1	На O
2	самом O
3	деле O
4	уже O
5	существуют O
6	продвинутые O
7	и O
8	проверенные O
9	методы O
10	ее O
11	обработки O
12	, O
13	использующие O
14	нейронные B-Model
15	сети I-Model
16	, O
17	с O
18	распознаванием B-Task
19	смысла I-Task
20	и I-Task
21	контекста I-Task
22	– O
23	BERT B-Model
24	( O
25	Bidirectional B-Model
26	Encoder I-Model
27	Representations I-Model
28	from I-Model
29	Transformers I-Model
30	) O
31	. O

# sent_id = 677
# text =   Перед тем как выбрать нейронные сети, мы протестировали несколько более стандартных архитектур, случайные леса и бустинг.
# relations = ""
1	Перед O
2	тем O
3	как O
4	выбрать O
5	нейронные B-Method
6	сети I-Method
7	, O
8	мы O
9	протестировали O
10	несколько O
11	более O
12	стандартных O
13	архитектур O
14	, O
15	случайные B-Method
16	леса I-Method
17	и O
18	бустинг B-Method
19	. O

# sent_id = 678
# text =   Эта модель была обучена на огромном корпусе русскоязычного текста с двумя задачами – предсказать замаскированное слово в предложениях и предсказать, если одно из предложений следует по смыслу за вторым.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isTrainedOn_Corpus 0 0"
1	Эта O
2	модель B-Model
3	была O
4	обучена B-Model_isTrainedOn_Corpus
5	на I-Model_isTrainedOn_Corpus
6	огромном O
7	корпусе B-Corpus
8	русскоязычного I-Corpus
9	текста I-Corpus
10	с O
11	двумя O
12	задачами O
13	– O
14	предсказать B-Task
15	замаскированное I-Task
16	слово I-Task
17	в I-Task
18	предложениях I-Task
19	и O
20	предсказать O
21	, O
22	если O
23	одно O
24	из O
25	предложений O
26	следует O
27	по O
28	смыслу O
29	за O
30	вторым O
31	. O

# sent_id = 679
# text =   На обширном корпусе русскоязычного текста данная модель была обучена выполнять две задачи: предсказывать замаскированные слова в предложениях и определять, следует ли одно предложение за другим по смыслу.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isTrainedOn_Corpus 0 0"
1	На O
2	обширном O
3	корпусе B-Corpus
4	русскоязычного I-Corpus
5	текста I-Corpus
6	данная O
7	модель B-Model
8	была O
9	обучена B-Model_isTrainedOn_Corpus
10	выполнять O
11	две O
12	задачи O
13	: O
14	предсказывать B-Task
15	замаскированные I-Task
16	слова I-Task
17	в I-Task
18	предложениях I-Task
19	и O
20	определять O
21	, O
22	следует O
23	ли O
24	одно O
25	предложение O
26	за O
27	другим O
28	по O
29	смыслу O
30	. O

# sent_id = 680
# text =   Наша задача – дообучить эту языковую модель для нашего приложения (одна модель для классификации и одна – для извлечения сущности).
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1"
1	Наша O
2	задача O
3	– O
4	дообучить O
5	эту O
6	языковую O
7	модель O
8	для O
9	нашего O
10	приложения O
11	( O
12	одна O
13	модель B-Model
14	для B-Model_isUsedForSolving_Task
15	классификации B-Task
16	и O
17	одна O
18	– O
19	для B-Model_isUsedForSolving_Task
20	извлечения B-Task
21	сущности I-Task
22	) O
23	. O

# sent_id = 681
# text =   результат первой модели – точность 77%
# relations = "Metric_hasValue_Value 0 0"
1	результат O
2	первой O
3	модели O
4	– O
5	точность B-Metric
6	77% B-Value

# sent_id = 682
# text =   Чтобы определить, какие ещё есть потенциальные классы, мы повели так называемое тематическое моделирование, используя несколько подходов: начиная от пробалистических моделей (латентное распределение Дирихле, ARTM) и всё те же нейронные сети (BERT).
# relations = "Method_isAlternativeNameFor_Method 2 1"
1	Чтобы O
2	определить O
3	, O
4	какие O
5	ещё O
6	есть O
7	потенциальные O
8	классы O
9	, O
10	мы O
11	повели O
12	так O
13	называемое O
14	тематическое B-Method
15	моделирование I-Method
16	, O
17	используя O
18	несколько O
19	подходов O
20	: O
21	начиная O
22	от O
23	пробалистических B-Model
24	моделей I-Model
25	( O
26	латентное B-Method
27	распределение I-Method
28	Дирихле I-Method
29	, O
30	ARTM B-Method
31	) O
32	и O
33	всё O
34	те O
35	же O
36	нейронные B-Method
37	сети I-Method
38	( O
39	BERT B-Model
40	) O
41	. O

# sent_id = 683
# text =   Теперь нам нужно было использовать некоторые технические способы, чтобы сделать максимально высоким качество модели, которая на новых классах давала точность 72%.
# relations = "Metric_hasValue_Value 0 0, Metric_isUsedFor_Model 0 0, Method_isUsedForTraining_Model 0 0"
1	Теперь O
2	нам O
3	нужно O
4	было O
5	использовать O
6	некоторые O
7	технические B-Method
8	способы I-Method
9	, O
10	чтобы O
11	сделать O
12	максимально O
13	высоким O
14	качество O
15	модели B-Model
16	, O
17	которая O
18	на O
19	новых O
20	классах O
21	давала O
22	точность B-Metric
23	72 B-Value
24	% I-Value
25	. O

# sent_id = 684
# text =   Второе, мы стандартно провели экстенсивный тюнинг гиперпараметров и изменили нашу метрику с точности на F1, чтобы ставить больше акцента на точность по каждому классу, так как общая точность предвзято относится к доминирующим классам.
# relations = "Metric_isAppliedTo_Method 0 0, Metric_isAppliedTo_Method 1 0"
1	Второе O
2	, O
3	мы O
4	стандартно O
5	провели O
6	экстенсивный B-Method
7	тюнинг I-Method
8	гиперпараметров I-Method
9	и O
10	изменили O
11	нашу O
12	метрику O
13	с O
14	точности B-Metric
15	на O
16	F1 B-Metric
17	, O
18	чтобы O
19	ставить O
20	больше O
21	акцента O
22	на O
23	точность B-Metric
24	по O
25	каждому O
26	классу O
27	, O
28	так O
29	как O
30	общая O
31	точность B-Metric
32	предвзято O
33	относится O
34	к O
35	доминирующим O
36	классам O
37	. O

# sent_id = 685
# text =   Мы провели экстенсивный тюнинг гиперпараметров и переключили нашу метрику с точности на F1.
# relations = "Metric_isAppliedTo_Method 0 0, Metric_isAppliedTo_Method 1 0"
1	Мы O
2	провели O
3	экстенсивный B-Method
4	тюнинг I-Method
5	гиперпараметров I-Method
6	и O
7	переключили O
8	нашу O
9	метрику O
10	с O
11	точности B-Metric
12	на O
13	F1 B-Metric
14	. O

# sent_id = 686
# text =   Изменение оптимизирующей метрики на F1 позволило алгоритму обучения дольше обучаться, так как почти на каждом этапе происходило улучшение по F1, когда метрика была точность, мы достигали плато гораздо быстрее.
# relations = ""
1	Изменение O
2	оптимизирующей O
3	метрики O
4	на O
5	F1 B-Metric
6	позволило O
7	алгоритму O
8	обучения O
9	дольше O
10	обучаться O
11	, O
12	так O
13	как O
14	почти O
15	на O
16	каждом O
17	этапе O
18	происходило O
19	улучшение O
20	по O
21	F1 B-Metric
22	, O
23	когда O
24	метрика O
25	была O
26	точность B-Metric
27	, O
28	мы O
29	достигали O
30	плато O
31	гораздо O
32	быстрее O
33	. O

# sent_id = 687
# text =   Изначально на этапе MVP (minimum viable product) мы применяли регулярные выражения для извлечения сущности.
# relations = "Method_solves_Task 0 0"
1	Изначально O
2	на O
3	этапе O
4	MVP B-Object
5	( O
6	minimum B-Object
7	viable I-Object
8	product I-Object
9	) O
10	мы O
11	применяли B-Method_isAppliedTo_Object
12	регулярные B-Method
13	выражения I-Method
14	для B-Method_solves_Task
15	извлечения B-Task
16	сущности I-Task
17	. O

# sent_id = 688
# text =   Протестировав поведение модели на продовских данных, мы обнаружили, что точность извлечения была около 50%.
# relations = "Metric_isUsedFor_Model 0 0, Metric_hasValue_Value 0 0"
1	Протестировав O
2	поведение O
3	модели B-Model
4	на O
5	продовских O
6	данных O
7	, O
8	мы O
9	обнаружили O
10	, O
11	что O
12	точность B-Metric
13	извлечения O
14	была O
15	около O
16	50 B-Value
17	% I-Value
18	. O

# sent_id = 689
# text =   Мы поняли, что даже извлечение сущности зависит от контекста, и решили использовать BERT.
# relations = "Model_isUsedForSolving_Task 0 0"
1	Мы O
2	поняли O
3	, O
4	что O
5	даже O
6	извлечение B-Task
7	сущности I-Task
8	зависит O
9	от O
10	контекста O
11	, O
12	и O
13	решили O
14	использовать B-Model_isUsedForSolving_Task
15	BERT B-Model
16	. O

# sent_id = 690
# text =   На вход необходимо представить размеченные данные с маркировкой BIO (beginning, intermediate, O – пустота).
# relations = ""
1	На O
2	вход O
3	необходимо O
4	представить O
5	размеченные O
6	данные O
7	с O
8	маркировкой B-Object
9	BIO B-Object
10	( O
11	beginning O
12	, O
13	intermediate O
14	, O
15	O O
16	– O
17	пустота O
18	) O
19	. O

# sent_id = 691
# text =   Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.
# relations = "Model_isTrainedOn_Dataset 0 0, Metric_isUsedFor_Model 0 0, Metric_hasValue_Value 0 0"
1	Мы O
2	производили O
3	разметку B-Method
4	800 O
5	обращений O
6	на O
7	DataTurcks B-Dataset
8	: O
9	Точность B-Metric
10	подхода O
11	BERT B-Model
12	– O
13	94 B-Value
14	% I-Value
15	на O
16	этапе O
17	обучения O
18	, O
19	она O
20	валидирована O
21	на O
22	тестовых O
23	данных O
24	. O

# sent_id = 692
# text =   Метод BERT демонстрирует точность 94% на этапе обучения, и эта точность проверена на тестовых данных.
# relations = "Metric_isAppliedTo_Method 0 0, Metric_hasValue_Value 0 0"
1	Метод B-Method
2	BERT I-Method
3	демонстрирует B-Metric_isAppliedTo_Method
4	точность B-Metric
5	94 B-Value
6	% I-Value
7	на O
8	этапе O
9	обучения O
10	, O
11	и O
12	эта O
13	точность B-Metric
14	проверена O
15	на O
16	тестовых O
17	данных O
18	. O

# sent_id = 693
# text =   Это постобработка увеличила точность до 98%.
# relations = "Metric_hasValue_Value 0 0"
1	Это O
2	постобработка O
3	увеличила O
4	точность B-Metric
5	до O
6	98% B-Value

# sent_id = 694
# text =   В иностранной литературе можно встретить термин Continuous Learning (CL), который объединяет различные методы использования новых данных для поддержания эффективности моделей.
# relations = "Method_includes_Method 0 2, Method_isAlternativeNameFor_Method 1 0"
1	В O
2	иностранной O
3	литературе O
4	можно O
5	встретить O
6	термин O
7	Continuous B-Method
8	Learning I-Method
9	( O
10	CL B-Method
11	) O
12	, O
13	который O
14	объединяет B-Method_includes_Method
15	различные O
16	методы B-Method
17	использования I-Method
18	новых I-Method
19	данных I-Method
20	для I-Method
21	поддержания I-Method
22	эффективности I-Method
23	моделей I-Method
24	. O

# sent_id = 695
# text =   Методы CL были положены в основу пайплайна переобучения.
# relations = ""
1	Методы O
2	CL B-Method
3	были O
4	положены O
5	в O
6	основу O
7	пайплайна O
8	переобучения O
9	. O

# sent_id = 696
# text =  Ученые Новосибирского государственного технического университета НЭТИ завершают разработку системы распознавания русского жестового языка.
# relations = "Application_isAppliedTo_Object 0 0, Application_hasAuthor_Organization 0 0"
1	Ученые O
2	Новосибирского B-Organization
3	государственного I-Organization
4	технического I-Organization
5	университета I-Organization
6	НЭТИ B-Organization
7	завершают B-Application_hasAuthor_Organization
8	разработку I-Application_hasAuthor_Organization
9	системы B-App_system
10	распознавания I-App_system
11	русского B-Object
12	жестового I-Object
13	языка I-Object
14	. O

# sent_id = 697
# text =   Точность распознавания составляет 92%.
# relations = "Metric_hasValue_Value 0 0"
1	Точность B-Metric
2	распознавания O
3	составляет O
4	92 B-Value
5	% I-Value
6	. O

# sent_id = 698
# text =   «Мы также вели работу над выделением эпентезы (межжестовое движение).
# relations = "Object_isUsedInSolving_Task 0 0"
1	« O
2	Мы O
3	также O
4	вели O
5	работу O
6	над O
7	выделением B-Task
8	эпентезы I-Task
9	( O
10	межжестовое B-Object
11	движение I-Object
12	) O
13	. O

# sent_id = 699
# text =   Сейчас точность выделения жестов в видеопотоке составляет 85—90%.
# relations = "Metric_isUsedIn_Task 0 0, Metric_hasValue_Value 0 0, Object_isUsedInSolving_Task 0 0"
1	Сейчас O
2	точность B-Metric
3	выделения B-Task
4	жестов I-Task
5	в B-Object_isUsedInSolving_Task
6	видеопотоке B-Object
7	составляет O
8	85—90 B-Value
9	% I-Value
10	. O

# sent_id = 700
# text =   С моделью от OpenAI связано сразу несколько новостей — хорошая и не очень.
# relations = "Model_hasAuthor_Organization 0 0"
1	С O
2	моделью B-Model
3	от O
4	OpenAI B-Organization
5	связано O
6	сразу O
7	несколько O
8	новостей O
9	— O
10	хорошая O
11	и O
12	не O
13	очень O
14	. O

# sent_id = 701
# text =  Сделка OpenAI и Microsoft.
# relations = ""
1	Сделка O
2	OpenAI B-Organization
3	и O
4	Microsoft B-Organization
5	. O

# sent_id = 702
# text =  Начать придется с менее приятной — компания Майкрософт завладела эксклюзивными правами на GPT-3.
# relations = ""
1	Начать O
2	придется O
3	с O
4	менее O
5	приятной O
6	— O
7	компания O
8	Майкрософт B-Organization
9	завладела O
10	эксклюзивными O
11	правами O
12	на O
13	GPT-3 B-Model
14	. O

# sent_id = 703
# text =   Сделка предсказуемо вызвала негодование — Элон Маск, основатель OpenAI, а ныне бывший член совета директоров компании, заявил, что Майкрософт по сути захватили OpenAI.
# relations = ""
1	Сделка O
2	предсказуемо O
3	вызвала O
4	негодование O
5	— O
6	Элон B-Person
7	Маск I-Person
8	, O
9	основатель O
10	OpenAI B-Organization
11	, O
12	а O
13	ныне O
14	бывший O
15	член O
16	совета O
17	директоров O
18	компании O
19	, O
20	заявил O
21	, O
22	что O
23	Майкрософт B-Organization
24	по O
25	сути O
26	захватили O
27	OpenAI B-Organization
28	. O

# sent_id = 704
# text =   Дело в том, что OpenAI изначально создавалась как некоммерческая организация с высокой миссией — не позволить искусственному интеллекту оказаться в руках отдельного государства или корпорации.
# relations = ""
1	Дело O
2	в O
3	том O
4	, O
5	что O
6	OpenAI B-Organization
7	изначально O
8	создавалась O
9	как O
10	некоммерческая O
11	организация O
12	с O
13	высокой O
14	миссией O
15	— O
16	не O
17	позволить O
18	искусственному B-Object
19	интеллекту I-Object
20	оказаться O
21	в O
22	руках O
23	отдельного O
24	государства O
25	или O
26	корпорации O
27	. O

# sent_id = 705
# text =   ruGPT3 от Сбера.
# relations = "Model_hasAuthor_Organization 0 0"
1	ruGPT3 B-Model
2	от B-Model_hasAuthor_Organization
3	Сбера B-Organization
4	. O

# sent_id = 706
# text =  Теперь к более приятной новости — исследователи из Сбера выложили в открытый доступ модель, которая повторяет архитектуру GPT-3 и основана на коде GPT-2 и, самое главное, обучена на русскоязычном корпусе.
# relations = "Model_isTrainedOn_Corpus 0 0"
1	Теперь O
2	к O
3	более O
4	приятной O
5	новости O
6	— O
7	исследователи O
8	из O
9	Сбера B-Organization
10	выложили O
11	в O
12	открытый O
13	доступ O
14	модель B-Model
15	, O
16	которая O
17	повторяет O
18	архитектуру O
19	GPT-3 B-Model
20	и O
21	основана O
22	на O
23	коде O
24	GPT-2 B-Model
25	и O
26	, O
27	самое O
28	главное O
29	, O
30	обучена B-Model_isTrainedOn_Corpus
31	на B-Model_isTrainedOn_Corpus
32	русскоязычном B-Lang
33	корпусе B-Corpus
34	. O

# sent_id = 707
# text =   Если коммерческие организации можно оправдать тем, что код часто вплетен в инфраструктуру проектов, то что говорить про исследовательские институты и некоммерческие компании вроде DeepMind и OpenAI?
# relations = ""
1	Если O
2	коммерческие O
3	организации O
4	можно O
5	оправдать O
6	тем O
7	, O
8	что O
9	код O
10	часто O
11	вплетен O
12	в O
13	инфраструктуру O
14	проектов O
15	, O
16	то O
17	что O
18	говорить O
19	про O
20	исследовательские O
21	институты O
22	и O
23	некоммерческие O
24	компании O
25	вроде O
26	DeepMind B-Organization
27	и O
28	OpenAI B-Organization
29	? O

# sent_id = 708
# text =   Платформа для видеозвонков Maxine объединяет в себе целый зоопарк ML-алгоритмов.
# relations = "Method_isUsedIn_Application 0 0"
1	Платформа O
2	для O
3	видеозвонков O
4	Maxine B-Technology
5	объединяет B-Method_isUsedIn_Application
6	в I-Method_isUsedIn_Application
7	себе I-Method_isUsedIn_Application
8	целый O
9	зоопарк O
10	ML B-Method
11	- I-Method
12	алгоритмов I-Method
13	. O

# sent_id = 709
# text = Maxine, платформа для видеозвонков, включает в себя разнообразные алгоритмы машинного обучения.
# relations = "Method_isUsedIn_Application 0 0"
1	Maxine B-Technology
2	, O
3	платформа O
4	для O
5	видеозвонков O
6	, O
7	включает B-Method_isUsedIn_Application
8	в I-Method_isUsedIn_Application
9	себя I-Method_isUsedIn_Application
10	разнообразные O
11	алгоритмы B-Method
12	машинного I-Method
13	обучения I-Method
14	. O

# sent_id = 710
# text =   Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).
# relations = "Library_isAppliedTo_Object 0 0, Method_hasAuthor_Organization 0 0, Library_hasAuthor_Organization 0 1, Method_isAppliedTo_Object 0 0"
1	Google B-Organization
2	Meet I-Organization
3	поделились O
4	кейсом O
5	создания B-Method_hasAuthor_Organization
6	своего O
7	алгоритма B-Method
8	для I-Method
9	качественного I-Method
10	удаления I-Method
11	фона B-Object
12	на O
13	основе O
14	фреймворка B-Library
15	от O
16	Mediapipe B-Organization
17	( O
18	который O
19	умеет O
20	отслеживание O
21	движение O
22	глаз O
23	, O
24	головы O
25	и O
26	рук O
27	) O
28	. O

# sent_id = 711
# text =   Google также запустил новую функцию для сервиса YouTube Stories на iOS, который позволяет улучшать качество речи.
# relations = "Environment_isUsedIn_Application 0 0"
1	Google B-Organization
2	также O
3	запустил O
4	новую O
5	функцию O
6	для O
7	сервиса O
8	YouTube B-Technology
9	Stories I-Technology
10	на B-Environment_isUsedIn_Application
11	iOS B-Environment
12	, O
13	который O
14	позволяет O
15	улучшать O
16	качество O
17	речи B-Object
18	. O

# sent_id = 712
# text =   Для решения этой проблемы требуется архитектура, которая позволяет GPT-3 анализировать содержание письма и оценивать, какая информация актуальна для ответа.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1"
1	Для O
2	решения O
3	этой O
4	проблемы O
5	требуется O
6	архитектура O
7	, O
8	которая O
9	позволяет O
10	GPT-3 B-Model
11	анализировать B-Task
12	содержание I-Task
13	письма I-Task
14	и O
15	оценивать B-Task
16	, I-Task
17	какая I-Task
18	информация I-Task
19	актуальна I-Task
20	для O
21	ответа O
22	. O

# sent_id = 713
# text =   OpenAI представила модель машинного обучения GPT-3, обученную на 175 млрд параметров, в июне 2020 года.
# relations = "Date_isDateOf_Model 0 0, Model_hasAuthor_Organization 0 0"
1	OpenAI B-Organization
2	представила B-Model_hasAuthor_Organization
3	модель O
4	машинного O
5	обучения O
6	GPT-3 B-Model
7	, O
8	обученную O
9	на O
10	175 O
11	млрд O
12	параметров O
13	, O
14	в O
15	июне B-Date
16	2020 I-Date
17	года I-Date
18	. O

# sent_id = 714
# text = В июне 2020 года OpenAI представила модель машинного обучения GPT-3, обученную на 175 миллиардах параметров.
# relations = "Date_isDateOf_Model 0 0, Model_hasAuthor_Organization 0 0"
1	В O
2	июне B-Date
3	2020 I-Date
4	года I-Date
5	OpenAI B-Organization
6	представила B-Model_hasAuthor_Organization
7	модель O
8	машинного O
9	обучения O
10	GPT B-Model
11	- I-Model
12	3 I-Model
13	, O
14	обученную O
15	на O
16	175 O
17	миллиардах O
18	параметров O
19	. O

# sent_id = 715
# text =   В отличие от предшественников GPT-2 и GPT-1 ее исходный код или обучающий набор данных решили не открывать.
# relations = ""
1	В O
2	отличие O
3	от O
4	предшественников O
5	GPT-2 B-Model
6	и O
7	GPT-1 B-Model
8	ее O
9	исходный O
10	код O
11	или O
12	обучающий O
13	набор O
14	данных O
15	решили O
16	не O
17	открывать O
18	. O

# sent_id = 716
# text =   Модель уже попытались применить в медицинской сфере для общения с пациентами, но результаты эксперимента оказались неутешительными.
# relations = "Model_isUsedIn_Science 0 0"
1	Модель B-Model
2	уже O
3	попытались B-Method_isUsedIn_Science
4	применить I-Method_isUsedIn_Science
5	в O
6	медицинской B-Science
7	сфере I-Science
8	для O
9	общения O
10	с O
11	пациентами O
12	, O
13	но O
14	результаты O
15	эксперимента B-Activity
16	оказались O
17	неутешительными O
18	. O

# sent_id = 717
# text =  Между тем создатели проекта GPT-Neo от EleutherAI решили воссоздать аналог GPT-3, но с открытым исходным кодом.
# relations = "Activity_hasAuthor_Organization 0 0"
1	Между O
2	тем O
3	создатели O
4	проекта O
5	GPT B-Activity
6	- I-Activity
7	Neo I-Activity
8	от B-Activity_hasAuthor_Organization
9	EleutherAI B-Organization
10	решили O
11	воссоздать O
12	аналог O
13	GPT-3 B-Model
14	, O
15	но O
16	с O
17	открытым O
18	исходным O
19	кодом O
20	. O

# sent_id = 718
# text =  Тем временем, разработчики проекта GPT-Neo от EleutherAI решили разработать свой аналог GPT-3 с открытым исходным кодом.
# relations = "Activity_hasAuthor_Organization 0 0"
1	Тем O
2	временем O
3	, O
4	разработчики O
5	проекта O
6	GPT B-Activity
7	- I-Activity
8	Neo I-Activity 
9	от B-Activity_hasAuthor_Organization
10	EleutherAI B-Organization
11	решили O
12	разработать O
13	свой O
14	аналог O
15	GPT-3 B-Model
16	с O
17	открытым O
18	исходным O
19	кодом O
20	. O

# sent_id = 719
# text =   Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.
# relations = "Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 1 1, Application_isUsedForSolving_Task 2 2"
1	Однако O
2	только O
3	сейчас O
4	мы O
5	немного O
6	приблизились O
7	к O
8	сюжетам O
9	фантастических O
10	фильмов O
11	: O
12	можем O
13	попросить O
14	Алису B-Application
15	убавить B-Task
16	громкость I-Task
17	, O
18	Google B-Application
19	Assistant I-Application
20	— O
21	заказать B-Task
22	такси I-Task
23	или O
24	Siri B-Application
25	— O
26	завести B-Task
27	будильник I-Task
28	. O

# sent_id = 720
# text =   Технологии языкового процессинга востребованы в разработках, связанных с построением искусственного интеллекта: в поисковых системах, для извлечения фактов, оценки тональности текста, машинного перевода и диалога.
# relations = "Method_isUsedIn_Application 0 0, Method_solves_Task 0 0, Method_solves_Task 0 1, Method_isUsedIn_Science 0 0"
1	Технологии B-Method
2	языкового I-Method
3	процессинга I-Method
4	востребованы B-Method_isUsedIn_Application
5	в I-Method_isUsedIn_Application
6	разработках O
7	, O
8	связанных O
9	с O
10	построением O
11	искусственного O
12	интеллекта O
13	: O
14	в O
15	поисковых B-Application
16	системах I-Application
17	, O
18	для O
19	извлечения B-Task
20	фактов I-Task
21	, O
22	оценки B-Task
23	тональности I-Task
24	текста I-Task
25	, O
26	машинного B-Science
27	перевода I-Science
28	и O
29	диалога O
30	. O

# sent_id = 721
# text = Технологии обработки естественного языка широко используются в разработках, связанных с созданием искусственного интеллекта, включая применение в поисковых системах и машинном переводе.
# relations = "Method_isUsedIn_Application 0 0, Method_isUsedIn_Science 0 0"
1	Технологии B-Method
2	обработки I-Method
3	естественного I-Method
4	языка I-Method
5	широко O
6	используются O
7	в O
8	разработках O
9	, O
10	связанных O
11	с O
12	созданием O
13	искусственного O
14	интеллекта O
15	, O
16	включая O
17	применение B-Method_isUsedIn_Application
18	в I-Method_isUsedIn_Application
19	поисковых B-Application
20	системах I-Application
21	и O
22	машинном B-Science
23	переводе I-Science
24	. O

# sent_id = 722
# text =   Первые разговоры об обработке естественного языка компьютером начались еще в 30-е годы XX-го века с философских рассуждений Айера — он предлагал отличать разумного человека от глупой машины с помощью эмпирического теста.
# relations = ""
1	Первые O
2	разговоры O
3	об O
4	обработке B-Task
5	естественного I-Task
6	языка I-Task
7	компьютером O
8	начались O
9	еще O
10	в O
11	30-е B-Date
12	годы I-Date
13	XX I-Date
14	- I-Date
15	го I-Date
16	века I-Date
17	с O
18	философских O
19	рассуждений O
20	Айера B-Person
21	— O
22	он O
23	предлагал O
24	отличать O
25	разумного O
26	человека O
27	от O
28	глупой O
29	машины O
30	с O
31	помощью O
32	эмпирического O
33	теста O
34	. O

# sent_id = 723
# text =   В 1950 году Алан Тьюринг в философском журнале Mind предложил такой тест, где судья должен определить, с кем он ведет диалог: с человеком или компьютером.
# relations = "Date_isDateOf_Method 0 0, Method_hasAuthor_Person 0 0"
1	В O
2	1950 B-Date
3	году O
4	Алан B-Person
5	Тьюринг I-Person
6	в O
7	философском O
8	журнале O
9	Mind B-InfoResource
10	предложил O
11	такой O
12	тест B-Method
13	, O
14	где O
15	судья O
16	должен O
17	определить O
18	, O
19	с O
20	кем O
21	он O
22	ведет O
23	диалог O
24	: O
25	с O
26	человеком O
27	или O
28	компьютером O
29	. O

# sent_id = 724
# text =   В 1950 году Алан Тьюринг предложил такой тест в философском журнале "Mind", в котором судье необходимо определить, ведет ли он диалог с человеком или с компьютером.
# relations = "Date_isDateOf_Method 0 0, Method_hasAuthor_Person 0 0"
1	В O
2	1950 B-Date
3	году O
4	Алан B-Person
5	Тьюринг I-Person
6	предложил O
7	такой O
8	тест B-Method
9	в O
10	философском O
11	журнале O
12	" O
13	Mind B-InfoResource
14	" O
15	, O
16	в O
17	котором O
18	судье O
19	необходимо O
20	определить O
21	, O
22	ведет O
23	ли O
24	он O
25	диалог O
26	с O
27	человеком O
28	или O
29	с O
30	компьютером O
31	. O

# sent_id = 725
# text =   В 1954 году Джорджтаунский университет совместно с компанией IBM продемонстрировали программу машинного перевода с русского на английский, которая работала на базе словаря из 250 слов и набора из 6 грамматических правил.
# relations = "Date_isDateOf_Application 0 0, Application_hasAuthor_Organization 0 0, Application_hasAuthor_Organization 0 1"
1	В O
2	1954 B-Date
3	году O
4	Джорджтаунский B-Organization
5	университет I-Organization
6	совместно O
7	с O
8	компанией O
9	IBM B-Organization
10	продемонстрировали B-Application_hasAuthor_Organization
11	программу B-Application
12	машинного I-Application
13	перевода I-Application
14	с O
15	русского B-Lang
16	на O
17	английский B-Lang
18	, O
19	которая O
20	работала O
21	на O
22	базе O
23	словаря O
24	из O
25	250 O
26	слов O
27	и O
28	набора O
29	из O
30	6 O
31	грамматических O
32	правил O
33	. O

# sent_id = 726
# text =   Параллельно с попытками научить компьютер переводить текст, ученые и целые университеты думали над созданием робота, способного имитировать речевое поведение человека.
# relations = ""
1	Параллельно O
2	с O
3	попытками O
4	научить O
5	компьютер O
6	переводить O
7	текст O
8	, O
9	ученые O
10	и O
11	целые O
12	университеты O
13	думали O
14	над O
15	созданием O
16	робота O
17	, O
18	способного O
19	имитировать B-Task
20	речевое I-Task
21	поведение I-Task
22	человека I-Task
23	. O

# sent_id = 727
# text =   Первой успешной реализацией чат-бота стал виртуальный собеседник ELIZA, написанный в 1966 году Джозефом Вейценбаумом.
# relations = "Date_isDateOf_Application 0 1, Application_hasAuthor_Person 1 0"
1	Первой O
2	успешной O
3	реализацией O
4	чат O
5	- O
6	бота O
7	стал O
8	виртуальный B-Technology
9	собеседник I-Technology
10	ELIZA B-Technology
11	, O
12	написанный O
13	в O
14	1966 B-Date
15	году I-Date
16	Джозефом B-Person
17	Вейценбаумом I-Person
18	. O

# sent_id = 728
# text =   Элиза пародировала поведение психотерапевта, выделяя значимые слова из фразы собеседника и задавая встречный вопрос.
# relations = ""
1	Элиза B-Technology
2	пародировала O
3	поведение O
4	психотерапевта O
5	, O
6	выделяя O
7	значимые O
8	слова O
9	из O
10	фразы O
11	собеседника O
12	и O
13	задавая O
14	встречный O
15	вопрос O
16	. O

# sent_id = 729
# text =   Можно считать, что это был первый чат-бот, построенный на правилах (rule-based bot), и он положил начало целому классу таких систем.
# relations = ""
1	Можно O
2	считать O
3	, O
4	что O
5	это O
6	был O
7	первый O
8	чат B-Application
9	- I-Application
10	бот I-Application
11	, O
12	построенный O
13	на O
14	правилах O
15	( O
16	rule B-Application
17	- I-Application
18	based I-Application
19	bot I-Application
20	) O
21	, O
22	и O
23	он O
24	положил O
25	начало O
26	целому O
27	классу O
28	таких O
29	систем O
30	. O

# sent_id = 730
# text =   Без Элизы не появились бы такие программы-собеседники, как Cleverbot, WeChat Xiaoice, Eugene Goostman — формально прошедший тест Тьюринга в 2014 году, — и даже Siri, Jarvis и Alexa.
# relations = ""
1	Без O
2	Элизы B-Technology
3	не O
4	появились O
5	бы O
6	такие O
7	программы O
8	- O
9	собеседники O
10	, O
11	как O
12	Cleverbot B-Technology
13	, O
14	WeChat B-Technology
15	Xiaoice I-Technology
16	, O
17	Eugene B-Technology
18	Goostman I-Technology
19	— O
20	формально O
21	прошедший O
22	тест B-Method
23	Тьюринга I-Method
24	в O
25	2014 B-Date
26	году O
27	, O
28	— O
29	и O
30	даже O
31	Siri B-Application
32	, O
33	Jarvis B-Application
34	и O
35	Alexa B-Application
36	. O

# sent_id = 731
# text =   В 1968 году Терри Виноградом на языке LISP была разработана программа SHRDLU.
# relations = "Environment_isUsedIn_Application 0 0, Date_isDateOf_Application 0 0, Application_hasAuthor_Person 0 0"
1	В O
2	1968 B-Date
3	году O
4	Терри B-Person
5	Виноградом I-Person
6	на O
7	языке O
8	LISP B-Environment
9	была O
10	разработана O
11	программа O
12	SHRDLU B-Technology
13	. O

# sent_id = 732
# text =   Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).
# relations = "Method_isUsedIn_Application 1 0, Method_isUsedIn_Application 2 0, Method_hasAuthor_Person 1 0, Method_hasAuthor_Person 2 0, Application_hasAuthor_Person 0 0, Method_isAlternativeNameFor_Method 2 1"
1	Следующим O
2	шагом O
3	в O
4	развитии O
5	чат O
6	- O
7	ботов O
8	стала O
9	программа O
10	A.L.I.C.E. B-Application
11	, O
12	для O
13	которой O
14	Ричард B-Person
15	Уоллес I-Person
16	разработал O
17	специальный O
18	язык O
19	разметки B-Method
20	— O
21	AIML B-Method
22	( O
23	англ O
24	. O
25	Artificial B-Method
26	Intelligence I-Method
27	Markup I-Method
28	Language I-Method
29	) O
30	. O

# sent_id = 733
# text =   Разговоры о нейронных сетях и глубоком обучении ходили уже в 90-е годы, а первый нейрокомпьютер «Марк-1» появился вообще в 1958 году.
# relations = "Date_isDateOf_Application 0 1, Date_isDateOf_Application 0 0"
1	Разговоры O
2	о O
3	нейронных B-Method
4	сетях I-Method
5	и O
6	глубоком O
7	обучении O
8	ходили O
9	уже O
10	в O
11	90-е O
12	годы O
13	, O
14	а O
15	первый O
16	нейрокомпьютер B-Application
17	« O
18	Марк-1 B-Application
19	» O
20	появился O
21	вообще O
22	в O
23	1958 B-Date
24	году I-Date
25	. O

# sent_id = 734
# text =   1970 г. Машинный перевод на основе правил (англ. RBMT) был первой попыткой научить машину переводить.
# relations = "Date_isDateOf_Method 0 0, Date_isDateOf_Method 0 1, Method_isAlternativeNameFor_Method 1 0"
1	1970 B-Date
2	г. I-Date
3	Машинный B-Method
4	перевод I-Method
5	на I-Method
6	основе I-Method
7	правил I-Method
8	( O
9	англ O
10	RBMT B-Method
11	. O
12	) O
13	был O
14	первой O
15	попыткой O
16	научить O
17	машину O
18	переводить O
19	. O

# sent_id = 735
# text =   1984 г. Машинный перевод на основе примеров (англ. EBMT) был способен переводить даже совсем не похожие друг на друга языки, где задавать какие-то правила было бесполезно.
# relations = "Date_isDateOf_Method 0 0, Date_isDateOf_Method 0 1, Method_isAlternativeNameFor_Method 1 0"
1	1984 B-Date
2	г. I-Date
3	Машинный B-Method
4	перевод I-Method
5	на I-Method
6	основе I-Method
7	примеров I-Method
8	( O
9	англ O
10	. O
11	EBMT B-Method
12	) O
13	был O
14	способен O
15	переводить O
16	даже O
17	совсем O
18	не O
19	похожие O
20	друг O
21	на O
22	друга O
23	языки O
24	, O
25	где O
26	задавать O
27	какие O
28	- O
29	то O
30	правила O
31	было O
32	бесполезно O
33	. O

# sent_id = 736
# text =   1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.
# relations = "Date_isDateOf_Method 0 0, Date_isDateOf_Method 0 1, Method_isAlternativeNameFor_Method 1 0, Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 1 0"
1	1990 B-Date
2	г. I-Date
3	Статистический B-Method
4	машинный I-Method
5	перевод I-Method
6	( O
7	англ O
8	. O
9	SMT B-Method
10	) O
11	в O
12	эпоху O
13	развития O
14	интернета O
15	позволил O
16	использовать O
17	не O
18	только O
19	готовые O
20	языковые B-Object
21	корпуса I-Object
22	, O
23	но O
24	даже O
25	книги O
26	и O
27	вольно O
28	переведенные O
29	статьи O
30	. O

# sent_id = 737
# text =   Статистические методы и сейчас активно используются в языковом процессинге.
# relations = ""
1	Статистические B-Method
2	методы I-Method
3	и O
4	сейчас O
5	активно O
6	используются O
7	в O
8	языковом B-Method
9	процессинге I-Method
10	. O

# sent_id = 738
# text =   По мере развития обработки естественного языка множество задач решалось классическими статистическими методами и множеством правил, однако проблему нечеткости и неоднозначности в языке это не решало.
# relations = "Method_solves_Task 0 0"
1	По O
2	мере O
3	развития O
4	обработки B-Task
5	естественного I-Task
6	языка I-Task
7	множество O
8	задач O
9	решалось B-Method_solves_Task
10	классическими O
11	статистическими B-Method
12	методами I-Method
13	и O
14	множеством O
15	правил O
16	, O
17	однако O
18	проблему B-Task
19	нечеткости I-Task
20	и I-Task
21	неоднозначности I-Task
22	в O
23	языке O
24	это O
25	не O
26	решало O
27	. O

# sent_id = 739
# text =   Так родился статистический метод анализа текста word2vec (англ. Word to vector).
# relations = "Method_includes_Method 0 1, Method_isAlternativeNameFor_Method 2 1"
1	Так O
2	родился O
3	статистический B-Method
4	метод I-Method
5	анализа I-Method
6	текста I-Method
7	word2vec B-Method
8	( O
9	англ O
10	. O
11	Word B-Method
12	to I-Method
13	vector I-Method
14	) O
15	. O

# sent_id = 740
# text =   Под эти критерии отлично подходит рекуррентная нейронная сеть (RNN), однако по мере увеличения расстояния между связанными частями текста необходимо увеличивать и размер RNN, из-за чего падает качество обработки информации.
# relations = "Method_isAlternativeNameFor_Method 1 0, Method_isAlternativeNameFor_Method 2 0"
1	Под O
2	эти O
3	критерии O
4	отлично O
5	подходит O
6	рекуррентная B-Method
7	нейронная I-Method
8	сеть I-Method
9	( O
10	RNN B-Method
11	) O
12	, O
13	однако O
14	по O
15	мере O
16	увеличения O
17	расстояния O
18	между O
19	связанными O
20	частями O
21	текста O
22	необходимо O
23	увеличивать O
24	и O
25	размер O
26	RNN B-Method
27	, O
28	из O
29	- O
30	за O
31	чего O
32	падает O
33	качество O
34	обработки O
35	информации O
36	. O

# sent_id = 741
# text =   Эту проблему решает сеть LSTM (англ. Long short-term memory).
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Эту O
2	проблему O
3	решает O
4	сеть O
5	LSTM B-Method
6	( O
7	англ O
8	. O
9	Long B-Method
10	short I-Method
11	- I-Method
12	term I-Method
13	memory I-Method
14	) O
15	. O

# sent_id = 742
# text =   Если говорить о языке Python, который часто используется для анализа данных, то это NLTK и Spacy.
# relations = ""
1	Если O
2	говорить O
3	о O
4	языке O
5	Python B-Environment
6	, O
7	который O
8	часто O
9	используется O
10	для O
11	анализа B-Method
12	данных I-Method
13	, O
14	то O
15	это O
16	NLTK B-Application
17	и O
18	Spacy B-Application
19	. O

# sent_id = 743
# text =   Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.
# relations = "Library_isUsedIn_Science 0 0, Library_isUsedIn_Science 1 0, Library_hasAuthor_Organization 0 0, Library_hasAuthor_Organization 1 1, Library_hasAuthor_Organization 1 2"
1	Крупные O
2	компании O
3	также O
4	принимают O
5	участие O
6	в O
7	разработке O
8	библиотек O
9	для O
10	NLP B-Science
11	, O
12	как O
13	например O
14	NLP B-Library
15	Architect I-Library
16	от B-Application_hasAuthor_Organization
17	Intel B-Organization
18	или O
19	PyTorch B-Library
20	от B-Application_hasAuthor_Organization
21	исследователей I-Application_hasAuthor_Organization
22	из I-Application_hasAuthor_Organization
23	Facebook B-Organization
24	и O
25	Uber B-Organization
26	. O

# sent_id = 744
# text =   Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.
# relations = "Library_isUsedIn_Science 0 0, Library_isUsedIn_Science 1 0, Library_hasAuthor_Organization 0 0, Library_hasAuthor_Organization 1 1, Library_hasAuthor_Organization 1 2"
1	Большие O
2	компании O
3	также O
4	активно O
5	участвуют O
6	в O
7	разработке O
8	библиотек O
9	для B-Application_isUsedIn_Science
10	обработки B-Science
11	естественного I-Science
12	языка I-Science
13	, O
14	таких O
15	как O
16	NLP B-Library
17	Architect I-Library
18	от B-Application_hasAuthor_Organization
19	Intel B-Organization
20	и O
21	PyTorch B-Library
22	от B-Application_hasAuthor_Organization
23	исследователей I-Application_hasAuthor_Organization
24	из I-Application_hasAuthor_Organization
25	Facebook B-Organization
26	и O
27	Uber B-Organization
28	. O

# sent_id = 745
# text =   Направление b2c не единственное, где можно применять чат-ботов.
# relations = ""
1	Направление O
2	b2c B-Science
3	не O
4	единственное O
5	, O
6	где O
7	можно O
8	применять O
9	чат O
10	- O
11	ботов O
12	. O

# sent_id = 746
# text =   Прорывы #DeepPavlov в 2019 году: обзор и итоги года Московский физико-технический институт (МФТИ).
# relations = "Organization_isAlternativeNameFor_Organization 1 0, Model_hasAuthor_Organization 0 0, Model_hasAuthor_Organization 0 1, Date_isDateOf_Model 0 0"
1	Прорывы O
# O
2	DeepPavlov B-Model
3	в O
4	2019 B-Date
5	году O
6	: O
7	обзор O
8	и O
9	итоги O
10	года O
11	Московский B-Organization
12	физико I-Organization
13	- I-Organization
14	технический I-Organization
15	институт I-Organization
16	( O
17	МФТИ B-Organization
18	) O
19	. O

# sent_id = 747
# text = Модель DeepPavlov была разработана командой из Московского физико-технического института (МФТИ).
# relations = "Organization_isAlternativeNameFor_Organization 1 0, Model_hasAuthor_Organization 0 1, Model_hasAuthor_Organization 0 0"
1	Модель O
2	DeepPavlov B-Model
3	была B-Model_hasAuthor_Organization
4	разработана I-Model_hasAuthor_Organization
5	командой O
6	из O
7	Московского B-Organization
8	физико-технического I-Organization
9	института I-Organization
10	( O
11	МФТИ B-Organization
12	) O
13	. O

# sent_id = 748
# text = Команда исследователей из Московского физико-технического института (МФТИ) представила модель DeepPavlov.
# relations = "Organization_isAlternativeNameFor_Organization 1 0, Model_hasAuthor_Organization 0 1, Model_hasAuthor_Organization 0 0"
1	Команда O
2	исследователей O
3	из O
4	Московского B-Organization
5	физико-технического I-Organization
6	института I-Organization
7	( O
8	МФТИ B-Organization
9	) O
10	представила B-Model_hasAuthor_Organization
11	модель O
12	DeepPavlov B-Model
13	. O

# sent_id = 749
# text =   Библиотеке #DeepPavlov, на минуточку, уже два года, и мы рады, что наше сообщество с каждым днем растет.
# relations = ""
1	Библиотеке O
# O
2	DeepPavlov B-Library
3	, O
4	на O
5	минуточку O
6	, O
7	уже O
8	два O
9	года O
10	, O
11	и O
12	мы O
13	рады O
14	, O
15	что O
16	наше O
17	сообщество O
18	с O
19	каждым O
20	днем O
21	растет O
22	. O

# sent_id = 750
# text =   Увеличилось количество коммерческих решений за счет state-of-art технологий, реализованных в DeepPavlov, в разных отраслях от ритейла до промышленности.
# relations = ""
1	Увеличилось O
2	количество O
3	коммерческих O
4	решений O
5	за O
6	счет O
7	state B-Method
8	- I-Method
9	of I-Method
10	- I-Method
11	art I-Method
12	технологий O
13	, O
14	реализованных O
15	в O
16	DeepPavlov B-Library
17	, O
18	в O
19	разных O
20	отраслях O
21	от O
22	ритейла O
23	до O
24	промышленности O
25	. O

# sent_id = 751
# text =   Вышел первый релиз DeepPavlov Agent.
# relations = ""
1	Вышел O
2	первый O
3	релиз O
4	DeepPavlov B-Application
5	Agent I-Application
6	. O

# sent_id = 752
# text =   DeepPavlov решает проблемы такие как: классификация текста, исправление опечаток, распознавание именованных сущностей, ответы на вопросы по базе знаний и многие другие.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1, Model_isUsedForSolving_Task 0 2, Model_isUsedForSolving_Task 0 3"
1	DeepPavlov B-Model
2	решает B-Model_isUsedForSolving_Task
3	проблемы I-Model_isUsedForSolving_Task
4	такие O
5	как O
6	: O
7	классификация B-Task
8	текста I-Task
9	, O
10	исправление B-Task
11	опечаток I-Task
12	, O
13	распознавание B-Task
14	именованных I-Task
15	сущностей I-Task
16	, O
17	ответы B-Task
18	на I-Task
19	вопросы I-Task
20	по O
21	базе O
22	знаний O
23	и O
24	многие O
25	другие O
26	. O

# sent_id = 753
# text =   Библиотека поддерживает платформы Linux и Windows.
# relations = "Environment_isUsedIn_Library 0 0, Environment_isUsedIn_Library 1 0"
1	Библиотека B-Library
2	поддерживает B-Environment_isUsedIn_Application
3	платформы I-Environment_isUsedIn_Application
4	Linux B-Environment
5	и O
6	Windows B-Environment
7	. O

# sent_id = 754
# text =   В настоящее время современные результаты во многих задачах были достигнуты благодаря применению моделей на основе BERT.
# relations = ""
1	В O
2	настоящее O
3	время O
4	современные O
5	результаты O
6	во O
7	многих O
8	задачах O
9	были O
10	достигнуты O
11	благодаря O
12	применению O
13	моделей O
14	на O
15	основе O
16	BERT B-Model
17	. O

# sent_id = 755
# text =   Команда DeepPavlov интегрировала BERT в три последующие задачи: классификация текста, распознавание именованных сущностей и ответы на вопросы.
# relations = "Model_isUsedInSolving_Task 0 0, Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1, Model_isUsedForSolving_Task 0 2"
1	Команда O
2	DeepPavlov B-Organization
3	интегрировала O
4	BERT B-Model
5	в O
6	три O
7	последующие O
8	задачи O
9	: O
10	классификация B-Task
11	текста I-Task
12	, O
13	распознавание B-Task
14	именованных I-Task
15	сущностей I-Task
16	и O
17	ответы B-Task
18	на I-Task
19	вопросы I-Task
20	. O

# sent_id = 756
# text =   Модель классификации текста на основе BERT DeepPavlov служит, например, для решения проблемы обнаружения оскорблений.
# relations = "Model_isUsedForSolving_Task 0 0"
1	Модель O
2	классификации O
3	текста O
4	на O
5	основе O
6	BERT B-Model
7	DeepPavlov I-Model
8	служит O
9	, O
10	например O
11	, O
12	для O
13	решения O
14	проблемы O
15	обнаружения B-Task
16	оскорблений I-Task
17	. O

# sent_id = 757
# text =   В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).
# relations = "Library_isUsedForSolving_Task 0 0, Library_isUsedForSolving_Task 0 1, Library_isUsedForSolving_Task 0 2, Model_isUsedForSolving_Task 0 0, Model_isIncludedIn_Library 0 0, Task_isAlternativeNameFor_Task 2 1, Model_isUsedForSolving_Task 0 1, Model_isUsedForSolving_Task 0 0"
1	В O
2	дополнение O
3	к O
4	моделям O
5	классификации B-Task
6	текста I-Task
7	DeepPavlov B-Library
8	содержит O
9	модель O
10	на B-Model_isModificationOf_Model
11	основе I-Model_isModificationOf_Model
12	BERT B-Model
13	для O
14	распознавания B-Task
15	именованных I-Task
16	сущностей I-Task
17	( O
18	NER B-Task
19	) O
20	. O

# sent_id = 758
# text =   Например, модель может извлечь важную информацию из резюме, чтобы облегчить работу специалистов по кадрам.
# relations = "Model_isUsedForSolving_Task 0 0"
1	Например O
2	, O
3	модель B-Model
4	может O
5	извлечь B-Task
6	важную I-Task
7	информацию I-Task
8	из O
9	резюме O
10	, O
11	чтобы O
12	облегчить O
13	работу O
14	специалистов O
15	по O
16	кадрам O
17	. O

# sent_id = 759
# text =   Кроме того, NER может использоваться для идентификации соответствующих объектов в запросах клиентов, таких как спецификации продуктов, названия компаний или данные о филиалах компании.
# relations = ""
1	Кроме O
2	того O
3	, O
4	NER B-Task
5	может O
6	использоваться O
7	для O
8	идентификации B-Task
9	соответствующих I-Task
10	объектов I-Task
11	в O
12	запросах O
13	клиентов O
14	, O
15	таких O
16	как O
17	спецификации O
18	продуктов O
19	, O
20	названия O
21	компаний O
22	или O
23	данные O
24	о O
25	филиалах O
26	компании O
27	. O

# sent_id = 760
# text =   Команда DeepPavlov обучила модель NER на англоязычном корпусе OntoNotes, который имеет 19 типов разметки, включая PER (человек), LOC (местоположение), ORG (организация) и многие другие.
# relations = "Model_isTrainedOn_Corpus 0 0, Model_hasAuthor_Organization 0 0"
1	Команда O
2	DeepPavlov B-Organization
3	обучила B-Model_isTrainedOn_Corpus
4	модель B-Model
5	NER I-Model
6	на O
7	англоязычном O
8	корпусе O
9	OntoNotes B-Corpus
10	, O
11	который O
12	имеет O
13	19 O
14	типов O
15	разметки B-Method
16	, O
17	включая O
18	PER O
19	( O
20	человек O
21	) O
22	, O
23	LOC O
24	( O
25	местоположение O
26	) O
27	, O
28	ORG O
29	( O
30	организация O
31	) O
32	и O
33	многие O
34	другие O
35	. O

# sent_id = 761
# text =   Одним из основных переломных моментов в этой области стал выпуск Стэнфордского набора данных для ответов на вопросы (SQuAD).
# relations = ""
1	Одним O
2	из O
3	основных O
4	переломных O
5	моментов O
6	в O
7	этой O
8	области O
9	стал O
10	выпуск O
11	Стэнфордского B-InfoResource
12	набора I-InfoResource
13	данных I-InfoResource
14	для I-InfoResource
15	ответов I-InfoResource
16	на I-InfoResource
17	вопросы I-InfoResource
18	( O
19	SQuAD B-InfoResource
20	) O
21	. O

# sent_id = 762
# text =   Недавно был выпущен Стэнфордский набор данных для ответов на вопросы (SQuAD).
# relations = ""
1	Недавно O
2	был O
3	выпущен O
4	Стэнфордский B-InfoResource
5	набор I-InfoResource
6	данных I-InfoResource
7	для I-InfoResource
8	ответов I-InfoResource
9	на I-InfoResource
10	вопросы I-InfoResource
11	( O
12	SQuAD B-InfoResource
13	) O
14	. O

# sent_id = 763
# text =   Набор данных SQuAD привел к появлению бесчисленных подходов к решению задачи вопросно-ответных систем.
# relations = "Method_solves_Task 0 0"
1	Набор O
2	данных O
3	SQuAD B-InfoResource
4	привел O
5	к O
6	появлению O
7	бесчисленных O
8	подходов B-Method
9	к O
10	решению B-Method_solves_Task
11	задачи B-Task
12	вопросно I-Task
13	- I-Task
14	ответных I-Task
15	систем I-Task
16	. O

# sent_id = 764
# text =   Одной из наиболее успешных является модель DeepPavlov BERT.
# relations = ""
1	Одной O
2	из O
3	наиболее O
4	успешных O
5	является O
6	модель O
7	DeepPavlov B-Model
8	BERT I-Model
9	. O

# sent_id = 765
# text =   Чтобы использовать модель QA на основе BERT с DeepPavlov, необходимо следующее.
# relations = ""
1	Чтобы O
2	использовать O
3	модель O
4	QA B-Model
5	на B-Model_isModificationOf_Model
6	основе I-Model_isModificationOf_Model
7	BERT B-Model
8	с O
9	DeepPavlov B-Model
10	, O
11	необходимо O
12	следующее O
13	. O

# sent_id = 766
# text =   DeepPavlov Agent — платформа для создания многозадачных чат-ботов.
# relations = ""
1	DeepPavlov B-Technology
2	Agent I-Technology
3	— O
4	платформа O
5	для O
6	создания O
7	многозадачных O
8	чат O
9	- O
10	ботов O
11	. O

# sent_id = 767
# text =   При разработке разговорных агентов в основном применяется модульная архитектура для целенаправленного диалога, при котором разворачивается сценарий.
# relations = "Method_isUsedIn_Application 0 0"
1	При O
2	разработке O
3	разговорных B-Technology
4	агентов I-Technology
5	в O
6	основном O
7	применяется B-Method_isUsedIn_Application
8	модульная B-Method
9	архитектура I-Method
10	для O
11	целенаправленного O
12	диалога O
13	, O
14	при O
15	котором O
16	разворачивается O
17	сценарий O
18	. O

# sent_id = 768
# text =   Для решения этой задачи в октябре 2019 года вышел первый релиз DeepPavlov Agent 1.0 — платформы для создания многозадачных чат-ботов.
# relations = "Date_isDateOf_Application 0 0, Application_isUsedForSolving_Task 0 1, Application_isUsedForSolving_Task 0 0"
1	Для B-Application_isUsedForSolving_Task
2	решения I-Application_isUsedForSolving_Task
3	этой O
4	задачи B-Task
5	в O
6	октябре O
7	2019 B-Date
8	года I-Date
9	вышел O
10	первый O
11	релиз O
12	DeepPavlov B-Technology
13	Agent I-Technology
14	1.0 I-Technology
15	— O
16	платформы O
17	для O
18	создания B-Task
19	многозадачных I-Task
20	чат I-Task
21	- I-Task
22	ботов I-Task
23	. O

# sent_id = 769
# text =   Агент помогает разработчикам производственных чатботов организовать несколько NLP моделей в одном конвейере.
# relations = ""
1	Агент O
2	помогает O
3	разработчикам O
4	производственных O
5	чатботов O
6	организовать B-Task
7	несколько I-Task
8	NLP I-Task
9	моделей I-Task
10	в O
11	одном O
12	конвейере O
13	. O

# sent_id = 770
# text =   Чтобы упростить работу с предобученными NLP моделями из DeepPavlov, в сентябрь 2019 года был запущен SaaS сервис.
# relations = "Date_isDateOf_Application 0 0, Model_isUsedIn_Application 0 0, Model_isIncludedIn_Library 0 0"
1	Чтобы O
2	упростить O
3	работу O
4	с O
5	предобученными O
6	NLP B-Model
7	моделями I-Model
8	из O
9	DeepPavlov B-Library
10	, O
11	в O
12	сентябрь B-Date
13	2019 I-Date
14	года I-Date
15	был O
16	запущен O
17	SaaS B-Technology
18	сервис I-Technology
19	. O

# sent_id = 771
# text =   В сентябре 2019 года был запущен сервис SaaS для упрощения взаимодействия с предварительно обученными моделями NLP от DeepPavlov.
# relations = "Date_isDateOf_Application 0 0, Model_isUsedIn_Application 0 0, Model_isIncludedIn_Library 0 0"
1	В O
2	сентябре B-Date
3	2019 I-Date
4	года I-Date
5	был O
6	запущен O
7	сервис O
8	SaaS B-Technology
9	для O
10	упрощения O
11	взаимодействия O
12	с O
13	предварительно O
14	обученными O
15	моделями B-Model
16	NLP I-Model
17	от O
18	DeepPavlov B-Library
19	. O

# sent_id = 772
# text =   DeepPavlov Cloud позволяет анализировать текст, а также хранить документы в облачном хранилище.
# relations = "Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 0 1"
1	DeepPavlov B-Technology
2	Cloud I-Technology
3	позволяет O
4	анализировать B-Task
5	текст I-Task
6	, O
7	а O
8	также O
9	хранить B-Task
10	документы I-Task
11	в O
12	облачном O
13	хранилище O
14	. O

# sent_id = 773
# text =   Оценка состояния диалога (DST — Dialogue State Traking) является основным компонентом в таких диалоговых системах.
# relations = "Task_isAlternativeNameFor_Task 1 0, Task_isAlternativeNameFor_Task 2 0"
1	Оценка B-Task
2	состояния I-Task
3	диалога I-Task
4	( O
5	DST B-Task
6	— O
7	Dialogue B-Task
8	State I-Task
9	Traking I-Task
10	) O
11	является O
12	основным O
13	компонентом O
14	в O
15	таких O
16	диалоговых O
17	системах O
18	. O

# sent_id = 774
# text =   DST отвечает за перевод высказываний на человеческом языке в семантическое представление языка, в частности, за извлечение намерений (intets) и пар слот-значение (slot, value), соответствующих цели пользователя.
# relations = "Method_solves_Task 0 0"
1	DST B-Method
2	отвечает B-Method_solves_Task
3	за I-Method_solves_Task
4	перевод B-Task
5	высказываний I-Task
6	на O
7	человеческом O
8	языке O
9	в O
10	семантическое O
11	представление O
12	языка O
13	, O
14	в O
15	частности O
16	, O
17	за O
18	извлечение O
19	намерений O
20	( O
21	intets O
22	) O
23	и O
24	пар O
25	слот O
26	- O
27	значение O
28	( O
29	slot O
30	, O
31	value O
32	) O
33	, O
34	соответствующих O
35	цели O
36	пользователя O
37	. O

# sent_id = 775
# text =   В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.
# relations = "Model_isModificationOf_Model 0 2, Model_isModificationOf_Model 1 2, Model_isUsedForSolving_Task 1 0, Model_isUsedForSolving_Task 0 0, Model_isAlternativeNameFor_Model 1 0"
1	В O
2	ходе O
3	участия O
4	команды O
5	в O
6	DSTC8 O
7	была O
8	разработана O
9	модель O
10	GOLOMB B-Model
11	( O
12	GOaL B-Model
13	- I-Model
14	Oriented I-Model
15	Multi I-Model
16	- I-Model
17	task I-Model
18	BERT I-Model
19	- I-Model
20	based I-Model
21	dialogue I-Model
22	state I-Model
23	tracker I-Model
24	) O
25	— O
26	целеориентированная O
27	мультизадачная O
28	модель O
29	на B-Model_isModificationOf_Model
30	базе I-Model_isModificationOf_Model
31	BERT B-Model
32	для B-Model_isUsedForSolving_Task
33	отслеживания B-Task
34	состояния I-Task
35	диалога I-Task
36	. O

# sent_id = 776
# text =   В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).
# relations = "Model_isUsedForSolving_Task 1 0, Model_isUsedForSolving_Task 2 0, Model_isAlternativeNameFor_Model 2 1"
1	В O
2	рамках O
3	участия O
4	в O
5	DSTC8 O
6	команда O
7	разработала O
8	целеориентированную O
9	мультизадачную O
10	модель O
11	отслеживания B-Task
12	состояния I-Task
13	диалога I-Task
14	с O
15	использованием B-Model_isModificationOf_Model
16	BERT B-Model
17	, O
18	названную O
19	GOLOMB B-Model
20	( O
21	GOaL B-Model
22	- I-Model
23	Oriented I-Model
24	Multi I-Model
25	- I-Model
26	task I-Model
27	BERT I-Model
28	- I-Model
29	based I-Model
30	dialogue I-Model
31	state I-Model
32	tracker I-Model
33	) O
34	. O

# sent_id = 777
# text =   Для предсказания состояния диалога модель решает несколько классификационных задач и задачу поиска подстроки.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1"
1	Для O
2	предсказания O
3	состояния O
4	диалога O
5	модель B-Model
6	решает B-Model_isUsedForSolving_Task
7	несколько O
8	классификационных B-Task
9	задач I-Task
10	и O
11	задачу B-Task
12	поиска I-Task
13	подстроки I-Task
14	. O

# sent_id = 778
# text =   В скором времени данная модель появится библиотеке DeepPavlov.
# relations = ""
1	В O
2	скором O
3	времени O
4	данная O
5	модель O
6	появится O
7	библиотеке O
8	DeepPavlov B-Model
9	. O

# sent_id = 779
# text =   Как было сказано ранее, DeepPavlov поставляется с несколькими предобученными компонентами, работающими на TensorFlow и Keras.
# relations = ""
1	Как O
2	было O
3	сказано O
4	ранее O
5	, O
6	DeepPavlov B-Application
7	поставляется O
8	с O
9	несколькими O
10	предобученными O
11	компонентами O
12	, O
13	работающими O
14	на O
15	TensorFlow B-Application
16	и O
17	Keras B-Application
18	. O

# sent_id = 780
# text =   На основании триггера на определенные ключевые слова она сможет определять, к примеру, признаки обмана, мошенничества.
# relations = ""
1	На O
2	основании O
3	триггера O
4	на O
5	определенные O
6	ключевые B-Object
7	слова I-Object
8	она O
9	сможет O
10	определять O
11	, O
12	к O
13	примеру O
14	, O
15	признаки B-Object
16	обмана I-Object
17	, O
18	мошенничества O
19	. O

# sent_id = 781
# text =   То есть, сформировав некоторый корпус слов-триггеров, вполне возможно классифицировать сайты по их текстовому содержанию.
# relations = ""
1	То O
2	есть O
3	, O
4	сформировав O
5	некоторый O
6	корпус B-Corpus
7	слов I-Corpus
8	- I-Corpus
9	триггеров I-Corpus
10	, O
11	вполне O
12	возможно O
13	классифицировать B-Task
14	сайты O
15	по O
16	их O
17	текстовому O
18	содержанию O
19	. O

# sent_id = 782
# text =   Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).
# relations = "Task_isSolvedIn_Science 0 0, Task_isSolvedIn_Science 0 1, Task_isSolvedIn_Science 0 2, Science_isAlternativeNameFor_Science 2 0, Science_isAlternativeNameFor_Science 1 0"
1	Задача B-Task
2	распознавания I-Task
3	текста I-Task
4	относится O
5	к O
6	сфере O
7	обработки B-Science
8	естественного I-Science
9	языка I-Science
10	или O
11	NLP B-Science
12	( O
13	natural B-Science
14	language I-Science
15	processing I-Science
16	) O
17	. O

# sent_id = 783
# text = Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).
# relations = "Task_isSolvedIn_Science 0 0, Task_isSolvedIn_Science 0 1, Task_isSolvedIn_Science 0 2, Science_isAlternativeNameFor_Science 2 0, Science_isAlternativeNameFor_Science 1 0"
1	Распознавание B-Task
2	текста I-Task
3	входит O
4	в O
5	область B-Science
6	обработки I-Science
7	естественного I-Science
8	языка I-Science
9	, O
10	или O
11	NLP B-Science
12	( O
13	Natural B-Science
14	Language I-Science
15	Processing I-Science
16	) O
17	. O

# sent_id = 784
# text =   NLP — направление искусственного интеллекта, нацеленное на обработку и анализ данных на естественном языке и обучение машин взаимодействию с людьми [1].
# relations = "Method_isUsedIn_Science 0 0, Method_isUsedIn_Science 0 1"
1	NLP B-Science
2	— O
3	направление B-Science_includes_Science
4	искусственного B-Science
5	интеллекта I-Science
6	, O
7	нацеленное O
8	на O
9	обработку O
10	и O
11	анализ B-Method
12	данных I-Method
13	на O
14	естественном O
15	языке O
16	и O
17	обучение O
18	машин O
19	взаимодействию O
20	с O
21	людьми O
22	[ O
23	1 O
24	] O
25	. O

# sent_id = 785
# text =   Такой подход называется методом вложения слов (word embedding).
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Такой O
2	подход O
3	называется O
4	методом B-Method
5	вложения I-Method
6	слов I-Method
7	( O
8	word B-Method
9	embedding I-Method
10	) O
11	. O

# sent_id = 786
# text =   Используя данные, состоящие из таких векторов, мы можем применять различные методы Machine Learning.
# relations = ""
1	Используя O
2	данные O
3	, O
4	состоящие O
5	из O
6	таких O
7	векторов O
8	, O
9	мы O
10	можем O
11	применять O
12	различные O
13	методы O
14	Machine B-Science
15	Learning I-Science
16	. O

# sent_id = 787
# text =   И поскольку искусственные нейронные сети лучшим образом справляются с векторно-матричными вычислениями, то выбор в их пользу становиться очевидным.
# relations = ""
1	И O
2	поскольку O
3	искусственные B-Method
4	нейронные I-Method
5	сети I-Method
6	лучшим O
7	образом O
8	справляются O
9	с O
10	векторно B-Method
11	- I-Method
12	матричными I-Method
13	вычислениями I-Method
14	, O
15	то O
16	выбор O
17	в O
18	их O
19	пользу O
20	становиться O
21	очевидным O
22	. O

# sent_id = 788
# text =   Искусственная нейронная сеть — это математическая модель, а также ее программное или аппаратное воплощение, построенные по принципу организации и функционирования биологических нейронных сетей — сетей нервных клеток живого организма.
# relations = "Method_includes_Method 1 0"
1	Искусственная B-Method
2	нейронная I-Method
3	сеть I-Method
4	— O
5	это O
6	математическая B-Method
7	модель I-Method
8	, O
9	а O
10	также O
11	ее O
12	программное O
13	или O
14	аппаратное O
15	воплощение O
16	, O
17	построенные O
18	по O
19	принципу O
20	организации O
21	и O
22	функционирования O
23	биологических O
24	нейронных O
25	сетей O
26	— O
27	сетей O
28	нервных O
29	клеток O
30	живого O
31	организма O
32	. O

# sent_id = 789
# text =   Современные модели представляют собой так называемые глубокие модели.
# relations = ""
1	Современные O
2	модели O
3	представляют O
4	собой O
5	так O
6	называемые O
7	глубокие B-Model
8	модели I-Model
9	. O

# sent_id = 790
# text =   И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).
# relations = "Method_includes_Method 0 1, Metric_isAppliedTo_Method 0 0, Metric_isAppliedTo_Method 0 1, Metric_isAppliedTo_Method 0 2, Method_isAlternativeNameFor_Method 2 1"
1	И O
2	в O
3	ее O
4	решении O
5	наилучшие O
6	метрики O
7	точности B-Metric
8	были O
9	достигнуты O
10	рекуррентными B-Method
11	нейронными I-Method
12	сетями I-Method
13	, O
14	LSTM B-Method
15	( O
16	сети B-Method
17	с I-Method
18	долгой I-Method
19	краткосрочной I-Method
20	памятью I-Method
21	) O
22	. O

# sent_id = 791
# text =   Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).
# relations = "Method_includes_Method 0 1, Metric_isAppliedTo_Method 0 0, Metric_isAppliedTo_Method 0 1, Method_isAlternativeNameFor_Method 2 1"
1	Лучшие O
2	показатели O
3	точности B-Metric
4	в O
5	ее O
6	решении O
7	были O
8	достигнуты O
9	с O
10	использованием O
11	рекуррентных B-Method
12	нейронных I-Method
13	сетей I-Method
14	, O
15	таких O
16	как O
17	LSTM B-Method
18	( O
19	сети B-Method
20	с I-Method
21	долгой I-Method
22	краткосрочной I-Method
23	памятью I-Method
24	) O
25	. O

# sent_id = 792
# text =   Позже свое превосходство в этой нише обрели NLP-модели-трансформеры.
# relations = ""
1	Позже O
2	свое O
3	превосходство O
4	в O
5	этой O
6	нише O
7	обрели O
8	NLP B-Model
9	- I-Model
10	модели I-Model
11	- I-Model
12	трансформеры I-Model
13	. O

# sent_id = 793
# text =  Описание упомянутых рекуррентных нейросетей (RNN), LSTM и GRU выходит за рамки темы статьи.
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Описание O
2	упомянутых O
3	рекуррентных B-Method
4	нейросетей I-Method
5	( O
6	RNN B-Method
7	) O
8	, O
9	LSTM B-Method
10	и O
11	GRU B-Method
12	выходит O
13	за O
14	рамки O
15	темы O
16	статьи O
17	. O

# sent_id = 794
# text =   Однако RNN способны фиксировать зависимости только в одном направлении языка.
# relations = "Method_solves_Task 0 0"
1	Однако O
2	RNN B-Method
3	способны B-Method_solves_Task
4	фиксировать B-Task
5	зависимости I-Task
6	только O
7	в O
8	одном O
9	направлении O
10	языка O
11	. O

# sent_id = 795
# text =   Кроме этого, RNN не очень хороши в захвате долгосрочных зависимостей.
# relations = ""
1	Кроме O
2	этого O
3	, O
4	RNN B-Method
5	не O
6	очень O
7	хороши B-Method_solves_Task
8	в I-Method_solves_Task
9	захвате B-Task
10	долгосрочных I-Task
11	зависимостей I-Task
12	. O

# sent_id = 796
# text =  LSTM избегают проблемы долговременной зависимости, запоминая значения как на короткие, так и на длинные промежутки времени.
# relations = ""
1	LSTM B-Method
2	избегают O
3	проблемы O
4	долговременной O
5	зависимости O
6	, O
7	запоминая O
8	значения O
9	как O
10	на O
11	короткие O
12	, O
13	так O
14	и O
15	на O
16	длинные O
17	промежутки O
18	времени O
19	. O

# sent_id = 797
# text =   Это объясняется тем, что LSTM не использует функцию активации внутри своих рекуррентных компонентов.
# relations = ""
1	Это O
2	объясняется O
3	тем O
4	, O
5	что O
6	LSTM B-Method
7	не O
8	использует O
9	функцию B-Method
10	активации I-Method
11	внутри O
12	своих O
13	рекуррентных O
14	компонентов O
15	. O

# sent_id = 798
# text =   LSTM часто используются в машинном переводе и в задачах генерирования текстов на естественном языке.
# relations = "Method_isUsedIn_Science 0 0, Method_solves_Task 0 0"
1	LSTM B-Method
2	часто O
3	используются B-Method_isUsedIn_Science
4	в I-Method_isUsedIn_Science
5	машинном B-Science
6	переводе I-Science
7	и O
8	в O
9	задачах O
10	генерирования B-Task
11	текстов I-Task
12	на O
13	естественном O
14	языке O
15	. O

# sent_id = 799
# text = Часто в машинном переводе и задачах генерации текстов на естественном языке применяют LSTM.
# relations = "Method_isUsedIn_Science 0 0, Method_solves_Task 0 0, Task_isSolvedIn_Science 0 0"
1	Часто O
2	в O
3	машинном B-Science
4	переводе I-Science
5	и O
6	задачах O
7	генерации B-Task
8	текстов I-Task
9	на O
10	естественном O
11	языке O
12	применяют B-Method_isUsedIn_Science
13	LSTM B-Method
14	. O

# sent_id = 800
# text =   Прежде чем использовать такой мощный и в то же время сложный инструмент, наша команда протестировала и более простые NLP-методы машинного обучения, в том числе «наивный байесовский классификатор», алгоритмы, использующие bag-of-words («мешок слов» — метод представления слов) и tf-idf (метрика определения частоты вхождения слов), а также простейшие модели нейронных сетей, состоящие из небольшого количества скрытых слоев.
# relations = ""
1	Прежде O
2	чем O
3	использовать O
4	такой O
5	мощный O
6	и O
7	в O
8	то O
9	же O
10	время O
11	сложный O
12	инструмент O
13	, O
14	наша O
15	команда O
16	протестировала O
17	и O
18	более O
19	простые O
20	NLP B-Method
21	- I-Method
22	методы I-Method
23	машинного I-Method
24	обучения I-Method
25	, O
26	в O
27	том O
28	числе O
29	« O
30	наивный B-Method
31	байесовский I-Method
32	классификатор I-Method
33	» O
34	, O
35	алгоритмы O
36	, O
37	использующие O
38	bag B-Method
39	- I-Method
40	of I-Method
41	- I-Method
42	words I-Method
43	( O
44	« O
45	мешок B-Method
46	слов I-Method
47	» O
48	— O
49	метод B-Method
50	представления I-Method
51	слов I-Method
52	) O
53	и O
54	tf B-Metric
55	- I-Metric
56	idf I-Metric
57	( O
58	метрика B-Metric
59	определения I-Metric
60	частоты I-Metric
61	вхождения I-Metric
62	слов I-
63	) O
64	, O
65	а O
66	также O
67	простейшие O
68	модели O
69	нейронных O
70	сетей O
71	, O
72	состоящие O
73	из O
74	небольшого O
75	количества O
76	скрытых O
77	слоев O
78	. O

# sent_id = 801
# text =   BERT, или Bidirectional Encoder Representations from Transformers, — нейросетевая модель-трансформер от Google, на которой сегодня строится большинство инструментов автоматической обработки языка.
# relations = "Model_hasAuthor_Organization 1 0, Model_hasAuthor_Organization 0 0, Model_isAlternativeNameFor_Model 1 0"
1	BERT B-Model
2	, O
3	или O
4	Bidirectional B-Model
5	Encoder I-Model
6	Representations I-Model
7	from I-Model
8	Transformers I-Model
9	, O
10	— O
11	нейросетевая O
12	модель O
13	- O
14	трансформер O
15	от B-Model_hasAuthor_Organization
16	Google B-Organization
17	, O
18	на O
19	которой O
20	сегодня O
21	строится O
22	большинство O
23	инструментов O
24	автоматической O
25	обработки O
26	языка O
27	. O

# sent_id = 802
# text =   BERT, сокращение от Bidirectional Encoder Representations from Transformers, представляет собой нейросетевую модель-трансформер от Google, на базе которой в настоящее время разрабатывается большинство средств автоматической обработки языка.
# relations = "Model_hasAuthor_Organization 1 0, Model_hasAuthor_Organization 0 0, Model_isAlternativeNameFor_Model 1 0"
1	BERT B-Model
2	, O
3	сокращение O
4	от O
5	Bidirectional B-Model
6	Encoder I-Model
7	Representations I-Model
8	from I-Model
9	Transformers I-Model
10	, O
11	представляет O
12	собой O
13	нейросетевую O
14	модель O
15	- O
16	трансформер O
17	от B-Model_hasAuthor_Organization
18	Google B-Organization
19	, O
20	на O
21	базе O
22	которой O
23	в O
24	настоящее O
25	время O
26	разрабатывается O
27	большинство O
28	средств O
29	автоматической O
30	обработки O
31	языка O
32	. O

# sent_id = 803
# text =  Релиз BERT в 2018 году стал некоторой переломной точкой в развитии NLP-моделей.
# relations = "Date_isDateOf_Model 0 0, Model_includes_Model 1 0"
1	Релиз O
2	BERT B-Model
3	в O
4	2018 B-Date
5	году I-Date
6	стал O
7	некоторой O
8	переломной O
9	точкой O
10	в O
11	развитии O
12	NLP B-Model
13	- I-Model
14	моделей I-Model
15	. O

# sent_id = 804
# text =  Выход модели BERT в 2018 году стал своеобразным переломным моментом в развитии моделей обработки естественного языка (NLP).
# relations = "Date_isDateOf_Model 0 0, Model_includes_Model 1 0"
1	Выход O
2	модели O
3	BERT B-Model
4	в O
5	2018 B-Date
6	году I-Date
7	стал O
8	своеобразным O
9	переломным O
10	моментом O
11	в O
12	развитии O
13	моделей B-Model
14	обработки I-Model
15	естественного I-Model
16	языка I-Model
17	( O
18	NLP B-Science
19	) O
20	. O

# sent_id = 805
# text =   Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).
# relations = "Model_hasAuthor_Person 3 2, Model_hasAuthor_Organization 5 2, Method_isUsedIn_Science 1 0, Model_hasAuthor_Person 6 8, Model_hasAuthor_Person 5 7, Model_hasAuthor_Person 5 6, Model_hasAuthor_Person 5 5, Model_hasAuthor_Organization 5 1, Model_hasAuthor_Person 4 4, Model_hasAuthor_Person 4 3, Model_hasAuthor_Organization 3 0, Model_hasAuthor_Organization 3 1, Model_hasAuthor_Person 3 2, Method_hasAuthor_Person 1 0, Method_hasAuthor_Person 1 1, Method_isUsedIn_Science 0 0"
1	Его O
2	появлению O
3	предшествовал O
4	ряд O
5	недавних O
6	разработок O
7	в O
8	области O
9	обработки O
10	естественного O
11	языка O
12	( O
13	BERT B-Model
14	, O
15	ELMO B-Model
16	и O
17	Ко B-Model
18	в O
19	картинках O
20	— O
21	как O
22	в O
23	NLP B-Science
24	пришло B-Method_isUsedIn_Science
25	трансферное B-Method
26	обучение I-Method
27	): O
28	Semi B-Method
29	- I-Method
30	supervised I-Method
31	Sequence I-Method
32	learning I-Method
33	( O
34	Andrew B-Person
35	Dai I-Person
36	и O
37	Quoc B-Person
38	Le I-Person
39	) O
40	, O
41	ELMo B-Model
42	( O
43	Matthew B-Person
44	Peters I-Person
45	и O
46	исследователи O
47	из O
48	AI2 B-Organization
49	и O
50	UW B-Organization
51	CSE I-Organization
52	) O
53	, O
54	ULMFiT B-Model
55	( O
56	Jeremy B-Person
57	Howard I-Person
58	и O
59	Sebastian B-Person
60	Ruder I-Person
61	) O
62	, O
63	OpenAI B-Model
64	Transformer I-Model
65	( O
66	исследователи O
67	OpenAI B-Organization
68	Radford I-Organization
69	, O
70	Narasimhan B-Person
71	, O
72	Salimans B-Person
73	, O
74	и O
75	Sutskever B-Person
76	) O
77	и O
78	Трансформер B-Model
79	( O
80	Vaswani B-Person
81	et O
82	al O
83	) O
84	. O

# sent_id = 806
# text =  Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).
# relations = "Method_isUsedForTraining_Model 0 0, Method_isUsedForTraining_Model 1 0, Method_isUsedIn_Science 0 0, Method_isUsedIn_Science 1 0"
1	Трансформеры B-Model
2	в O
3	машинном B-Science
4	обучении I-Science
5	— O
6	это O
7	семейство O
8	архитектур O
9	нейронных O
10	сетей O
11	, O
12	общая O
13	идея O
14	которых O
15	основана O
16	на O
17	так O
18	называемом O
19	« O
20	самовнимании B-Method
21	» O
22	( O
23	self B-Method
24	- I-Method
25	attention I-Method
26	) O
27	. O

# sent_id = 807
# text =   Однако алгоритм Self-attention не сразу поймет смысл предложения.
# relations = ""
1	Однако O
2	алгоритм O
3	Self B-Method
4	- I-Method
5	attention I-Method
6	не O
7	сразу O
8	поймет O
9	смысл O
10	предложения O
11	. O

# sent_id = 808
# text = По своей сути BERT — это обученный стек энкодеров Трансформера.
# relations = "Model_includes_Model 1 0"
1	По O
2	своей O
3	сути O
4	BERT B-Model
5	— O
6	это O
7	обученный O
8	стек O
9	энкодеров B-Model
10	Трансформера I-Model
11	. O

# sent_id = 809
# text =   Разработкой и обучением модели BERT занималась целая группа исследователей Google AI Language на многомиллионном наборе слов на разных языках (более 100).
# relations = "Model_hasAuthor_Organization 0 0"
1	Разработкой O
2	и O
3	обучением O
4	модели O
5	BERT B-Model
6	занималась B-Model_hasAuthor_Organization
7	целая O
8	группа O
9	исследователей O
10	Google B-Organization
11	AI I-Organization
12	Language I-Organization
13	на O
14	многомиллионном O
15	наборе O
16	слов O
17	на O
18	разных O
19	языках O
20	( O
21	более O
22	100 O
23	) O
24	. O

# sent_id = 810
# text =   И мы дообучили BERT распознавать текстовое содержимое сайтов по 63 категориям (медицина, здоровье, видео, интернет-магазины, юмористические сайты, эротика, оружие, секты, криминал и пр.).
# relations = ""
1	И O
2	мы O
3	дообучили O
4	BERT B-Model
5	распознавать O
6	текстовое O
7	содержимое O
8	сайтов O
9	по O
10	63 O
11	категориям O
12	( O
13	медицина B-Science
14	, O
15	здоровье O
16	, O
17	видео O
18	, O
19	интернет O
20	- O
21	магазины O
22	, O
23	юмористические O
24	сайты O
25	, O
26	эротика O
27	, O
28	оружие O
29	, O
30	секты O
31	, O
32	криминал O
33	и O
34  пр. O
35	) O
36	. O

# sent_id = 811
# text =   Smart-Cat на первом этапе проводит их предобработку.
# relations = ""
1	Smart B-App_system
2	- I-App_system
3	Cat I-App_system
4	на O
5	первом O
6	этапе O
7	проводит O
8	их O
9	предобработку O
10	. O

# sent_id = 812
# text =   Для удобства работы с категоризатором Smart-Cat мы создали специальный Telegram-бот.
# relations = ""
1	Для O
2	удобства O
3	работы O
4	с O
5	категоризатором O
6	Smart B-App_system
7	- I-App_system
8	Cat I-App_system
9	мы O
10	создали O
11	специальный O
12	Telegram B-Technology
13	- I-Technology
14	бот I-Technology
15	. O

# sent_id = 813
# text =   После своей работы BERT-bot отправит CSV-таблицу.
# relations = ""
1	После O
2	своей O
3	работы O
4	BERT B-Technology
5	- I-Technology
6	bot I-Technology
7	отправит O
8	CSV O
9	- O
10	таблицу O
11	. O

# sent_id = 814
# text =   Но, как я уже сказал ранее, такие модели могут применяться не только в задачах классификации текста.
# relations = ""
1	Но O
2	, O
3	как O
4	я O
5	уже O
6	сказал O
7	ранее O
8	, O
9	такие O
10	модели B-Model
11	могут B-Model_isUsedForSolving_Task
12	применяться I-Model_isUsedForSolving_Task
13	не O
14	только O
15	в O
16	задачах O
17	классификации B-Task
18	текста I-Task
19	. O

# sent_id = 815
# text =   Участникам предлагалось определить потенциальные заболевания коров по реальным жалобам людей из открытых источников, а также научиться выделять из текстов симптомы заболеваний (NER - Named Entity Recognition).
# relations = "Task_isAlternativeNameFor_Task 1 0"
1	Участникам O
2	предлагалось O
3	определить O
4	потенциальные O
5	заболевания O
6	коров O
7	по O
8	реальным O
9	жалобам O
10	людей O
11	из O
12	открытых O
13	источников O
14	, O
15	а O
16	также O
17	научиться O
18	выделять O
19	из O
20	текстов O
21	симптомы O
22	заболеваний O
23	( O
24	NER B-Task
25	- O
26	Named B-Task
27	Entity I-Task
28	Recognition I-Task
29	) O
30	. O

# sent_id = 816
# text =   Эта статья будет интересна не только тем, кто специализируется в NLP (Natural Language Processing), но и начинающим исследователям данных.
# relations = "Science_isAlternativeNameFor_Science 1 0"
1	Эта O
2	статья O
3	будет O
4	интересна O
5	не O
6	только O
7	тем O
8	, O
9	кто O
10	специализируется O
11	в O
12	NLP B-Science
13	( O
14	Natural B-Science
15	Language I-Science
16	Processing I-Science
17	) O
18	, O
19	но O
20	и O
21	начинающим O
22	исследователям O
23	данных O
24	. O

# sent_id = 817
# text =   Эта статья будет интересна специалистам в области обработки естественного языка (Natural Language Processing, NLP).
# relations = "Science_isAlternativeNameFor_Science 1 0, Science_isAlternativeNameFor_Science 2 0"
1	Эта O
2	статья O
3	будет O
4	интересна O
5	специалистам O
6	в O
7	области B-Science
8	обработки I-Science
9	естественного I-Science
10	языка I-Science
11	( O
12	Natural B-Science
13	Language I-Science
14	Processing I-Science
15	, O
16	NLP B-Science
17	) O
18	. O

# sent_id = 818
# text =   Спаны - это участки текста, которые содержат в себе определенный смысл.
# relations = "Object_includes_Object 1 0"
1	Спаны B-Object
2	- O
3	это O
4	участки O
5	текста B-Object
6	, O
7	которые O
8	содержат O
9	в O
10	себе O
11	определенный O
12	смысл O
13	. O

# sent_id = 819
# text =   Программа для разметки YEDDA и процесс разметки.
# relations = "Method_isUsedIn_Application 0 0"
1	Программа O
2	для O
3	разметки B-Method
4	YEDDA B-Application
5	и O
6	процесс O
7	разметки O
8	. O

# sent_id = 820
# text =   Так как задача является составной, то и метрика состояла из двух компонентов с весом 0.8 для задачи классификации и 0.2 для задачи NER.
# relations = "Metric_isUsedIn_Task 0 0, Metric_isUsedIn_Task 0 1, Metric_hasValue_Value 0 0, Metric_hasValue_Value 0 1"
1	Так O
2	как O
3	задача O
4	является O
5	составной O
6	, O
7	то O
8	и O
9	метрика B-Metric
10	состояла O
11	из O
12	двух O
13	компонентов O
14	с O
15	весом O
16	0.8 B-Value
17	для O
18	задачи O
19	классификации B-Task
20	и O
21	0.2 B-Value
22	для O
23	задачи O
24	NER B-Task
25	. O

# sent_id = 821
# text =   В задаче классификации использовался logloss, вычисляемый как среднее значение метрики sklearn.metrics.log_loss по классам болезней.
# relations = "Metric_isUsedIn_Task 0 0, Metric_isUsedIn_Task 1 0"
1	В O
2	задаче O
3	классификации B-Task
4	использовался B-Method_solves_Task
5	logloss B-Metric
6	, O
7	вычисляемый O
8	как O
9	среднее O
10	значение O
11	метрики O
12	sklearn.metrics.log_loss B-Metric
13	по O
14	классам O
15	болезней O
16	. O

# sent_id = 822
# text =  В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.
# relations = "Object_isUsedInSolving_Task 0 0, Object_isUsedInSolving_Task 1 0, Object_isUsedInSolving_Task 2 0, Object_isUsedInSolving_Task 3 0, Metric_isUsedIn_Task 0 0"
1	В O
2	задаче O
3	NER B-Task
4	использовался B-Metric_isUsedIn_Task
5	span B-Metric
6	- I-Metric
7	based I-Metric
8	F1-score I-Metric
9	, O
10	рассчитываемый O
11	следующим O
12	образом O
13	: O
14	для O
15	каждого O
16	текста B-Object
17	берутся O
18	предсказанные O
19	индексы B-Object
20	начала O
21	и O
22	конца O
23	размеченных O
24	признаков O
25	болезни O
26	, O
27	по O
28	ним O
29	выделяются O
30	из O
31	текста O
32	токены B-Object
33	( O
34	отдельные O
35	слова B-Object
36	, O
37	разделенные O
38	пробелом O
39	) O
40	и O
41	сравниваются O
42	с O
43	истинной O
44	( O
45	экспертной O
46	) O
47	разметкой O
48	. O

# sent_id = 823
# text =   Код для подсчета метрики span-based F1-score.
# relations = ""
1	Код O
2	для O
3	подсчета O
4	метрики O
5	span B-Metric
6	- I-Metric
7	based I-Metric
8	F1-score I-Metric
9	. O

# sent_id = 824
# text =   Этим решением стало использование классификатора CatBoost, который прямо из коробки может обрабатывать текстовые фичи.
# relations = ""
1	Этим O
2	решением O
3	стало O
4	использование O
5	классификатора O
6	CatBoost B-Method
7	, O
8	который O
9	прямо O
10	из O
11	коробки O
12	может O
13	обрабатывать O
14	текстовые O
15	фичи O
16	. O

# sent_id = 825
# text =   Решение для задачи распознавания симптомов мы давать не стали, чтобы участники Data Science чемпионата могли покреативить.
# relations = ""
1	Решение B-Task_isSolvedIn_Science
2	для I-Task_isSolvedIn_Science
3	задачи B-Task
4	распознавания I-Task
5	симптомов I-Task
6	мы O
7	давать O
8	не O
9	стали O
10	, O
11	чтобы O
12	участники O
13	Data B-Activity
14	Science I-Activity
15	чемпионата I-Activity
16	могли O
17	покреативить O
18	. O

# sent_id = 826
# text =   Во-первых, конкретно для этого соревнования наиболее эффективный подход - это доразметка спанов тренировочных данных для задачи NER.
# relations = "Method_solves_Task 0 0"
1	Во O
2	- O
3	первых O
4	, O
5	конкретно O
6	для O
7	этого O
8	соревнования O
9	наиболее O
10	эффективный O
11	подход O
12	- O
13	это O
14	доразметка B-Method
15	спанов I-Method
16	тренировочных I-Method
17	данных I-Method
18	для B-Method_solves_Task
19	задачи O
20	NER B-Task
21	. O

# sent_id = 827
# text =   Во-вторых, участники использовали базовые подходы для NLP-задач: удаление стоп-слов и знаков пунктуации, приведение к нижнему регистру, стемминг и лемматизация.
# relations = "Method_isUsedIn_Science 0 0, Method_isUsedIn_Science 1 0"
1	Во O
2	- O
3	вторых O
4	, O
5	участники O
6	использовали O
7	базовые O
8	подходы O
9	для O
10	NLP B-Science
11	- O
12	задач O
13	: O
14	удаление O
15	стоп O
16	- O
17	слов O
18	и O
19	знаков O
20	пунктуации O
21	, O
22	приведение O
23	к O
24	нижнему O
25	регистру O
26	, O
27	стемминг B-Method
28	и O
29	лемматизация B-Method
30	. O

# sent_id = 828
# text =  Более же продвинутым подходом является аугментация данных.
# relations = ""
1	Более O
2	же O
3	продвинутым O
4	подходом O
5	является O
6	аугментация B-Method
7	данных I-Method
8	. O

# sent_id = 829
# text =   Один из возможных способов аугментации текста - перифраз текста.
# relations = "Method_solves_Task 0 0"
1	Один O
2	из O
3	возможных O
4	способов O
5	аугментации B-Task
6	текста I-Task
7	- O
8	перифраз B-Method
9	текста I-Method
10	. O

# sent_id = 830
# text =   Примером данного решения является использование парафрайзера на основе “rut5-base-paraphraser” из библиотеки huggingface.
# relations = "Model_isIncludedIn_Library 0 0, Model_isModificationOf_Model 0 1"
1	Примером O
2	данного O
3	решения O
4	является O
5	использование O
6	парафрайзера B-Model
7	на O
8	основе O
9	“ O
10	rut5-base B-Model
11	- I-Model
12	paraphraser I-Model
13	” O
14	из B-Method_isUsedIn_Library
15	библиотеки I-Method_isUsedIn_Library
16	huggingface B-Library
17	. O

# sent_id = 831
# text =   Реализуется данный метод аналогично с предыдущим, как модель можно использовать “LaBSE-en-ru”.
# relations = ""
1	Реализуется O
2	данный O
3	метод O
4	аналогично O
5	с O
6	предыдущим O
7	, O
8	как O
9	модель O
10	можно O
11	использовать O
12	“ O
13	LaBSE B-Model
14	- I-Model
15	en I-Model
16	- I-Model
17	ru I-Model
18	” O
19	. O

# sent_id = 832
# text =   Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.
# relations = "Object_includes_Object 0 0, Object_isUsedInSolving_Task 0 0, Object_isUsedInSolving_Task 0 1, Object_isUsedInSolving_Task 1 0, Object_isUsedInSolving_Task 1 1, Task_isAlternativeNameFor_Task 1 0"
1	Сначала O
2	решается O
3	задача B-Task
4	выделения I-Task
5	симптомов I-Task
6	( O
7	NER B-Task
8	) O
9	, O
10	после O
11	чего O
12	в O
13	текстах B-Object
14	убираются O
15	все O
16	слова B-Object
17	, O
18	не O
19	являющиеся O
20	симптомами O
21	. O

# sent_id = 833
# text =   Базовым вариантом эмбеддингов является TF-IDF, который зависит от частоты употребления слова в документе.
# relations = ""
1	Базовым O
2	вариантом O
3	эмбеддингов B-Object
4	является O
5	TF B-Metric
6	- I-Metric
7	IDF I-Metric
8	, O
9	который O
10	зависит O
11	от O
12	частоты B-Metric
13	употребления I-Metric
14	слова I-Metric
15	в O
16	документе O
17	. O

# sent_id = 834
# text =   И чтобы его улучшить, можно использовать эмбеддинги предобученных моделей, таких как Word2Vec, FastText и тд.
# relations = ""
1	И O
2	чтобы O
3	его O
4	улучшить O
5	, O
6	можно O
7	использовать O
8	эмбеддинги B-Object
9	предобученных I-Object
10	моделей I-Object
11	, O
12	таких O
13	как O
14	Word2Vec B-Model
15	, O
16	FastText B-Model
17	и O
18	тд O
19	. O

# sent_id = 835
# text =   В частности, в одном из лучших решений использовался необычный FastText, предобученный на корпусе текстов RuDReC, который содержит отзывы потребителей на русском языке о фармацевтической продукции.
# relations = "Dataset_Language_Lang 0 0, Model_Language_Lang 0 0, Model_isTrainedOn_Dataset 0 0"
1	В O
2	частности O
3	, O
4	в O
5	одном O
6	из O
7	лучших O
8	решений O
9	использовался O
10	необычный O
11	FastText B-Model
12	, O
13	предобученный B-Model_isTrainedOn_Dataset
14	на I-Model_isTrainedOn_Dataset
15	корпусе O
16	текстов O
17	RuDReC B-Dataset
18	, O
19	который O
20	содержит O
21	отзывы O
22	потребителей O
23	на O
24	русском B-Lang
25	языке I-Lang
26	о O
27	фармацевтической O
28	продукции O
29	. O

# sent_id = 836
# text =   Напомним, что алгоритм работы с трансформерами можно представить следующим образом: сначала тексты преобразовываются токенизатором, далее обучается модель-трансформер.
# relations = ""
1	Напомним O
2	, O
3	что O
4	алгоритм O
5	работы O
6	с O
7	трансформерами B-Model
8	можно O
9	представить O
10	следующим O
11	образом O
12	: O
13	сначала O
14	тексты O
15	преобразовываются O
16	токенизатором B-Method
17	, O
18	далее O
19	обучается O
20	модель B-Model
21	- I-Model
22	трансформер I-Model
23	. O

# sent_id = 837
# text =   Если же говорить о выборе моделей, то наилучшие результаты были получены следующими из них: RuBERT-base, RuBERT-large, LaBSE-en-ru.
# relations = ""
1	Если O
2	же O
3	говорить O
4	о O
5	выборе O
6	моделей O
7	, O
8	то O
9	наилучшие O
10	результаты O
11	были O
12	получены O
13	следующими O
14	из O
15	них O
16	: O
17	RuBERT B-Model
18	- I-Model
19	base I-Model
20	, O
21	RuBERT B-Model
22	- I-Model
23	large I-Model
24	, O
25	LaBSE B-Model
26	- I-Model
27	en I-Model
28	- I-Model
29	ru I-Model
30	. O

# sent_id = 838
# text =   Предположим, что вы и так слышали о моделях семейства BERT (в предыдущей статье мы описывали, как применяем BERT в других задачах), а вот LaBSE - выбор совершенно неочевидный.
# relations = ""
1	Предположим O
2	, O
3	что O
4	вы O
5	и O
6	так O
7	слышали O
8	о O
9	моделях O
10	семейства O
11	BERT B-Model
12	( O
13	в O
14	предыдущей O
15	статье O
16	мы O
17	описывали O
18	, O
19	как O
20	применяем O
21	BERT B-Model
22	в O
23	других O
24	задачах O
25	) O
26	, O
27	а O
28	вот O
29	LaBSE B-Model
30	- O
31	выбор O
32	совершенно O
33	неочевидный O
34	. O

# sent_id = 839
# text = Далее слова в тестовом наборе текстов также приводятся к векторам и сравниваются со словами из тренировочной разметки при помощи косинусной близости.
# relations = ""
1	Далее O
2	слова O
3	в O
4	тестовом O
5	наборе O
6	текстов O
7	также O
8	приводятся O
9	к O
10	векторам O
11	и O
12	сравниваются O
13	со O
14	словами O
15	из O
16	тренировочной O
17	разметки O
18	при O
19	помощи O
20	косинусной B-Metric
21	близости I-Metric
22	. O

# sent_id = 840
# text =   Архитектура в свою очередь может содержать LSTM, BiLSTM, RNN или GRU слои.
# relations = ""
1	Архитектура O
2	в O
3	свою O
4	очередь O
5	может O
6	содержать O
7	LSTM B-Model
8	, O
9	BiLSTM B-Model
10	, O
11	RNN B-Model
12	или O
13	GRU B-Model
14	слои O
15	. O

# sent_id = 841
# text =   Из интересных решений один из участников представил BiLSTM-сеть с CRF слоем.
# relations = "Model_includes_Model 0 1"
1	Из O
2	интересных O
3	решений O
4	один O
5	из O
6	участников O
7	представил O
8	BiLSTM B-Model
9	- I-Model
10	сеть I-Model
11	с O
12	CRF B-Model
13	слоем O
14	. O

# sent_id = 842
# text =   Для задачи NER тексты преобразовываются с помощью токенизатора и теггинга.
# relations = "Method_solves_Task 0 0, Method_solves_Task 1 0"
1	Для O
2	задачи O
3	NER B-Task
4	тексты O
5	преобразовываются O
6	с O
7	помощью O
8	токенизатора B-Method
9	и O
10	теггинга B-Method
11	. O

# sent_id = 843
# text =   Сначала тексты при помощи токенизатора переводятся в вектора - это то, на чем обучается модель.
# relations = "Method_isAppliedTo_Object 0 0"
1	Сначала O
2	тексты B-Object
3	при B-Method_isAppliedTo_Object
4	помощи I-Method_isAppliedTo_Object
5	токенизатора B-Method
6	переводятся O
7	в O
8	вектора B-Object
9	- O
10	это O
11	то O
12	, O
13	на O
14	чем O
15	обучается O
16	модель O
17	. O

# sent_id = 844
# text =   Далее создаются таргеты при помощи теггинга.
# relations = ""
1	Далее O
2	создаются O
3	таргеты B-Object
4	при O
5	помощи O
6	теггинга B-Method
7	. O

# sent_id = 845
# text =   Самым распространенным алгоритмом теггинга является “Inside-outside-beginning”.
# relations = ""
1	Самым O
2	распространенным O
3	алгоритмом O
4	теггинга O
5	является O
6	“ O
7	Inside B-Method
8	- I-Method
9	outside I-Method
10	- I-Method
11	beginning I-Method
12	” O
13	. O

# sent_id = 846
# text =   Тег указывает на то, что слово находится внутри спана.
# relations = ""
1	Тег B-Object
2	указывает O
3	на O
4	то O
5	, O
6	что O
7	слово O
8	находится O
9	внутри O
10	спана B-Object
11	. O

# sent_id = 847
# text =   Среди решений были как кастомный код для обучения и инференса, так и код от huggingface, который можно использовать из коробки.
# relations = ""
1	Среди O
2	решений O
3	были O
4	как O
5	кастомный O
6	код O
7	для O
8	обучения O
9	и O
10	инференса O
11	, O
12	так O
13	и O
14	код O
15	от O
16	huggingface B-Organization
17	, O
18	который O
19	можно O
20	использовать O
21	из O
22	коробки O
23	. O

# sent_id = 848
# text =   Безусловно, основной метрикой оценивания являлся лидерборд.
# relations = ""
1	Безусловно O
2	, O
3	основной O
4	метрикой O
5	оценивания O
6	являлся O
7	лидерборд B-Metric
8	. O

# sent_id = 849
# text =   Для решения ситуации мы можем искусственно сгенерировать данные с помощью языка программирования.
# relations = ""
1	Для O
2	решения O
3	ситуации O
4	мы O
5	можем O
6	искусственно O
7	сгенерировать B-Task
8	данные I-Task
9	с O
10	помощью O
11	языка O
12	программирования O
13	. O

# sent_id = 850
# text =   Пересмотрев множество примеров и статей, была найдена англоязычная статья, в которой рассмотрены три самых интересных, в плане функциональности и простоты использования, способа генерации синтетических данных с помощью пакетов Python.
# relations = ""
1	Пересмотрев O
2	множество O
3	примеров O
4	и O
5	статей O
6	, O
7	была O
8	найдена O
9	англоязычная B-Lang
10	статья O
11	, O
12	в O
13	которой O
14	рассмотрены O
15	три O
16	самых O
17	интересных O
18	, O
19	в O
20	плане O
21	функциональности O
22	и O
23	простоты O
24	использования O
25	, O
26	способа O
27	генерации B-Task
28	синтетических I-Task
29	данных I-Task
30	с O
31	помощью O
32	пакетов O
33	Python B-Environment
34	. O

# sent_id = 851
# text =   Faker - это пакет Python, разработанный для упрощения генерации синтетических данных.
# relations = "Library_isUsedForSolving_Task 0 0, Environment_isUsedIn_Library 0 0"
1	Faker B-Library
2	- O
3	это O
4	пакет O
5	Python B-Environment
6	, O
7	разработанный O
8	для O
9	упрощения O
10	генерации B-Task
11	синтетических I-Task
12	данных I-Task
13	. O

# sent_id = 852
# text =   SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.
# relations = "Library_isUsedForSolving_Task 1 0, Library_isAlternativeNameFor_Library 1 0, Environment_isUsedIn_Library 0 0, Environment_isUsedIn_Library 0 1, Library_isUsedForSolving_Task 0 0"
1	SDV B-Library
2	или O
3	Synthetic B-Library
4	Data I-Library
5	Vault I-Library
6	- O
7	это O
8	пакет O
9	Python B-Environment
10	для O
11	генерации B-Task
12	синтетических I-Task
13	данных I-Task
14	на O
15	основе O
16	предоставленного O
17	набора O
18	данных O
19	. O

# sent_id = 853
# text = Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.
# relations = "Library_isAlternativeNameFor_Library 1 0, Environment_isUsedIn_Library 0 0, Environment_isUsedIn_Library 0 1, Library_isUsedForSolving_Task 0 0, Library_isUsedForSolving_Task 1 0"
1	Synthetic B-Library
2	Data I-Library
3	Vault I-Library
4	( O
5	SDV B-Library
6	) O
7	- O
8	это O
9	библиотека O
10	Python B-Environment
11	, O
12	использующаяся O
13	для O
14	генерации B-Task
15	синтетических I-Task
16	данных I-Task
17	на O
18	основе O
19	предоставленного O
20	набора O
21	данных O
22	. O

# sent_id = 854
# text =  SDV генерирует данные, применяя математические методы и модели машинного обучения.
# relations = "Method_isUsedIn_Library 0 0, Method_solves_Task 0 0, Library_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 0"
1	SDV B-Library
2	генерирует B-Task
3	данные I-Task
4	, O
5	применяя B-Method_solves_Task
6	математические B-Method
7	методы I-Method
8	и O
9	модели B-Model
10	машинного I-Model
11	обучения I-Model
12	. O

# sent_id = 855
# text = Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.
# relations = "Method_isUsedIn_Library 0 0, Method_isUsedIn_Library 0 1, Library_isAlternativeNameFor_Library 1 0, Method_solves_Task 0 0, Library_isUsedForSolving_Task 0 0, Library_isUsedForSolving_Task 1 0, Model_isUsedForSolving_Task 0 0"
1	Synthetic B-Library
2	Data I-Library
3	Vault I-Library
4	( O
5	SDV B-Library
6	) O
7	создает B-Task
8	данные I-Task
9	с B-Method_solves_Task
10	использованием I-Method_solves_Task
11	математических B-Method
12	методов I-Method
13	и O
14	моделей B-Model
15	машинного I-Model
16	обучения I-Model
17	. O

# sent_id = 856
# text =   С помощью SVD можно обработать данные, даже если они содержат несколько типов данных и отсутствующие значения.
# relations = "Library_isUsedForSolving_Task 0 0"
1	С O
2	помощью O
3	SVD B-Library
4	можно O
5	обработать B-Task
6	данные I-Task
7	, O
8	даже O
9	если O
10	они O
11	содержат O
12	несколько O
13	типов O
14	данных O
15	и O
16	отсутствующие O
17	значения O
18	. O

# sent_id = 857
# text =   С помощью Synthetic Data Vault (SDV) могут быть обработаны данные нескольких типов.
# relations = "Library_isAlternativeNameFor_Library 1 0, Library_isUsedForSolving_Task 0 0, Library_isUsedForSolving_Task 1 0"
1	С O
2	помощью O
3	Synthetic B-Library
4	Data I-Library
5	Vault I-Library
6	( O
7	SDV B-Library
8	) O
9	могут O
10	быть O
11	обработаны B-Task
12	данные I-Task
13	нескольких O
14	типов O
15	. O

# sent_id = 858
# text =   Используем для этого одну из доступных моделей SVD Singular Table GaussianCopula.
# relations = "Model_isUsedIn_Library 0 0"
1	Используем O
2	для O
3	этого O
4	одну O
5	из O
6	доступных O
7	моделей O
8	SVD B-Library
9	Singular B-Model
10	Table I-Model
11	GaussianCopula I-Model
12	. O

# sent_id = 859
# text =   Для этого применяем одну из моделей, доступных в библиотеке SVD - Singular Table GaussianCopula.
# relations = "Model_isUsedIn_Library 0 0"
1	Для O
2	этого O
3	применяем O
4	одну O
5	из O
6	моделей O
7	, O
8	доступных O
9	в O
10	библиотеке O
11	SVD B-Library
12	- O
13	Singular B-Model
14	Table I-Model
15	GaussianCopula I-Model
16	. O

# sent_id = 860
# text =   Воспользуемся функцией evaluate из SDV.
# relations = "Method_isUsedIn_Library 0 0"
1	Воспользуемся O
2	функцией O
3	evaluate B-Method
4	из B-Method_isUsedIn_Library
5	SDV B-Library
6	. O

# sent_id = 861
# text =   Возьмем для примера статистические метрики (критерии Колмогорова-Смирнова и Хи-квадрат) и метрику обнаружения, основанную на классификаторе логистической регрессии.
# relations = ""
1	Возьмем O
2	для O
3	примера O
4	статистические B-Metric
5	метрики I-Metric
6	( O
7	критерии B-Metric
8	Колмогорова I-Metric
9	- I-Metric
10	Смирнова I-Metric
11	и O
12	Хи B-Metric
13	- I-Metric
14	квадрат I-Metric
15	) O
16	и O
17	метрику B-Metric
18	обнаружения I-Metric
19	, O
20	основанную O
21	на O
22	классификаторе B-Method
23	логистической I-Method
24	регрессии I-Method
25	. O

# sent_id = 862
# text =   KSTest используется для сравнения столбцов с непрерывными данными, а CSTest с дискретными данными.
# relations = ""
1	KSTest B-Metric
2	используется O
3	для O
4	сравнения O
5	столбцов O
6	с O
7	непрерывными O
8	данными O
9	, O
10	а O
11	CSTest B-Metric
12	с O
13	дискретными O
14	данными O
15	. O

# sent_id = 863
# text =   Метрика LogisticDetection при помощи машинного обучения позволяет оценить насколько сложно отличить синтетические данные от исходных.
# relations = "Metric_isUsedIn_Task 0 0"
1	Метрика O
2	LogisticDetection B-Metric
3	при O
4	помощи O
5	машинного O
6	обучения O
7	позволяет B-Metric_isUsedIn_Task
8	оценить I-Metric_isUsedIn_Task
9	насколько O
10	сложно O
11	отличить B-Task
12	синтетические I-Task
13	данные I-Task
14	от I-Task
15	исходных I-Task
16	. O

# sent_id = 864
# text =   Gretel или Gretel Synthetics – это пакет Python с открытым исходным кодом, основанный на рекуррентной нейронной сети для создания структурированных и не структурированных данных.
# relations = "Environment_isUsedIn_Library 0 0, Environment_isUsedIn_Library 0 1, Library_isAlternativeNameFor_Library 1 0"
1	Gretel B-Library
2	или O
3	Gretel B-Library
4	Synthetics I-Library
5	– O
6	это O
7	пакет O
8	Python B-Environment
9	с O
10	открытым O
11	исходным O
12	кодом O
13	, O
14	основанный O
15	на O
16	рекуррентной B-Model
17	нейронной I-Model
18	сети I-Model
19	для O
20	создания O
21	структурированных O
22	и O
23	не O
24	структурированных O
25	данных O
26	. O

# sent_id = 865
# text = Gretel (Gretel Synthetics, GS) – это библиотека на Python.
# relations = "Environment_isUsedIn_Library 0 0, Environment_isUsedIn_Library 0 1, Environment_isUsedIn_Library 0 2, Library_isAlternativeNameFor_Library 1 0, Library_isAlternativeNameFor_Library 2 0, Library_isAlternativeNameFor_Library 2 1"
1	Gretel B-Library
2	( O
3	Gretel B-Library
4	Synthetics I-Library
5	, O
6	GS B-Library
7	) O
8	– O
9	это O
10	библиотека O
11	на O
12	Python B-Environment
13	. O

# sent_id = 866
# text =   Этот модуль работает непосредственно с датафреймами данных Pandas и позволяет автоматически разбивать датафрейм на более мелкие датафреймы (по кластерам столбцов), выполнять обучение модели и генерацию для каждого фрейма независимо.
# relations = ""
1	Этот O
2	модуль O
3	работает O
4	непосредственно O
5	с O
6	датафреймами O
7	данных O
8	Pandas B-Library
9	и O
10	позволяет O
11	автоматически O
12	разбивать O
13	датафрейм O
14	на O
15	более O
16	мелкие O
17	датафреймы O
18	( O
19	по O
20	кластерам O
21	столбцов O
22	) O
23	, O
24	выполнять O
25	обучение O
26	модели O
27	и O
28	генерацию O
29	для O
30	каждого O
31	фрейма O
32	независимо O
33	. O

# sent_id = 867
# text =   Теперь с помощью пакета Gretel cгенерируем синтетические данные для Stroke Prediction Dataset и проанализируем их относительно данных полученных с помощью пакета SVD из пункта 2.
# relations = ""
1	Теперь O
2	с O
3	помощью O
4	пакета O
5	Gretel B-Library
6	cгенерируем O
7	синтетические O
8	данные O
9	для O
10	Stroke B-Dataset
11	Prediction I-Dataset
12	Dataset I-Dataset
13	и O
14	проанализируем O
15	их O
16	относительно O
17	данных O
18	полученных O
19	с O
20	помощью O
21	пакета O
22	SVD B-Library
23	из O
24	пункта O
25	2 O
26	. O

# sent_id = 868
# text =   В современном мире всё большую популярность приобретает методика под названием customer development для тестирования идей и гипотез о будущем продукте.
# relations = ""
1	В O
2	современном O
3	мире O
4	всё O
5	большую O
6	популярность O
7	приобретает O
8	методика O
9	под O
10	названием O
11	customer B-Method
12	development I-Method
13	для O
14	тестирования O
15	идей O
16	и O
17	гипотез O
18	о O
19	будущем O
20	продукте O
21	. O

# sent_id = 869
# text =   В данном решении была использована готовая нейросеть от сервиса RusVectores, обученная на корпусе НКРЯ с использованием алгоритма word2vec CBOW с длиной вектора 300.
# relations = "Method_isUsedIn_Application 0 0"
1	В O
2	данном O
3	решении O
4	была O
5	использована O
6	готовая O
7	нейросеть O
8	от O
9	сервиса O
10	RusVectores B-Technology
11	, O
12	обученная O
13	на O
14	корпусе O
15	НКРЯ B-Corpus
16	с O
17	использованием O
18	алгоритма O
19	word2vec B-Method
20	CBOW I-Method
21	с O
22	длиной O
23	вектора O
24	300 O
25  . O

# sent_id = 870
# text =  НКРЯ – это совокупность русскоязычных текстов, Национальный Корпус Русского Языка в полном объёме.
# relations = "Corpus_isAlternativeNameFor_Corpus 1 0"
1	НКРЯ B-Corpus
2	– O
3	это O
4	совокупность O
5	русскоязычных O
6	текстов O
7	, O
8	Национальный B-Corpus
9	Корпус I-Corpus
10	Русского I-Corpus
11	Языка I-Corpus
12	в O
13	полном O
14	объёме O
15	. O

# sent_id = 871
# text =  Национальный Корпус Русского Языка, или НКРЯ, представляет собой совокупность русскоязычных текстов.
# relations = "Corpus_isAlternativeNameFor_Corpus 1 0"
1	Национальный B-Corpus
2	Корпус I-Corpus
3	Русского I-Corpus
4	Языка I-Corpus
5	, O
6	или O
7	НКРЯ B-Corpus
8	, O
9	представляет O
10	собой O
11	совокупность O
12	русскоязычных O
13	текстов O
14	. O

# sent_id = 872
# text =  Word2vec CBOW — алгоритм, благодаря которому слово на естественном языке представляется в виде числового вектора.
# relations = ""
1	Word2vec B-Method
2	CBOW I-Method
3	— O
4	алгоритм O
5	, O
6	благодаря O
7	которому O
8	слово O
9	на O
10	естественном O
11	языке O
12	представляется O
13	в O
14	виде O
15	числового O
16	вектора O
17	. O

# sent_id = 873
# text =   CBOW – это аббревиатура Continuous Bag of Words.
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	CBOW B-Method
2	– O
3	это O
4	аббревиатура O
5	Continuous B-Method
6	Bag I-Method
7	of I-Method
8	Words I-Method
9	. O

# sent_id = 874
# text =  Она обозначает алгоритм, который есть в word2vec.
# relations = ""
1	Она O
2	обозначает O
3	алгоритм O
4	, O
5	который O
6	есть O
7	в O
8	word2vec B-Model
9	. O

# sent_id = 875
# text =   Данный алгоритм называют моделью «мешка слов», он предсказывает слово по контексту.
# relations = "Method_solves_Task 0 0"
1	Данный O
2	алгоритм O
3	называют O
4	моделью O
5	« O
6	мешка B-Method
7	слов I-Method
8	» O
9	, O
10	он O
11	предсказывает B-Task
12	слово I-Task
13	по I-Task
14	контексту I-Task
15	. O

# sent_id = 876
# text =   Ещё один алгоритм в word2vec - Skip-gram предсказывает контекст по слову.
# relations = ""
1	Ещё O
2	один O
3	алгоритм O
4	в O
5	word2vec B-Library
6	- O
7	Skip B-Method
8	- I-Method
9	gram I-Method
10	предсказывает O
11	контекст O
12	по O
13	слову O
14	. O

# sent_id = 877
# text =  С помощью данных алгоритмов генерируют близкие по смыслу слова при запросе в поисковой системе, сравнивают документы по смыслу, определяют смысловую близость слов и предложений.
# relations = ""
1	С O
2	помощью O
3	данных O
4	алгоритмов O
5	генерируют O
6	близкие O
7	по O
8	смыслу O
9	слова O
10	при O
11	запросе O
12	в O
13	поисковой O
14	системе O
15	, O
16	сравнивают B-Task
17	документы I-Task
18	по I-Task
19	смыслу I-Task
20	, O
21	определяют B-Task
22	смысловую I-Task
23	близость I-Task
24	слов I-Task
25	и O
26	предложений O
27	. O

# sent_id = 878
# text =  Более подробно о word2vec можно почитать в статье "Немного про word2vec: полезная теория".
# relations = ""
1	Более O
2	подробно O
3	о O
4	word2vec B-Application
5	можно O
6	почитать O
7	в O
8	статье O
9	" O
10	Немного O
11	про O
12	word2vec B-Application
13	: O
14	полезная O
15	теория" O
16	. O

# sent_id = 879
# text =  О векторном представлении слов (эмбеддинге) хорошо и с примерами описано в статье "Что такое эмбеддинги и как они помогают машинам понимать тексты".
# relations = ""
1	О O
2	векторном B-Object
3	представлении I-Object
4	слов I-Object
5	( O
6	эмбеддинге B-Object
7	) O
8	хорошо O
9	и O
10	с O
11	примерами O
12	описано O
13	в O
14	статье O
15	" O
16	Что O
17	такое O
18	эмбеддинги O
19	и O
20	как O
21	они O
22	помогают O
23	машинам O
24	понимать O
25	тексты" O
26	. O

# sent_id = 880
# text =   Т.к. у меня таких мощностей нет, я воспользовался доступным онлайн сервисом RusVectores.
# relations = ""
1	Т.к O
2	. O
3	у O
4	меня O
5	таких O
6	мощностей O
7	нет O
8	, O
9	я O
10	воспользовался O
11	доступным O
12	онлайн O
13	сервисом O
14	RusVectores B-Application
15	. O

# sent_id = 881
# text =   Метрикой оценки качества является ROC-AUC.
# relations = ""
1	Метрикой O
2	оценки O
3	качества O
4	является O
5	ROC B-Metric
6	- I-Metric
7	AUC I-Metric
8	. O

# sent_id = 882
# text =   Разработанный подход для решения задачи кредитного скоринга в дальнейшем легко переносим и на прочие банковские задачи: модели склонности, оттока и дохода.
# relations = "Method_solves_Task 0 0"
1	Разработанный O
2	подход B-Method
3	для O
4	решения O
5	задачи B-Task
6	кредитного I-Task
7	скоринга I-Task
8	в O
9	дальнейшем O
10	легко O
11	переносим O
12	и O
13	на O
14	прочие O
15	банковские O
16	задачи O
17	: O
18	модели O
19	склонности O
20	, O
21	оттока O
22	и O
23	дохода O
24	. O

# sent_id = 883
# text =   Токены, относящиеся к ФИО, мы выделяем с помощью клиентской базы и проверки с помощью библиотек для морфологического анализа.
# relations = "Method_isAppliedTo_Object 0 0"
1	Токены B-Object
2	, O
3	относящиеся O
4	к O
5	ФИО O
6	, O
7	мы O
8	выделяем O
9	с O
10	помощью O
11	клиентской O
12	базы O
13	и O
14	проверки O
15	с O
16	помощью O
17	библиотек O
18	для O
19	морфологического B-Method
20	анализа I-Method
21	. O

# sent_id = 884
# text =  Лемматизация оставшихся токенов.
# relations = "Method_isAppliedTo_Object 0 0"
1	Лемматизация B-Method
2	оставшихся O
3	токенов B-Object
4	. O

# sent_id = 885
# text =   Для этого корпуса мы обучили word2vec-модель, где для каждого токена выучили эмбеддинг размера 50.
# relations = "Model_isTrainedOn_Corpus 0 0"
1	Для O
2	этого O
3	корпуса B-Corpus
4	мы O
5	обучили O
6	word2vec B-Model
7	- I-Model
8	модель I-Model
9	, O
10	где O
11	для O
12	каждого O
13	токена O
14	выучили O
15	эмбеддинг B-Object
16	размера O
17	50 O
18	. O

# sent_id = 886
# text =   Благодаря богатому набору данных бустинг индивидуально имеет приличное качество.
# relations = ""
1	Благодаря O
2	богатому O
3	набору O
4	данных O
5	бустинг B-Method
6	индивидуально O
7	имеет O
8	приличное O
9	качество O
10	. O

# sent_id = 887
# text =   Эти модели всегда ищут синонимы — даже для устоявшихся словосочетаний.
# relations = "Model_isUsedForSolving_Task 0 0, Object_isUsedInSolving_Task 0 0"
1	Эти O
2	модели B-Model
3	всегда O
4	ищут B-Task
5	синонимы I-Task
6	— O
7	даже O
8	для O
9	устоявшихся O
10	словосочетаний B-Object
11	. O

# sent_id = 888
# text =   Одной из первых практических задач было определение авторства политических текстов The Federalist Papers, написанных в США в 1780 годах.
# relations = ""
1	Одной O
2	из O
3	первых O
4	практических O
5	задач O
6	было O
7	определение B-Task
8	авторства I-Task
9	политических O
10	текстов O
11	The O
12	Federalist O
13	Papers O
14	, O
15	написанных O
16	в O
17	США O
18	в O
19	1780 B-Date
20	годах I-Date
21	. O

# sent_id = 889
# text =   Я рассмотрю простейший способ анализа с помощью несложных расчетов и пакета Natural Language Toolkit, что в совокупности с matplotlib позволяет получить интересные результаты буквально в несколько строк кода.
# relations = ""
1	Я O
2	рассмотрю O
3	простейший O
4	способ O
5	анализа O
6	с O
7	помощью O
8	несложных O
9	расчетов O
10	и O
11	пакета O
12	Natural B-Library
13	Language I-Library
14	Toolkit I-Library
15	, O
16	что O
17	в O
18	совокупности O
19	с O
20	matplotlib B-Library
21	позволяет O
22	получить O
23	интересные O
24	результаты O
25	буквально O
26	в O
27	несколько O
28	строк O
29	кода O
30	. O

# sent_id = 890
# text =  Перед переходом к самим метрикам необходимо ввести важную концепцию для описания этих метрик в терминах ошибок классификации — confusion matrix (матрица ошибок).
# relations = ""
1	Перед O
2	переходом O
3	к O
4	самим O
5	метрикам O
6	необходимо O
7	ввести O
8	важную O
9	концепцию O
10	для O
11	описания O
12	этих O
13	метрик O
14	в O
15	терминах O
16	ошибок O
17	классификации B-Task
18	— O
19	confusion B-Method
20	matrix I-Method
21	( O
22	матрица B-Method
23	ошибок I-Method
24	) O
25	. O

# sent_id = 891
# text =  Интуитивно понятной, очевидной и почти неиспользуемой метрикой является accuracy — доля правильных ответов алгоритма.
# relations = ""
1	Интуитивно O
2	понятной O
3	, O
4	очевидной O
5	и O
6	почти O
7	неиспользуемой O
8	метрикой O
9	является O
10	accuracy B-Metric
11	— O
12	доля O
13	правильных O
14	ответов O
15	алгоритма O
16	. O

# sent_id = 892
# text =   Для оценки качества работы алгоритма на каждом из классов по отдельности введем метрики precision (точность) и recall (полнота).
# relations = ""
1	Для O
2	оценки O
3	качества O
4	работы O
5	алгоритма O
6	на O
7	каждом O
8	из O
9	классов B-Object
10	по O
11	отдельности O
12	введем O
13	метрики O
14	precision B-Metric
15	( O
16	точность B-Metric
17	) O
18	и O
19	recall B-Metric
20	( O
21	полнота B-Metric
22	) O
23	. O

# sent_id = 893
# text =   Precision можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а recall показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм.
# relations = ""
1	Precision B-Metric
2	можно O
3	интерпретировать O
4	как O
5	долю O
6	объектов O
7	, O
8	названных O
9	классификатором O
10	положительными O
11	и O
12	при O
13	этом O
14	действительно O
15	являющимися O
16	положительными O
17	, O
18	а O
19	recall B-Metric
20	показывает O
21	, O
22	какую O
23	долю O
24	объектов O
25	положительного O
26	класса O
27	из O
28	всех O
29	объектов O
30	положительного O
31	класса O
32	нашел O
33	алгоритм O
34	. O

# sent_id = 894
# text =   F-мера достигает максимума при полноте и точности, равными единице, и близка к нулю, если один из аргументов близок к нулю.
# relations = ""
1	F B-Metric
2	- I-Metric
3	мера I-Metric
4	достигает O
5	максимума O
6	при O
7	полноте B-Metric
8	и O
9	точности B-Metric
10	, O
11	равными O
12	единице O
13	, O
14	и O
15	близка O
16	к O
17	нулю O
18	, O
19	если O
20	один O
21	из O
22	аргументов O
23	близок O
24	к O
25	нулю O
26	. O

# sent_id = 895
# text =  Одним из способов оценить модель в целом, не привязываясь к конкретному порогу, является AUC-ROC (или ROC AUC) — площадь (Area Under Curve) под кривой ошибок (Receiver Operating Characteristic curve ).
# relations = ""
1	Одним O
2	из O
3	способов O
4	оценить B-Task
5	модель I-Task
6	в O
7	целом O
8	, O
9	не O
10	привязываясь O
11	к O
12	конкретному O
13	порогу O
14	, O
15	является O
16	AUC B-Metric
17	- I-Metric
18	ROC I-Metric
19	( O
20	или O
21	ROC B-Metric
22	AUC I-Metric
23	) O
24	— O
25	площадь B-Metric
26	( O
27	Area B-Metric
28	Under I-Metric
29	Curve I-Metric
30	) O
31	под O
32	кривой O
33	ошибок O
34	( O
35	Receiver B-Metric
36	Operating I-Metric
37	Characteristic I-Metric
38	curve I-Metric
39	) O
40	. O

# sent_id = 896
# text =  Интуитивно можно представить минимизацию logloss как задачу максимизации accuracy путем штрафа за неверные предсказания.
# relations = ""
1	Интуитивно O
2	можно O
3	представить O
4	минимизацию O
5	logloss B-Metric
6	как O
7	задачу B-Task
8	максимизации I-Task
9	accuracy I-Task
10	путем O
11	штрафа O
12	за O
13	неверные O
14	предсказания O
15	. O

# sent_id = 897
# text =   Вчера OpenAI выпустили Whisper.
# relations = "Application_hasAuthor_Organization 0 0"
1	Вчера O
2	OpenAI B-Organization
3	выпустили B-Application_hasAuthor_Organization
4	Whisper B-Application
5	. O

# sent_id = 898
# text =   По сути авторы попытались: Исключить транскрипты других систем ASR из датасета; Привести пунктуации к некому стандарту.
# relations = ""
1	По O
2	сути O
3	авторы O
4	попытались O
5	: O
6	Исключить O
7	транскрипты O
8	других O
9	систем O
10	ASR B-Application
11	из O
12	датасета O
13	; O
14	Привести O
15	пунктуации O
16	к O
17	некому O
18	стандарту O
19	. O

# sent_id = 899
# text =   Серьезной нормализации или денормализации текста не делалось.
# relations = ""
1	Серьезной O
2	нормализации B-Method
3	или O
4	денормализации B-Method
5	текста O
6	не O
7	делалось O
8	. O

# sent_id = 900
# text =   Под капотом же seq2seq модель, глядишь сама всё и так выучит.
# relations = ""
1	Под O
2	капотом O
3	же O
4	seq2seq B-Model
5	модель O
6	, O
7	глядишь O
8	сама O
9	всё O
10	и O
11	так O
12	выучит O
13	. O

# sent_id = 901
# text =   Ведь исходя из названий FAIR, OpenAI и прочие же FOSS - альтруисты, борющиеся за наше будущее, они же выложили код для тренировки (а повторить смогут лишь GAFA компании) и все датасеты, не так ли?
# relations = ""
1	Ведь O
2	исходя O
3	из O
4	названий O
5	FAIR B-Organization
6	, O
7	OpenAI B-Organization
8	и O
9	прочие O
10	же O
11	FOSS B-Organization
12	- O
13	альтруисты O
14	, O
15	борющиеся O
16	за O
17	наше O
18	будущее O
19	, O
20	они O
21	же O
22	выложили O
23	код O
24	для O
25	тренировки O
26	( O
27	а O
28	повторить O
29	смогут O
30	лишь O
31	GAFA B-Organization
32	компании O
33	) O
34	и O
35	все O
36	датасеты O
37	, O
38	не O
39	так O
40	ли O
41	? O

# sent_id = 902
# text =   На практике OpenAI уже давно не Open, а недавняя история с DALLE-2 / Midjourney / Stable Diffusion скорее иллюстрируют тренд.
# relations = "Model_hasAuthor_Organization 0 0, Model_hasAuthor_Organization 1 0, Model_hasAuthor_Organization 2 0"
1	На O
2	практике O
3	OpenAI B-Organization
4	уже O
5	давно O
6	не O
7	Open O
8	, O
9	а O
10	недавняя O
11	история O
12	с O
13	DALLE-2 B-Model
14	/ O
15	Midjourney B-Model
16	/ O
17	Stable B-Model
18	Diffusion I-Model
19	скорее O
20	иллюстрируют O
21	тренд O
22	. O

# sent_id = 903
# text =   Наверное стоит только сказать, что это sequence-to-sequence encoder-decoder трансформерная модель, без особого снижения длины инпута с довольном стандартным окном в 25 миллисекунд и шагом в 10 миллисекунд, работающая на аудио в 16 килогерц.
# relations = ""
1	Наверное O
2	стоит O
3	только O
4	сказать O
5	, O
6	что O
7	это O
8	sequence B-Model
9	- I-Model
10	to I-Model
11	- I-Model
12	sequence I-Model
13	encoder I-Model
14	- I-Model
15	decoder I-Model
16	трансформерная O
17	модель O
18	, O
19	без O
20	особого O
21	снижения O
22	длины O
23	инпута O
24	с O
25	довольном O
26	стандартным O
27	окном O
28	в O
29	25 O
30	миллисекунд O
31	и O
32	шагом O
33	в O
34	10 O
35	миллисекунд O
36	, O
37	работающая O
38	на O
39	аудио O
40	в O
41	16 O
42	килогерц O
43	. O

# sent_id = 904
# text =   Решать конечно вам для вашего конкретного приложения, но если сравнивать только саму модель распознавания, а не весь обвес в виде сервиса (понятно, что тут VAD и детектор языка запихали тоже в модель), например с древними бенчмарками из silero-models, то самые маленькие модели на CPU в расчете на 1 ядро (1 ядро = 2 потока) отличаются по скорости … на два порядка.
# relations = ""
1	Решать O
2	конечно O
3	вам O
4	для O
5	вашего O
6	конкретного O
7	приложения O
8	, O
9	но O
10	если O
11	сравнивать O
12	только O
13	саму O
14	модель O
15	распознавания O
16	, O
17	а O
18	не O
19	весь O
20	обвес O
21	в O
22	виде O
23	сервиса O
24	( O
25	понятно O
26	, O
27	что O
28	тут O
29	VAD B-Method
30	и O
31	детектор O
32	языка O
33	запихали O
34	тоже O
35	в O
36	модель O
37	) O
38	, O
39	например O
40	с O
41	древними O
42	бенчмарками O
43	из O
44	silero B-Model
45	- I-Model
46	models I-Model
47	, O
48	то O
49	самые O
50	маленькие O
51	модели O
52	на O
53	CPU O
54	в O
55	расчете O
56	на O
57	1 O
58	ядро O
59	( O
60	1 O
61	ядро O
62	= O
63	2 O
64	потока O
65	) O
66	отличаются O
67	по O
68	скорости O
69	… O
70	на O
71	два O
72	порядка O
73	. O

# sent_id = 905
# text =   Для наших моделей из прошлого релиза, многие из этих датасетов тоже как бы "zero-shot" (то есть у нас нет соответствующего большого тренировочного датасета).
# relations = ""
1	Для O
2	наших O
3	моделей O
4	из O
5	прошлого O
6	релиза O
7	, O
8	многие O
9	из O
10	этих O
11	датасетов O
12	тоже O
13	как O
14	бы O
15	" O
16	zero B-Method
17	- I-Method
18	shot I-Method
19	" O
20	( O
21	то O
22	есть O
23	у O
24	нас O
25	нет O
26	соответствующего O
27	большого O
28	тренировочного O
29	датасета O
30	) O
31	. O

# sent_id = 906
# text =   К этой группе относятся решения от крупнейших компаний: Amazon Machine Learning, Microsoft Azure Machine Learning и Microsoft Cognitive Services, Google Cloud Prediction API и Google Cloud Machine Learning, IBM Watson Cloud и AlchemyAPI, BigML и другие.
# relations = ""
1	К O
2	этой O
3	группе O
4	относятся O
5	решения O
6	от O
7	крупнейших O
8	компаний O
9	: O
10	Amazon B-Application
11	Machine I-Application
12	Learning I-Application
13	, O
14	Microsoft B-Application
15	Azure I-Application
16	Machine I-Application
17	Learning I-Application
18	и O
19	Microsoft B-Application
20	Cognitive I-Application
21	Services I-Application
22	, O
23	Google B-Application
24	Cloud I-Application
25	Prediction I-Application
26	API I-Application
27	и O
28	Google B-Application
29	Cloud I-Application
30	Machine I-Application
31	Learning I-Application
32	, O
33	IBM B-Application
34	Watson I-Application
35	Cloud I-Application
36	и O
37	AlchemyAPI B-Application
38	, O
39	BigML B-Application
40	и O
41	другие O
42	. O

# sent_id = 907
# text =   Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).
# relations = "Application_isAppliedTo_Object 3 0, Application_isUsedIn_Science 3 1, Application_isUsedIn_Science 4 1, Application_isUsedForSolving_Task 3 6, Application_isUsedForSolving_Task 3 5, Application_isUsedForSolving_Task 3 4, Application_isUsedForSolving_Task 2 3, Application_isUsedForSolving_Task 2 2, Application_isUsedForSolving_Task 1 1, Application_isUsedForSolving_Task 1 0, Application_isUsedIn_Science 0 0, Application_isUsedIn_Science 0 1, Application_isUsedIn_Science 2 0, Application_isUsedIn_Science 3 0, Application_isUsedIn_Science 4 0, Library_isUsedIn_Science 0 0"
1	Возможности O
2	этого O
3	сервиса O
4	в O
5	области B-Science
6	анализа I-Science
7	речи I-Science
8	и I-Science
9	естественного I-Science
10	языка I-Science
11	пока O
12	ограничиваются O
13	английским B-Lang
14	языком I-Lang
15	, O
16	однако O
17	многие O
18	другие O
19	сервисы O
20	поддерживают O
21	русский B-Lang
22	язык O
23	, O
24	например O
25	, O
26	полностью O
27	бесплатный O
28	wit.ai B-Application
29	, O
30	приобретённый O
31	Facebook B-Organization
32	, O
33	и O
34	его O
35	российский O
36	конкурент O
37	api.ai B-Application
38	( O
39	понимание B-Task
40	текстовых I-Task
41	и I-Task
42	голосовых I-Task
43	команд I-Task
44	и I-Task
45	вопросов I-Task
46	на O
47	естественных O
48	языках O
49	, O
50	преобразование B-Task
51	речи I-Task
52	в I-Task
53	текст I-Task
54	) O
55	, O
56	IBM B-Application
57	AlchemyAPI I-Application
58	( O
59	анализ B-Task
60	тональности I-Task
61	текста I-Task
62	, O
63	выявление B-Task
64	сущностей I-Task
65	и I-Task
66	ключевых I-Task
67	слов I-Task
68	) O
69	, O
70	Google B-Application
71	Natural I-Application
72	Language I-Application
73	API I-Application
74	( O
75	классификация B-Task
76	текстов I-Task
77	, O
78	графы B-Object
79	связей I-Object
80	, O
81	извлечение B-Task
82	информации I-Task
83	из I-Task
84	текстов I-Task
85	, O
86	анализ B-Task
87	тональности I-Task
88	, O
89	намерений O
90	, O
91	извлечение O
92	инсайтов O
93	; O
94	поддерживает O
95	русский O
96	язык O
97	с O
98	помощью O
99	технологии O
100	машинного B-Science
101	перевода I-Science
102	Google B-Application
103	Translate I-Application
104	, O
105	использует O
106	глубокое O
107	обучение O
108	и O
109	word2vec B-Library
110	) O
111	. O

# sent_id = 908
# text =   Google Natural Language API  поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec.
# relations = "Application_isUsedIn_Science 0 0, Library_isUsedIn_Science 0 0"
1	Google B-Application
2	Natural I-Application
3	Language I-Application
4	API I-Application
5	поддерживает O
6	русский B-Lang
7	язык I-Lang
8	с O
9	помощью O
10	технологии O
11	машинного B-Science
12	перевода I-Science
13	Google B-Application
14	Translate I-Application
15	, O
16	использует O
17	глубокое O
18	обучение O
19	и O
20	word2vec B-Library
21	. O

# sent_id = 909
# text =   Например, IBM Watson предлагает инструмент Personality Insights, позволяющий определять черты личности человека, его потребности и ценности, намерения и другие характеристики по его записям в Твиттере, социальных сетях или по другим текстовым источникам.
# relations = ""
1	Например O
2	, O
3	IBM B-Application
4	Watson I-Application
5	предлагает O
6	инструмент O
7	Personality B-Application
8	Insights I-Application
9	, O
10	позволяющий O
11	определять O
12	черты O
13	личности O
14	человека O
15	, O
16	его O
17	потребности O
18	и O
19	ценности O
20	, O
21	намерения O
22	и O
23	другие O
24	характеристики O
25	по O
26	его O
27	записям O
28	в O
29	Твиттере B-Application
30	, O
31	социальных O
32	сетях O
33	или O
34	по O
35	другим O
36	текстовым O
37	источникам O
38	. O

# sent_id = 910
# text =   Например, Diffbot позволяет автоматически сканировать страницы сайтов, извлекать из них нужную информацию: тексты, изображения, видео, информацию о продуктах, комментарии и др., в очищенном в структурированном виде, а также позволяет классифицировать страницы.
# relations = "Application_isUsedForSolving_Task 0 1, Application_isUsedForSolving_Task 0 0"
1	Например O
2	, O
3	Diffbot B-Application
4	позволяет O
5	автоматически O
6	сканировать B-Task
7	страницы I-Task
8	сайтов I-Task
9	, O
10	извлекать O
11	из O
12	них O
13	нужную O
14	информацию O
15	: O
16	тексты O
17	, O
18	изображения O
19	, O
20	видео O
21	, O
22	информацию O
23	о O
24	продуктах O
25	, O
26	комментарии O
27	и O
28  др. O
28	, O
29	в O
30	очищенном O
31	в O
32	структурированном O
33	виде O
34	, O
35	а O
36	также O
37	позволяет O
38	классифицировать B-Task
39	страницы I-Task
40	. O

# sent_id = 911
# text =   При этом используются широкий спектр технологий: анализ структуры страниц, машинное обучение, искусственный интеллект, обработка естественных языков и машинное зрение.
# relations = ""
1	При O
2	этом O
3	используются O
4	широкий O
5	спектр O
6	технологий O
7	: O
8	анализ B-Task
9	структуры I-Task
10	страниц I-Task
11	, O
12	машинное B-Science
13	обучение I-Science
14	, O
15	искусственный B-Science
16	интеллект I-Science
17	, O
18	обработка B-Task
19	естественных I-Task
20	языков I-Task
21	и O
22	машинное B-Science
23	зрение I-Science
24	. O

# sent_id = 912
# text =   Решения, основанные на Deepomatic, позволяют находить информацию о фильме по его постеру, информацию о картине или скульптуре на выставке по ее фото, сделанному на камеру телефона, позволяют скачивать музыку, сфотографировав обложку альбома на диске и т.п.
# relations = "Application_isUsedForSolving_Task 0 0"
1	Решения O
2	, O
3	основанные O
4	на O
5	Deepomatic B-Application
6	, O
7	позволяют O
8	находить B-Task
9	информацию I-Task
10	о I-Task
11	фильме I-Task
12	по O
13	его O
14	постеру O
15	, O
16	информацию O
17	о O
18	картине O
19	или O
20	скульптуре O
21	на O
22	выставке O
23	по O
24	ее O
25	фото O
26	, O
27	сделанному O
28	на O
29	камеру O
30	телефона O
31	, O
32	позволяют O
33	скачивать O
34	музыку O
35	, O
36	сфотографировав O
37	обложку O
38	альбома O
39	на O
40	диске O
41	и O
42	т.п. O

# sent_id = 913
# text =   В течение четырех лет вышло несколько версий модели, способных транскрибировать лекции, телефонные разговоры, телевизионные программы, радиошоу и другие прямые трансляции с «человеческой точностью».
# relations = "Model_isUsedForSolving_Task 0 0"
1	В O
2	течение O
3	четырех O
4	лет O
5	вышло O
6	несколько O
7	версий O
8	модели B-Model
9	, O
10	способных O
11	транскрибировать B-Task
12	лекции I-Task
13	, O
14	телефонные O
15	разговоры O
16	, O
17	телевизионные O
18	программы O
19	, O
20	радиошоу O
21	и O
22	другие O
23	прямые O
24	трансляции O
25	с O
26	« O
27	человеческой O
28	точностью O
29	» O
30	. O

# sent_id = 914
# text =   Модель DeepSpeech представляет собой сквозную обучаемую архитектуру на уровне символов, которая может транскрибировать аудио на различных языках.
# relations = "Model_isUsedForSolving_Task 0 0"
1	Модель O
2	DeepSpeech B-Model
3	представляет O
4	собой O
5	сквозную O
6	обучаемую O
7	архитектуру O
8	на O
9	уровне O
10	символов O
11	, O
12	которая O
13	может O
14	транскрибировать B-Task
15	аудио I-Task
16	на O
17	различных O
18	языках O
19	. O

# sent_id = 915
# text =   Вдохновленная этими усилиями по сбору данных, исследовательская группа Mozilla в сотрудничестве с группой открытых инноваций запустила проект Common Voice, цель которого заключалась в сборе и проверке речевых данных.
# relations = "Activity_hasAuthor_Organization 0 0"
1	Вдохновленная O
2	этими O
3	усилиями O
4	по O
5	сбору O
6	данных O
7	, O
8	исследовательская O
9	группа O
10	Mozilla B-Organization
11	в O
12	сотрудничестве O
13	с O
14	группой O
15	открытых O
16	инноваций O
17	запустила O
18	проект O
19	Common B-Activity
20	Voice I-Activity
21	, O
22	цель O
23	которого O
24	заключалась B-Task_isSolvedIn_Activity
25	в I-Task_isSolvedIn_Activity
26	сборе O
27	и O
28	проверке B-Task
29	речевых I-Task
30	данных I-Task
31	. O

# sent_id = 916
# text =   Common Voice включает не только речевые записи, но и из добровольно предоставленные метаданные, такие как возраст, пол и акцент говорящего.
# relations = ""
1	Common B-Activity
2	Voice I-Activity
3	включает O
4	не O
5	только O
6	речевые B-Object
7	записи I-Object
8	, O
9	но O
10	и O
11	из O
12	добровольно O
13	предоставленные O
14	метаданные B-Object
15	, O
16	такие O
17	как O
18	возраст O
19	, O
20	пол O
21	и O
22	акцент O
23	говорящего O
24	. O

# sent_id = 917
# text =   Сегодня Common Voice является одним из крупнейших в мире мультиязычных корпусов, являющихся общественным достоянием, с более чем 9 тысячами часов голосовых данных на 60 различных языках, включая такие редкие языки, как валлийский и киньяруанда.
# relations = "Corpus_Language_Lang 0 0, Corpus_Language_Lang 0 1"
1	Сегодня O
2	Common B-Corpus
3	Voice I-Corpus
4	является O
5	одним O
6	из O
7	крупнейших O
8	в O
9	мире O
10	мультиязычных B-Corpus
11	корпусов I-Corpus
12	, O
13	являющихся O
14	общественным O
15	достоянием O
16	, O
17	с O
18	более O
19	чем O
20	9 O
21	тысячами O
22	часов O
23	голосовых O
24	данных O
25	на O
26	60 O
27	различных O
28	языках O
29	, O
30	включая O
31	такие O
32	редкие O
33	языки O
34	, O
35	как O
36	валлийский B-Lang
37	и O
38	киньяруанда B-Lang
39	. O

# sent_id = 918
# text =   На сегодняшний день Common Voice представляет собой один из крупнейших в мире мультиязычных корпусов, включающих такие редкие языки, как валлийский и киньяруанда.
# relations = "Corpus_Language_Lang 0 0, Corpus_Language_Lang 0 1"
1	На O
2	сегодняшний O
3	день O
4	Common B-Corpus
5	Voice I-Corpus
6	представляет O
7	собой O
8	один O
9	из O
10	крупнейших O
11	в O
12	мире O
13	мультиязычных B-Corpus
14	корпусов I-Corpus
15	, O
16	включающих O
17	такие O
18	редкие O
19	языки O
20	, O
21	как O
22	валлийский B-Lang
23	и O
24	киньяруанда B-Lang
25	. O

# sent_id = 919
# text =   В нашем случае цель была сформулирована как повышение эффективности поиска кандидатов.
# relations = ""
26	В O
27	нашем O
28	случае O
29	цель O
30	была O
31	сформулирована O
32	как O
33	повышение B-Task
34	эффективности I-Task
35	поиска I-Task
36	кандидатов I-Task
37	. O

# sent_id = 920
# text =   Основная задача здесь — найти эффективный способ отображения соответствия кандидатов и навыков.
# relations = ""
1	Основная O
2	задача O
3	здесь O
4	— O
5	найти B-Task
6	эффективный I-Task
7	способ I-Task
8	отображения I-Task
9	соответствия I-Task
10	кандидатов I-Task
11	и I-Task
12	навыков I-Task
13	. O

# sent_id = 921
# text =   Кодирование в переменные — One-Hot Encoding (OHE) 
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Кодирование O
2	в O
3	переменные O
4	— O
5	One B-Method
6	- I-Method
7	Hot I-Method
8	Encoding I-Method
9	( O
10	OHE B-Method
11	) O

# sent_id = 922
# text =   Для этого используют метод TF-IDF.
# relations = ""
1	Для O
2	этого O
3	используют O
4	метод O
5	TF B-Metric
6	- I-Metric
7	IDF I-Metric
8	. O

# sent_id = 923
# text =   Соответственно, можно схлопнуть похожие навыки в некоторые факторы/компоненты/латентные признаки.
# relations = ""
1	Соответственно O
2	, O
3	можно O
4	схлопнуть O
5	похожие O
6	навыки O
7	в O
8	некоторые O
9	факторы B-Object
10	/ O
11	компоненты B-Object
12	/ O
13	латентные B-Object
14	признаки I-Object
15	. O

# sent_id = 924
# text =   Одним из подходов, позволяющих находить такие компоненты, является группа методов матричной факторизации.
# relations = "Method_isAppliedTo_Object 0 0"
1	Одним O
2	из O
3	подходов O
4	, O
5	позволяющих O
6	находить O
7	такие O
8	компоненты B-Object
9	, O
10	является O
11	группа O
12	методов B-Method
13	матричной I-Method
14	факторизации I-Method
15	. O

# sent_id = 925
# text =   Полученные представления кандидатов и навыков называют эмбедингами.
# relations = ""
1	Полученные O
2	представления O
3	кандидатов O
4	и O
5	навыков O
6	называют O
7	эмбедингами B-Object
8	. O

# sent_id = 926
# text =   При создании нашей системы рекомендации кандидатов на позиции мы использовали нейронную сеть — StarSpace.
# relations = "Model_includes_Model 0 1"
1	При O
2	создании O
3	нашей O
4	системы O
5	рекомендации O
6	кандидатов O
7	на O
8	позиции O
9	мы O
10	использовали O
11	нейронную B-Model
12	сеть I-Model
13	— O
14	StarSpace B-Model
15	. O

# sent_id = 927
# text =  Другая группа методов, позволяющая решать задачи репрезентации сущностей — репрезентация графов.
# relations = ""
1	Другая O
2	группа O
3	методов O
4	, O
5	позволяющая O
6	решать O
7	задачи B-Task
8	репрезентации I-Task
9	сущностей I-Task
10	— O
11	репрезентация B-Task
12	графов I-Task
13	. O

# sent_id = 928
# text =   Но большинство методов графовой репрезентации работает с одномодальными графами, поэтому обычно двухмодальные графы следует трансформировать в граф, где узлы представлены одним видом сущностей.
# relations = "Method_isAppliedTo_Object 0 0"
1	Но O
2	большинство O
3	методов B-Method
4	графовой I-Method
5	репрезентации I-Method
6	работает B-Method_isAppliedTo_Object
7	с I-Method_isAppliedTo_Object
8	одномодальными B-Object
9	графами I-Object
10	, O
11	поэтому O
12	обычно O
13	двухмодальные B-Object
14	графы I-Object
15	следует O
16	трансформировать O
17	в O
18	граф O
19	, O
20	где O
21	узлы O
22	представлены O
23	одним O
24	видом O
25	сущностей O
26	. O

# sent_id = 929
# text =   В первую очередь рассмотрим метод, основанный на графовой факторизации.
# relations = ""
1	В O
2	первую O
3	очередь O
4	рассмотрим O
5	метод O
6	, O
7	основанный O
8	на O
9	графовой B-Method
10	факторизации I-Method
11	. O

# sent_id = 930
# text =   Это группа методов очень похожа на методы, применяемые для репрезентации текстов — w2v (skip-gram), doc2vec.
# relations = "Method_isAlternativeNameFor_Method 1 0, Method_solves_Task 0 0, Method_solves_Task 2 0, Method_solves_Task 1 0"
1	Это O
2	группа O
3	методов O
4	очень O
5	похожа O
6	на O
7	методы O
8	, O
9	применяемые O
10	для O
11	репрезентации B-Task
12	текстов I-Task
13	— O
14	w2v B-Method 
15	( O
16	skip B-Method
17	- I-Method
18	gram I-Method
19	) O
20	, O
21	doc2vec B-Method
22	. O

# sent_id = 931
# text =   Почитать подробнее про подобные методы графовой репрезентации можно, например, тут — DeepWalk, Node2vec, Graph2vec.
# relations = "Method_includes_Method 0 1, Method_includes_Method 0 2, Method_includes_Method 0 3"
1	Почитать O
2	подробнее O
3	про O
4	подобные O
5	методы B-Method
6	графовой I-Method
7	репрезентации I-Method
8	можно O
9	, O
10	например O
11	, O
12	тут O
13	— O
14	DeepWalk B-Method
15	, O
16	Node2vec B-Method
17	, O
18	Graph2vec B-Method
19	. O

# sent_id = 932
# text =   Сверточные сети на графах (Graph Convolutional Networks).
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Сверточные B-Method
2	сети I-Method
3	на I-Method
4	графах I-Method
5	( O
6	Graph B-Method
7	Convolutional I-Method
8	Networks I-Method
9	) O
10	. O

# sent_id = 933
# text =   Для задачи репрезентации графов связей между сущностями мы использовали фреймворк PyTorch BigGraph — это ещё один фреймворк от Facebook Research.
# relations = "Library_hasAuthor_Organization 0 0, Library_isUsedForSolving_Task 0 0"
1	Для O
2	задачи O
3	репрезентации B-Task
4	графов I-Task
5	связей I-Task
6	между I-Task
7	сущностями I-Task
8	мы O
9	использовали O
10	фреймворк O
11	PyTorch B-Library
12	BigGraph I-Library
13	— O
14	это O
15	ещё O
16	один O
17	фреймворк B-Application_hasAuthor_Organization
18	от I-Application_hasAuthor_Organization
19	Facebook B-Organization
20	Research I-Organization
21	. O

# sent_id = 934
# text =  В этой статье мы научим вас генерировать текст с помощью предварительно обученного GPT-2 — более легкого предшественника GPT-3.
# relations = "Model_isUsedForSolving_Task 0 0"
1	В O
2	этой O
3	статье O
4	мы O
5	научим O
6	вас O
7	генерировать B-Task
8	текст I-Task
9	с O
10	помощью O
11	предварительно O
12	обученного O
13	GPT-2 B-Model
14	— O
15	более O
16	легкого O
17	предшественника O
18	GPT-3 B-Model
19	. O

# sent_id = 935
# text =   Мы будем использовать именитую библиотеку Transformers, разработанную Huggingface.
# relations = "Library_hasAuthor_Organization 0 0"
1	Мы O
2	будем O
3	использовать O
4	именитую O
5	библиотеку O
6	Transformers B-Library
7	, O
8	разработанную B-Application_hasAuthor_Organization
9	Huggingface B-Organization
10	. O

# sent_id = 936
# text =   Модель по умолчанию для конвейера генерации текста — GPT-2, самая популярная модель декодирующего трансформера для генерации языка.
# relations = "Model_isUsedForSolving_Task 1 1, Model_isUsedForSolving_Task 1 0, Model_isUsedForSolving_Task 0 0"
1	Модель B-Model
2	по O
3	умолчанию O
4	для B-Model_isUsedForSolving_Task
5	конвейера O
6	генерации B-Task
7	текста I-Task
8	— O
9	GPT-2 B-Model
10	, O
11	самая O
12	популярная O
13	модель O
14	декодирующего O
15	трансформера B-Model
16	для B-Model_isUsedForSolving_Task
17	генерации B-Task
18	языка I-Task
19	. O

# sent_id = 937
# text =   Эта модель GPT2 от CKIPLab предварительно обучена на китайском корпусе, поэтому мы можем использовать их модель без необходимости заниматься настройкой самостоятельно.
# relations = "Model_isTrainedOn_Corpus 0 0, Model_hasAuthor_Organization 0 0"
1	Эта O
2	модель O
3	GPT2 B-Model
4	от B-Model_hasAuthor_Organization
5	CKIPLab B-Organization
6	предварительно O
7	обучена O
8	на O
9	китайском B-Corpus
10	корпусе I-Corpus
11	, O
12	поэтому O
13	мы O
14	можем O
15	использовать O
16	их O
17	модель O
18	без O
19	необходимости O
20	заниматься O
21	настройкой O
22	самостоятельно O
23	. O

# sent_id = 938
# text =   Энкодер предложений (sentence encoder) – это модель, которая сопоставляет коротким текстам векторы в многомерном пространстве, причём так, что у текстов, похожих по смыслу, и векторы тоже похожи.
# relations = "Method_isAlternativeNameFor_Method 1 0"
1	Энкодер B-Method
2	предложений I-Method
3	( O
4	sentence B-Method
5	encoder I-Method
6	) O
7	– O
8	это O
9	модель O
10	, O
11	которая O
12	сопоставляет O
13	коротким O
14	текстам O
15	векторы O
16	в O
17	многомерном O
18	пространстве O
19	, O
20	причём O
21	так O
22	, O
23	что O
24	у O
25	текстов O
26	, O
27	похожих O
28	по O
29	смыслу O
30	, O
31	и O
32	векторы O
33	тоже O
34	похожи O
35	. O

# sent_id = 939
# text =   Обычно для этой цели используются нейросети, а полученные векторы называются эмбеддингами.
# relations = "Method_isAppliedTo_Object 0 0"
1	Обычно O
2	для O
3	этой O
4	цели O
5	используются O
6	нейросети B-Method
7	, O
8	а O
9	полученные O
10	векторы O
11	называются O
12	эмбеддингами B-Object
13	. O

# sent_id = 940
# text =   Они полезны для кучи задач, например, few-shot классификации текстов, семантического поиска, или оценки качества перефразирования.
# relations = ""
1	Они O
2	полезны O
3	для O
4	кучи O
5	задач O
6	, O
7	например O
8	, O
9	few B-Task
10	- I-Task
11	shot I-Task
12	классификации I-Task
13	текстов I-Task
14	, O
15	семантического B-Task
16	поиска I-Task
17	, O
18	или O
19	оценки B-Task
20	качества I-Task
21	перефразирования I-Task
22	. O

# sent_id = 941
# text =   Самой качественной моделью оказался mUSE, самой быстрой из предобученных – FastText, а по балансу скорости и качества победил rubert-tiny2.
# relations = ""
1	Самой O
2	качественной O
3	моделью O
4	оказался O
5	mUSE B-Model
6	, O
7	самой O
8	быстрой O
9	из O
10	предобученных O
11	– O
12	FastText B-Model
13	, O
14	а O
15	по O
16	балансу O
17	скорости O
18	и O
19	качества O
20	победил O
21	rubert B-Model
22	- I-Model
23	tiny2 I-Model
24	. O

# sent_id = 942
# text =   Первой известной попыткой системно сравнить английские эмбеддинги предложений был SentEval, сочетающий чисто лингвистические задачи со вполне прикладными.
# relations = "Dataset_Language_Lang 0 0"
1	Первой O
2	известной O
3	попыткой O
4	системно O
5	сравнить O
6	английские B-Lang
7	эмбеддинги B-Object
8	предложений O
9	был O
10	SentEval B-Dataset
11	, O
12	сочетающий O
13	чисто O
14	лингвистические O
15	задачи O
16	со O
17	вполне O
18	прикладными O
19	. O

# sent_id = 943
# text =   Для русского языка тоже было создано немало разного рода бенчмарков NLU моделей:RussianSuperGLUE: бенчмарк "сложных" NLP задач; фокус на дообучаемых моделях.
# relations = "Metric_isUsedFor_Model 0 0, Model_isUsedInSolving_Task 0 0, Metric_isUsedIn_Task 0 0"
1	Для O
2	русского B-Lang
3	языка O
4	тоже O
5	было O
6	создано O
7	немало O
8	разного O
9	рода O
10	бенчмарков O
11	NLU B-Model
12	моделей I-Model
13	: O
14	RussianSuperGLUE B-Metric
15	: O
16	бенчмарк O
17	" O
18	сложных O
19	" O
20	NLP B-Task
21	задач I-Task
22	; O
23	фокус O
24	на O
25	дообучаемых O
26	моделях O
27	. O

# sent_id = 944
# text = MOROCCO: RussianSuperGLUE + оценка производительности, довольно трудновоспроизводимый бенчмарк.
# relations = ""
1	MOROCCO B-Model
2	: O
3	RussianSuperGLUE B-Model
4	+ O
5	оценка O
6	производительности O
7	, O
8	довольно O
9	трудновоспроизводимый O
10	бенчмарк O
11	. O

# sent_id = 945
# text =   RuSentEval: бенчмарк BERT-подобных энкодеров предложений на лингвистических задачах.
# relations = ""
1	RuSentEval B-Application
2	: O
3	бенчмарк O
4	BERT B-Model
5	- I-Model
6	подобных I-Model
7	энкодеров I-Model
8	предложений I-Model
9	на O
10	лингвистических O
11	задачах O
12	. O

# sent_id = 946
# text =   SentEvalRu и deepPavlovEval: два хороших, но давно не обновлявшихся прикладных бенчмарка.
# relations = ""
1	SentEvalRu B-Application
2	и O
3	deepPavlovEval B-Application
4	: O
5	два O
6	хороших O
7	, O
8	но O
9	давно O
10	не O
11	обновлявшихся O
12	прикладных O
13	бенчмарка O
14	. O

# sent_id = 947
# text =   С тех пор появилось много новых русскоязычных моделей, включая rubert-tiny2, поэтому и бенчмарк пришло время обновить.
# relations = ""
1	С O
2	тех O
3	пор O
4	появилось O
5	много O
6	новых O
7	русскоязычных O
8	моделей O
9	, O
10	включая O
11	rubert B-Model
12	- I-Model
13	tiny2 I-Model
14	, O
15	поэтому O
16	и O
17	бенчмарк O
18	пришло O
19	время O
20	обновить O
21	. O

# sent_id = 948
# text =   В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.
# relations = "Model_isModificationOf_Model 1 0, Model_isModificationOf_Model 2 0, Model_isModificationOf_Model 3 0, Model_isModificationOf_Model 4 0, Model_isModificationOf_Model 5 0, Model_isModificationOf_Model 6 0, Model_isModificationOf_Model 7 0, Model_isModificationOf_Model 8 0, Model_isModificationOf_Model 9 0, Model_isModificationOf_Model 10 0, Model_isModificationOf_Model 11 0, Model_isModificationOf_Model 12 0, Model_hasAuthor_Organization 1 0, Model_hasAuthor_Organization 2 0, Model_hasAuthor_Organization 3 0, Model_hasAuthor_Organization 4 1, Model_hasAuthor_Organization 5 1, Model_hasAuthor_Organization 6 1, Model_hasAuthor_Organization 7 1, Model_includes_Model 0 1, Model_includes_Model 0 2, Model_includes_Model 0 3, Model_includes_Model 0 4, Model_includes_Model 0 5, Model_includes_Model 0 6, Model_includes_Model 0 7, Model_includes_Model 0 8, Model_includes_Model 0 9, Model_includes_Model 0 10, Model_includes_Model 0 11, Model_includes_Model 0 12"
1	В O
2	основу O
3	бенчмарка O
4	легли O
5	BERT B-Model
6	- I-Model
7	подобные I-Model
8	модели I-Model
9	: O
10	sbert_large_nlu_ru B-Model
11	, O
12	sbert_large_mt_nlu_ru B-Model
13	, O
14	и O
15	ruRoberta B-Model
16	- I-Model
17	large I-Model
18	от O
19	Сбера B-Organization
20	; O
21	rubert B-Model
22	- I-Model
23	base I-Model
24	- I-Model
25	cased I-Model
26	- I-Model
27	sentence I-Model
28	, O
29	rubert B-Model
30	- I-Model
31	base I-Model
32	- I-Model
33	cased I-Model
34	- I-Model
35	conversational I-Model
36	, O
37	distilrubert B-Model
38	- I-Model
39	tiny I-Model
40	- I-Model
41	cased I-Model
42	- I-Model
43	conversational I-Model
44	, O
45	и O
46	distilrubert B-Model
47	- I-Model
48	base I-Model
49	- I-Model
50	cased I-Model
51	- I-Model
52	conversational I-Model
53	от O
54	DeepPavlov B-Organization
55	; O
56	мои O
57	rubert B-Model
58	- I-Model
59	tiny I-Model
60	и O
61	rubert B-Model
62	- I-Model
63	tiny2 I-Model
64	; O
65	мультиязычные O
66	LaBSE B-Model
67	( O
68	плюс O
69	урезанная O
70	версия O
71	LaBSE B-Model
72	- I-Model
73	en I-Model
74	- I-Model
75	ru I-Model
76	) O
77	и O
78	старый O
79	добрый O
80	bert B-Model
81	- I-Model
82	base I-Model
83	- I-Model
84	multilingual I-Model
85	- I-Model
86	cased I-Model
87	. O

# sent_id = 949
# text =   Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.
# relations = "Model_hasAuthor_Organization 6 0, Model_hasAuthor_Organization 5 0"
1	Кроме O
2	этого O
3	, O
4	я O
5	добавил O
6	в O
7	бенчмарк O
8	разные O
9	T5 B-Model
10	модели I-Model
11	, O
12	т.к. O
13	они O
14	тоже O
15	должны O
16	хорошо O
17	понимать O
18	тексты O
19	: O
20	мои O
21	rut5-small B-Model
22	, O
23	rut5-base B-Model
24	, O
25	rut5-base B-Model
26	- I-Model
27	multitask I-Model
28	, O
29	и O
30	rut5-base B-Model
31	- I-Model
32	paraphraser I-Model
33	, O
34	и O
35	Сберовские B-Organization
36	ruT5-base B-Model
37	и O
38	ruT5-large B-Model
39	. O

# sent_id = 950
# text =   Помимо BERTов и T5, я включил в бенчмарк большие мультиязычные модели Laser от FAIR и USE-multilingual-large от Google.
# relations = "Model_hasAuthor_Organization 0 0, Model_hasAuthor_Organization 1 1"
1	Помимо O
2	BERTов O
3	и O
4	T5 O
5	, O
6	я O
7	включил O
8	в O
9	бенчмарк O
10	большие O
11	мультиязычные O
12	модели O
13	Laser B-Model
14	от O
15	FAIR B-Organization
16	и O
17	USE B-Model
18	- I-Model
19	multilingual I-Model
20	- I-Model
21	large I-Model
22	от O
23	Google B-Organization
24	. O

# sent_id = 951
# text =   В качестве быстрого бейзлайна, я добавил FastText, а именно, geowac_tokens_none_fasttextskipgram_300_5_2020  с RusVectores, а также его сжатую версию.
# relations = ""
1	В O
2	качестве O
3	быстрого O
4	бейзлайна O
5	, O
6	я O
7	добавил O
8	FastText B-Model
9	, O
10	а O
11	именно O
12	, O
13	geowac_tokens_none_fasttextskipgram_300_5_2020 B-Model
14	с O
15	RusVectores B-Model
16	, O
17	а O
18	также O
19	его O
20	сжатую O
21	версию O
22	. O

# sent_id = 952
# text =   Наконец, я добавил парочку "моделей", которые вообще не выучивают никаких параметров, а просто используют HashingVectorizer для превращения текста в вектор признаков.
# relations = ""
1	Наконец O
2	, O
3	я O
4	добавил O
5	парочку O
6	" O
7	моделей O
8	" O
9	, O
10	которые O
11	вообще O
12	не O
13	выучивают O
14	никаких O
15	параметров O
16	, O
17	а O
18	просто O
19	используют O
20	HashingVectorizer B-Application
21	для O
22	превращения O
23	текста O
24	в O
25	вектор O
26	признаков O
27	. O

# sent_id = 953
# text =   Это доработанная версия rubert-tiny: я расширил словарь модели c 30К до 80К токенов, увеличил максимальную длину текста с 512 до 2048 токенов, и дообучил модель на комбинации задач masked language modelling, natural language inference, и аппроксимации эмбеддингов LaBSE.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1, Model_isUsedForSolving_Task 0 2"
1	Это O
2	доработанная O
3	версия O
4	rubert B-Model
5	- I-Model
6	tiny I-Model
7	: O
8	я O
9	расширил O
10	словарь O
11	модели O
12	c O
13	30К O
14	до O
15	80К O
16	токенов O
17	, O
18	увеличил O
19	максимальную O
20	длину O
21	текста O
22	с O
23	512 O
24	до O
25	2048 O
26	токенов O
27	, O
28	и O
29	дообучил O
30	модель O
31	на O
32	комбинации O
33	задач O
34	masked B-Task
35	language I-Task
36	modelling I-Task
37	, O
38	natural B-Task
39	language I-Task
40	inference I-Task
41	, O
42	и O
43	аппроксимации B-Task
44	эмбеддингов I-Task
45	LaBSE I-Task
46	. O

# sent_id = 954
# text =   В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.
# relations = "Dataset_isTrainedForSolving_Task 3 7, Dataset_isTrainedForSolving_Task 3 6, Dataset_isTrainedForSolving_Task 2 5, Dataset_isTrainedForSolving_Task 2 4, Task_isAlternativeNameFor_Task 7 6, Task_isAlternativeNameFor_Task 5 4, Dataset_isTrainedForSolving_Task 1 3, Dataset_isTrainedForSolving_Task 1 2, Task_isAlternativeNameFor_Task 3 2, Dataset_isTrainedForSolving_Task 0 1, Dataset_isTrainedForSolving_Task 0 0, Task_isAlternativeNameFor_Task 1 0"
1	В O
2	новой O
3	версии O
4	бенчмарка O
5	я O
6	оставил O
7	всё O
8	те O
9	же O
10	10 O
11	задач O
12	, O
13	что O
14	и O
15	в O
16	прежней O
17	, O
18	но O
19	слегка O
20	изменил O
21	формат O
22	некоторых O
23	из O
24	них O
25	: O
26	Semantic B-Task
27	text I-Task
28	similarity I-Task
29	( O
30	STS B-Task
31	) O
32	на O
33	основе O
34	переведённого O
35	датасета O
36	STS B-Dataset
37	- I-Dataset
38	B I-Dataset
39	; O
40	Paraphrase B-Task
41	identification I-Task
42	( O
43	PI B-Task
44	) O
45	на O
46	основе O
47	датасета O
48	paraphraser.ru B-Dataset
49	; O
50	Natural B-Task
51	language I-Task
52	inference I-Task
53	( O
54	NLI B-Task
55	) O
56	на O
57	датасете O
58	XNLI B-Dataset
59	; O
60	Sentiment B-Task
61	analysis I-Task
62	( O
63	SA B-Task
64	) O
65	на O
66	данных O
67	SentiRuEval2016 B-Dataset
68	. O

# sent_id = 955
# text =   В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.
# relations = "Dataset_Language_Lang 2 0, Dataset_isTrainedForSolving_Task 2 5, Dataset_isTrainedForSolving_Task 2 4, Dataset_isTrainedForSolving_Task 2 6, Task_isAlternativeNameFor_Task 5 4, Dataset_isTrainedForSolving_Task 1 3, Dataset_isTrainedForSolving_Task 1 2, Task_isAlternativeNameFor_Task 3 2, Dataset_isTrainedForSolving_Task 0 1, Dataset_isTrainedForSolving_Task 0 0, Task_isAlternativeNameFor_Task 1 0"
1	В O
2	прошлой O
3	версии O
4	бенчмарка O
5	я O
6	собрал O
7	кривые O
8	тестовые O
9	выборки O
10	, O
11	поэтому O
12	этот O
13	датасет O
14	я O
15	переделал O
16	; O
17	Toxicity B-Task
18	identification I-Task
19	( O
20	TI B-Task
21	) O
22	на O
23	датасете B-Dataset
24	токсичных I-Dataset
25	комментариев I-Dataset
26	из O
27	OKMLCup B-Application
28	; O
29	Inappropriateness B-Task
30	identification I-Task
31	( O
32	II B-Task
33	) O
34	на O
35	датасете B-Dataset
36	Сколтеха I-Dataset
37	; O
38	Intent B-Task
39	classification I-Task
40	( O
41	IC B-Task
42	) O
43	и O
44	её O
45	кросс O
46	- O
47	язычная O
48	версия O
49	ICX B-Task
50	на O
51	датасете O
52	NLU B-Dataset
53	- I-Dataset
54	evaluation I-Dataset
55	- I-Dataset
56	data I-Dataset
57	, O
58	который O
59	я O
60	автоматически O
61	перевёл O
62	на O
63	русский B-Lang
64	. O

# sent_id = 956
# text =   В IC классификатор обучается на русских данных, а в ICX – на английских, а тестируется в обоих случаях на русских.
# relations = "Model_Language_Lang 0 0, Model_Language_Lang 1 1"
1	В O
2	IC B-Model
3	классификатор I-Model
4	обучается O
5	на O
6	русских B-Lang
7	данных O
8	, O
9	а O
10	в O
11	ICX B-Model
12	– O
13	на O
14	английских B-Lang
15	, O
16	а O
17	тестируется O
18	в O
19	обоих O
20	случаях O
21	на O
22	русских O
23	. O

# sent_id = 957
# text =   Распознавание именованных сущностей () на датасетах factRuEval-2016E1 и RuDReC (NE2).
# relations = "Dataset_isAlternativeNameFor_Dataset 2 1, Dataset_isTrainedForSolving_Task 0 0, Dataset_isTrainedForSolving_Task 1 0, Dataset_isTrainedForSolving_Task 2 0"
1	Распознавание B-Task
2	именованных I-Task
3	сущностей I-Task
4	( O
5	) O
6	на O
7	датасетах O
8	factRuEval-2016E1 B-Dataset
9	и O
10	RuDReC B-Dataset
11	( O
12	NE2 B-Dataset
13	) O
14	. O

# sent_id = 958
# text =   Эти две задачи требуют получать эмбеддинги отдельных токенов, а не целых предложений; поэтому модели USE и Laser, не выдающие эмбеддинги токенов "из коробки", в оценке этих задач не участвовали.
# relations = ""
1	Эти O
2	две O
3	задачи O
4	требуют O
5	получать O
6	эмбеддинги O
7	отдельных O
8	токенов O
9	, O
10	а O
11	не O
12	целых O
13	предложений O
14	; O
15	поэтому O
16	модели O
17	USE B-Model
18	и O
19	Laser B-Model
20	, O
21	не O
22	выдающие O
23	эмбеддинги O
24	токенов O
25	" O
26	из O
27	коробки O
28	" O
29	, O
30	в O
31	оценке O
32	этих O
33	задач O
34	не O
35	участвовали O
36	. O

# sent_id = 959
# text =   В задачах STS, PI и NLI оценивается степень связи двух текстов.
# relations = ""
1	В O
2	задачах O
3	STS B-Task
4	, O
5	PI B-Task
6	и O
7	NLI B-Task
8	оценивается O
9	степень O
10	связи O
11	двух O
12	текстов O
13	. O

# sent_id = 960
# text =   Хороший энкодер предложений должен отражать эту степень в их косинусной близости, поэтому для STS и PI мы измеряем качество как Спирмановскую корреляцию косинусной близости и человеческих оценок сходства.
# relations = ""
1	Хороший O
2	энкодер O
3	предложений O
4	должен O
5	отражать O
6	эту O
7	степень O
8	в O
9	их O
10	косинусной B-Metric
11	близости B-Metric
12	, O
13	поэтому O
14	для O
15	STS B-Task
16	и O
17	PI B-Task
18	мы O
19	измеряем O
20	качество O
21	как O
22	Спирмановскую B-Metric
23	корреляцию I-Metric
24	косинусной O
25	близости O
26	и O
27	человеческих O
28	оценок O
29	сходства O
30	. O

# sent_id = 961
# text =   Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).
# relations = "Metric_isAlternativeNameFor_Metric 2 1, Metric_isUsedIn_Task 2 0, Metric_isUsedIn_Task 1 0, Metric_isUsedFor_Model 2 0, Metric_isUsedFor_Model 1 0, Metric_isUsedFor_Model 0 0, Model_isUsedForSolving_Task 0 0"
1	Для O
2	NLI B-Task
3	я O
4	обучил O
5	трёхклассовую O
6	( O
7	entail O
8	/ O
9	contradict O
10	/ O
11	neutral O
12	) O
13	логистическую B-Model
14	регрессию I-Model
15	поверх O
16	косинусной B-Metric
17	близости I-Metric
18	, O
19	и O
20	измеряю O
21	её O
22	точность B-Metric
23	( O
24	accuracy B-Metric
25	) O
26	. O

# sent_id = 962
# text = Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).
# relations = "Metric_isAlternativeNameFor_Metric 2 1, Metric_isUsedIn_Task 2 0, Metric_isUsedIn_Task 1 0, Metric_isUsedFor_Model 2 0, Metric_isUsedFor_Model 1 0, Metric_isUsedFor_Model 0 0, Model_isUsedForSolving_Task 0 0"
1	Для O
2	задачи O
3	NLI B-Task
4	я O
5	провел O
6	обучение O
7	логистической B-Model
8	регрессии I-Model
9	с O
10	тремя O
11	классами O
12	( O
13	entail O
14	/ O
15	contradict O
16	/ O
17	neutral O
18	) O
19	на O
20	основе O
21	косинусной B-Metric
22	близости I-Metric
23	и O
24	измеряю O
25	ее O
26	точность B-Metric
27	( O
28	accuracy B-Metric
29	) O
30	. O

# sent_id = 963
# text =   Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).
# relations = "Metric_isAlternativeNameFor_Metric 2 1, Metric_isUsedIn_Task 2 4, Metric_isUsedIn_Task 2 3, Metric_isUsedIn_Task 2 2, Metric_isUsedIn_Task 1 4, Metric_isUsedIn_Task 1 3, Metric_isUsedIn_Task 1 2, Metric_isUsedIn_Task 0 0, Metric_isUsedIn_Task 0 1"
1	Для O
2	задач O
3	бинарной O
4	классификации O
5	TI B-Task
6	и O
7	II B-Task
8	я O
9	измеряю O
10	ROC B-Metric
11	AUC I-Metric
12	, O
13	а O
14	в O
15	задачах O
16	многоклассовой O
17	классификации O
18	SA B-Task
19	, O
20	IC B-Task
21	и O
22	ICX B-Task
23	– O
24	точность B-Metric
25	( O
26	accuracy B-Metric
27	) O
28	. O

# sent_id = 964
# text =   Для всех задач классификации я обучаю логистическую регрессию либо KNN поверх эмбеддингов предложений, и выбираю лучшую модель из двух.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 1 0"
1	Для O
2	всех O
3	задач O
4	классификации B-Task
5	я O
6	обучаю O
7	логистическую B-Model
8	регрессию I-Model
9	либо O
10	KNN B-Model
11	поверх O
12	эмбеддингов O
13	предложений O
14	, O
15	и O
16	выбираю O
17	лучшую O
18	модель O
19	из O
20	двух O
21	. O

# sent_id = 965
# text =   Для задач NER я классифицировал токены логистической регрессией поверх их эмбеддингов, и измерял macro F1 по всем классам токенов, кроме О. 
# relations = "Method_solves_Task 0 0, Metric_isUsedIn_Task 0 0, Metric_isAppliedTo_Method 0 0"
1	Для O
2	задач O
3	NER B-Task
4	я O
5	классифицировал O
6	токены O
7	логистической B-Method
8	регрессией I-Method
9	поверх O
10	их O
11	эмбеддингов B-TERM
12	, O
13	и O
14	измерял O
15	macro B-Metric
16	F1 I-Metric
17	по O
18	всем O
19	классам O
20	токенов O
21	, O
22	кроме O
23	О O
24	. O

# sent_id = 966
# text =   В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса "O".
# relations = "Object_isUsedInSolving_Task 0 0, Object_isUsedInSolving_Task 0 1, Object_isUsedInSolving_Task 0 2, Object_isUsedInSolving_Task 1 0, Object_isUsedInSolving_Task 1 1, Object_isUsedInSolving_Task 1 2, Metric_isUsedIn_Task 0 1, Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 0 1, Task_isAlternativeNameFor_Task 1 0, Method_solves_Task 0 0, Method_solves_Task 0 1, Method_solves_Task 0 2, Metric_isUsedIn_Task 0 0, Metric_isUsedIn_Task 0 2, Metric_isAppliedTo_Method 0 0"
1	В O
2	задаче O
3	извлечения B-Task
4	именованных I-Task
5	сущностей I-Task
6	( O
7	NER B-Task
8	) O
9	я O
10	использовал O
11	логистическую B-Method
12	регрессию I-Method
13	для O
14	классификации B-Task
15	токенов B-Object
16	на O
17	основе O
18	их O
19	эмбеддингов B-Object
20	и O
21	вычислял O
22	macro B-Metric
23	F1 I-Metric
24	для O
25	всех O
26	классов O
27	токенов O
28	, O
29	кроме O
30	класса O
31	" O
32	O O
33	" O
34	. O

# sent_id = 967
# text =  Поскольку разные модели токенизируют тексты по-разному, я токенизировал все тексты razdel'ом, и вычислял эмбеддинг слова как средний эмбеддинг его токенов.
# relations = ""
1	Поскольку O
2	разные O
3	модели O
4	токенизируют O
5	тексты O
6	по O
7	- O
8	разному O
9	, O
10	я O
11	токенизировал O
12	все O
13	тексты O
14	razdel'ом B-Technology
15	, O
16	и O
17	вычислял O
18	эмбеддинг O
19	слова O
20	как O
21	средний O
22	эмбеддинг O
23	его O
24	токенов O
25	. O

# sent_id = 968
# text =   Единого победителя нет, но MUSE, sbert_large_mt_nlu_ru и rubert-base-cased-sentence взяли по многу призовых мест.
# relations = ""
1	Единого O
2	победителя O
3	нет O
4	, O
5	но O
6	MUSE B-Model
7	, O
8	sbert_large_mt_nlu_ru B-Model
9	и O
10	rubert B-Model
11	- I-Model
12	base I-Model
13	- I-Model
14	cased I-Model
15	- I-Model
16	sentence I-Model
17	взяли O
18	по O
19	многу O
20	призовых O
21	мест O
22	. O

# sent_id = 969
# text =   Удивительно, но модели T5 очень хорошо показали себя на задачах NER.
# relations = "Model_isUsedForSolving_Task 0 0"
1	Удивительно O
2	, O
3	но O
4	модели O
5	T5 B-Model
6	очень O
7	хорошо O
8	показали O
9	себя O
10	на O
11	задачах O
12	NER B-Task
13	. O

# sent_id = 970
# text =   Самыми качественными энкодерами предложений оказались мультиязычные MUSE, LaBSE и Laser.
# relations = ""
1	Самыми O
2	качественными O
3	энкодерами O
4	предложений O
5	оказались O
6	мультиязычные O
7	MUSE B-Model
8	, O
9	LaBSE B-Model
10	и O
11	Laser B-Model
12	. O

# sent_id = 971
# text =   Но выбирать стоит из Парето-оптимальных моделей: таких, что ни одна другая модель не превосходит их по всем критериям.
# relations = ""
1	Но O
2	выбирать O
3	стоит O
4	из O
5	Парето B-Model
6	- I-Model
7	оптимальных I-Model
8	моделей I-Model
9	: O
10	таких O
11	, O
12	что O
13	ни O
14	одна O
15	другая O
16	модель O
17	не O
18	превосходит O
19	их O
20	по O
21	всем O
22	критериям O
23	. O

# sent_id = 972
# text =   Из 25 моделей только 12 Парето-оптимальны:MUSE, rubert-tiny2, FT_geowac, Hashing_1000_char и Hashing_1000 обладают самым лучшим качеством для своей скорости на CPU; MUSE, LaBSE, rubert-tiny2, и distilbert-tiny обладают наилучшим качеством для своей скорости на GPU;MUSE, LaBSE, rubert-tiny2, rubert-tiny, FT_geowac_21mb, и Hashing_1000_char обладают наилучшим качеством для своего размера.
# relations = ""
1	Из O
2	25 O
3	моделей O
4	только O
5	12 O
6	Парето O
7	- O
8	оптимальны O
9	: O
10	MUSE B-Model
11	, O
12	rubert B-Model
13	- I-Model
14	tiny2 I-Model
15	, O
16	FT_geowac B-Model
17	, O
18	Hashing_1000_char B-Model
19	и O
20	Hashing_1000 B-Model
21	обладают O
22	самым O
23	лучшим O
24	качеством O
25	для O
26	своей O
27	скорости O
28	на O
29	CPU O
30	; O
31	MUSE B-Model
32	, O
33	LaBSE B-Model
34	, O
35	rubert B-Model
36	- I-Model
37	tiny2 I-Model
38	, O
39	и O
40	distilbert B-Model
41	- I-Model
42	tiny I-Model
43	обладают O
44	наилучшим O
45	качеством O
46	для O
47	своей O
48	скорости O
49	на O
50	GPU O
51	; O
52	MUSE B-Model
53	, O
54	LaBSE B-Model
55	, O
56	rubert B-Model
57	- I-Model
58	tiny2 I-Model
59	, O
60	rubert B-Model
61	- I-Model
62	tiny I-Model
63	, O
64	FT_geowac_21 B-Model
65	mb O
66	, O
67	и O
68	Hashing_1000_char B-Model
69	обладают O
70	наилучшим O
71	качеством O
72	для O
73	своего O
74	размера O
75	. O

# sent_id = 973
# text =   Однажды нам понадобилось выбрать синтаксический парсер для работы с русским языком.
# relations = ""
1	Однажды O
2	нам O
3	понадобилось O
4	выбрать O
5	синтаксический B-Application
6	парсер I-Application
7	для O
8	работы O
9	с O
10	русским O
11	языком O
12	. O

# sent_id = 974
# text =   Для этого мы углубились в дебри морфологии и токенизации, протестировали разные варианты и оценили их применение.
# relations = ""
1	Для O
2	этого O
3	мы O
4	углубились O
5	в O
6	дебри O
7	морфологии B-Science
8	и O
9	токенизации B-Method
10	, O
11	протестировали O
12	разные O
13	варианты O
14	и O
15	оценили O
16	их O
17	применение O
18	. O

# sent_id = 975
# text =   В первой строке предложение разобрано в рамках грамматики зависимостей.
# relations = ""
1	В O
2	первой O
3	строке O
4	предложение O
5	разобрано O
6	в O
7	рамках O
8	грамматики B-Method
9	зависимостей I-Method
10	. O

# sent_id = 976
# text =   Во второй строке разбор идет в соответствии с грамматикой непосредственно составляющих.
# relations = ""
1	Во O
2	второй O
3	строке O
4	разбор O
5	идет O
6	в O
7	соответствии O
8	с O
9	грамматикой B-Method
10	непосредственно I-Method
11	составляющих I-Method
12	. O

# sent_id = 977
# text =   Поэтому в автоматическом парсинге русского языка принято работать исходя из грамматики зависимостей.
# relations = "Method_solves_Task 0 0"
1	Поэтому O
2	в O
3	автоматическом B-Task
4	парсинге I-Task
5	русского B-Lang
6	языка O
7	принято O
8	работать O
9	исходя O
10	из O
11	грамматики B-Method
12	зависимостей I-Method
13	. O

# sent_id = 978
# text =   Чтобы облегчить себе выбор парсера, мы обратили свой взгляд на проект Universal Dependencies и недавно прошедшее в его рамках соревнование CoNLL Shared Task.
# relations = ""
1	Чтобы O
2	облегчить O
3	себе O
4	выбор O
5	парсера O
6	, O
7	мы O
8	обратили O
9	свой O
10	взгляд O
11	на O
12	проект O
13	Universal B-Activity
14	Dependencies I-Activity
15	и O
16	недавно O
17	прошедшее O
18	в O
19	его O
20	рамках O
21	соревнование O
22	CoNLL O
23	Shared O
24	Task O
25	. O

# sent_id = 979
# text =   Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.
# relations = "Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 0 1, Method_solves_Task 0 0, Object_isUsedInSolving_Task 0 0, Object_isUsedInSolving_Task 1 0"
1	Universal B-Activity
2	Dependencies I-Activity
3	— O
4	это O
5	проект O
6	по O
7	унификации B-Task
8	разметки I-Task
9	синтаксических B-Object
10	корпусов I-Object
11	( O
12	трибанков B-Object
13	) O
14	в O
15	рамках O
16	грамматики B-Method
17	зависимостей I-Method
18	. O

# sent_id = 980
# text =   Мы можем оценивать, правильно ли нашли вершину слова — метрика UAS (Unlabeled attachment score).
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	Мы O
2	можем O
3	оценивать O
4	, O
5	правильно O
6	ли O
7	нашли O
8	вершину O
9	слова O
10	— O
11	метрика O
12	UAS B-Metric
13	( O
14	Unlabeled B-Metric
15	attachment I-Metric
16	score I-Metric
17	) O
18	. O

# sent_id = 981
# text =   Мы можем оценивать, корректно ли обнаружены вершины слова, используя метрику UAS (Unlabeled Attachment Score).
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	Мы O
2	можем O
3	оценивать O
4	, O
5	корректно O
6	ли O
7	обнаружены O
8	вершины O
9	слова O
10	, O
11	используя O
12	метрику O
13	UAS B-Metric
14	( O
15	Unlabeled B-Metric
16	Attachment I-Metric
17	Score I-Metric
18	) O
19	. O

# sent_id = 982
# text =   Или оценивать, правильно ли найдена как вершина, так и тип зависимости — метрика LAS (Labeled attachment score).
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	Или O
2	оценивать O
3	, O
4	правильно O
5	ли O
6	найдена O
7	как O
8	вершина O
9	, O
10	так O
11	и O
12	тип O
13	зависимости O
14	— O
15	метрика O
16	LAS B-Metric
17	( O
18	Labeled B-Metric
19	attachment I-Metric
20	score I-Metric
21	) O
22	. O

# sent_id = 983
# text =   Либо проверять, были ли правильно определены и вершина, и тип зависимости, используя метрику LAS (Labeled Attachment Score).
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	Либо O
2	проверять O
3	, O
4	были O
5	ли O
6	правильно O
7	определены O
8	и O
9	вершина O
10	, O
11	и O
12	тип O
13	зависимости O
14	, O
15	используя O
16	метрику O
17	LAS B-Metric
18	( O
19	Labeled B-Metric
20	Attachment I-Metric
21	Score I-Metric
22	) O
23	. O

# sent_id = 984
# text =   Казалось бы, здесь напрашивается оценка точности (accuracy) — считаем, сколько раз мы попали из общего количества случаев.
# relations = "Metric_isAlternativeNameFor_Metric 1 0"
1	Казалось O
2	бы O
3	, O
4	здесь O
5	напрашивается O
6	оценка O
7	точности B-Metric
8	( O
9	accuracy B-Metric
10	) O
11	— O
12	считаем O
13	, O
14	сколько O
15	раз O
16	мы O
17	попали O
18	из O
19	общего O
20	количества O
21	случаев O
22	. O

# sent_id = 985
# text =   Разработчики, решающие задачи автоматического парсинга, часто берут на вход сырой текст, который в соответствии с пирамидой анализа проходит этапы токенизации и морфологического анализа.
# relations = "Method_solves_Task 0 0, Method_solves_Task 1 0"
1	Разработчики O
2	, O
3	решающие O
4	задачи O
5	автоматического B-Task
6	парсинга I-Task
7	, O
8	часто O
9	берут O
10	на O
11	вход O
12	сырой O
13	текст O
14	, O
15	который O
16	в O
17	соответствии O
18	с O
19	пирамидой O
20	анализа O
21	проходит O
22	этапы O
23	токенизации B-Method
24	и O
25	морфологического B-Method
26	анализа I-Method
27	. O

# sent_id = 986
# text =   Поэтому формулой оценки в данном случае является ф-мера, где точность (precision) — доля точных попаданий относительно общего числа предсказаний, а полнота — доля точных попаданий относительно числа связей в размеченных данных.
# relations = "Metric_isAlternativeNameFor_Metric 2 1" 
1	Поэтому O
2	формулой O
3	оценки O
4	в O
5	данном O
6	случае O
7	является O
8	ф B-Metric
9	- I-Metric
10	мера I-Metric
11	, O
12	где O
13	точность B-Metric
14	( O
15	precision B-Metric
16	) O
17	— O
18	доля O
19	точных O
20	попаданий O
21	относительно O
22	общего O
23	числа O
24	предсказаний O
25	, O
26	а O
27	полнота B-Metric
28	— O
29	доля O
30	точных O
31	попаданий O
32	относительно O
33	числа O
34	связей O
35	в O
36	размеченных O
37	данных O
38	. O

# sent_id = 987
# text =   Очевидно, что все эксперименты проводятся на SynTagRus (разработка ИППИ РАН), в котором более миллиона токенов.
# relations = ""
1	Очевидно O
2	, O
3	что O
4	все O
5	эксперименты B-Activity
6	проводятся O
7	на O
8	SynTagRus B-Dataset
9	( O
10	разработка O
11	ИППИ B-Organization
12	РАН I-Organization
13	) O
14	, O
15	в O
16	котором O
17	более O
18	миллиона O
19	токенов B-Object
20	. O

# sent_id = 988
# text =   По итогам соревнования прошлого года модели, которые обучались на одном и том же SynTagRus, достигли следующих показателей LAS:
# relations = ""
1	По O
2	итогам O
3	соревнования O
4	прошлого O
5	года O
6	модели O
7	, O
8	которые O
9	обучались O
10	на O
11	одном O
12	и O
13	том O
14	же O
15	SynTagRus B-Dataset
16	, O
17	достигли O
18	следующих O
19	показателей O
20	LAS B-Metric
21	: O

# sent_id = 989
# text =   Забегая вперед, заметим, что новая версия UDPipe (Future) оказалась еще выше в этом году.
# relations = "Application_hasAuthor_Organization 0 0"
1	Забегая O
2	вперед O
3	, O
4	заметим O
5	, O
6	что O
7	новая O
8	версия O
9	UDPipe B-Application
10	( O
11	Future B-Organization
12	) O
13	оказалась O
14	еще O
15	выше O
16	в O
17	этом O
18	году O
19	. O

# sent_id = 990
# text =   В список не вошел Syntaxnet — парсер Google.
# relations = "Application_hasAuthor_Organization 0 0"
1	В O
2	список O
3	не O
4	вошел O
5	Syntaxnet B-Application
6	— O
7	парсер O
8	Google B-Organization
9	. O

# sent_id = 991
# text =   Ответ прост: Syntaxnet начинался лишь с этапа морфологического анализа.
# relations = "Method_isUsedIn_Application 0 0"
1	Ответ O
2	прост O
3	: O
4	Syntaxnet B-Application
5	начинался O
6	лишь O
7	с O
8	этапа O
9	морфологического B-Method
10	анализа I-Method
11	. O

# sent_id = 992
# text =   В качестве начальных данных у нас есть табличка выше с лидирующим Syntaxnet и с UDPipe 2.0 где-то на 7 месте.
# relations = ""
1	В O
2	качестве O
3	начальных O
4	данных O
5	у O
6	нас O
7	есть O
8	табличка O
9	выше O
10	с O
11	лидирующим O
12	Syntaxnet B-Application
13	и O
14	с O
15	UDPipe B-Application
16	2.0 I-Application
17	где O
18	- O
19	то O
20	на O
21	7 O
22	месте O
23	. O

# sent_id = 993
# text =   Синтаксис, разумеется, далеко не единственный модуль «под капотом» real-time системы, поэтому тратить на него больше десятка миллисекунд не стоит.
# relations = "Application_isUsedIn_Science 0 0"
1	Синтаксис B-Science
2	, O
3	разумеется O
4	, O
5	далеко O
6	не O
7	единственный O
8	модуль O
9	« O
10	под O
11	капотом O
12	» O
13	real B-Application
14	- I-Application
15	time I-Application
16	системы O
17	, O
18	поэтому O
19	тратить O
20	на O
21	него O
22	больше O
23	десятка O
24	миллисекунд O
25	не O
26	стоит O
27	. O

# sent_id = 994
# text =   Разумеется, синтаксис - не единственный модуль real-time системы, поэтому нецелесообразно затрачивать на него более десятка миллисекунд.
# relations = "Application_isUsedIn_Science 0 0"
1	Разумеется O
2	, O
3	синтаксис B-Science
4	- O
5	не O
6	единственный O
7	модуль O
8	real B-Application
9	- I-Application
10	time I-Application
11	системы O
12	, O
13	поэтому O
14	нецелесообразно O
15	затрачивать O
16	на O
17	него O
18	более O
19	десятка O
20	миллисекунд O
21	. O

# sent_id = 995
# text =   Для русского языка у нас есть достаточно хорошие морфологические анализаторы, которые могут встроиться в нашу пирамиду.
# relations = ""
1	Для O
2	русского B-Lang
3	языка O
4	у O
5	нас O
6	есть O
7	достаточно O
8	хорошие O
9	морфологические B-Application
10	анализаторы I-Application
11	, O
12	которые O
13	могут O
14	встроиться O
15	в O
16	нашу O
17	пирамиду O
18	. O

# sent_id = 996
# text =   Затем начинает работу теггер — штука, которая предсказывает морфологические свойства токена: в каком падеже слово стоит, в каком числе.
# relations = ""
1	Затем O
2	начинает O
3	работу O
4	теггер B-Application
5	— O
6	штука O
7	, O
8	которая O
9	предсказывает O
10	морфологические B-Object
11	свойства I-Object
12	токена I-Object
13	: O
14	в O
15	каком O
16	падеже O
17	слово O
18	стоит O
19	, O
20	в O
21	каком O
22	числе O
23	. O

# sent_id = 997
# text =   В UDPipe есть еще лемматизатор, который подбирает для слов начальную форму.
# relations = ""
1	В O
2	UDPipe B-App_system
3	есть O
4	еще O
5	лемматизатор B-Application
6	, O
7	который O
8	подбирает O
9	для O
10	слов O
11	начальную B-Object
12	форму I-Object
13	. O

# sent_id = 998
# text =   UDPipe — это transition-based архитектура: она работает быстро, за линейное время проходя по всем токенам один раз.
# relations = "Model_includes_Model 1 0"
1	UDPipe B-Model
2	— O
3	это O
4	transition B-Model
5	- I-Model
6	based I-Model
7	архитектура O
8	: O
9	она O
10	работает O
11	быстро O
12	, O
13	за O
14	линейное O
15	время O
16	проходя O
17	по O
18	всем O
19	токенам B-Object
20	один O
21	раз O
22	. O

# sent_id = 999
# text =   RightArc — то же самое, но зависимость строится в другую сторону, и отбрасывается верхушка.
# relations = ""
1	RightArc B-Model
2	— O
3	то O
4	же O
5	самое O
6	, O
7	но O
8	зависимость O
9	строится O
10	в O
11	другую O
12	сторону O
13	, O
14	и O
15	отбрасывается O
16	верхушка O
17	. O

# sent_id = 1000
# text =   У классических transition-based parser возможны три операции, перечисленные выше: стрелка в одну сторону, стрелка в другую сторону и шифт.
# relations = ""
1	У O
2	классических O
3	transition B-Application
4	- I-Application
5	based I-Application
6	parser I-Application
7	возможны O
8	три O
9	операции O
10	, O
11	перечисленные O
12	выше O
13	: O
14	стрелка O
15	в O
16	одну O
17	сторону O
18	, O
19	стрелка O
20	в O
21	другую O
22	сторону O
23	и O
24	шифт O
25	. O

# sent_id = 1001
# text =   Анализатор Mystem (разработка яндекса) в определении частей речи достигает лучших результатов, чем UDPipe.
# relations = "Application_hasAuthor_Organization 0 0"
1	Анализатор O
2	Mystem B-Application
3	( O
4	разработка O
5	яндекса B-Organization
6	) O
7	в O
8	определении O
9	частей O
10	речи O
11	достигает O
12	лучших O
13	результатов O
14	, O
15	чем O
16	UDPipe B-App_system
17	. O

# sent_id = 1002
# text =   Многие знают, что Mystem не полностью понимает морфологическую омонимию.
# relations = "Application_isAppliedTo_Object 0 0"
1	Многие O
2	знают O
3	, O
4	что O
5	Mystem B-Application
6	не O
7	полностью O
8	понимает O
9	морфологическую B-Object
10	омонимию I-Object
11	. O

# sent_id = 1003
# text =   При помощи анализатора RNNMorph.
# relations = ""
1	При O
2	помощи O
3	анализатора O
4	RNNMorph B-Application
5	. O

# sent_id = 1004
# text =   Про него мало кто слышал, но в прошлом году он выиграл соревнование среди морфологических анализаторов, проводившееся в рамках конференции «Диалог».
# relations = ""
1	Про O
2	него O
3	мало O
4	кто O
5	слышал O
6	, O
7	но O
8	в O
9	прошлом O
10	году O
11	он O
12	выиграл O
13	соревнование O
14	среди O
15	морфологических B-Object
16	анализаторов I-Object
17	, O
18	проводившееся O
19	в O
20	рамках O
21	конференции O
22	« O
23	Диалог O
24	» O
25	. O

# sent_id = 1005
# text =   Хотя если сравнивать их чисто на уровне качества морфологической разметки (данные с MorphoRuEval-2017), то проигрыш получается значительный — порядка 15%, если считать accuracy по словам.
# relations = ""
1	Хотя O
2	если O
3	сравнивать O
4	их O
5	чисто O
6	на O
7	уровне O
8	качества O
9	морфологической B-Method
10	разметки I-Method
11	( O
12	данные O
13	с O
14	MorphoRuEval-2017 O
15	) O
16	, O
17	то O
18	проигрыш O
19	получается O
20	значительный O
21	— O
22	порядка O
23	15 O
24	% O
25	, O
26	если O
27	считать O
28	accuracy B-Metric
29	по O
30	словам O
31	. O

# sent_id = 1006
# text =   Дальше буду сравнивать нас с Syntaxnet и остальными алгоритмами.
# relations = ""
1	Дальше O
2	буду O
3	сравнивать O
4	нас O
5	с O
6	Syntaxnet B-App_system
7	и O
8	остальными O
9	алгоритмами O
10	. O

# sent_id = 1007
# text =   Интересно, что мы почти дотянулись по метрике LAS до версии Syntaxnet.
# relations = ""
1	Интересно O
2	, O
3	что O
4	мы O
5	почти O
6	дотянулись O
7	по O
8	метрике O
9	LAS B-Metric
10	до O
11	версии O
12	Syntaxnet B-App_system
13	. O

# sent_id = 1008
# text =   В архитектуре стенфордского парсера и Syntaxnet заложена другая концепия: сначала они генерируют полный ориентированный граф, и дальше работа алгоритма состоит в том, чтобы оставить тот скелет (минимальное остовное дерево), который будет наиболее вероятным.
# relations = "Application_isAppliedTo_Object 0 0, Application_isAppliedTo_Object 0 1"
1	В O
2	архитектуре O
3	стенфордского O
4	парсера O
5	и O
6	Syntaxnet B-App_system
7	заложена O
8	другая O
9	концепия O
10	: O
11	сначала O
12	они O
13	генерируют O
14	полный O
15	ориентированный B-Object
16	граф I-Object
17	, O
18	и O
19	дальше O
20	работа O
21	алгоритма O
22	состоит O
23	в O
24	том O
25	, O
26	чтобы O
27	оставить O
28	тот O
29	скелет O
30	( O
31	минимальное B-Object
32	остовное I-Object
33	дерево I-Object
34	) O
35	, O
36	который O
37	будет O
38	наиболее O
39	вероятным O
40	. O

# sent_id = 1009
# text =   Поддержка NlpCraft IDL добавлена в систему начиная с версии 0.7.5.
# relations = ""
1	Поддержка O
2	NlpCraft B-Environment
3	IDL I-Environment
4	добавлена O
5	в O
6	систему O
7	начиная O
8	с O
9	версии O
10	0.7.5 O
11	. O

# sent_id = 1010
# text =   Новая версия декларативного языка определения интентов, получившая название NlpCraft IDL (NlpCraft Intents Definition Language), значительно упростила процесс работы с интентами в диалоговых и поисковых системах, построенных на базе проекта Apache NlpCraft и вместе с тем расширила возможности системы.
# relations = "Environment_isUsedIn_Application 0 0"
1	Новая O
2	версия O
3	декларативного O
4	языка O
5	определения O
6	интентов O
7	, O
8	получившая O
9	название O
10	NlpCraft B-Environment
11	IDL I-Environment
12	( O
13	NlpCraft B-Environment
14	Intents I-Environment
15	Definition I-Environment
16	Language I-Environment
17	) O
18	, O
19	значительно O
20	упростила O
21	процесс O
22	работы O
23	с O
24	интентами O
25	в O
26	диалоговых O
27	и O
28	поисковых B-Application
29	системах I-Application
30	, O
31	построенных O
32	на O
33	базе O
34	проекта O
35	Apache B-Activity
36	NlpCraft I-Activity
37	и O
38	вместе O
39	с O
40	тем O
41	расширила O
42	возможности O
43	системы O
44	. O

# sent_id = 1011
# text =   NlpCraft IDL - это декларативный язык, позволяющий создавать определения интентов для их последующего использования в моделях Apache NlpCraft.
# relations = ""
1	NlpCraft B-Environment
2	IDL I-Environment
3	- O
4	это O
5	декларативный O
6	язык O
7	, O
8	позволяющий O
9	создавать O
10	определения B-Task
11	интентов I-Task
12	для O
13	их O
14	последующего O
15	использования O
16	в O
17	моделях O
18	Apache B-Model
19	NlpCraft I-Model
20	. O

# sent_id = 1012
# text =   Чаще всего на практике в NLP приходится сталкиваться с задачей построения эмбеддингов.
# relations = "Task_isSolvedIn_Science 0 0"
1	Чаще O
2	всего O
3	на O
4	практике O
5	в O
6	NLP B-Science
7	приходится O
8	сталкиваться O
9	с O
10	задачей O
11	построения B-Task
12	эмбеддингов I-Task
13	. O

# sent_id = 1013
# text =   Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.
# relations = "Method_solves_Task 0 0, Method_solves_Task 0 1, Method_solves_Task 0 2"
1	Для O
2	ее O
3	решения O
4	обычно O
5	используют O
6	один O
7	из O
8	следующих O
9	инструментов O
10	: O
11	Готовые O
12	векторы B-Object
13	/ O
14	эмбеддинги B-Object
15	слов I-Object
16	[ O
17	6 O
18	] O
19	; O
20	Внутренние O
21	состояния O
22	CNN B-Method
23	, O
24	натренированных O
25	на O
26	таких O
27	задачах O
28	как O
29	, O
30	как O
31	определение B-Task
32	фальшивых I-Task
33	предложений I-Task
34	/ O
35	языковое B-Task
36	моделирование I-Task
37	/ O
38	классификация B-Task
39	[ O
40	7 O
41	] O
42	; O
43	Комбинация O
44	выше O
45	перечисленных O
46	методов O
47	; O
48	Кроме O
49	того O
50	, O
51	уже O
52	много O
53	раз O
54	было O
55	показано O
56	[ O
57	9 O
58	] O
59	, O
60	что O
61	в O
62	качестве O
63	хорошего O
64	бейслайна O
65	для O
66	эмбеддингов O
67	предложений O
68	можно O
69	взять O
70	и O
71	просто O
72	усредненные O
73	( O
74	с O
75	парой O
76	незначительных O
77	деталей O
78	, O
79	которые O
80	сейчас O
81	опустим O
82	) O
83	векторы O
84	слов O
85	. O

# sent_id = 1014
# text =   Выраженная в тексте эмоциональная оценка называется тональностью или сентиментом (от англ. sentiment — чувство; мнение, настроение) текста.
# relations = ""
1	Выраженная O
2	в O
3	тексте O
4	эмоциональная B-Object
5	оценка I-Object
6	называется O
7	тональностью B-Object
8	или O
9	сентиментом B-Object
10	( O
11	от O
12	англ O
13	. O 
14	sentiment O
15	— O
16	чувство O
17	; O
18	мнение O
19	, O
20	настроение O
21	) O
22	текста O
23	. O

# sent_id = 1015
# text =   Исторически сложилось так, что традиционный подход к сентимент анализу представляет собой задачу классификации текста (части текста) на две-три категории (негативный, позитивный, нейтральный или просто: негативный или позитивный) [Pang & Lee; Turney ].
# relations = "Method_hasAuthor_Person 0 0, Method_hasAuthor_Person 0 1, Method_hasAuthor_Person 0 2, Method_solves_Task 0 0"
1	Исторически O
2	сложилось O
3	так O
4	, O
5	что O
6	традиционный O
7	подход O
8	к O
9	сентимент B-Method
10	анализу I-Method
11	представляет O
12	собой O
13	задачу O
14	классификации B-Task
15	текста O
16	( O
17	части O
18	текста O
19	) O
20	на O
21	две O
22	- O
23	три O
24	категории O
25	( O
26	негативный O
27	, O
28	позитивный O
29	, O
30	нейтральный O
31	или O
32	просто O
33	: O
34	негативный O
35	или O
36	позитивный O
37	) O
38	[ O
39	Pang B-Person
40	& O
41	Lee B-Person
42	; O
43	Turney B-Person
44	] O
45	. O

# sent_id = 1016
# text =   Такой вид сентимент анализа называется объектной тональностью (object-based).
# relations = "Method_includes_Method 0 1, Method_isAlternativeNameFor_Method 2 1"
1	Такой O
2	вид O
3	сентимент B-Method
4	анализа I-Method
5	называется O
6	объектной B-Method
7	тональностью I-Method
8	( O
9	object B-Method
10	- I-Method
11	based I-Method
12	) O
13	. O

# sent_id = 1017
# text =   Таким образом, тональность высказывания определяется тремя компонентами: субъектом тональности (кто высказал оценку), объектом тональности (о ком или о чём высказана оценка) и собственно тональной оценкой (как оценили).
# relations = "Object_includes_Object 0 3, Object_includes_Object 0 2, Object_includes_Object 0 1"
1	Таким O
2	образом O
3	, O
4	тональность B-Object
5	высказывания I-Object
6	определяется O
7	тремя O
8	компонентами O
9	: O
10	субъектом B-Object
11	тональности I-Object
12	( O
13	кто O
14	высказал O
15	оценку O
16	) O
17	, O
18	объектом B-Object
19	тональности I-Object
20	( O
21	о O
22	ком O
23	или O
24	о O
25	чём O
26	высказана O
27	оценка O
28	) O
29	и O
30	собственно O
31	тональной B-Object
32	оценкой I-Object
33	( O
34	как O
35	оценили O
36	) O
37	. O

# sent_id = 1018
# text =   Еще одним направлением сентимент анализа является выявление негативности/позитивности атрибутов объекта тональности (feature-based/aspect-based sentiment analysis).
# relations = "Method_includes_Method 0 1, Method_solves_Task 0 0, Method_solves_Task 1 0"
1	Еще O
2	одним O
3	направлением O
4	сентимент B-Method
5	анализа I-Method
6	является O
7	выявление B-Task
8	негативности I-Task
9	/ I-Task
10	позитивности I-Task
11	атрибутов I-Task
12	объекта I-Task
13	тональности I-Task
14	( O
15	feature B-Method
16	- I-Method
17	based I-Method
18	/ I-Method
19	aspect I-Method
20	- I-Method
21	based I-Method
22	sentiment I-Method
23	analysis I-Method
24	) O
25	. O

# sent_id = 1019
# text =   При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].
# relations = "Model_isUsedForSolving_Task 0 0, Method_solves_Task 0 0, Method_solves_Task 1 0, Method_solves_Task 2 0, Method_isAlternativeNameFor_Method 1 0"
1	При O
2	статистическом O
3	подходе O
4	для O
5	решения O
6	задачи O
7	общей O
8	классификации B-Task
9	текстов O
10	на O
11	классы O
12	тональности O
13	широко O
14	используют B-Method_solves_Task
15	метод B-Method
16	опорных I-Method
17	векторов I-Method
18	( O
19	SVM B-Method
20	) O
21	, O
22	Байесовы B-Model
23	модели I-Model
24	, O
25	различного O
26	рода O
27	регрессии B-Method
28	[ O
29	Chetviorkin B-Person
30	& O
31	Loukachevitch B-Person
32	— O
33	описание O
34	соревнования O
35	ROMIP-2011 O
36	по O
37	сентимент B-Method
38	анализу I-Method
39	данных O
40	, O
41	практически O
42	все O
43	участники O
44	использовали O
45	SVM B-Method
46	или O
47	Байес B-Method
48	] O
49	. O

# sent_id = 1020
# text =   Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].
# relations = "Method_solves_Task 2 0, Method_solves_Task 3 0, Method_solves_Task 4 0, Method_solves_Task 5 0, Method_solves_Task 6 0, Method_solves_Task 7 0, Method_hasAuthor_Person 7 2, Method_hasAuthor_Person 7 3, Method_isAlternativeNameFor_Method 6 5, Method_includes_Method 2 5, Method_isAlternativeNameFor_Method 4 3, Method_includes_Method 2 3, Method_hasAuthor_Person 1 1, Method_hasAuthor_Person 1 0, Method_solves_Task 1 0, Method_solves_Task 0 0"
1	Если O
2	же O
3	целью O
4	является O
5	определение B-Task
6	тональности I-Task
7	у O
8	определенного O
9	, O
10	заранее O
11	заданного O
12	объекта O
13	( O
14	нескольких O
15	объектов O
16	) O
17	, O
18	то O
19	применяют B-Method_solves_Task
20	более O
21	сложные O
22	статистические B-Method
23	алгоритмы I-Method
24	, O
25	такие O
26	как O
27	CRF B-Method
28	[ O
29	Антонова B-Person
30	и O
31	Соловьев B-Person
32	] O
33	, O
34	алгоритмы B-Method
35	семантической I-Method
36	близости I-Method
37	( O
38	например O
39	, O
40	латентно B-Method
41	- I-Method
42	семантический I-Method
43	анализ I-Method
44	– O
45	LSA B-Method
46	, O
47	латентное B-Method
48	размещение I-Method
49	Дирихле I-Method
50	— O
51	LDA B-Method
52	) O
53	и O
54  др. O
54	, O
55	а O
56	также O
57	методы B-Method
58	, I-Method
59	основанные I-Method
60	на I-Method
61	правилах I-Method
62	[ O
63	Пазельская B-Person
64	и O
65	Соловьев B-Person
66	] O
67	. O

# sent_id = 1021
# text =   Если для дальнейшей обработки не важен порядок слов, то текст упаковывают в Мешок слов (Bag-of-words).
# relations = "Method_isAppliedTo_Object 0 0, Method_isAppliedTo_Object 1 0, Method_isAlternativeNameFor_Method 1 0"
1	Если O
2	для O
3	дальнейшей O
4	обработки O
5	не O
6	важен O
7	порядок O
8	слов O
9	, O
10	то O
11	текст B-Object
12	упаковывают O
13	в O
14	Мешок B-Method
15	слов I-Method
16	( O
17	Bag B-Method
18	- I-Method
19	of I-Method
20	- I-Method
21	words I-Method
22	) O

# sent_id = 1022
# text =   В обучающей выборке мы имеем письма с отметками спам/не спам, и скармливаем их в нейросеть: в полносвязную сеть и CNN подаем Bag-of-words, а в RNN уже можно учесть порядок слов, отправив ей Word Vector.
# relations = "Method_isAppliedTo_Object 2 0"
1	В O
2	обучающей O
3	выборке O
4	мы O
5	имеем O
6	письма O
7	с O
8	отметками O
9	спам O
10	/ O
11	не O
12	спам O
13	, O
14	и O
15	скармливаем O
16	их O
17	в O
18	нейросеть O
19	: O
20	в O
21	полносвязную O
22	сеть O
23	и O
24	CNN B-Method
25	подаем O
26	Bag B-Method
27	- I-Method
28	of I-Method
29	- I-Method
30	words I-Method
31	, O
32	а O
33	в O
34	RNN B-Method
35	уже O
36	можно O
37	учесть O
38	порядок O
39	слов O
40	, O
41	отправив O
42	ей O
43	Word B-Object
44	Vector I-Object
45	. O

# sent_id = 1023
# text =   Удалось найти лишь это упоминание про систему Deepgram.
# relations = ""
1	Удалось O
2	найти O
3	лишь O
4	это O
5	упоминание O
6	про O
7	систему O
8	Deepgram B-App_system
9	. O

# sent_id = 1024
# text =   Также очень похожая функциональность есть у Microsoft в Streams, но нигде не нашел упоминания про поддержку русского языка, судя по всему, ее тоже нет.
# relations = "Application_hasAuthor_Organization 0 0"
1	Также O
2	очень O
3	похожая O
4	функциональность O
5	есть O
6	у O
7	Microsoft B-Organization
8	в O
9	Streams B-App_system
10	, O
11	но O
12	нигде O
13	не O
14	нашел O
15	упоминания O
16	про O
17	поддержку O
18	русского O
19	языка O
20	, O
21	судя O
22	по O
23	всему O
24	, O
25	ее O
26	тоже O
27	нет O
28	. O

# sent_id = 1025
# text =   Нейросети, которые могут преобразовывать речь в текст называются (сюрприз-сюрприз), speech-to-text.
# relations = "Task_isAlternativeNameFor_Task 1 0"
1	Нейросети O
2	, O
3	которые O
4	могут O
5	преобразовывать B-Task
6	речь I-Task
7	в I-Task
8	текст I-Task
9	называются O
10	( O
11	сюрприз O
12	- O
13	сюрприз O
14	) O
15	, O
16	speech B-Task
17	- I-Task
18	to I-Task
19	- I-Task
20	text I-Task
21	. O

# sent_id = 1026
# text =   Если получится найти публичный сервис speech-to-text, то его можно использовать, чтобы «оцифровать» речь во всех вебинарах, а сделать потом нечеткий поиск по тексту – более простая задача.
# relations = "Application_isUsedForSolving_Task 0 0"
1	Если O
2	получится O
3	найти O
4	публичный O
5	сервис B-App_system
6	speech I-App_system
7	- I-App_system
8	to I-App_system
9	- I-App_system
10	text I-App_system
11	, O
12	то O
13	его O
14	можно O
15	использовать O
16	, O
17	чтобы O
18	« O
19	оцифровать O
20	» O
21	речь O
22	во O
23	всех O
24	вебинарах O
25	, O
26	а O
27	сделать O
28	потом O
29	нечеткий O
30	поиск B-Task
31	по I-Task
32	тексту I-Task
33	– O
34	более O
35	простая O
36	задача O
37	. O

# sent_id = 1027
# text =   Поиск сервисов, способных делать speech-to-text показал, что таких систем масса, в том числе и разработанных в России, есть среди них также глобальные облачные провайдеры вроде Google, Amazon, MS Azure.
# relations = ""
1	Поиск O
2	сервисов O
3	, O
4	способных O
5	делать O
6	speech B-App_system
7	- I-App_system
8	to I-App_system
9	- I-App_system
10	text I-App_system
11	показал O
12	, O
13	что O
14	таких O
15	систем O
16	масса O
17	, O
18	в O
19	том O
20	числе O
21	и O
22	разработанных O
23	в O
24	России O
25	, O
26	есть O
27	среди O
28	них O
29	также O
30	глобальные O
31	облачные O
32	провайдеры O
33	вроде O
34	Google B-Organization
35	, O
36	Amazon B-Organization
37	, O
38	MS B-Organization
39	Azure I-Organization
40	. O

# sent_id = 1028
# text =   Custom Vocabularies – позволяет создать «словарь» из тех, слов, которые должна «выучить» нейросеть перед тем, как приступить к распознаванию.
# relations = "Application_isUsedForSolving_Task 0 0"
1	Custom B-App_system
2	Vocabularies I-App_system
3	– O
4	позволяет O
5	создать O
6	« O
7	словарь O
8	» O
9	из O
10	тех O
11	, O
12	слов O
13	, O
14	которые O
15	должна O
16	« O
17	выучить O
18	» O
19	нейросеть O
20	перед O
21	тем O
22	, O
23	как O
24	приступить O
25	к O
26	распознаванию B-Task
27	. O

# sent_id = 1029
# text =   Можно попробовать прикрутить к итоговому набору текстов алгоритм BERT (Bi-directional Encoder Representation from Transformer), описание есть тут.
# relations = "Model_isAlternativeNameFor_Model 1 0"
1	Можно O
2	попробовать O
3	прикрутить O
4	к O
5	итоговому O
6	набору O
7	текстов O
8	алгоритм O
9	BERT B-Model
10	( O
11	Bi B-Model
12	- I-Model
13	directional I-Model
14	Encoder I-Model
15	Representation I-Model
16	from I-Model
17	Transformer I-Model
18	) O
19	, O
20	описание O
21	есть O
22	тут O
23	. O

# sent_id = 1030
# text =   Вы можете попробовать интегрировать алгоритм BERT (Bi-directional Encoder Representation from Transformer) в окончательный набор текстов, описание которого доступно здесь.
# relations = "Model_isAlternativeNameFor_Model 1 0"
1	Вы O
2	можете O
3	попробовать O
4	интегрировать O
5	алгоритм O
6	BERT B-Model
7	( O
8	Bi B-Model
9	- I-Model
10	directional I-Model
11	Encoder I-Model
12	Representation I-Model
13	from I-Model
14	Transformer I-Model
15	) O
16	в O
17	окончательный O
18	набор O
19	текстов O
20	, O
21	описание O
22	которого O
23	доступно O
24	здесь O
25	. O

# sent_id = 1031
# text =   Сначала Яндекс распознаёт речь в текст с указанием таймингов и спикеров (за это отвечает голосовая биометрия).
# relations = ""
1	Сначала O
2	Яндекс B-Organization
3	распознаёт B-Task
4	речь I-Task
5	в O
6	текст O
7	с O
8	указанием O
9	таймингов O
10	и O
11	спикеров O
12	( O
13	за O
14	это O
15	отвечает O
16	голосовая B-Task
17	биометрия I-Task
18	) O
19	. O

# sent_id = 1032
# text =   Добавили поддержку немецкого, французского и испанского языков.
# relations = ""
1	Добавили O
2	поддержку O
3	немецкого B-Lang
4	, O
5	французского B-Lang
6	и O
7	испанского B-Lang
8	языков O
9	. O

# sent_id = 1033
# text =   Поэтому всё время существования как Яндекс Браузера, так и Яндекс Переводчика мы стараемся не просто переводить, но и помогать учить язык.
# relations = ""
1	Поэтому O
2	всё O
3	время O
4	существования O
5	как O
6	Яндекс B-Technology
7	Браузера I-Technology
8	, O
9	так O
10	и O
11	Яндекс B-Technology
12	Переводчика I-Technology
13	мы O
14	стараемся O
15	не O
16	просто O
17	переводить O
18	, O
19	но O
20	и O
21	помогать O
22	учить O
23	язык O
24	. O

# sent_id = 1034
# text =   С 27 по 30 мая в Российском государственном гуманитарном университете (РГГУ) пройдет международная научная конференция по компьютерной лингвистике «Диалог».
# relations = "Organization_isAlternativeNameFor_Organization 1 0"
1	С O
2	27 O
3	по O
4	30 O
5	мая O
6	в O
7	Российском B-Organization
8	государственном I-Organization
9	гуманитарном I-Organization
10	университете I-Organization
11	( O
12	РГГУ B-Organization
13	) O
14	пройдет O
15	международная B-Activity
16	научная I-Activity
17	конференция I-Activity
18	по I-Activity
19	компьютерной I-Activity
20	лингвистике I-Activity
21	« O
22	Диалог B-Activity
23	» O
24	. O

# sent_id = 1035
# text = Международная научная конференция по компьютерной лингвистике «Диалог» прошла в Российском государственном гуманитарном университете (РГГУ).
# relations = "Organization_isAlternativeNameFor_Organization 1 0"
1	Международная B-Activity
2	научная I-Activity
3	конференция I-Activity
4	по I-Activity
5	компьютерной I-Activity
6	лингвистике I-Activity
7	« O
8	Диалог B-Activity
9	» O
10	прошла O
11	в O
12	Российском B-Organization
13	государственном I-Organization
14	гуманитарном I-Organization
15	университете I-Organization
16	( O
17	РГГУ B-Organization
18	) O
19	. O

# sent_id = 1036
# text = Научная конференция по компьютерной лингвистике "Диалог" состоялась в Российском государственном гуманитарном университете (РГГУ).
# relations = "Organization_isAlternativeNameFor_Organization 1 0"
1	Научная B-Activity
2	конференция I-Activity
3	по I-Activity
4	компьютерной I-Activity
5	лингвистике I-Activity
6	" O
7	Диалог B-Activity
8	" O
9	состоялась O
10	в O
11	Российском B-Organization
12	государственном I-Organization
13	гуманитарном I-Organization
14	университете I-Organization
15	( O
16	РГГУ B-Organization
17	) O
18	. O

# sent_id = 1037
# text =   Подробно о том, что такое «Диалог» и почему ABBYY организует эту конференцию, мы писали здесь .
# relations = "Activity_hasAuthor_Organization 0 0"
1	Подробно O
2	о O
3	том O
4	, O
5	что O
6	такое O
7	« O
8	Диалог B-Activity
9	» O
10	и O
11	почему O
12	ABBYY B-Organization
13	организует O
14	эту O
15	конференцию O
16	, O
17	мы O
18	писали O
19	здесь O
20	. O

# sent_id = 1038
# text =   Мы уже рассказали подробности о том, что представляет собой "Диалог" и почему ABBYY организует эту конференцию, в данной публикации.
# relations = "Activity_hasAuthor_Organization 0 0"
1	Мы O
2	уже O
3	рассказали O
4	подробности O
5	о O
6	том O
7	, O
8	что O
9	представляет O
10	собой O
11	" O
12	Диалог B-Activity
13	" O
14	и O
15	почему O
16	ABBYY B-Organization
17	организует O
18	эту O
19	конференцию O
20	, O
21	в O
22	данной O
23	публикации O
24	. O

# sent_id = 1039
# text =   Главной задачей проведенных ранее тестирований был автоматический анализ тональности в целом небольших текстов – отзывов пользователей (о фильмах, книгах, цифровых фотокамерах) или мнений, выраженных в форме прямой или косвенной речи (новости).
# relations = "Object_isUsedInSolving_Task 0 0"
1	Главной O
2	задачей O
3	проведенных O
4	ранее O
5	тестирований O
6	был O
7	автоматический B-Task
8	анализ I-Task
9	тональности I-Task
10	в O
11	целом O
12	небольших O
13	текстов B-Object
14	– O
15	отзывов O
16	пользователей O
17	( O
18	о O
19	фильмах O
20	, O
21	книгах O
22	, O
23	цифровых O
24	фотокамерах O
25	) O
26	или O
27	мнений O
28	, O
29	выраженных O
30	в O
31	форме O
32	прямой O
33	или O
34	косвенной O
35	речи O
36	( O
37	новости O
38	) O
39	. O

# sent_id = 1040
# text =   Основной целью нового цикла тестирований является автоматическая оценка тональности по отношению к заданному объекту и его конкретным свойствам.
# relations = ""
1	Основной O
2	целью O
3	нового O
4	цикла O
5	тестирований B-Activity
6	является O
7	автоматическая B-Task
8	оценка I-Task
9	тональности I-Task
10	по O
11	отношению O
12	к O
13	заданному O
14	объекту O
15	и O
16	его O
17	конкретным O
18	свойствам O
19	. O

# sent_id = 1041
# text =   Фишинговые электронные письма - это сообщения, которые кажутся очень похожими на настоящие, например, рассылку от вашего любимого интернет-магазина, но при этом они заманивают людей нажимать на прикрепленные вредоносные ссылки или документы.
# relations = ""
1	Фишинговые B-Object
2	электронные I-Object
3	письма I-Object
4	- O
5	это O
6	сообщения O
7	, O
8	которые O
9	кажутся O
10	очень O
11	похожими O
12	на O
13	настоящие O
14	, O
15	например O
16	, O
17	рассылку O
18	от O
19	вашего O
20	любимого O
21	интернет O
22	- O
23	магазина O
24	, O
25	но O
26	при O
27	этом O
28	они O
29	заманивают O
30	людей O
31	нажимать O
32	на O
33	прикрепленные O
34	вредоносные O
35	ссылки O
36	или O
37	документы O
38	. O

# sent_id = 1042
# text =   Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).
# relations = "Method_isAlternativeNameFor_Method 2 1, Model_isAlternativeNameFor_Model 1 0, Method_uses_Model 0 0, Method_uses_Model 1 0, Method_uses_Model 2 0, Method_uses_Model 0 1, Method_uses_Model 1 1, Method_uses_Model 2 1"
1	Поэтому O
2	в O
3	статье O
4	предлагается O
5	способ B-Method
6	обнаружения I-Method
7	фишинговых I-Method
8	сообщений I-Method
9	, O
10	называемый O
11	Federated B-Method
12	Phish I-Method
13	Bowl I-Method
14	( O
15	далее O
16	FPB B-Method
17	) O
18	, O
19	использующий O
20	федеративное B-Method
21	обучение I-Method
22	и O
23	рекуррентную B-Model
24	нейронную I-Model
25	сеть I-Model
26	с I-Model
27	долгой I-Model
28	краткосрочной I-Model
29	памятью I-Model
30	( O
31	LSTM B-Model
32	) O
33	. O

# sent_id = 1043
# text =   Для работы с текстовыми последовательностями были придуманы рекуррентные нейронные сети (RNN, их улучшение - LSTM, которая бывает двунаправленной, когда последовательность обрабатывается в двух направлениях).
# relations = ""
1	Для O
2	работы O
3	с O
4	текстовыми O
5	последовательностями O
6	были O
7	придуманы O
8	рекуррентные O
9	нейронные O
10	сети O
11	( O
12	RNN B-Method
13	, O
14	их O
15	улучшение O
16	- O
17	LSTM B-Method
18	, O
19	которая O
20	бывает O
21	двунаправленной O
22	, O
23	когда O
24	последовательность O
25	обрабатывается O
26	в O
27	двух O
28	направлениях O
29	) O
30	. O

# sent_id = 1044
# text =   Например, сеть можно сделать двунаправленной (Bidirectional LSTM).
# relations = ""
1	Например O
2	, O
3	сеть O
4	можно O
5	сделать O
6	двунаправленной O
7	( O
8	Bidirectional B-Method
9	LSTM I-Method
10	) O
11	. O

# sent_id = 1045
# text =   FPB предлагает использовать подход, показанный на следующем изображении: 
# relations = ""
1	FPB B-Method
2	предлагает O
3	использовать O
4	подход O
5	, O
6	показанный O
7	на O
8	следующем O
9	изображении O
10	: O

# sent_id = 1046
# text =   Федеративное обучение - это метод машинного обучения, который обучает алгоритм на нескольких децентрализованных устройствах или серверах, содержащих локальные образцы данных, без обмена ими.
# relations = "Method_includes_Method 1 0"
1	Федеративное B-Method
2	обучение I-Method
3	- O
4	это O
5	метод B-Method
6	машинного I-Method
7	обучения I-Method
8	, O
9	который O
10	обучает O
11	алгоритм O
12	на O
13	нескольких O
14	децентрализованных O
15	устройствах O
16	или O
17	серверах O
18	, O
19	содержащих O
20	локальные O
21	образцы O
22	данных O
23	, O
24	без O
25	обмена O
26	ими O
27	. O

# sent_id = 1047
# text =   Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.
# relations = "Method_isUsedForTraining_Model 0 0, Method_isUsedForTraining_Model 1 0, Method_isAlternativeNameFor_Method 5 4, Method_isAlternativeNameFor_Method 3 2, Method_isAlternativeNameFor_Method 1 0"
1	Для O
2	обучения O
3	модели O
4	FPB B-Model
5	с O
6	использованием O
7	федеративного B-Method
8	обучения I-Method
9	( O
10	FL B-Method
11	) O
12	сервер B-Method
13	параметров I-Method
14	( O
15	PS B-Method
16	) O
17	инициализирует O
18	глобальную B-Model
19	модель I-Model
20	( O
21	DL B-Method
22	) O
23	на O
24	основе O
25	вышеупомянутых O
26	двунаправленных O
27	нейронных O
28	сетей O
29	LSTM B-Method
30	и O
31	отправляет O
32	глобальную O
33	модель O
34	с O
35	глобальной O
36	матрицей O
37	преобразования O
38	слов O
39	в O
40	векторы O
41	всем O
42	клиентам O
43	на O
44	первом O
45	этапе O
46	обучения O
47	. O

# sent_id = 1048
# text =   В рамках курса вы узнаете: Как латентные переменные применяются в задачах анализа текстов и как строить глубинные генеративные модели с латентными дискретными переменными.
# relations = "Object_isUsedInSolving_Task 0 0"
1	В O
2	рамках O
3	курса O
4	вы O
5	узнаете O
6	: O
7	Как O
8	латентные B-Object
9	переменные I-Object
10	применяются O
11	в O
12	задачах O
13	анализа B-Task
14	текстов I-Task
15	и O
16	как O
17	строить O
18	глубинные B-Model
19	генеративные I-Model
20	модели I-Model
21	с O
22	латентными O
23	дискретными O
24	переменными O
25	. O

# sent_id = 1049
# text =   Что такое semantic parsing: как строить формальные представления смысла текста, извлекая при этом неявные значения.
# relations = ""
1	Что O
2	такое O
3	semantic B-Method
4	parsing I-Method
5	: O
6	как O
7	строить O
8	формальные O
9	представления O
10	смысла O
11	текста O
12	, O
13	извлекая O
14	при O
15	этом O
16	неявные O
17	значения O
18	. O

# sent_id = 1050
# text =   Британские ученые обучили ИИ трансформировать устную речь в видео с виртуальным сурдопереводчиком.
# relations = ""
1	Британские O
2	ученые O
3	обучили O
4	ИИ O
5	трансформировать O
6	устную B-Object
7	речь I-Object
8	в O
9	видео O
10	с O
11	виртуальным B-Application
12	сурдопереводчиком I-Application
13	. O

# sent_id = 1051
# text =   В Университете Суррея разработчики создали алгоритм сурдоперевода нового поколения.
# relations = "Method_hasAuthor_Organization 0 0"
1	В O
2	Университете B-Organization
3	Суррея I-Organization
4	разработчики O
5	создали B-Method_hasAuthor_Organization
6	алгоритм B-Method
7	сурдоперевода I-Method
8	нового O
9	поколения O
10	. O

# sent_id = 1052
# text = В Университете Суррея инженеры разработали новейший алгоритм сурдоперевода.
# relations = "Method_hasAuthor_Organization 0 0"
1	В O
2	Университете B-Organization
3	Суррея I-Organization
4	инженеры O
5	разработали B-Method_hasAuthor_Organization
6	новейший O
7	алгоритм B-Method
8	сурдоперевода I-Method
9	. O

# sent_id = 1053
# text =   После этого последовательность поз подается сверточной нейросети U-Net.
# relations = ""
1	После O
2	этого O
3	последовательность O
4	поз O
5	подается O
6	сверточной O
7	нейросети O
8	U B-Method
9	- I-Method
10	Net I-Method
11	. O

# sent_id = 1054
# text =   Один из самых известных продуктов — анимированный виртуальный переводчик от IBM.
# relations = ""
1	Один O
2	из O
3	самых O
4	известных O
5	продуктов O
6	— O
7	анимированный O
8	виртуальный O
9	переводчик O
10	от O
11	IBM B-Technology
12	. O

# sent_id = 1055
# text =   Программа, придуманная учеными из Новосибирского академгородка, распознает речь, анализирует смысл и переводит на жестовый язык.
# relations = "Application_isAppliedTo_Object 0 0, Application_isUsedForSolving_Task 0 1, Application_isUsedForSolving_Task 0 0, Application_hasAuthor_Organization 0 0"
1	Программа B-Application
2	, O
3	придуманная O
4	учеными O
5	из O
6	Новосибирского B-Organization
7	академгородка I-Organization
8	, O
9	распознает B-Task
10	речь I-Task
11	, O
12	анализирует B-Task
13	смысл I-Task
14	и O
15	переводит O
16	на O
17	жестовый B-Object
18	язык I-Object
19	. O

# sent_id = 1056
# text =   В то время считали, что разработка станет такой же популярной, как Google Translator.
# relations = ""
1	В O
2	то O
3	время O
4	считали O
5	, O
6	что O
7	разработка O
8	станет O
9	такой O
10	же O
11	популярной O
12	, O
13	как O
14	Google B-Technology
15	Translator I-Technology
16	. O

# sent_id = 1057
# text =   Российские ученые из Института проблем управления им. В.А. Трапезникова РАН (ИПУ РАН) несколько лет назад начали разработку подобного ИИ.
# relations = "Organization_isAlternativeNameFor_Organization 1 0"
1	Российские O
2	ученые O
3	из O
4	Института B-Organization
5	проблем I-Organization
6	управления I-Organization
7	им. I-Organization
8	В.А. I-Organization
9	Трапезникова I-Organization
10	РАН I-Organization
11	( O
12	ИПУ B-Organization
13	РАН I-Organization
14	) O
15	несколько O
16	лет O
17	назад O
18	начали O
19	разработку O
20	подобного O
21	ИИ O
22	. O

# sent_id = 1058
# text =  Несколько лет назад разработку такой системы начали специалисты из Института проблем управления им. В.А. Трапезникова РАН (ИПУ РАН).
# relations = "Organization_isAlternativeNameFor_Organization 1 0"
1	Несколько O
2	лет O
3	назад O
4	разработку O
5	такой O
6	системы O
7	начали O
8	специалисты O
9	из O
10	Института B-Organization
11	проблем I-Organization
12	управления I-Organization
13	им. I-Organization
14	В.А. I-Organization
15	Трапезникова I-Organization
16	РАН I-Organization
17	( O
18	ИПУ B-Organization
19	РАН I-Organization
20	) O
21	. O

# sent_id = 1059
# text =  Разработка системы началась недавно в Институте проблем управления им. В.А. Трапезникова РАН (ИПУ РАН).
# relations = "Organization_isAlternativeNameFor_Organization 1 0"
1	Разработка O
2	системы O
3	началась O
4	недавно O
5	в O
6	Институте B-Organization
7	проблем I-Organization
8	управления I-Organization
9	им. I-Organization
10	В.А. I-Organization
11	Трапезникова I-Organization
12	РАН I-Organization
13	( O
14	ИПУ B-Organization
15	РАН I-Organization
16	) O
17	. O

# sent_id = 1060
# text =   Она несколько лет развивает сайт «Сурдосервер».
# relations = ""
1	Она O
2	несколько O
3	лет O
4	развивает O
5	сайт O
6	« O
7	Сурдосервер B-Technology
8	» O
9	. O

# sent_id = 1061
# text =   N-грамм это просто последовательности букв из слова.
# relations = ""
1	N B-Object
2	- I-Object
3	грамм I-Object
4	это O
5	просто O
6	последовательности O
7	букв O
8	из O
9	слова O
10	. O

# sent_id = 1062
# text =   Создаются лексические и синтаксические признаки токенов текста.
# relations = ""
1	Создаются O
2	лексические B-Object
3	и O
4	синтаксические B-Object
5	признаки I-Object
6	токенов B-Object
7	текста B-Object
8	. O

# sent_id = 1063
# text =   В качестве классификатора намерений применяем Transformer.
# relations = "Method_includes_Method 0 1"
1	В O
2	качестве O
3	классификатора B-Method
4	намерений O
5	применяем O
6	Transformer B-Method
7	. O

# sent_id = 1064
# text = В 1966 году Джозефом Вейценбаумом был создан виртуальный собеседник ELIZA, который стал первым успешным примером реализации чат-бота.
# relations = "Application_hasAuthor_Person 0 0, Date_isDateOf_Application 0 0"
1	В O
2	1966 B-Date
3	году I-Date
4	Джозефом B-Person
5	Вейценбаумом I-Person
6	был O
7	создан O
8	виртуальный O
9	собеседник O
10	ELIZA B-Technology
11	, O
12	который O
13	стал O
14	первым O
15	успешным O
16	примером O
17	реализации O
18	чат O
19	- O
20	бота O
21	. O

# sent_id = 1065
# text = Dusha представляет собой самый обширный открытый корпус данных на русском языке, предназначенный для анализа эмоций в речи.
# relations = "Dataset_Language_Lang 0 0, Dataset_isTrainedForSolving_Task 0 0"
1	Dusha B-Dataset
2	представляет O
3	собой O
4	самый O
5	обширный O
6	открытый O
7	корпус O
8	данных O
9	на O
10	русском B-Lang
11	языке I-Lang
12	, O
13	предназначенный O
14	для O
15	анализа B-Task
16	эмоций I-Task
17	в O
18	речи O
19	. O

# sent_id = 1066
# text = В одном из выдающихся решений применялся особый FastText, предварительно обученный на корпусе текстов RuDReC, включающем отзывы на русском языке о медикаментозной продукции.
# relations = "Dataset_Language_Lang 0 0, Model_isTrainedOn_Dataset 0 0"
1	В O
2	одном O
3	из O
4	выдающихся O
5	решений O
6	применялся O
7	особый O
8	FastText B-Model
9	, O
10	предварительно O
11	обученный O
12	на O
13	корпусе O
14	текстов O
15	RuDReC B-Dataset
16	, O
17	включающем O
18	отзывы O
19	на O
20	русском B-Lang
21	языке I-Lang
22	о O
23	медикаментозной O
24	продукции O
25	. O

# sent_id = 1067
# text = Набор данных IEMOCAP на английском языке является эталоном для анализа эмоций.
# relations = "Dataset_Language_Lang 0 0"
1	Набор O
2	данных O
3	IEMOCAP B-Dataset
4	на O
5	английском B-Lang
6	языке I-Lang
7	является O
8	эталоном O
9	для O
10	анализа O
11	эмоций O
12	. O

# sent_id = 1068
# text = SentEval был первой известной попыткой системного сопоставления английских векторных представлений предложений, объединяющей лингвистические задачи с практическими применениями.
# relations = "Dataset_Language_Lang 0 0, Dataset_isTrainedForSolving_Task 0 0"
1	SentEval B-Dataset
2	был O
3	первой O
4	известной O
5	попыткой O
6	системного O
7	сопоставления O
8	английских B-Lang
9	векторных O
10	представлений O
11	предложений O
12	, O
13	объединяющей O
14	лингвистические B-Task
15	задачи I-Task
16	с O
17	практическими O
18	применениями O
19	. O

# sent_id = 1069
# text = На данный момент модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face пользуются наибольшей популярностью.
# relations = "Model_isIncludedIn_Library 0 0, Model_isIncludedIn_Library 1 0, Model_isIncludedIn_Library 2 0"
1	На O
2	данный O
3	момент O
4	модели O
5	ALBERT B-Model
6	, O
7	RoBERTa B-Model
8	и O
9	DistilBERT B-Model
10	из O
11	репозитория O
12	Hugging B-Library
13	Face I-Library
14	пользуются O
15	наибольшей O
16	популярностью O
17	. O


# sent_id = 1070
# text = На сегодняшний день модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face наиболее востребованы.
# relations = "Model_isIncludedIn_Library 0 0, Model_isIncludedIn_Library 1 0, Model_isIncludedIn_Library 2 0"
1	На O
2	сегодняшний O
3	день O
4	модели O
5	ALBERT B-Model
6	, O
7	RoBERTa B-Model
8	и O
9	DistilBERT B-Model
10	из O
11	репозитория O
12	Hugging B-Library
13	Face I-Library
14	наиболее O
15	востребованы O
16	. O

# sent_id = 1071
# text = Этот подход иллюстрируется применением парафразатора, основанного на "rut5-base-paraphraser" из репозитория Hugging Face.
# relations = "Model_isIncludedIn_Library 0 0"
1	Этот O
2	подход O
3	иллюстрируется O
4	применением O
5	парафразатора O
6	, O
7	основанного O
8	на O
9	" O
10	rut5 B-Model
11	- I-Model
12	base I-Model
13	- I-Model
14	paraphraser I-Model
15	" O
16	из O
17	репозитория O
18	Hugging B-Library
19	Face I-Library
20	. O

# sent_id = 1072
# text = SequenceEncoder представляет собой рекуррентную нейронную сеть (RNN), применяемую для анализа последовательностей в данных о транзакциях и кликах.
# relations = "Model_isAlternativeNameFor_Model 2 1, Model_includes_Model 1 0, Model_includes_Model 2 0, Model_isUsedForSolving_Task 0 0"
1	SequenceEncoder B-Model
2	представляет O
3	собой O
4	рекуррентную B-Model
5	нейронную I-Model
6	сеть I-Model
7	( O
8	RNN B-Model
9	) O
10	, O
11	применяемую O
12	для O
13	анализа B-Task
14	последовательностей B-Task
15	в O
16	данных O
17	о O
18	транзакциях O
19	и O
20	кликах O
21	. O

# sent_id = 1073
# text = Суть BERT заключается в том, что это предварительно обученная модель, основанная на стеке энкодеров Трансформера.
# relations = "Model_includes_Model 1 0"
1	Суть O
2	BERT B-Model
3	заключается O
4	в O
5	том O
6	, O
7	что O
8	это O
9	предварительно O
10	обученная O
11	модель O
12	, O
13	основанная O
14	на O
15	стеке O
16	энкодеров B-Model
17	Трансформера I-Model
18	. O

# sent_id = 1074
# text = UDPipe представляет собой transition-based архитектуру на основе переходов: она обеспечивает быструю обработку, проходя по всем токенам один раз за линейное время.
# relations = "Model_includes_Model 1 0"
1	UDPipe B-Model
2	представляет O
3	собой O
4	transition B-Model
5	- I-Model
6	based I-Model
7	архитектуру O
8	на O
9	основе O
10	переходов O
11	: O
12	она O
13	обеспечивает O
14	быструю O
15	обработку O
16	, O
17	проходя O
18	по O
19	всем O
20	токенам O
21	один O
22	раз O
23	за O
24	линейное O
25	время O
26	. O

# sent_id = 1075
# text = Среди замечательных подходов один из участников предложил использовать BiLSTM с уровнем CRF.
# relations = "Model_includes_Model 1 0"
1	Среди O
2	замечательных O
3	подходов O
4	один O
5	из O
6	участников O
7	предложил O
8	использовать O
9	BiLSTM B-Model
10	с O
11	уровнем O
12	CRF B-Model
13	. O

# sent_id = 1076
# text = Один из участников выделил BiLSTM-архитектуру с добавлением слоя CRF в качестве интересного решения.
# relations = "Model_includes_Model 1 0"
1	Один O
2	из O
3	участников O
4	выделил O
5	BiLSTM B-Model
6	- I-Model
7	архитектуру I-Model
8	с O
9	добавлением O
10	слоя O
11	CRF B-Model
12	в O
13	качестве O
14	интересного O
15	решения O
16	. O

# sent_id = 1077
# text = Появление модели BERT в 2018 году отметило своеобразный поворотный пункт в прогрессе развития моделей обработки естественного языка (NLP).
# relations = "Date_isDateOf_Model 0 0, Model_includes_Model 1 0, Model_isUsedIn_Science 0 0"
1	Появление O
2	модели O
3	BERT B-Model
4	в O
5	2018 B-Date
6	году I-Date
7	отметило O
8	своеобразный O
9	поворотный O
10	пункт O
11	в O
12	прогрессе O
13	развития v
14	моделей B-Model
15	обработки I-Model
16	естественного I-Model
17	языка I-Model
18	( O
19	NLP B-Science
20	) O
21	. O


# sent_id = 1078
# text = Голосовые ассистенты (ГА, IVA) распознают намерения пользователей и выполняют указания.
# relations = "Application_isAlternativeNameFor_Application 1 0, Application_isAlternativeNameFor_Application 2 0, Application_isAlternativeNameFor_Application 2 1"
1	Голосовые B-Application
2	ассистенты I-Application
3	( O
4	ГА B-Application
5	, O
6	IVA B-Application
7	) O
8	распознают O
9	намерения B-Object
10	пользователей O
11	и O
12	выполняют O
13	указания O
14	. O

# sent_id = 1079
# text = Голосовые виртуальные помощники (ГВП, ИВА) распознают намерения пользователей и выполняют указания.
# relations = "Application_isAlternativeNameFor_Application 1 0, Application_isAlternativeNameFor_Application 2 0, Application_isAlternativeNameFor_Application 2 1"
1	Голосовые B-Application
2	виртуальные I-Application
3	помощники I-Application
4	( O
5	ГВП B-Application
6	, O
7	ИВА B-Application
8	) O
9	распознают O
10	намерения B-Object
11	пользователей O
12	и O
13	выполняют O
14	указания O
15	. O

# sent_id = 1080
# text = На сегодняшний день мы поделимся информацией о нашем вкладе в разработку и внедрение корпоративной интеллектуальной информационно-поисковой системы (КИИПС) для НПО "Энергомаш".
# relations = "Application_hasAuthor_Organization 0 0, Application_hasAuthor_Organization 1 0, Application_isAlternativeNameFor_Application 1 0"
1	На O
2	сегодняшний O
3	день O
4	мы O
5	поделимся O
6	информацией O
7	о O
8	нашем O
9	вкладе O
10	в O
11	разработку O
12	и O
13	внедрение O
14	корпоративной B-Application
15	интеллектуальной I-Application
16	информационно I-Application
17	- I-Application
18	поисковой I-Application
19	системы I-Application
20	( O
21	КИИПС B-Application
22	) O
23	для O
24	НПО B-Organization
25	" I-Organization
26	Энергомаш I-Organization
27	" I-Organization
28	. O

# sent_id = 1081
# text = Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.
# relations = "Application_isUsedForSolving_Task 0 0, Application_isUsedForSolving_Task 1 0, Application_isAlternativeNameFor_Application 1 0, Application_hasAuthor_Organization 0 0, Application_hasAuthor_Organization 1 0"
1	Objective B-Application
2	Revision I-Application
3	Evaluation I-Application
4	Service I-Application
5	( O
6	ORES B-Application
7	) O
8	, O
9	разработанная O
10	Wikimedia B-Organization
11	Foundation I-Organization
12	, O
13	проверяет O
14	наличие B-Task
15	спама I-Task
16	. O

# sent_id = 1082
# text = Сервис Objective Revision Evaluation Service (ORES) будет производить анализ всех изменений с целью выявления признаков спама или троллинга.
# relations = "Application_isAlternativeNameFor_Application 1 0"
1	Сервис O
2	Objective B-Application
3	Revision I-Application
4	Evaluation I-Application
5	Service I-Application
6	( O
7	ORES B-Application
8	) O
9	будет O
10	производить O
11	анализ O
12	всех O
13	изменений O
14	с O
15	целью O
16	выявления O
17	признаков O
18	спама O
19	или O
20	троллинга O
21	. O

# sent_id = 1083
# text = Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.
# relations = "Model_isIncludedIn_Library 0 0, Method_isAlternativeNameFor_Method 1 0, Method_isUsedForTraining_Model 0 0, Method_isUsedForTraining_Model 1 0"
1	Для O
2	этого O
3	использовалась O
4	точная B-Method
5	настройка I-Method
6	( O
7	fine B-Method
8	- I-Method
9	tune I-Method
10	) O
11	предварительно O
12	обученной O
13	модели B-Model
14	трансформера I-Model
15	от O
16	HuggingFace B-Library
17	на O
18	данных O
19	, O
20	собранных O
21	с O
22	платформы O
23	Genius B-Application
24	. O

# sent_id = 1084
# text = Я расскажу вам о проведении бинарного анализа тональности русскоязычных текстов с использованием сверточной нейронной сети, векторные представления слов для которой были созданы с использованием обученной модели Word2Vec.
# relations = "Method_isAppliedTo_Object 0 0, Method_uses_Model 0 0, Method_uses_Model 0 1"
1	Я O
2	расскажу O
3	вам O
4	о O
5	проведении O
6	бинарного B-Method
7	анализа I-Method
8	тональности I-Method
9	русскоязычных B-Object
10	текстов I-Object
11	с O
12	использованием O
13	сверточной B-Model
14	нейронной I-Model
15	сети I-Model
16	, O
17	векторные B-Object
18	представления I-Object
19	слов I-Object
20	для O
21	которой O
22	были O
23	созданы O
24	с O
25	использованием O
26	обученной O
27	модели O
28	Word2Vec B-Model
29	. O

# sent_id = 1085
# text = Я представлю вам анализ тональности русскоязычных текстов с применением сверточной нейронной сети, используя векторные представления слов, полученные из обученной модели Word2Vec.
# relations = "Method_isAppliedTo_Object 0 0, Method_uses_Model 0 0, Method_uses_Model 0 1"
1	Я O
2	представлю O
3	вам O
4	анализ B-Method
5	тональности I-Method
6	русскоязычных B-Object
7	текстов I-Object
8	с O
9	применением O
10	сверточной B-Model
11	нейронной I-Model
12	сети I-Model
13	, O
14	используя O
15	векторные B-Object
16	представления I-Object
17	слов I-Object
18	, O
19	полученные O
20	из O
21	обученной O
22	модели O
23	Word2Vec B-Model
24	. O

# sent_id = 1086
# text = Давайте обратимся к этой статье, где была исследована классификация тональности с использованием модели Word2vec в архитектуре CNN.
# relations = "Method_solves_Task 0 0, Model_isUsedForSolving_Task 0 0, Method_uses_Model 0 0"
1	Давайте O
2	обратимся O
3	к O
4	этой O
5	статье O
6	, O
7	где O
8	была O
9	исследована O
10	классификация B-Task
11	тональности I-Task
12	с O
13	использованием O
14	модели O
15	Word2vec B-Model
16	в O
17	архитектуре O
18	CNN B-Method
19	. O

# sent_id = 1087
# text =  В этом случае эмбеддинги fastText, обученные на ruscorpora, продемонстрировали более высокую эффективность по сравнению с теми, которые были обучены на корпусе araneum.
# relations = "Model_isTrainedOn_Dataset 0 0, Model_isTrainedOn_Dataset 0 1"
1	В O
2	этом O
3	случае O
4	эмбеддинги O
5	fastText B-Model
6	, O
7	обученные O
8	на O
9	ruscorpora B-Dataset
10	, O
11	продемонстрировали O
12	более O
13	высокую O
14	эффективность O
15	по O
16	сравнению O
17	с O
18	теми O
19	, O
20	которые O
21	были O
22	обучены O
23	на O
24	корпусе O
25	araneum B-Dataset
26	. O

# sent_id = 1088
# text = В процессе обучения модели text-davinci-003 применяются наборы данных текстов и программного кода, собранные OpenAI к концу 2021 года.
# relations = "Model_isTrainedOn_Dataset 0 0"
1	В O
2	процессе O
3	обучения O
4	модели O
5	text B-Model
6	- I-Model
7	davinci I-Model
8	- I-Model
9	003 I-Model
10	применяются O
11	наборы B-Dataset
12	данных I-Dataset
13	текстов I-Dataset
14	и I-Dataset	
15	программного I-Dataset
16	кода I-Dataset
17	, O
18	собранные O
19	OpenAI B-Organization
20	к O
21	концу O	
22	2021 O	
23	года O
24	. O

# sent_id = 1088
# text = Давайте проверим эффективность этого подхода, обучив модель на наборе данных California Housing.
# relations = "Method_isUsedForTraining_Model 0 0, Model_isTrainedOn_Dataset 0 0"
1	Давайте O
2	проверим O
3	эффективность O
4	этого O
5	подхода B-Method
6	, O
7	обучив O
8	модель B-Model
9	на O
10	наборе O
11	данных O
12	California B-Dataset
13	Housing I-Dataset
14	. O

