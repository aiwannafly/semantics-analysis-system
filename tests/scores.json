{
  "Method_isPartOf_Method": {
    "predicted": {
      "incorrect": {
        "count": 7,
        "examples": [
          {
            "text": "В отличие от предыдущего уровня (phrase-based translation– однократное нахождение соответствий отдельных слов и фраз), нейронный переводчик в какой-то степени трансформирует предложения, анализирует их как единое целое и устанавливает соответствия «из конца в конец» в несколько стадий(end-to-end mapping – сквозное преобразование, полного цикла, непрерывная трансформация многообразия данных со входа на выход).",
            "relation": "(однократное нахождение соответствий отдельных слов) isPartOf (phrase-based translation)"
          },
          {
            "text": "Описание упомянутых рекуррентных нейросетей (RNN), LSTM и GRU выходит за рамки темы статьи.",
            "relation": "(GRU) isPartOf (рекуррентных нейросетей)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(CRF) isPartOf (статистические алгоритмы)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(способ обнаружения фишинговых сообщений) isPartOf (Federated Phish Bowl)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(федеративное обучение) isPartOf (Federated Phish Bowl)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(LSTM) isPartOf (DL)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(сервер параметров) isPartOf (федеративного обучения)"
          }
        ]
      },
      "correct": {
        "count": 4,
        "examples": [
          {
            "text": "GRU - Recurrent Neural Network",
            "relation": "(GRU) isPartOf (Recurrent Neural Network)"
          },
          {
            "text": "В иностранной литературе можно встретить термин Continuous Learning (CL), который объединяет различные методы использования новых данных для поддержания эффективности моделей.",
            "relation": "(методы использования новых данных для поддержания эффективности моделей) isPartOf (Continuous Learning)"
          },
          {
            "text": "Еще одним направлением сентимент анализа является выявление негативности/позитивности атрибутов объекта тональности (feature-based/aspect-based sentiment analysis).",
            "relation": "(feature-based/aspect-based sentiment analysis) isPartOf (сентимент анализа)"
          },
          {
            "text": "Федеративное обучение - это метод машинного обучения, который обучает алгоритм на нескольких децентрализованных устройствах или серверах, содержащих локальные образцы данных, без обмена ими.",
            "relation": "(Федеративное обучение) isPartOf (метод машинного обучения)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 22,
        "examples": [
          {
            "text": "В разметочные функции (labeling functions) закодированы все возможные правила, по которым можно поставить какую-либо метку каждому примеру из набора данных.",
            "relation": "(правила) isPartOf (labeling functions)"
          },
          {
            "text": "В разметочные функции (labeling functions) закодированы все возможные правила, по которым можно поставить какую-либо метку каждому примеру из набора данных.",
            "relation": "(правила) isPartOf (разметочные функции)"
          },
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(кластеризация) isPartOf (методом обучения без учителя)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(тематическим моделированием) isPartOf (подход обучения без учителя)"
          },
          {
            "text": "Если отказываемся от методов unsupervised learning, то логично обратиться к методам обучения с учителем (supervised learning) и в частности к классификации.",
            "relation": "(классификации) isPartOf (методам обучения с учителем)"
          },
          {
            "text": "Отчасти эти ситуации позволяют обработать методы построения \"векторных представлений слов\", например, знаменитый word2vec или более модные skip-gramm.",
            "relation": "(word2vec) isPartOf (методы построения)"
          },
          {
            "text": "Отчасти эти ситуации позволяют обработать методы построения \"векторных представлений слов\", например, знаменитый word2vec или более модные skip-gramm.",
            "relation": "(skip-gramm) isPartOf (методы построения)"
          },
          {
            "text": "Современный подход — анализ семантики без учителя, поэтому его называют анализом скрытой (латентной) семантики.",
            "relation": "(анализом скрытой (латентной) семантики) isPartOf (анализ семантики без учителя)"
          },
          {
            "text": "Исторически первый подход к латентно-семантическому анализу — это латентно-семантическое индексирование.",
            "relation": "(латентно-семантическое индексирование) isPartOf (латентно-семантическому анализу)"
          },
          {
            "text": "Важно понять, что техника вероятностного латентно-семантического индекса — это техника факторизации матрицы.",
            "relation": "(техника вероятностного латентно-семантического индекса) isPartOf (техника факторизации матрицы)"
          },
          {
            "text": "По сравнению с классической факторизацией на основе сингулярного разложения у вероятностной генерирующей модели есть важное преимущество.",
            "relation": "(сингулярного разложения) isPartOf (классической факторизацией)"
          },
          {
            "text": "Так родился статистический метод анализа текста word2vec (англ. Word to vector).",
            "relation": "(word2vec) isPartOf (статистический метод анализа текста)"
          },
          {
            "text": "Искусственная нейронная сеть — это математическая модель, а также ее программное или аппаратное воплощение, построенные по принципу организации и функционирования биологических нейронных сетей — сетей нервных клеток живого организма.",
            "relation": "(Искусственная нейронная сеть) isPartOf (математическая модель)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(LSTM) isPartOf (рекуррентными нейронными сетями)"
          },
          {
            "text": "Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(LSTM) isPartOf (рекуррентных нейронных сетей)"
          },
          {
            "text": "Почитать подробнее про подобные методы графовой репрезентации можно, например, тут — DeepWalk, Node2vec, Graph2vec.",
            "relation": "(Node2vec) isPartOf (методы графовой репрезентации)"
          },
          {
            "text": "Почитать подробнее про подобные методы графовой репрезентации можно, например, тут — DeepWalk, Node2vec, Graph2vec.",
            "relation": "(Graph2vec) isPartOf (методы графовой репрезентации)"
          },
          {
            "text": "Почитать подробнее про подобные методы графовой репрезентации можно, например, тут — DeepWalk, Node2vec, Graph2vec.",
            "relation": "(DeepWalk) isPartOf (методы графовой репрезентации)"
          },
          {
            "text": "Такой вид сентимент анализа называется объектной тональностью (object-based).",
            "relation": "(объектной тональностью) isPartOf (сентимент анализа)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(латентное размещение Дирихле) isPartOf (алгоритмы семантической близости)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(латентно-семантический анализ) isPartOf (алгоритмы семантической близости)"
          },
          {
            "text": "В качестве классификатора намерений применяем Transformer.",
            "relation": "(Transformer) isPartOf (классификатора)"
          }
        ]
      },
      "found": {
        "count": 4,
        "examples": [
          {
            "text": "GRU - Recurrent Neural Network",
            "relation": "(GRU) isPartOf (Recurrent Neural Network)"
          },
          {
            "text": "В иностранной литературе можно встретить термин Continuous Learning (CL), который объединяет различные методы использования новых данных для поддержания эффективности моделей.",
            "relation": "(методы использования новых данных для поддержания эффективности моделей) isPartOf (Continuous Learning)"
          },
          {
            "text": "Еще одним направлением сентимент анализа является выявление негативности/позитивности атрибутов объекта тональности (feature-based/aspect-based sentiment analysis).",
            "relation": "(feature-based/aspect-based sentiment analysis) isPartOf (сентимент анализа)"
          },
          {
            "text": "Федеративное обучение - это метод машинного обучения, который обучает алгоритм на нескольких децентрализованных устройствах или серверах, содержащих локальные образцы данных, без обмена ими.",
            "relation": "(Федеративное обучение) isPartOf (метод машинного обучения)"
          }
        ]
      }
    }
  },
  "Library_isUsedIn_Science": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 5,
        "examples": [
          {
            "text": "Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) isUsedIn (NLP)"
          },
          {
            "text": "Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.",
            "relation": "(NLP Architect) isUsedIn (NLP)"
          },
          {
            "text": "Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.",
            "relation": "(NLP Architect) isUsedIn (обработки естественного языка)"
          },
          {
            "text": "Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) isUsedIn (обработки естественного языка)"
          },
          {
            "text": "Google Natural Language API  поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec.",
            "relation": "(word2vec) isUsedIn (машинного перевода)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(word2vec) isUsedIn (области анализа речи и естественного языка)"
          }
        ]
      },
      "found": {
        "count": 5,
        "examples": [
          {
            "text": "Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) isUsedIn (NLP)"
          },
          {
            "text": "Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.",
            "relation": "(NLP Architect) isUsedIn (NLP)"
          },
          {
            "text": "Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) isUsedIn (обработки естественного языка)"
          },
          {
            "text": "Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.",
            "relation": "(NLP Architect) isUsedIn (обработки естественного языка)"
          },
          {
            "text": "Google Natural Language API  поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec.",
            "relation": "(word2vec) isUsedIn (машинного перевода)"
          }
        ]
      }
    }
  },
  "Model_isIncludedIn_Library": {
    "predicted": {
      "incorrect": {
        "count": 3,
        "examples": [
          {
            "text": "Примеры обучения LDA часто демонстрируются на \"образцовых\" датасетах, например \"20 newsgroups dataset\", который есть в sklearn.",
            "relation": "(LDA) isIncludedIn (sklearn)"
          },
          {
            "text": "Примером данного решения является использование парафрайзера на основе “rut5-base-paraphraser” из библиотеки huggingface.",
            "relation": "(rut5-base-paraphraser) isIncludedIn (huggingface)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(моделей машинного обучения) isIncludedIn (Synthetic Data Vault)"
          }
        ]
      },
      "correct": {
        "count": 17,
        "examples": [
          {
            "text": "Библиотека предоставляет не только получение стандартных признаков на основе TF-IDF, но и на основе эмбеддингов:1) На основе встроенного FastText, который можно тренировать на том или ином корпусе2) Предобученных моделей Gensim3) Любой другой объект, который имеет вид словаря, где на вход подается слово, а на выходе его эмбеддинги",
            "relation": "(Gensim3) isIncludedIn (Библиотека)"
          },
          {
            "text": "Библиотека предоставляет не только получение стандартных признаков на основе TF-IDF, но и на основе эмбеддингов:1) На основе встроенного FastText, который можно тренировать на том или ином корпусе2) Предобученных моделей Gensim3) Любой другой объект, который имеет вид словаря, где на вход подается слово, а на выходе его эмбеддинги",
            "relation": "(FastText) isIncludedIn (Библиотека)"
          },
          {
            "text": "Модели ALBERT, RoBERTa и DistilBERT из библиотеки Hugging Face — самые популярные на сегодняшний день.",
            "relation": "(RoBERTa) isIncludedIn (Hugging Face)"
          },
          {
            "text": "Модели ALBERT, RoBERTa и DistilBERT из библиотеки Hugging Face — самые популярные на сегодняшний день.",
            "relation": "(DistilBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "Модели ALBERT, RoBERTa и DistilBERT из библиотеки Hugging Face — самые популярные на сегодняшний день.",
            "relation": "(ALBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(BERT) isIncludedIn (DeepPavlov)"
          },
          {
            "text": "Чтобы упростить работу с предобученными NLP моделями из DeepPavlov, в сентябрь 2019 года был запущен SaaS сервис.",
            "relation": "(NLP моделями) isIncludedIn (DeepPavlov)"
          },
          {
            "text": "В сентябре 2019 года был запущен сервис SaaS для упрощения взаимодействия с предварительно обученными моделями NLP от DeepPavlov.",
            "relation": "(моделями NLP) isIncludedIn (DeepPavlov)"
          },
          {
            "text": "Примером данного решения является использование парафрайзера на основе “rut5-base-paraphraser” из библиотеки huggingface.",
            "relation": "(парафрайзера) isIncludedIn (huggingface)"
          },
          {
            "text": "На данный момент модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face пользуются наибольшей популярностью.",
            "relation": "(RoBERTa) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На данный момент модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face пользуются наибольшей популярностью.",
            "relation": "(DistilBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На данный момент модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face пользуются наибольшей популярностью.",
            "relation": "(ALBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На сегодняшний день модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face наиболее востребованы.",
            "relation": "(RoBERTa) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На сегодняшний день модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face наиболее востребованы.",
            "relation": "(DistilBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На сегодняшний день модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face наиболее востребованы.",
            "relation": "(ALBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "Этот подход иллюстрируется применением парафразатора, основанного на \"rut5-base-paraphraser\" из репозитория Hugging Face.",
            "relation": "(rut5-base-paraphraser) isIncludedIn (Hugging Face)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(модели трансформера) isIncludedIn (HuggingFace)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 17,
        "examples": [
          {
            "text": "Библиотека предоставляет не только получение стандартных признаков на основе TF-IDF, но и на основе эмбеддингов:1) На основе встроенного FastText, который можно тренировать на том или ином корпусе2) Предобученных моделей Gensim3) Любой другой объект, который имеет вид словаря, где на вход подается слово, а на выходе его эмбеддинги",
            "relation": "(Gensim3) isIncludedIn (Библиотека)"
          },
          {
            "text": "Библиотека предоставляет не только получение стандартных признаков на основе TF-IDF, но и на основе эмбеддингов:1) На основе встроенного FastText, который можно тренировать на том или ином корпусе2) Предобученных моделей Gensim3) Любой другой объект, который имеет вид словаря, где на вход подается слово, а на выходе его эмбеддинги",
            "relation": "(FastText) isIncludedIn (Библиотека)"
          },
          {
            "text": "Модели ALBERT, RoBERTa и DistilBERT из библиотеки Hugging Face — самые популярные на сегодняшний день.",
            "relation": "(RoBERTa) isIncludedIn (Hugging Face)"
          },
          {
            "text": "Модели ALBERT, RoBERTa и DistilBERT из библиотеки Hugging Face — самые популярные на сегодняшний день.",
            "relation": "(DistilBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "Модели ALBERT, RoBERTa и DistilBERT из библиотеки Hugging Face — самые популярные на сегодняшний день.",
            "relation": "(ALBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(BERT) isIncludedIn (DeepPavlov)"
          },
          {
            "text": "Чтобы упростить работу с предобученными NLP моделями из DeepPavlov, в сентябрь 2019 года был запущен SaaS сервис.",
            "relation": "(NLP моделями) isIncludedIn (DeepPavlov)"
          },
          {
            "text": "В сентябре 2019 года был запущен сервис SaaS для упрощения взаимодействия с предварительно обученными моделями NLP от DeepPavlov.",
            "relation": "(моделями NLP) isIncludedIn (DeepPavlov)"
          },
          {
            "text": "Примером данного решения является использование парафрайзера на основе “rut5-base-paraphraser” из библиотеки huggingface.",
            "relation": "(парафрайзера) isIncludedIn (huggingface)"
          },
          {
            "text": "На данный момент модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face пользуются наибольшей популярностью.",
            "relation": "(RoBERTa) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На данный момент модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face пользуются наибольшей популярностью.",
            "relation": "(DistilBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На данный момент модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face пользуются наибольшей популярностью.",
            "relation": "(ALBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На сегодняшний день модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face наиболее востребованы.",
            "relation": "(RoBERTa) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На сегодняшний день модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face наиболее востребованы.",
            "relation": "(DistilBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "На сегодняшний день модели ALBERT, RoBERTa и DistilBERT из репозитория Hugging Face наиболее востребованы.",
            "relation": "(ALBERT) isIncludedIn (Hugging Face)"
          },
          {
            "text": "Этот подход иллюстрируется применением парафразатора, основанного на \"rut5-base-paraphraser\" из репозитория Hugging Face.",
            "relation": "(rut5-base-paraphraser) isIncludedIn (Hugging Face)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(модели трансформера) isIncludedIn (HuggingFace)"
          }
        ]
      }
    }
  },
  "Task_isSolvedIn_Science": {
    "predicted": {
      "incorrect": {
        "count": 1,
        "examples": [
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(анализ личности персонажей пьес Шекспира) isSolvedIn (психотерапии)"
          }
        ]
      },
      "correct": {
        "count": 32,
        "examples": [
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(оценка личности персонажей пьес Шекспира) isSolvedIn (искусстве)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(оценки состояния пациентов) isSolvedIn (психотерапии)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(анализ личности персонажей пьес Шекспира) isSolvedIn (искусстве)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(оценки состояния пациентов) isSolvedIn (психотерапии)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(машинный перевод) isSolvedIn (AI)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(генерация) isSolvedIn (AI)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(понимание естественного языка) isSolvedIn (AI)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(NLG) isSolvedIn (AI)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(NLU) isSolvedIn (AI)"
          },
          {
            "text": "Яндекс открывает датасеты Беспилотных автомобилей, Погоды и Переводчика, чтобы помочь решить проблему сдвига данных в ML",
            "relation": "(сдвига данных) isSolvedIn (ML)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(определения эмоций) isSolvedIn (компьютерной лингвистике)"
          },
          {
            "text": "Извлечение именованных сущностей из текста — одна из востребованных функций текстовой аналитики.",
            "relation": "(Извлечение именованных сущностей) isSolvedIn (текстовой аналитики)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(генерации текста) isSolvedIn (обработки естественного языка)"
          },
          {
            "text": "Разработчики уточнили, что модель mGPT показывает выдающиеся результаты на многих задачах few-shot и zero-shot learning: в этой области машинного обучения не требуется отдельно доучивать модель, достаточно сформулировать задачу текстом и привести несколько примеров, после чего mGPT научится выполнять новую задачу.",
            "relation": "(few-shot) isSolvedIn (машинного обучения)"
          },
          {
            "text": "Разработчики уточнили, что модель mGPT показывает выдающиеся результаты на многих задачах few-shot и zero-shot learning: в этой области машинного обучения не требуется отдельно доучивать модель, достаточно сформулировать задачу текстом и привести несколько примеров, после чего mGPT научится выполнять новую задачу.",
            "relation": "(zero-shot learning) isSolvedIn (машинного обучения)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(генерации сценариев диалоговых систем) isSolvedIn (речевых технологий)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(улучшения качества распознавания речи) isSolvedIn (речевых технологий)"
          },
          {
            "text": "Соответственно, мы приходим к стандартной задаче Machine Learning (ML) – «многоклассовая классификация».",
            "relation": "(многоклассовая классификация) isSolvedIn (ML)"
          },
          {
            "text": "Соответственно, мы приходим к стандартной задаче Machine Learning (ML) – «многоклассовая классификация».",
            "relation": "(многоклассовая классификация) isSolvedIn (Machine Learning)"
          },
          {
            "text": "Стандартной задачей Machine Learning (ML)  является многоклассовая классификация.",
            "relation": "(многоклассовая классификация) isSolvedIn (ML)"
          },
          {
            "text": "Стандартной задачей Machine Learning (ML)  является многоклассовая классификация.",
            "relation": "(многоклассовая классификация) isSolvedIn (Machine Learning)"
          },
          {
            "text": "Многоклассовая классификация - это известная задача Machine Learning (ML).",
            "relation": "(Многоклассовая классификация) isSolvedIn (Machine Learning)"
          },
          {
            "text": "Многоклассовая классификация - это известная задача Machine Learning (ML).",
            "relation": "(Многоклассовая классификация) isSolvedIn (ML)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(Задача распознавания текста) isSolvedIn (NLP)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(Задача распознавания текста) isSolvedIn (natural language processing)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(Задача распознавания текста) isSolvedIn (обработки естественного языка)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Распознавание текста) isSolvedIn (Natural Language Processing)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Распознавание текста) isSolvedIn (NLP)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Распознавание текста) isSolvedIn (область обработки естественного языка)"
          },
          {
            "text": "Часто в машинном переводе и задачах генерации текстов на естественном языке применяют LSTM.",
            "relation": "(генерации текстов) isSolvedIn (машинном переводе)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(понимание текстовых и голосовых команд и вопросов) isSolvedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Чаще всего на практике в NLP приходится сталкиваться с задачей построения эмбеддингов.",
            "relation": "(построения эмбеддингов) isSolvedIn (NLP)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 6,
        "examples": [
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(анализ тональности) isSolvedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(выявление сущностей и ключевых слов) isSolvedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(анализ тональности текста) isSolvedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(преобразование речи в текст) isSolvedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(извлечение информации из текстов) isSolvedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(классификация текстов) isSolvedIn (области анализа речи и естественного языка)"
          }
        ]
      },
      "found": {
        "count": 32,
        "examples": [
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(оценка личности персонажей пьес Шекспира) isSolvedIn (искусстве)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(оценки состояния пациентов) isSolvedIn (психотерапии)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(анализ личности персонажей пьес Шекспира) isSolvedIn (искусстве)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(оценки состояния пациентов) isSolvedIn (психотерапии)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(генерация) isSolvedIn (AI)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(машинный перевод) isSolvedIn (AI)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(понимание естественного языка) isSolvedIn (AI)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(NLG) isSolvedIn (AI)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(NLU) isSolvedIn (AI)"
          },
          {
            "text": "Яндекс открывает датасеты Беспилотных автомобилей, Погоды и Переводчика, чтобы помочь решить проблему сдвига данных в ML",
            "relation": "(сдвига данных) isSolvedIn (ML)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(определения эмоций) isSolvedIn (компьютерной лингвистике)"
          },
          {
            "text": "Извлечение именованных сущностей из текста — одна из востребованных функций текстовой аналитики.",
            "relation": "(Извлечение именованных сущностей) isSolvedIn (текстовой аналитики)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(генерации текста) isSolvedIn (обработки естественного языка)"
          },
          {
            "text": "Разработчики уточнили, что модель mGPT показывает выдающиеся результаты на многих задачах few-shot и zero-shot learning: в этой области машинного обучения не требуется отдельно доучивать модель, достаточно сформулировать задачу текстом и привести несколько примеров, после чего mGPT научится выполнять новую задачу.",
            "relation": "(few-shot) isSolvedIn (машинного обучения)"
          },
          {
            "text": "Разработчики уточнили, что модель mGPT показывает выдающиеся результаты на многих задачах few-shot и zero-shot learning: в этой области машинного обучения не требуется отдельно доучивать модель, достаточно сформулировать задачу текстом и привести несколько примеров, после чего mGPT научится выполнять новую задачу.",
            "relation": "(zero-shot learning) isSolvedIn (машинного обучения)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(генерации сценариев диалоговых систем) isSolvedIn (речевых технологий)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(улучшения качества распознавания речи) isSolvedIn (речевых технологий)"
          },
          {
            "text": "Соответственно, мы приходим к стандартной задаче Machine Learning (ML) – «многоклассовая классификация».",
            "relation": "(многоклассовая классификация) isSolvedIn (ML)"
          },
          {
            "text": "Соответственно, мы приходим к стандартной задаче Machine Learning (ML) – «многоклассовая классификация».",
            "relation": "(многоклассовая классификация) isSolvedIn (Machine Learning)"
          },
          {
            "text": "Стандартной задачей Machine Learning (ML)  является многоклассовая классификация.",
            "relation": "(многоклассовая классификация) isSolvedIn (ML)"
          },
          {
            "text": "Стандартной задачей Machine Learning (ML)  является многоклассовая классификация.",
            "relation": "(многоклассовая классификация) isSolvedIn (Machine Learning)"
          },
          {
            "text": "Многоклассовая классификация - это известная задача Machine Learning (ML).",
            "relation": "(Многоклассовая классификация) isSolvedIn (Machine Learning)"
          },
          {
            "text": "Многоклассовая классификация - это известная задача Machine Learning (ML).",
            "relation": "(Многоклассовая классификация) isSolvedIn (ML)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(Задача распознавания текста) isSolvedIn (NLP)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(Задача распознавания текста) isSolvedIn (natural language processing)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(Задача распознавания текста) isSolvedIn (обработки естественного языка)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Распознавание текста) isSolvedIn (Natural Language Processing)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Распознавание текста) isSolvedIn (NLP)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Распознавание текста) isSolvedIn (область обработки естественного языка)"
          },
          {
            "text": "Часто в машинном переводе и задачах генерации текстов на естественном языке применяют LSTM.",
            "relation": "(генерации текстов) isSolvedIn (машинном переводе)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(понимание текстовых и голосовых команд и вопросов) isSolvedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Чаще всего на практике в NLP приходится сталкиваться с задачей построения эмбеддингов.",
            "relation": "(построения эмбеддингов) isSolvedIn (NLP)"
          }
        ]
      }
    }
  },
  "Method_hasAuthor_Organization": {
    "predicted": {
      "incorrect": {
        "count": 2,
        "examples": [
          {
            "text": "Google запускает Coral ai – аналог raspberry pi, мини-компьютер для внедрения нейросетей в экспериментальные установки.",
            "relation": "(нейросетей) hasAuthor (Google)"
          },
          {
            "text": "В Graphcore предполагают, что алгоритм упаковки также может применяться в геномике, в моделях фолдинга белков и других моделях с перекошенным распределением длины, оказывая гораздо более широкое влияние на различные отрасли и приложения.",
            "relation": "(алгоритм упаковки) hasAuthor (Graphcore)"
          }
        ]
      },
      "correct": {
        "count": 19,
        "examples": [
          {
            "text": "Используя новый алгоритм упаковки, в Graphcore ускорили обработку естественного языка более чем в 2 раза при обучении BERT-Large.",
            "relation": "(алгоритм упаковки) hasAuthor (Graphcore)"
          },
          {
            "text": "В Graphcore считают, что алгоритм упаковки может быть успешно применен не только в области геномики, но и в моделях фолдинга белков и других моделях с неравномерным распределением длины.",
            "relation": "(алгоритм упаковки) hasAuthor (Graphcore)"
          },
          {
            "text": "В новой работе Graphcore представили высокоэффективный алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами (или NNLSHP), а также алгоритм BERT, применяемый к упакованным последовательностям.",
            "relation": "(NNLSHP) hasAuthor (Graphcore)"
          },
          {
            "text": "В новой работе Graphcore представили высокоэффективный алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами (или NNLSHP), а также алгоритм BERT, применяемый к упакованным последовательностям.",
            "relation": "(алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами) hasAuthor (Graphcore)"
          },
          {
            "text": "В последнем исследовании от Graphcore был представлен эффективный алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов (NNLSHP), а также алгоритм BERT, примененный к упакованным последовательностям.",
            "relation": "(NNLSHP) hasAuthor (Graphcore)"
          },
          {
            "text": "В последнем исследовании от Graphcore был представлен эффективный алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов (NNLSHP), а также алгоритм BERT, примененный к упакованным последовательностям.",
            "relation": "(алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов) hasAuthor (Graphcore)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(SuperGLUE) hasAuthor (Noah’s Ark Huawei)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(SuperGLUE) hasAuthor (AGI NLP Сбербанка)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(Russian SuperGLUE) hasAuthor (AGI NLP Сбербанка)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(Russian SuperGLUE) hasAuthor (ВШЭ)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(Russian SuperGLUE) hasAuthor (Noah’s Ark Huawei)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(SuperGLUE) hasAuthor (ВШЭ)"
          },
          {
            "text": "Стоит отметить, что и для них всё было непросто – конкурсная задача матчинга позволила удачно применить разработанный в Лаборатории ИИ метод генерации эмбеддингов транзакционных данных одновременно для двух разных доменов событийных данных (транзакции и кликстрим – атрибуты посещения веб-страниц).",
            "relation": "(метод генерации эмбеддингов транзакционных данных) hasAuthor (Лаборатории ИИ)"
          },
          {
            "text": "Однако использование разработанного в Лаборатории ИИ метода генерации эмбеддингов транзакционных данных позволило успешно применить его одновременно к двум различным доменам событийных данных – транзакциям и кликстриму (атрибутам посещения веб-страниц).",
            "relation": "(метода генерации эмбеддингов транзакционных данных) hasAuthor (Лаборатории ИИ)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(JARVIS) hasAuthor (Сбер)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(JARVIS) hasAuthor (Сбер)"
          },
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(алгоритма для качественного удаления) hasAuthor (Google Meet)"
          },
          {
            "text": "В Университете Суррея разработчики создали алгоритм сурдоперевода нового поколения.",
            "relation": "(алгоритм сурдоперевода) hasAuthor (Университете Суррея)"
          },
          {
            "text": "В Университете Суррея инженеры разработали новейший алгоритм сурдоперевода.",
            "relation": "(алгоритм сурдоперевода) hasAuthor (Университете Суррея)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "Хочу заметить, что 5-граммы слов я назвал не просто так: именно их (со сглаживанием, конечно) Google демонстрирует в статье “One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling” — и показывает результаты, весьма сопоставимые с результатами у рекуррентных нейронных сетей — о которых, собственно, и пойдет далее речь.",
            "relation": "(рекуррентных нейронных сетей) hasAuthor (Google)"
          }
        ]
      },
      "found": {
        "count": 19,
        "examples": [
          {
            "text": "Используя новый алгоритм упаковки, в Graphcore ускорили обработку естественного языка более чем в 2 раза при обучении BERT-Large.",
            "relation": "(алгоритм упаковки) hasAuthor (Graphcore)"
          },
          {
            "text": "В Graphcore считают, что алгоритм упаковки может быть успешно применен не только в области геномики, но и в моделях фолдинга белков и других моделях с неравномерным распределением длины.",
            "relation": "(алгоритм упаковки) hasAuthor (Graphcore)"
          },
          {
            "text": "В новой работе Graphcore представили высокоэффективный алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами (или NNLSHP), а также алгоритм BERT, применяемый к упакованным последовательностям.",
            "relation": "(алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами) hasAuthor (Graphcore)"
          },
          {
            "text": "В новой работе Graphcore представили высокоэффективный алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами (или NNLSHP), а также алгоритм BERT, применяемый к упакованным последовательностям.",
            "relation": "(NNLSHP) hasAuthor (Graphcore)"
          },
          {
            "text": "В последнем исследовании от Graphcore был представлен эффективный алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов (NNLSHP), а также алгоритм BERT, примененный к упакованным последовательностям.",
            "relation": "(алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов) hasAuthor (Graphcore)"
          },
          {
            "text": "В последнем исследовании от Graphcore был представлен эффективный алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов (NNLSHP), а также алгоритм BERT, примененный к упакованным последовательностям.",
            "relation": "(NNLSHP) hasAuthor (Graphcore)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(SuperGLUE) hasAuthor (Noah’s Ark Huawei)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(Russian SuperGLUE) hasAuthor (AGI NLP Сбербанка)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(Russian SuperGLUE) hasAuthor (ВШЭ)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(Russian SuperGLUE) hasAuthor (Noah’s Ark Huawei)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(SuperGLUE) hasAuthor (AGI NLP Сбербанка)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(SuperGLUE) hasAuthor (ВШЭ)"
          },
          {
            "text": "Стоит отметить, что и для них всё было непросто – конкурсная задача матчинга позволила удачно применить разработанный в Лаборатории ИИ метод генерации эмбеддингов транзакционных данных одновременно для двух разных доменов событийных данных (транзакции и кликстрим – атрибуты посещения веб-страниц).",
            "relation": "(метод генерации эмбеддингов транзакционных данных) hasAuthor (Лаборатории ИИ)"
          },
          {
            "text": "Однако использование разработанного в Лаборатории ИИ метода генерации эмбеддингов транзакционных данных позволило успешно применить его одновременно к двум различным доменам событийных данных – транзакциям и кликстриму (атрибутам посещения веб-страниц).",
            "relation": "(метода генерации эмбеддингов транзакционных данных) hasAuthor (Лаборатории ИИ)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(JARVIS) hasAuthor (Сбер)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(JARVIS) hasAuthor (Сбер)"
          },
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(алгоритма для качественного удаления) hasAuthor (Google Meet)"
          },
          {
            "text": "В Университете Суррея разработчики создали алгоритм сурдоперевода нового поколения.",
            "relation": "(алгоритм сурдоперевода) hasAuthor (Университете Суррея)"
          },
          {
            "text": "В Университете Суррея инженеры разработали новейший алгоритм сурдоперевода.",
            "relation": "(алгоритм сурдоперевода) hasAuthor (Университете Суррея)"
          }
        ]
      }
    }
  },
  "Library_isUsedForSolving_Task": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 21,
        "examples": [
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(Yagry) isUsedForSolving (извлечения фактов)"
          },
          {
            "text": "JavaScript-библиотека для обработки текстов на русском языке",
            "relation": "(JavaScript-библиотека) isUsedForSolving (обработки текстов)"
          },
          {
            "text": "Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.",
            "relation": "(фреймворк) isUsedForSolving (определение зависимости между переменными)"
          },
          {
            "text": "Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.",
            "relation": "(фреймворк) isUsedForSolving (оценкой функции регрессии)"
          },
          {
            "text": "Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.",
            "relation": "(фреймворк) isUsedForSolving (регрессионного анализа)"
          },
          {
            "text": "Для решения данной проблемы была использована библиотека Yandex Speller, которая исправляет орфографические ошибки.",
            "relation": "(Yandex Speller) isUsedForSolving (исправляет орфографические ошибки)"
          },
          {
            "text": "Для выравнивания воспользуемся библиотекой lingtrain-aligner, над которой я работаю около года и которая родилась из кучи скриптов на python, часть из которых еще ждет своего часа.",
            "relation": "(lingtrain-aligner) isUsedForSolving (выравнивания воспользуемся)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(DeepPavlov) isUsedForSolving (распознавания именованных сущностей)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(DeepPavlov) isUsedForSolving (NER)"
          },
          {
            "text": "Faker - это пакет Python, разработанный для упрощения генерации синтетических данных.",
            "relation": "(Faker) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(SDV) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Synthetic Data Vault) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(SDV) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Synthetic Data Vault) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "SDV генерирует данные, применяя математические методы и модели машинного обучения.",
            "relation": "(SDV) isUsedForSolving (генерирует данные)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(SDV) isUsedForSolving (создает данные)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(Synthetic Data Vault) isUsedForSolving (создает данные)"
          },
          {
            "text": "С помощью SVD можно обработать данные, даже если они содержат несколько типов данных и отсутствующие значения.",
            "relation": "(SVD) isUsedForSolving (обработать данные)"
          },
          {
            "text": "С помощью Synthetic Data Vault (SDV) могут быть обработаны данные нескольких типов.",
            "relation": "(SDV) isUsedForSolving (обработаны данные)"
          },
          {
            "text": "С помощью Synthetic Data Vault (SDV) могут быть обработаны данные нескольких типов.",
            "relation": "(Synthetic Data Vault) isUsedForSolving (обработаны данные)"
          },
          {
            "text": "Для задачи репрезентации графов связей между сущностями мы использовали фреймворк PyTorch BigGraph — это ещё один фреймворк от Facebook Research.",
            "relation": "(PyTorch BigGraph) isUsedForSolving (репрезентации графов связей между сущностями)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(DeepPavlov) isUsedForSolving (классификации текста)"
          }
        ]
      },
      "found": {
        "count": 21,
        "examples": [
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(Yagry) isUsedForSolving (извлечения фактов)"
          },
          {
            "text": "JavaScript-библиотека для обработки текстов на русском языке",
            "relation": "(JavaScript-библиотека) isUsedForSolving (обработки текстов)"
          },
          {
            "text": "Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.",
            "relation": "(фреймворк) isUsedForSolving (определение зависимости между переменными)"
          },
          {
            "text": "Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.",
            "relation": "(фреймворк) isUsedForSolving (регрессионного анализа)"
          },
          {
            "text": "Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.",
            "relation": "(фреймворк) isUsedForSolving (оценкой функции регрессии)"
          },
          {
            "text": "Для решения данной проблемы была использована библиотека Yandex Speller, которая исправляет орфографические ошибки.",
            "relation": "(Yandex Speller) isUsedForSolving (исправляет орфографические ошибки)"
          },
          {
            "text": "Для выравнивания воспользуемся библиотекой lingtrain-aligner, над которой я работаю около года и которая родилась из кучи скриптов на python, часть из которых еще ждет своего часа.",
            "relation": "(lingtrain-aligner) isUsedForSolving (выравнивания воспользуемся)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(DeepPavlov) isUsedForSolving (распознавания именованных сущностей)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(DeepPavlov) isUsedForSolving (NER)"
          },
          {
            "text": "Faker - это пакет Python, разработанный для упрощения генерации синтетических данных.",
            "relation": "(Faker) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(SDV) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Synthetic Data Vault) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(SDV) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Synthetic Data Vault) isUsedForSolving (генерации синтетических данных)"
          },
          {
            "text": "SDV генерирует данные, применяя математические методы и модели машинного обучения.",
            "relation": "(SDV) isUsedForSolving (генерирует данные)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(SDV) isUsedForSolving (создает данные)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(Synthetic Data Vault) isUsedForSolving (создает данные)"
          },
          {
            "text": "С помощью SVD можно обработать данные, даже если они содержат несколько типов данных и отсутствующие значения.",
            "relation": "(SVD) isUsedForSolving (обработать данные)"
          },
          {
            "text": "С помощью Synthetic Data Vault (SDV) могут быть обработаны данные нескольких типов.",
            "relation": "(SDV) isUsedForSolving (обработаны данные)"
          },
          {
            "text": "С помощью Synthetic Data Vault (SDV) могут быть обработаны данные нескольких типов.",
            "relation": "(Synthetic Data Vault) isUsedForSolving (обработаны данные)"
          },
          {
            "text": "Для задачи репрезентации графов связей между сущностями мы использовали фреймворк PyTorch BigGraph — это ещё один фреймворк от Facebook Research.",
            "relation": "(PyTorch BigGraph) isUsedForSolving (репрезентации графов связей между сущностями)"
          }
        ]
      }
    }
  },
  "Method_solves_Task": {
    "predicted": {
      "incorrect": {
        "count": 2,
        "examples": [
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(сентимент анализу) solves (классификации)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(Байес) solves (классификации)"
          }
        ]
      },
      "correct": {
        "count": 84,
        "examples": [
          {
            "text": "Всё-таки обработка предложений сильно завязана на предшествующий морфологический анализ.",
            "relation": "(морфологический анализ) solves (обработка предложений)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(линейная регрессия) solves (предсказания характеристик)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(ридж-регрессия) solves (предсказания характеристик)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(латентным семантическим анализом) solves (предсказания характеристик)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(SVM) solves (предсказания характеристик)"
          },
          {
            "text": "В литературе для регрессии рекомендуют использовать линейную активацию или RelU.",
            "relation": "(линейную активацию) solves (регрессии)"
          },
          {
            "text": "В литературе для регрессии рекомендуют использовать линейную активацию или RelU.",
            "relation": "(RelU) solves (регрессии)"
          },
          {
            "text": "Тест SuperGLUE включает в себя ряд задач, которые разработаны для оценки способности ИИ-моделей распознавать и понимать естественный язык, например, дать правильный ответ на вопрос на базе прочитанного абзаца, определить, правильно ли используется многозначное слово в определенном контексте и т.д.",
            "relation": "(SuperGLUE) solves (дать правильный ответ на вопрос на базе прочитанного абзаца)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(контекстно-свободных грамматик) solves (извлечения фактов)"
          },
          {
            "text": "За основу возьмем данную статью, в которой была рассмотрена классификация тональности на архитектуре CNN с использованием Word2vec модели.",
            "relation": "(CNN) solves (классификация тональности)"
          },
          {
            "text": "Суть подхода состоит в использовании transfer learning в задачах NLP, когда вы используете предобученные модели, сокращая время на обучение своих моделей и снижая требования к размерам размеченной тестовой выборки.",
            "relation": "(transfer learning) solves (задачах NLP)"
          },
          {
            "text": "Анализ тональности текстов с помощью сверточных нейронных сетей",
            "relation": "(сверточных нейронных сетей) solves (Анализ тональности текстов)"
          },
          {
            "text": "CNN изначально были разработаны для обработки изображений, однако они успешно справляются с решением задач в сфере автоматической обработки текстов.",
            "relation": "(CNN) solves (обработки изображений)"
          },
          {
            "text": "Это генеративная нейронная сеть, способная решать множество задач по обработке естествнного языка (NLP).",
            "relation": "(генеративная нейронная сеть) solves (задач по обработке естествнного языка)"
          },
          {
            "text": "Это генеративная нейронная сеть, способная решать множество задач по обработке естествнного языка (NLP).",
            "relation": "(генеративная нейронная сеть) solves (NLP)"
          },
          {
            "text": "Чтобы обрабатывать последовательности произвольной длины, используют рекуррентные слои.",
            "relation": "(рекуррентные слои) solves (обрабатывать последовательности произвольной длины)"
          },
          {
            "text": "Для классификации используется обыкновенная функция потерь – кросс энтропия.",
            "relation": "(функция потерь – кросс энтропия) solves (классификации)"
          },
          {
            "text": "Автоматическое определение эмоций в текстовых беседах с использованием нейронных сетей",
            "relation": "(нейронных сетей) solves (Автоматическое определение эмоций)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(рекуррентной нейросети) solves (определения эмоций)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) solves (идентифицировать)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(topic modeling) solves (выявить в неразмеченных текстах основные тематики)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(тематическим моделированием) solves (выявить в неразмеченных текстах основные тематики)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(подход обучения без учителя) solves (выявить в неразмеченных текстах основные тематики)"
          },
          {
            "text": "После преобразования сообщений в векторы можно использовать любой классический метод для классификации: логистическую регрессию, SVM, случайный лес, бустинг.",
            "relation": "(SVM) solves (классификации)"
          },
          {
            "text": "После преобразования сообщений в векторы можно использовать любой классический метод для классификации: логистическую регрессию, SVM, случайный лес, бустинг.",
            "relation": "(логистическую регрессию) solves (классификации)"
          },
          {
            "text": "После преобразования сообщений в векторы можно использовать любой классический метод для классификации: логистическую регрессию, SVM, случайный лес, бустинг.",
            "relation": "(бустинг) solves (классификации)"
          },
          {
            "text": "После преобразования сообщений в векторы можно использовать любой классический метод для классификации: логистическую регрессию, SVM, случайный лес, бустинг.",
            "relation": "(случайный лес) solves (классификации)"
          },
          {
            "text": "Решать задачу будем с использованием нейронных сетей, но оптимизируемых генетическим алгоритмом (ГА) – такой процесс называют нейроэволюцией.",
            "relation": "(генетическим алгоритмом) solves (задачу)"
          },
          {
            "text": "Решать задачу будем с использованием нейронных сетей, но оптимизируемых генетическим алгоритмом (ГА) – такой процесс называют нейроэволюцией.",
            "relation": "(ГА) solves (задачу)"
          },
          {
            "text": "В этой статье мы расскажем о методе Propensity Score Adjustment, который применим для коррекции смещений и улучшения данных, полученных на онлайн-панелях.",
            "relation": "(методе Propensity Score Adjustment) solves (коррекции смещений)"
          },
          {
            "text": "В этой статье мы расскажем о методе Propensity Score Adjustment, который применим для коррекции смещений и улучшения данных, полученных на онлайн-панелях.",
            "relation": "(методе Propensity Score Adjustment) solves (улучшения данных)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(Взвешивание) solves (коррекции)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(Weighting) solves (коррекции)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(random forest) solves (корректировки)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(случайных лесов) solves (корректировки)"
          },
          {
            "text": "Сейчас стандарт коррекции онлайн-выборок находится на стадии обсуждения и разработки и метод Propensity Score Adjustment, который мы рассмотрели, может стать общепринятым способом коррекции онлайн-панелей.",
            "relation": "(метод Propensity Score Adjustment) solves (коррекции)"
          },
          {
            "text": "В частности, семантический анализ (о чём документ?), генерация автоматической аннотации и автоматического summary, перевод и создание документов.",
            "relation": "(семантический анализ) solves (генерация автоматической аннотации и автоматического summary)"
          },
          {
            "text": "Поэтому применим классический воркэраунд для задачи холодного старта и построим систему контентных рекомендаций: попробуем научить машину понимать, о чём написан пост.",
            "relation": "(воркэраунд) solves (холодного старта)"
          },
          {
            "text": "Мы уже использовали для решения задач коллаборативных рекомендаций хорошо зарекомендовавшие себя техники факторизации матриц.",
            "relation": "(техники факторизации матриц) solves (задач коллаборативных рекомендаций)"
          },
          {
            "text": "В результате данного анализа решается задача — сбор сводной аналитики по организации.",
            "relation": "(анализа) solves (сбор сводной аналитики по организации)"
          },
          {
            "text": "Наше выработанное решение – обучить нейронную сеть, которая способна по тексту обращения автоматически распознавать заранее ранжированные по классам проблемы, извлекать сущность (номер заказа и телефон клиента) и по определённым классам сделать автоматизацию решения.",
            "relation": "(нейронную сеть) solves (автоматически распознавать заранее ранжированные по классам проблемы)"
          },
          {
            "text": "Изначально на этапе MVP (minimum viable product) мы применяли регулярные выражения для извлечения сущности.",
            "relation": "(регулярные выражения) solves (извлечения сущности)"
          },
          {
            "text": "Технологии языкового процессинга востребованы в разработках, связанных с построением искусственного интеллекта: в поисковых системах, для извлечения фактов, оценки тональности текста, машинного перевода и диалога.",
            "relation": "(Технологии языкового процессинга) solves (оценки тональности текста)"
          },
          {
            "text": "Технологии языкового процессинга востребованы в разработках, связанных с построением искусственного интеллекта: в поисковых системах, для извлечения фактов, оценки тональности текста, машинного перевода и диалога.",
            "relation": "(Технологии языкового процессинга) solves (извлечения фактов)"
          },
          {
            "text": "Набор данных SQuAD привел к появлению бесчисленных подходов к решению задачи вопросно-ответных систем.",
            "relation": "(подходов) solves (задачи вопросно-ответных систем)"
          },
          {
            "text": "DST отвечает за перевод высказываний на человеческом языке в семантическое представление языка, в частности, за извлечение намерений (intets) и пар слот-значение (slot, value), соответствующих цели пользователя.",
            "relation": "(DST) solves (перевод высказываний)"
          },
          {
            "text": "Однако RNN способны фиксировать зависимости только в одном направлении языка.",
            "relation": "(RNN) solves (фиксировать зависимости)"
          },
          {
            "text": "LSTM часто используются в машинном переводе и в задачах генерирования текстов на естественном языке.",
            "relation": "(LSTM) solves (генерирования текстов)"
          },
          {
            "text": "Часто в машинном переводе и задачах генерации текстов на естественном языке применяют LSTM.",
            "relation": "(LSTM) solves (генерации текстов)"
          },
          {
            "text": "Во-первых, конкретно для этого соревнования наиболее эффективный подход - это доразметка спанов тренировочных данных для задачи NER.",
            "relation": "(доразметка спанов тренировочных данных) solves (NER)"
          },
          {
            "text": "Один из возможных способов аугментации текста - перифраз текста.",
            "relation": "(перифраз текста) solves (аугментации текста)"
          },
          {
            "text": "Для задачи NER тексты преобразовываются с помощью токенизатора и теггинга.",
            "relation": "(теггинга) solves (NER)"
          },
          {
            "text": "Для задачи NER тексты преобразовываются с помощью токенизатора и теггинга.",
            "relation": "(токенизатора) solves (NER)"
          },
          {
            "text": "SDV генерирует данные, применяя математические методы и модели машинного обучения.",
            "relation": "(математические методы) solves (генерирует данные)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(математических методов) solves (создает данные)"
          },
          {
            "text": "Данный алгоритм называют моделью «мешка слов», он предсказывает слово по контексту.",
            "relation": "(мешка слов) solves (предсказывает слово по контексту)"
          },
          {
            "text": "Разработанный подход для решения задачи кредитного скоринга в дальнейшем легко переносим и на прочие банковские задачи: модели склонности, оттока и дохода.",
            "relation": "(подход) solves (задачи кредитного скоринга)"
          },
          {
            "text": "Это группа методов очень похожа на методы, применяемые для репрезентации текстов — w2v (skip-gram), doc2vec.",
            "relation": "(w2v) solves (репрезентации текстов)"
          },
          {
            "text": "Это группа методов очень похожа на методы, применяемые для репрезентации текстов — w2v (skip-gram), doc2vec.",
            "relation": "(skip-gram) solves (репрезентации текстов)"
          },
          {
            "text": "Это группа методов очень похожа на методы, применяемые для репрезентации текстов — w2v (skip-gram), doc2vec.",
            "relation": "(doc2vec) solves (репрезентации текстов)"
          },
          {
            "text": "Для задач NER я классифицировал токены логистической регрессией поверх их эмбеддингов, и измерял macro F1 по всем классам токенов, кроме О.",
            "relation": "(логистической регрессией) solves (NER)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) solves (классификации)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) solves (NER)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) solves (извлечения именованных сущностей)"
          },
          {
            "text": "Поэтому в автоматическом парсинге русского языка принято работать исходя из грамматики зависимостей.",
            "relation": "(грамматики зависимостей) solves (автоматическом парсинге)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(грамматики зависимостей) solves (унификации разметки)"
          },
          {
            "text": "Разработчики, решающие задачи автоматического парсинга, часто берут на вход сырой текст, который в соответствии с пирамидой анализа проходит этапы токенизации и морфологического анализа.",
            "relation": "(токенизации) solves (автоматического парсинга)"
          },
          {
            "text": "Разработчики, решающие задачи автоматического парсинга, часто берут на вход сырой текст, который в соответствии с пирамидой анализа проходит этапы токенизации и морфологического анализа.",
            "relation": "(морфологического анализа) solves (автоматического парсинга)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(CNN) solves (определение фальшивых предложений)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(CNN) solves (языковое моделирование)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(CNN) solves (классификация)"
          },
          {
            "text": "Исторически сложилось так, что традиционный подход к сентимент анализу представляет собой задачу классификации текста (части текста) на две-три категории (негативный, позитивный, нейтральный или просто: негативный или позитивный) [Pang & Lee; Turney ].",
            "relation": "(сентимент анализу) solves (классификации)"
          },
          {
            "text": "Еще одним направлением сентимент анализа является выявление негативности/позитивности атрибутов объекта тональности (feature-based/aspect-based sentiment analysis).",
            "relation": "(feature-based/aspect-based sentiment analysis) solves (выявление негативности/позитивности атрибутов объекта тональности)"
          },
          {
            "text": "Еще одним направлением сентимент анализа является выявление негативности/позитивности атрибутов объекта тональности (feature-based/aspect-based sentiment analysis).",
            "relation": "(сентимент анализа) solves (выявление негативности/позитивности атрибутов объекта тональности)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(метод опорных векторов) solves (классификации)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(SVM) solves (классификации)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(CRF) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(алгоритмы семантической близости) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(статистические алгоритмы) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LDA) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(латентное размещение Дирихле) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(латентно-семантический анализ) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LSA) solves (определение тональности)"
          },
          {
            "text": "Давайте обратимся к этой статье, где была исследована классификация тональности с использованием модели Word2vec в архитектуре CNN.",
            "relation": "(CNN) solves (классификация тональности)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 8,
        "examples": [
          {
            "text": "Именно эти технологии, вместе с заметным продвижением в области технологий синтеза и распознавания речи, а также распространением мессенджеров и вебчатов – обусловили стремительный рост количества внедрений NLU-технологий в 2015-2018-м годах.",
            "relation": "(NLU-технологий) solves (синтеза и распознавания речи)"
          },
          {
            "text": "В 2000-е анализ естественных языков начал применяться уже не только для поиска в Интернете, но и для решения разнообразных задач.",
            "relation": "(анализ естественных языков) solves (поиска)"
          },
          {
            "text": "В частности, семантический анализ (о чём документ?), генерация автоматической аннотации и автоматического summary, перевод и создание документов.",
            "relation": "(семантический анализ) solves (перевод)"
          },
          {
            "text": "В частности, семантический анализ (о чём документ?), генерация автоматической аннотации и автоматического summary, перевод и создание документов.",
            "relation": "(семантический анализ) solves (создание документов)"
          },
          {
            "text": "Наше выработанное решение – обучить нейронную сеть, которая способна по тексту обращения автоматически распознавать заранее ранжированные по классам проблемы, извлекать сущность (номер заказа и телефон клиента) и по определённым классам сделать автоматизацию решения.",
            "relation": "(нейронную сеть) solves (извлекать сущность)"
          },
          {
            "text": "По мере развития обработки естественного языка множество задач решалось классическими статистическими методами и множеством правил, однако проблему нечеткости и неоднозначности в языке это не решало.",
            "relation": "(статистическими методами) solves (обработки естественного языка)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(регрессии) solves (классификации)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(методы, основанные на правилах) solves (определение тональности)"
          }
        ]
      },
      "found": {
        "count": 84,
        "examples": [
          {
            "text": "Всё-таки обработка предложений сильно завязана на предшествующий морфологический анализ.",
            "relation": "(морфологический анализ) solves (обработка предложений)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(линейная регрессия) solves (предсказания характеристик)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(ридж-регрессия) solves (предсказания характеристик)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(латентным семантическим анализом) solves (предсказания характеристик)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(SVM) solves (предсказания характеристик)"
          },
          {
            "text": "В литературе для регрессии рекомендуют использовать линейную активацию или RelU.",
            "relation": "(линейную активацию) solves (регрессии)"
          },
          {
            "text": "В литературе для регрессии рекомендуют использовать линейную активацию или RelU.",
            "relation": "(RelU) solves (регрессии)"
          },
          {
            "text": "Тест SuperGLUE включает в себя ряд задач, которые разработаны для оценки способности ИИ-моделей распознавать и понимать естественный язык, например, дать правильный ответ на вопрос на базе прочитанного абзаца, определить, правильно ли используется многозначное слово в определенном контексте и т.д.",
            "relation": "(SuperGLUE) solves (дать правильный ответ на вопрос на базе прочитанного абзаца)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(контекстно-свободных грамматик) solves (извлечения фактов)"
          },
          {
            "text": "За основу возьмем данную статью, в которой была рассмотрена классификация тональности на архитектуре CNN с использованием Word2vec модели.",
            "relation": "(CNN) solves (классификация тональности)"
          },
          {
            "text": "Суть подхода состоит в использовании transfer learning в задачах NLP, когда вы используете предобученные модели, сокращая время на обучение своих моделей и снижая требования к размерам размеченной тестовой выборки.",
            "relation": "(transfer learning) solves (задачах NLP)"
          },
          {
            "text": "Анализ тональности текстов с помощью сверточных нейронных сетей",
            "relation": "(сверточных нейронных сетей) solves (Анализ тональности текстов)"
          },
          {
            "text": "CNN изначально были разработаны для обработки изображений, однако они успешно справляются с решением задач в сфере автоматической обработки текстов.",
            "relation": "(CNN) solves (обработки изображений)"
          },
          {
            "text": "Это генеративная нейронная сеть, способная решать множество задач по обработке естествнного языка (NLP).",
            "relation": "(генеративная нейронная сеть) solves (задач по обработке естествнного языка)"
          },
          {
            "text": "Это генеративная нейронная сеть, способная решать множество задач по обработке естествнного языка (NLP).",
            "relation": "(генеративная нейронная сеть) solves (NLP)"
          },
          {
            "text": "Чтобы обрабатывать последовательности произвольной длины, используют рекуррентные слои.",
            "relation": "(рекуррентные слои) solves (обрабатывать последовательности произвольной длины)"
          },
          {
            "text": "Для классификации используется обыкновенная функция потерь – кросс энтропия.",
            "relation": "(функция потерь – кросс энтропия) solves (классификации)"
          },
          {
            "text": "Автоматическое определение эмоций в текстовых беседах с использованием нейронных сетей",
            "relation": "(нейронных сетей) solves (Автоматическое определение эмоций)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(рекуррентной нейросети) solves (определения эмоций)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) solves (идентифицировать)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(topic modeling) solves (выявить в неразмеченных текстах основные тематики)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(тематическим моделированием) solves (выявить в неразмеченных текстах основные тематики)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(подход обучения без учителя) solves (выявить в неразмеченных текстах основные тематики)"
          },
          {
            "text": "После преобразования сообщений в векторы можно использовать любой классический метод для классификации: логистическую регрессию, SVM, случайный лес, бустинг.",
            "relation": "(SVM) solves (классификации)"
          },
          {
            "text": "После преобразования сообщений в векторы можно использовать любой классический метод для классификации: логистическую регрессию, SVM, случайный лес, бустинг.",
            "relation": "(логистическую регрессию) solves (классификации)"
          },
          {
            "text": "После преобразования сообщений в векторы можно использовать любой классический метод для классификации: логистическую регрессию, SVM, случайный лес, бустинг.",
            "relation": "(бустинг) solves (классификации)"
          },
          {
            "text": "После преобразования сообщений в векторы можно использовать любой классический метод для классификации: логистическую регрессию, SVM, случайный лес, бустинг.",
            "relation": "(случайный лес) solves (классификации)"
          },
          {
            "text": "Решать задачу будем с использованием нейронных сетей, но оптимизируемых генетическим алгоритмом (ГА) – такой процесс называют нейроэволюцией.",
            "relation": "(генетическим алгоритмом) solves (задачу)"
          },
          {
            "text": "Решать задачу будем с использованием нейронных сетей, но оптимизируемых генетическим алгоритмом (ГА) – такой процесс называют нейроэволюцией.",
            "relation": "(ГА) solves (задачу)"
          },
          {
            "text": "В этой статье мы расскажем о методе Propensity Score Adjustment, который применим для коррекции смещений и улучшения данных, полученных на онлайн-панелях.",
            "relation": "(методе Propensity Score Adjustment) solves (коррекции смещений)"
          },
          {
            "text": "В этой статье мы расскажем о методе Propensity Score Adjustment, который применим для коррекции смещений и улучшения данных, полученных на онлайн-панелях.",
            "relation": "(методе Propensity Score Adjustment) solves (улучшения данных)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(Взвешивание) solves (коррекции)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(Weighting) solves (коррекции)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(random forest) solves (корректировки)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(случайных лесов) solves (корректировки)"
          },
          {
            "text": "Сейчас стандарт коррекции онлайн-выборок находится на стадии обсуждения и разработки и метод Propensity Score Adjustment, который мы рассмотрели, может стать общепринятым способом коррекции онлайн-панелей.",
            "relation": "(метод Propensity Score Adjustment) solves (коррекции)"
          },
          {
            "text": "В частности, семантический анализ (о чём документ?), генерация автоматической аннотации и автоматического summary, перевод и создание документов.",
            "relation": "(семантический анализ) solves (генерация автоматической аннотации и автоматического summary)"
          },
          {
            "text": "Поэтому применим классический воркэраунд для задачи холодного старта и построим систему контентных рекомендаций: попробуем научить машину понимать, о чём написан пост.",
            "relation": "(воркэраунд) solves (холодного старта)"
          },
          {
            "text": "Мы уже использовали для решения задач коллаборативных рекомендаций хорошо зарекомендовавшие себя техники факторизации матриц.",
            "relation": "(техники факторизации матриц) solves (задач коллаборативных рекомендаций)"
          },
          {
            "text": "В результате данного анализа решается задача — сбор сводной аналитики по организации.",
            "relation": "(анализа) solves (сбор сводной аналитики по организации)"
          },
          {
            "text": "Наше выработанное решение – обучить нейронную сеть, которая способна по тексту обращения автоматически распознавать заранее ранжированные по классам проблемы, извлекать сущность (номер заказа и телефон клиента) и по определённым классам сделать автоматизацию решения.",
            "relation": "(нейронную сеть) solves (автоматически распознавать заранее ранжированные по классам проблемы)"
          },
          {
            "text": "Изначально на этапе MVP (minimum viable product) мы применяли регулярные выражения для извлечения сущности.",
            "relation": "(регулярные выражения) solves (извлечения сущности)"
          },
          {
            "text": "Технологии языкового процессинга востребованы в разработках, связанных с построением искусственного интеллекта: в поисковых системах, для извлечения фактов, оценки тональности текста, машинного перевода и диалога.",
            "relation": "(Технологии языкового процессинга) solves (оценки тональности текста)"
          },
          {
            "text": "Технологии языкового процессинга востребованы в разработках, связанных с построением искусственного интеллекта: в поисковых системах, для извлечения фактов, оценки тональности текста, машинного перевода и диалога.",
            "relation": "(Технологии языкового процессинга) solves (извлечения фактов)"
          },
          {
            "text": "Набор данных SQuAD привел к появлению бесчисленных подходов к решению задачи вопросно-ответных систем.",
            "relation": "(подходов) solves (задачи вопросно-ответных систем)"
          },
          {
            "text": "DST отвечает за перевод высказываний на человеческом языке в семантическое представление языка, в частности, за извлечение намерений (intets) и пар слот-значение (slot, value), соответствующих цели пользователя.",
            "relation": "(DST) solves (перевод высказываний)"
          },
          {
            "text": "Однако RNN способны фиксировать зависимости только в одном направлении языка.",
            "relation": "(RNN) solves (фиксировать зависимости)"
          },
          {
            "text": "LSTM часто используются в машинном переводе и в задачах генерирования текстов на естественном языке.",
            "relation": "(LSTM) solves (генерирования текстов)"
          },
          {
            "text": "Часто в машинном переводе и задачах генерации текстов на естественном языке применяют LSTM.",
            "relation": "(LSTM) solves (генерации текстов)"
          },
          {
            "text": "Во-первых, конкретно для этого соревнования наиболее эффективный подход - это доразметка спанов тренировочных данных для задачи NER.",
            "relation": "(доразметка спанов тренировочных данных) solves (NER)"
          },
          {
            "text": "Один из возможных способов аугментации текста - перифраз текста.",
            "relation": "(перифраз текста) solves (аугментации текста)"
          },
          {
            "text": "Для задачи NER тексты преобразовываются с помощью токенизатора и теггинга.",
            "relation": "(теггинга) solves (NER)"
          },
          {
            "text": "Для задачи NER тексты преобразовываются с помощью токенизатора и теггинга.",
            "relation": "(токенизатора) solves (NER)"
          },
          {
            "text": "SDV генерирует данные, применяя математические методы и модели машинного обучения.",
            "relation": "(математические методы) solves (генерирует данные)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(математических методов) solves (создает данные)"
          },
          {
            "text": "Данный алгоритм называют моделью «мешка слов», он предсказывает слово по контексту.",
            "relation": "(мешка слов) solves (предсказывает слово по контексту)"
          },
          {
            "text": "Разработанный подход для решения задачи кредитного скоринга в дальнейшем легко переносим и на прочие банковские задачи: модели склонности, оттока и дохода.",
            "relation": "(подход) solves (задачи кредитного скоринга)"
          },
          {
            "text": "Это группа методов очень похожа на методы, применяемые для репрезентации текстов — w2v (skip-gram), doc2vec.",
            "relation": "(w2v) solves (репрезентации текстов)"
          },
          {
            "text": "Это группа методов очень похожа на методы, применяемые для репрезентации текстов — w2v (skip-gram), doc2vec.",
            "relation": "(skip-gram) solves (репрезентации текстов)"
          },
          {
            "text": "Это группа методов очень похожа на методы, применяемые для репрезентации текстов — w2v (skip-gram), doc2vec.",
            "relation": "(doc2vec) solves (репрезентации текстов)"
          },
          {
            "text": "Для задач NER я классифицировал токены логистической регрессией поверх их эмбеддингов, и измерял macro F1 по всем классам токенов, кроме О.",
            "relation": "(логистической регрессией) solves (NER)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) solves (классификации)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) solves (извлечения именованных сущностей)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) solves (NER)"
          },
          {
            "text": "Поэтому в автоматическом парсинге русского языка принято работать исходя из грамматики зависимостей.",
            "relation": "(грамматики зависимостей) solves (автоматическом парсинге)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(грамматики зависимостей) solves (унификации разметки)"
          },
          {
            "text": "Разработчики, решающие задачи автоматического парсинга, часто берут на вход сырой текст, который в соответствии с пирамидой анализа проходит этапы токенизации и морфологического анализа.",
            "relation": "(токенизации) solves (автоматического парсинга)"
          },
          {
            "text": "Разработчики, решающие задачи автоматического парсинга, часто берут на вход сырой текст, который в соответствии с пирамидой анализа проходит этапы токенизации и морфологического анализа.",
            "relation": "(морфологического анализа) solves (автоматического парсинга)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(CNN) solves (определение фальшивых предложений)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(CNN) solves (языковое моделирование)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(CNN) solves (классификация)"
          },
          {
            "text": "Исторически сложилось так, что традиционный подход к сентимент анализу представляет собой задачу классификации текста (части текста) на две-три категории (негативный, позитивный, нейтральный или просто: негативный или позитивный) [Pang & Lee; Turney ].",
            "relation": "(сентимент анализу) solves (классификации)"
          },
          {
            "text": "Еще одним направлением сентимент анализа является выявление негативности/позитивности атрибутов объекта тональности (feature-based/aspect-based sentiment analysis).",
            "relation": "(feature-based/aspect-based sentiment analysis) solves (выявление негативности/позитивности атрибутов объекта тональности)"
          },
          {
            "text": "Еще одним направлением сентимент анализа является выявление негативности/позитивности атрибутов объекта тональности (feature-based/aspect-based sentiment analysis).",
            "relation": "(сентимент анализа) solves (выявление негативности/позитивности атрибутов объекта тональности)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(метод опорных векторов) solves (классификации)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(SVM) solves (классификации)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(латентно-семантический анализ) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(CRF) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LSA) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(алгоритмы семантической близости) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(латентное размещение Дирихле) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(статистические алгоритмы) solves (определение тональности)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LDA) solves (определение тональности)"
          },
          {
            "text": "Давайте обратимся к этой статье, где была исследована классификация тональности с использованием модели Word2vec в архитектуре CNN.",
            "relation": "(CNN) solves (классификация тональности)"
          }
        ]
      }
    }
  },
  "Model_isUsedIn_Application": {
    "predicted": {
      "incorrect": {
        "count": 5,
        "examples": [
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedIn (чат-ботами)"
          },
          {
            "text": "В этой статье я покажу, как мы использовали для этих целей внутреннюю разработку компании – фреймворк LightAutoML, в котором имеется всё для решения поставленной задачи – предобученные готовые векторные представления слов FastText и готовые текстовые пресеты, в которых необходимо только указать гиперпараметры.",
            "relation": "(FastText) isUsedIn (LightAutoML)"
          },
          {
            "text": "GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.",
            "relation": "(ANN) isUsedIn (Google Translate)"
          },
          {
            "text": "GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.",
            "relation": "(ANN) isUsedIn (NMT)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(модели трансформера) isUsedIn (Genius)"
          }
        ]
      },
      "correct": {
        "count": 14,
        "examples": [
          {
            "text": "Генеративная модель, являющаяся сердцем Сноркеля, попытается учесть недостатки отдельных функций.",
            "relation": "(Генеративная модель) isUsedIn (Сноркеля)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedIn (Bing)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedIn (Azure Cognitive Services)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedIn (Office)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedIn (Dynamics)"
          },
          {
            "text": "Тьюринговые модели применяются в продуктах, таких как Bing, Office, Dynamics и Azure Cognitive Services.",
            "relation": "(Тьюринговые модели) isUsedIn (Bing)"
          },
          {
            "text": "Тьюринговые модели применяются в продуктах, таких как Bing, Office, Dynamics и Azure Cognitive Services.",
            "relation": "(Тьюринговые модели) isUsedIn (Office)"
          },
          {
            "text": "Тьюринговые модели применяются в продуктах, таких как Bing, Office, Dynamics и Azure Cognitive Services.",
            "relation": "(Тьюринговые модели) isUsedIn (Dynamics)"
          },
          {
            "text": "Тьюринговые модели применяются в продуктах, таких как Bing, Office, Dynamics и Azure Cognitive Services.",
            "relation": "(Тьюринговые модели) isUsedIn (Azure Cognitive Services)"
          },
          {
            "text": "В обоих случаях они от Texas Instruments, но в Станции Макс используется более свежая и мощная модель TAS5825M.",
            "relation": "(TAS5825M) isUsedIn (Станции Макс)"
          },
          {
            "text": "GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.",
            "relation": "(ANN) isUsedIn (GNMT)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(версию нейросети GPT-3) isUsedIn (Салют)"
          },
          {
            "text": "Чтобы упростить работу с предобученными NLP моделями из DeepPavlov, в сентябрь 2019 года был запущен SaaS сервис.",
            "relation": "(NLP моделями) isUsedIn (SaaS сервис)"
          },
          {
            "text": "В сентябре 2019 года был запущен сервис SaaS для упрощения взаимодействия с предварительно обученными моделями NLP от DeepPavlov.",
            "relation": "(моделями NLP) isUsedIn (SaaS)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 14,
        "examples": [
          {
            "text": "Генеративная модель, являющаяся сердцем Сноркеля, попытается учесть недостатки отдельных функций.",
            "relation": "(Генеративная модель) isUsedIn (Сноркеля)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedIn (Bing)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedIn (Azure Cognitive Services)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedIn (Office)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedIn (Dynamics)"
          },
          {
            "text": "Тьюринговые модели применяются в продуктах, таких как Bing, Office, Dynamics и Azure Cognitive Services.",
            "relation": "(Тьюринговые модели) isUsedIn (Bing)"
          },
          {
            "text": "Тьюринговые модели применяются в продуктах, таких как Bing, Office, Dynamics и Azure Cognitive Services.",
            "relation": "(Тьюринговые модели) isUsedIn (Office)"
          },
          {
            "text": "Тьюринговые модели применяются в продуктах, таких как Bing, Office, Dynamics и Azure Cognitive Services.",
            "relation": "(Тьюринговые модели) isUsedIn (Dynamics)"
          },
          {
            "text": "Тьюринговые модели применяются в продуктах, таких как Bing, Office, Dynamics и Azure Cognitive Services.",
            "relation": "(Тьюринговые модели) isUsedIn (Azure Cognitive Services)"
          },
          {
            "text": "В обоих случаях они от Texas Instruments, но в Станции Макс используется более свежая и мощная модель TAS5825M.",
            "relation": "(TAS5825M) isUsedIn (Станции Макс)"
          },
          {
            "text": "GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.",
            "relation": "(ANN) isUsedIn (GNMT)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(версию нейросети GPT-3) isUsedIn (Салют)"
          },
          {
            "text": "Чтобы упростить работу с предобученными NLP моделями из DeepPavlov, в сентябрь 2019 года был запущен SaaS сервис.",
            "relation": "(NLP моделями) isUsedIn (SaaS сервис)"
          },
          {
            "text": "В сентябре 2019 года был запущен сервис SaaS для упрощения взаимодействия с предварительно обученными моделями NLP от DeepPavlov.",
            "relation": "(моделями NLP) isUsedIn (SaaS)"
          }
        ]
      }
    }
  },
  "Date_isDateOf_Model": {
    "predicted": {
      "incorrect": {
        "count": 5,
        "examples": [
          {
            "text": "С марта 2017 года нейросеть стали использовать для перевода на русский.",
            "relation": "(2017) isDateOf (нейросеть)"
          },
          {
            "text": "21 апреля 2022 года команда разработчиков SberDevices представила многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(21 апреля 2022) isDateOf (GPT-3)"
          },
          {
            "text": "21 апреля 2022 года SberDevices представили многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(21 апреля 2022) isDateOf (GPT-3)"
          },
          {
            "text": "Чтобы упростить работу с предобученными NLP моделями из DeepPavlov, в сентябрь 2019 года был запущен SaaS сервис.",
            "relation": "(сентябрь 2019 года) isDateOf (NLP моделями)"
          },
          {
            "text": "В сентябре 2019 года был запущен сервис SaaS для упрощения взаимодействия с предварительно обученными моделями NLP от DeepPavlov.",
            "relation": "(сентябре 2019 года) isDateOf (моделями NLP)"
          }
        ]
      },
      "correct": {
        "count": 15,
        "examples": [
          {
            "text": "Модель ULMFIT была представлена разработчиками fast.ai (Jeremy Howard, Sebastian Ruder) в 2018 году.",
            "relation": "(2018) isDateOf (ULMFIT)"
          },
          {
            "text": "На момент создания в 2020 году такая модель была наикрупнейшей.",
            "relation": "(2020) isDateOf (модель)"
          },
          {
            "text": "В 2020 году появился GPT-3.",
            "relation": "(2020) isDateOf (GPT-3)"
          },
          {
            "text": "С появлением в 2020 году нейронной сети GPT3 и других архитектур – трансформеров, генерируемые тексты стали невероятно правдоподобными.",
            "relation": "(2020) isDateOf (GPT3)"
          },
          {
            "text": "21 апреля 2022 года команда разработчиков SberDevices представила многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(21 апреля 2022) isDateOf (mGPT)"
          },
          {
            "text": "21 апреля 2022 года SberDevices представили многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(21 апреля 2022) isDateOf (mGPT)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(2020) isDateOf (версию нейросети GPT-3)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(ноябре 2021 года) isDateOf (ruGPT-3)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(ноябре 2021 года) isDateOf (ruGPT-3)"
          },
          {
            "text": "OpenAI представила модель машинного обучения GPT-3, обученную на 175 млрд параметров, в июне 2020 года.",
            "relation": "(июне 2020 года) isDateOf (GPT-3)"
          },
          {
            "text": "В июне 2020 года OpenAI представила модель машинного обучения GPT-3, обученную на 175 миллиардах параметров.",
            "relation": "(июне 2020 года) isDateOf (GPT-3)"
          },
          {
            "text": "Прорывы #DeepPavlov в 2019 году: обзор и итоги года Московский физико-технический институт (МФТИ).",
            "relation": "(2019) isDateOf (#DeepPavlov)"
          },
          {
            "text": "Релиз BERT в 2018 году стал некоторой переломной точкой в развитии NLP-моделей.",
            "relation": "(2018 году) isDateOf (BERT)"
          },
          {
            "text": "Выход модели BERT в 2018 году стал своеобразным переломным моментом в развитии моделей обработки естественного языка (NLP).",
            "relation": "(2018 году) isDateOf (BERT)"
          },
          {
            "text": "Появление модели BERT в 2018 году отметило своеобразный поворотный пункт в прогрессе развития моделей обработки естественного языка (NLP).",
            "relation": "(2018 году) isDateOf (BERT)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "С появлением в 2020 году нейронной сети GPT3 и других архитектур – трансформеров, генерируемые тексты стали невероятно правдоподобными.",
            "relation": "(2020) isDateOf (архитектур – трансформеров)"
          }
        ]
      },
      "found": {
        "count": 15,
        "examples": [
          {
            "text": "Модель ULMFIT была представлена разработчиками fast.ai (Jeremy Howard, Sebastian Ruder) в 2018 году.",
            "relation": "(2018) isDateOf (ULMFIT)"
          },
          {
            "text": "На момент создания в 2020 году такая модель была наикрупнейшей.",
            "relation": "(2020) isDateOf (модель)"
          },
          {
            "text": "В 2020 году появился GPT-3.",
            "relation": "(2020) isDateOf (GPT-3)"
          },
          {
            "text": "С появлением в 2020 году нейронной сети GPT3 и других архитектур – трансформеров, генерируемые тексты стали невероятно правдоподобными.",
            "relation": "(2020) isDateOf (GPT3)"
          },
          {
            "text": "21 апреля 2022 года команда разработчиков SberDevices представила многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(21 апреля 2022) isDateOf (mGPT)"
          },
          {
            "text": "21 апреля 2022 года SberDevices представили многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(21 апреля 2022) isDateOf (mGPT)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(2020) isDateOf (версию нейросети GPT-3)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(ноябре 2021 года) isDateOf (ruGPT-3)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(ноябре 2021 года) isDateOf (ruGPT-3)"
          },
          {
            "text": "OpenAI представила модель машинного обучения GPT-3, обученную на 175 млрд параметров, в июне 2020 года.",
            "relation": "(июне 2020 года) isDateOf (GPT-3)"
          },
          {
            "text": "В июне 2020 года OpenAI представила модель машинного обучения GPT-3, обученную на 175 миллиардах параметров.",
            "relation": "(июне 2020 года) isDateOf (GPT-3)"
          },
          {
            "text": "Прорывы #DeepPavlov в 2019 году: обзор и итоги года Московский физико-технический институт (МФТИ).",
            "relation": "(2019) isDateOf (#DeepPavlov)"
          },
          {
            "text": "Релиз BERT в 2018 году стал некоторой переломной точкой в развитии NLP-моделей.",
            "relation": "(2018 году) isDateOf (BERT)"
          },
          {
            "text": "Выход модели BERT в 2018 году стал своеобразным переломным моментом в развитии моделей обработки естественного языка (NLP).",
            "relation": "(2018 году) isDateOf (BERT)"
          },
          {
            "text": "Появление модели BERT в 2018 году отметило своеобразный поворотный пункт в прогрессе развития моделей обработки естественного языка (NLP).",
            "relation": "(2018 году) isDateOf (BERT)"
          }
        ]
      }
    }
  },
  "InfoResource_Language_Lang": {
    "predicted": {
      "incorrect": {
        "count": 1,
        "examples": [
          {
            "text": "Русскоязычная версия GPT-3, разработанная «Сбером», доступна на платформе SmartMarket.",
            "relation": "(SmartMarket) Language (Русскоязычная)"
          }
        ]
      },
      "correct": {
        "count": 0,
        "examples": []
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 0,
        "examples": []
      }
    }
  },
  "Environment_isUsedIn_Library": {
    "predicted": {
      "incorrect": {
        "count": 3,
        "examples": [
          {
            "text": "PyCaret – это, по сути, оболочка Python над несколькими библиотеками машинного обучения, такими как scikit-learn, XGBoost, Microsoft LightGBM, spaCy и многими другими.",
            "relation": "(Python) isUsedIn (scikit-learn)"
          },
          {
            "text": "PyCaret – это, по сути, оболочка Python над несколькими библиотеками машинного обучения, такими как scikit-learn, XGBoost, Microsoft LightGBM, spaCy и многими другими.",
            "relation": "(Python) isUsedIn (Microsoft LightGBM)"
          },
          {
            "text": "PyCaret – это, по сути, оболочка Python над несколькими библиотеками машинного обучения, такими как scikit-learn, XGBoost, Microsoft LightGBM, spaCy и многими другими.",
            "relation": "(Python) isUsedIn (XGBoost)"
          }
        ]
      },
      "correct": {
        "count": 19,
        "examples": [
          {
            "text": "В итоге получалось, что мне нужно было бы: разобраться, как оптимизировать код и почему даже с C++ библиотекой получается так медленно; написать более простую в установке обертку для OpenFST (или использовать другую реализацию FST — например, сделать свою) + сделать реализацию небольшой части OpenFST (или просто реализацию FST) на Python (чтоб pymorphy можно было использовать без компилятора), ну и формулировать все алгоритмы в терминах конечных автоматов.",
            "relation": "(C++) isUsedIn (OpenFST)"
          },
          {
            "text": "Выбор пал на C++ библиотеку marisa-trie, которую написал гуру структур данных Susumu Yata.",
            "relation": "(C++) isUsedIn (marisa-trie)"
          },
          {
            "text": "Было решено использовать библиотеку marisa-trie на C++, созданную экспертом в области структур данных Сусуму Ята.",
            "relation": "(C++) isUsedIn (marisa-trie)"
          },
          {
            "text": "Если не использовать ни PyPy, ни C++ реализацию DAWG, pymorphy2 все равно будет работать во много раз быстрее (по прикидкам — в пару десятков раз), чем pymorphy1 cо всеми включенными ускорениями — ну и разбирать лучше.",
            "relation": "(C++) isUsedIn (DAWG)"
          },
          {
            "text": "Рады представить вам PyCaret – библиотеку машинного обучения с открытым исходным кодом на Python для обучения и развертывания моделей с учителем и без учителя в low-code среде.",
            "relation": "(Python) isUsedIn (PyCaret)"
          },
          {
            "text": "PyCaret – это, по сути, оболочка Python над несколькими библиотеками машинного обучения, такими как scikit-learn, XGBoost, Microsoft LightGBM, spaCy и многими другими.",
            "relation": "(Python) isUsedIn (PyCaret)"
          },
          {
            "text": "Для выравнивания воспользуемся библиотекой lingtrain-aligner, над которой я работаю около года и которая родилась из кучи скриптов на python, часть из которых еще ждет своего часа.",
            "relation": "(python) isUsedIn (lingtrain-aligner)"
          },
          {
            "text": "Библиотека поддерживает платформы Linux и Windows.",
            "relation": "(Linux) isUsedIn (Библиотека)"
          },
          {
            "text": "Библиотека поддерживает платформы Linux и Windows.",
            "relation": "(Windows) isUsedIn (Библиотека)"
          },
          {
            "text": "Faker - это пакет Python, разработанный для упрощения генерации синтетических данных.",
            "relation": "(Python) isUsedIn (Faker)"
          },
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Python) isUsedIn (Synthetic Data Vault)"
          },
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Python) isUsedIn (SDV)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Python) isUsedIn (Synthetic Data Vault)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Python) isUsedIn (SDV)"
          },
          {
            "text": "Gretel или Gretel Synthetics – это пакет Python с открытым исходным кодом, основанный на рекуррентной нейронной сети для создания структурированных и не структурированных данных.",
            "relation": "(Python) isUsedIn (Gretel Synthetics)"
          },
          {
            "text": "Gretel или Gretel Synthetics – это пакет Python с открытым исходным кодом, основанный на рекуррентной нейронной сети для создания структурированных и не структурированных данных.",
            "relation": "(Python) isUsedIn (Gretel)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(Python) isUsedIn (Gretel)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(Python) isUsedIn (Gretel Synthetics)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(Python) isUsedIn (GS)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 19,
        "examples": [
          {
            "text": "В итоге получалось, что мне нужно было бы: разобраться, как оптимизировать код и почему даже с C++ библиотекой получается так медленно; написать более простую в установке обертку для OpenFST (или использовать другую реализацию FST — например, сделать свою) + сделать реализацию небольшой части OpenFST (или просто реализацию FST) на Python (чтоб pymorphy можно было использовать без компилятора), ну и формулировать все алгоритмы в терминах конечных автоматов.",
            "relation": "(C++) isUsedIn (OpenFST)"
          },
          {
            "text": "Выбор пал на C++ библиотеку marisa-trie, которую написал гуру структур данных Susumu Yata.",
            "relation": "(C++) isUsedIn (marisa-trie)"
          },
          {
            "text": "Было решено использовать библиотеку marisa-trie на C++, созданную экспертом в области структур данных Сусуму Ята.",
            "relation": "(C++) isUsedIn (marisa-trie)"
          },
          {
            "text": "Если не использовать ни PyPy, ни C++ реализацию DAWG, pymorphy2 все равно будет работать во много раз быстрее (по прикидкам — в пару десятков раз), чем pymorphy1 cо всеми включенными ускорениями — ну и разбирать лучше.",
            "relation": "(C++) isUsedIn (DAWG)"
          },
          {
            "text": "Рады представить вам PyCaret – библиотеку машинного обучения с открытым исходным кодом на Python для обучения и развертывания моделей с учителем и без учителя в low-code среде.",
            "relation": "(Python) isUsedIn (PyCaret)"
          },
          {
            "text": "PyCaret – это, по сути, оболочка Python над несколькими библиотеками машинного обучения, такими как scikit-learn, XGBoost, Microsoft LightGBM, spaCy и многими другими.",
            "relation": "(Python) isUsedIn (PyCaret)"
          },
          {
            "text": "Для выравнивания воспользуемся библиотекой lingtrain-aligner, над которой я работаю около года и которая родилась из кучи скриптов на python, часть из которых еще ждет своего часа.",
            "relation": "(python) isUsedIn (lingtrain-aligner)"
          },
          {
            "text": "Библиотека поддерживает платформы Linux и Windows.",
            "relation": "(Linux) isUsedIn (Библиотека)"
          },
          {
            "text": "Библиотека поддерживает платформы Linux и Windows.",
            "relation": "(Windows) isUsedIn (Библиотека)"
          },
          {
            "text": "Faker - это пакет Python, разработанный для упрощения генерации синтетических данных.",
            "relation": "(Python) isUsedIn (Faker)"
          },
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Python) isUsedIn (Synthetic Data Vault)"
          },
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Python) isUsedIn (SDV)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Python) isUsedIn (Synthetic Data Vault)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Python) isUsedIn (SDV)"
          },
          {
            "text": "Gretel или Gretel Synthetics – это пакет Python с открытым исходным кодом, основанный на рекуррентной нейронной сети для создания структурированных и не структурированных данных.",
            "relation": "(Python) isUsedIn (Gretel Synthetics)"
          },
          {
            "text": "Gretel или Gretel Synthetics – это пакет Python с открытым исходным кодом, основанный на рекуррентной нейронной сети для создания структурированных и не структурированных данных.",
            "relation": "(Python) isUsedIn (Gretel)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(Python) isUsedIn (Gretel)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(Python) isUsedIn (Gretel Synthetics)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(Python) isUsedIn (GS)"
          }
        ]
      }
    }
  },
  "Activity_isAlternativeNameFor_Activity": {
    "predicted": {
      "incorrect": {
        "count": 1,
        "examples": [
          {
            "text": "Международная научная конференция по компьютерной лингвистике «Диалог» прошла в Российском государственном гуманитарном университете (РГГУ).",
            "relation": "(Международная научная конференция по компьютерной лингвистике) isAlternativeNameFor (Диалог)"
          }
        ]
      },
      "correct": {
        "count": 1,
        "examples": [
          {
            "text": "С 27 по 30 мая в Российском государственном гуманитарном университете (РГГУ) пройдет международная научная конференция по компьютерной лингвистике «Диалог».",
            "relation": "(Диалог) isAlternativeNameFor (международная научная конференция по компьютерной лингвистике)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 1,
        "examples": [
          {
            "text": "С 27 по 30 мая в Российском государственном гуманитарном университете (РГГУ) пройдет международная научная конференция по компьютерной лингвистике «Диалог».",
            "relation": "(Диалог) isAlternativeNameFor (международная научная конференция по компьютерной лингвистике)"
          }
        ]
      }
    }
  },
  "Dataset_isTrainedForSolving_Task": {
    "predicted": {
      "incorrect": {
        "count": 1,
        "examples": [
          {
            "text": "Яндекс открывает датасеты Беспилотных автомобилей, Погоды и Переводчика, чтобы помочь решить проблему сдвига данных в ML",
            "relation": "(датасеты) isTrainedForSolving (сдвига данных)"
          }
        ]
      },
      "correct": {
        "count": 25,
        "examples": [
          {
            "text": "Чтобы оценить точность регрессора, мы будем использовать наборы данных Medical Cost Personal Datasets | Kaggle.",
            "relation": "(Medical Cost Personal Datasets) isTrainedForSolving (оценить точность регрессора)"
          },
          {
            "text": "Dusha: самый большой открытый датасет для распознавания эмоций в устной речи на русском языке.",
            "relation": "(Dusha) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "Dusha: самый большой открытый датасет для распознавания эмоций в устной речи на русском языке.",
            "relation": "(датасет) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "Dusha - это крупнейший открытый набор данных на русском языке для распознавания эмоций в речи.",
            "relation": "(набор данных) isTrainedForSolving (распознавания эмоций в речи)"
          },
          {
            "text": "Dusha - это крупнейший открытый набор данных на русском языке для распознавания эмоций в речи.",
            "relation": "(Dusha) isTrainedForSolving (распознавания эмоций в речи)"
          },
          {
            "text": "Де-факто, в подавляющем большинстве случаев, бенчмарком для новых моделей распознавания эмоций является англоязычный датасет IEMOCAP с игрой профессиональных актёров.",
            "relation": "(IEMOCAP) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "IEMOCAP, англоязычный набор данных, служит стандартом для распознавания эмоций.",
            "relation": "(IEMOCAP) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "Столкнувшись с описанными выше проблемами, мы решили собрать свой датасет для распознавания эмоций и назвали его Dusha, по аналогии с датасетом для распознавания речи — Golos.",
            "relation": "(Dusha) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "Столкнувшись с описанными выше проблемами, мы решили собрать свой датасет для распознавания эмоций и назвали его Dusha, по аналогии с датасетом для распознавания речи — Golos.",
            "relation": "(Golos) isTrainedForSolving (распознавания речи)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(paraphraser.ru) isTrainedForSolving (Paraphrase identification)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(STS-B) isTrainedForSolving (STS)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(paraphraser.ru) isTrainedForSolving (PI)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(SentiRuEval2016) isTrainedForSolving (Sentiment analysis)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(XNLI) isTrainedForSolving (Natural language inference)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(XNLI) isTrainedForSolving (NLI)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(SentiRuEval2016) isTrainedForSolving (SA)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(STS-B) isTrainedForSolving (Semantic text similarity)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(датасете Сколтеха) isTrainedForSolving (II)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(датасете токсичных комментариев) isTrainedForSolving (Toxicity identification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(датасете токсичных комментариев) isTrainedForSolving (TI)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(датасете Сколтеха) isTrainedForSolving (Inappropriateness identification)"
          },
          {
            "text": "Распознавание именованных сущностей () на датасетах factRuEval-2016E1 и RuDReC (NE2).",
            "relation": "(factRuEval-2016E1) isTrainedForSolving (Распознавание именованных сущностей)"
          },
          {
            "text": "Распознавание именованных сущностей () на датасетах factRuEval-2016E1 и RuDReC (NE2).",
            "relation": "(NE2) isTrainedForSolving (Распознавание именованных сущностей)"
          },
          {
            "text": "Распознавание именованных сущностей () на датасетах factRuEval-2016E1 и RuDReC (NE2).",
            "relation": "(RuDReC) isTrainedForSolving (Распознавание именованных сущностей)"
          },
          {
            "text": "Dusha представляет собой самый обширный открытый корпус данных на русском языке, предназначенный для анализа эмоций в речи.",
            "relation": "(Dusha) isTrainedForSolving (анализа эмоций)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 5,
        "examples": [
          {
            "text": "А на некоторых заданиях лучших результатов удалось достичь на few-shot, т. е. без дообучения модели (задача RCB и RuCoS, YaLM от Яндекса).",
            "relation": "(RuCoS) isTrainedForSolving (few-shot)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(NLU-evaluation-data) isTrainedForSolving (ICX)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(NLU-evaluation-data) isTrainedForSolving (IC)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(NLU-evaluation-data) isTrainedForSolving (Intent classification)"
          },
          {
            "text": "SentEval был первой известной попыткой системного сопоставления английских векторных представлений предложений, объединяющей лингвистические задачи с практическими применениями.",
            "relation": "(SentEval) isTrainedForSolving (лингвистические задачи)"
          }
        ]
      },
      "found": {
        "count": 25,
        "examples": [
          {
            "text": "Чтобы оценить точность регрессора, мы будем использовать наборы данных Medical Cost Personal Datasets | Kaggle.",
            "relation": "(Medical Cost Personal Datasets) isTrainedForSolving (оценить точность регрессора)"
          },
          {
            "text": "Dusha: самый большой открытый датасет для распознавания эмоций в устной речи на русском языке.",
            "relation": "(Dusha) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "Dusha: самый большой открытый датасет для распознавания эмоций в устной речи на русском языке.",
            "relation": "(датасет) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "Dusha - это крупнейший открытый набор данных на русском языке для распознавания эмоций в речи.",
            "relation": "(набор данных) isTrainedForSolving (распознавания эмоций в речи)"
          },
          {
            "text": "Dusha - это крупнейший открытый набор данных на русском языке для распознавания эмоций в речи.",
            "relation": "(Dusha) isTrainedForSolving (распознавания эмоций в речи)"
          },
          {
            "text": "Де-факто, в подавляющем большинстве случаев, бенчмарком для новых моделей распознавания эмоций является англоязычный датасет IEMOCAP с игрой профессиональных актёров.",
            "relation": "(IEMOCAP) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "IEMOCAP, англоязычный набор данных, служит стандартом для распознавания эмоций.",
            "relation": "(IEMOCAP) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "Столкнувшись с описанными выше проблемами, мы решили собрать свой датасет для распознавания эмоций и назвали его Dusha, по аналогии с датасетом для распознавания речи — Golos.",
            "relation": "(Dusha) isTrainedForSolving (распознавания эмоций)"
          },
          {
            "text": "Столкнувшись с описанными выше проблемами, мы решили собрать свой датасет для распознавания эмоций и назвали его Dusha, по аналогии с датасетом для распознавания речи — Golos.",
            "relation": "(Golos) isTrainedForSolving (распознавания речи)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(paraphraser.ru) isTrainedForSolving (Paraphrase identification)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(STS-B) isTrainedForSolving (STS)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(paraphraser.ru) isTrainedForSolving (PI)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(SentiRuEval2016) isTrainedForSolving (Sentiment analysis)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(XNLI) isTrainedForSolving (Natural language inference)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(XNLI) isTrainedForSolving (NLI)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(SentiRuEval2016) isTrainedForSolving (SA)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(STS-B) isTrainedForSolving (Semantic text similarity)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(датасете токсичных комментариев) isTrainedForSolving (Toxicity identification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(датасете Сколтеха) isTrainedForSolving (II)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(датасете токсичных комментариев) isTrainedForSolving (TI)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(датасете Сколтеха) isTrainedForSolving (Inappropriateness identification)"
          },
          {
            "text": "Распознавание именованных сущностей () на датасетах factRuEval-2016E1 и RuDReC (NE2).",
            "relation": "(NE2) isTrainedForSolving (Распознавание именованных сущностей)"
          },
          {
            "text": "Распознавание именованных сущностей () на датасетах factRuEval-2016E1 и RuDReC (NE2).",
            "relation": "(factRuEval-2016E1) isTrainedForSolving (Распознавание именованных сущностей)"
          },
          {
            "text": "Распознавание именованных сущностей () на датасетах factRuEval-2016E1 и RuDReC (NE2).",
            "relation": "(RuDReC) isTrainedForSolving (Распознавание именованных сущностей)"
          },
          {
            "text": "Dusha представляет собой самый обширный открытый корпус данных на русском языке, предназначенный для анализа эмоций в речи.",
            "relation": "(Dusha) isTrainedForSolving (анализа эмоций)"
          }
        ]
      }
    }
  },
  "Model_isPartOf_Model": {
    "predicted": {
      "incorrect": {
        "count": 4,
        "examples": [
          {
            "text": "SequenceEncoder – рекурентно-нейронная сеть (RNN), совместно используемая для транзакций и кликов.",
            "relation": "(рекурентно-нейронная сеть) isPartOf (SequenceEncoder)"
          },
          {
            "text": "По своей сути BERT — это обученный стек энкодеров Трансформера.",
            "relation": "(энкодеров Трансформера) isPartOf (BERT)"
          },
          {
            "text": "SequenceEncoder представляет собой рекуррентную нейронную сеть (RNN), применяемую для анализа последовательностей в данных о транзакциях и кликах.",
            "relation": "(рекуррентную нейронную сеть) isPartOf (SequenceEncoder)"
          },
          {
            "text": "Суть BERT заключается в том, что это предварительно обученная модель, основанная на стеке энкодеров Трансформера.",
            "relation": "(энкодеров Трансформера) isPartOf (BERT)"
          }
        ]
      },
      "correct": {
        "count": 1,
        "examples": [
          {
            "text": "Модель, которую построил заказчик использовала вектора слов word2vec и рекуррентную нейронную сеть на базе GRU (gated recurrent unit) (Рис 1а).",
            "relation": "(рекуррентную нейронную сеть) isPartOf (Модель)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.",
            "relation": "(DeBERTa) isPartOf (Microsoft Turing)"
          }
        ]
      },
      "found": {
        "count": 1,
        "examples": [
          {
            "text": "Модель, которую построил заказчик использовала вектора слов word2vec и рекуррентную нейронную сеть на базе GRU (gated recurrent unit) (Рис 1а).",
            "relation": "(рекуррентную нейронную сеть) isPartOf (Модель)"
          }
        ]
      }
    }
  },
  "Library_isAlternativeNameFor_Library": {
    "predicted": {
      "incorrect": {
        "count": 1,
        "examples": [
          {
            "text": "В итоге получалось, что мне нужно было бы: разобраться, как оптимизировать код и почему даже с C++ библиотекой получается так медленно; написать более простую в установке обертку для OpenFST (или использовать другую реализацию FST — например, сделать свою) + сделать реализацию небольшой части OpenFST (или просто реализацию FST) на Python (чтоб pymorphy можно было использовать без компилятора), ну и формулировать все алгоритмы в терминах конечных автоматов.",
            "relation": "(OpenFST) isAlternativeNameFor (FST)"
          }
        ]
      },
      "correct": {
        "count": 6,
        "examples": [
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Synthetic Data Vault) isAlternativeNameFor (SDV)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(SDV) isAlternativeNameFor (Synthetic Data Vault)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(SDV) isAlternativeNameFor (Synthetic Data Vault)"
          },
          {
            "text": "С помощью Synthetic Data Vault (SDV) могут быть обработаны данные нескольких типов.",
            "relation": "(SDV) isAlternativeNameFor (Synthetic Data Vault)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(GS) isAlternativeNameFor (Gretel Synthetics)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(GS) isAlternativeNameFor (Gretel)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 2,
        "examples": [
          {
            "text": "Gretel или Gretel Synthetics – это пакет Python с открытым исходным кодом, основанный на рекуррентной нейронной сети для создания структурированных и не структурированных данных.",
            "relation": "(Gretel Synthetics) isAlternativeNameFor (Gretel)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(Gretel Synthetics) isAlternativeNameFor (Gretel)"
          }
        ]
      },
      "found": {
        "count": 6,
        "examples": [
          {
            "text": "SDV или Synthetic Data Vault - это пакет Python для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(Synthetic Data Vault) isAlternativeNameFor (SDV)"
          },
          {
            "text": "Synthetic Data Vault (SDV) - это библиотека Python, использующаяся для генерации синтетических данных на основе предоставленного набора данных.",
            "relation": "(SDV) isAlternativeNameFor (Synthetic Data Vault)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(SDV) isAlternativeNameFor (Synthetic Data Vault)"
          },
          {
            "text": "С помощью Synthetic Data Vault (SDV) могут быть обработаны данные нескольких типов.",
            "relation": "(SDV) isAlternativeNameFor (Synthetic Data Vault)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(GS) isAlternativeNameFor (Gretel Synthetics)"
          },
          {
            "text": "Gretel (Gretel Synthetics, GS) – это библиотека на Python.",
            "relation": "(GS) isAlternativeNameFor (Gretel)"
          }
        ]
      }
    }
  },
  "Science_isAlternativeNameFor_Science": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 18,
        "examples": [
          {
            "text": "1 January 2010 at 07:59 Заметки об NLP (часть 2) Artificial Intelligence Natural Language Processing.",
            "relation": "(Natural Language Processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Заметки об NLP (Natural Language Processing).",
            "relation": "(Natural Language Processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Сентиментный анализ (анализ тональности) – это область компьютерной лингвистики, занимающаяся изучением эмоций в текстовых документах, в основе которой лежит машинное обучение.",
            "relation": "(анализ тональности) isAlternativeNameFor (Сентиментный анализ)"
          },
          {
            "text": "Сентиментный анализ, также известный как анализ тональности, представляет собой сферу компьютерной лингвистики, которая занимается изучением эмоций в текстовых документах, применяя методы машинного обучения.",
            "relation": "(анализ тональности) isAlternativeNameFor (Сентиментный анализ)"
          },
          {
            "text": "Сентимент-анализ, или анализ тональности, является разделом компьютерной лингвистики, в которой занимаются изучением эмоций в текстах с помощью методов машинного обучения.",
            "relation": "(анализ тональности) isAlternativeNameFor (Сентимент-анализ)"
          },
          {
            "text": "Соответственно, мы приходим к стандартной задаче Machine Learning (ML) – «многоклассовая классификация».",
            "relation": "(ML) isAlternativeNameFor (Machine Learning)"
          },
          {
            "text": "Стандартной задачей Machine Learning (ML)  является многоклассовая классификация.",
            "relation": "(ML) isAlternativeNameFor (Machine Learning)"
          },
          {
            "text": "Многоклассовая классификация - это известная задача Machine Learning (ML).",
            "relation": "(ML) isAlternativeNameFor (Machine Learning)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(NLP) isAlternativeNameFor (обработки естественного языка)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(natural language processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(natural language processing) isAlternativeNameFor (обработки естественного языка)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Natural Language Processing) isAlternativeNameFor (область обработки естественного языка)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Natural Language Processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(NLP) isAlternativeNameFor (область обработки естественного языка)"
          },
          {
            "text": "Эта статья будет интересна не только тем, кто специализируется в NLP (Natural Language Processing), но и начинающим исследователям данных.",
            "relation": "(Natural Language Processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Эта статья будет интересна специалистам в области обработки естественного языка (Natural Language Processing, NLP).",
            "relation": "(NLP) isAlternativeNameFor (области обработки естественного языка)"
          },
          {
            "text": "Эта статья будет интересна специалистам в области обработки естественного языка (Natural Language Processing, NLP).",
            "relation": "(NLP) isAlternativeNameFor (Natural Language Processing)"
          },
          {
            "text": "Эта статья будет интересна специалистам в области обработки естественного языка (Natural Language Processing, NLP).",
            "relation": "(Natural Language Processing) isAlternativeNameFor (области обработки естественного языка)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 18,
        "examples": [
          {
            "text": "1 January 2010 at 07:59 Заметки об NLP (часть 2) Artificial Intelligence Natural Language Processing.",
            "relation": "(Natural Language Processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Заметки об NLP (Natural Language Processing).",
            "relation": "(Natural Language Processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Сентиментный анализ (анализ тональности) – это область компьютерной лингвистики, занимающаяся изучением эмоций в текстовых документах, в основе которой лежит машинное обучение.",
            "relation": "(анализ тональности) isAlternativeNameFor (Сентиментный анализ)"
          },
          {
            "text": "Сентиментный анализ, также известный как анализ тональности, представляет собой сферу компьютерной лингвистики, которая занимается изучением эмоций в текстовых документах, применяя методы машинного обучения.",
            "relation": "(анализ тональности) isAlternativeNameFor (Сентиментный анализ)"
          },
          {
            "text": "Сентимент-анализ, или анализ тональности, является разделом компьютерной лингвистики, в которой занимаются изучением эмоций в текстах с помощью методов машинного обучения.",
            "relation": "(анализ тональности) isAlternativeNameFor (Сентимент-анализ)"
          },
          {
            "text": "Соответственно, мы приходим к стандартной задаче Machine Learning (ML) – «многоклассовая классификация».",
            "relation": "(ML) isAlternativeNameFor (Machine Learning)"
          },
          {
            "text": "Стандартной задачей Machine Learning (ML)  является многоклассовая классификация.",
            "relation": "(ML) isAlternativeNameFor (Machine Learning)"
          },
          {
            "text": "Многоклассовая классификация - это известная задача Machine Learning (ML).",
            "relation": "(ML) isAlternativeNameFor (Machine Learning)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(NLP) isAlternativeNameFor (обработки естественного языка)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(natural language processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Задача распознавания текста относится к сфере обработки естественного языка или NLP (natural language processing).",
            "relation": "(natural language processing) isAlternativeNameFor (обработки естественного языка)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Natural Language Processing) isAlternativeNameFor (область обработки естественного языка)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(Natural Language Processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Распознавание текста входит в область обработки естественного языка, или NLP (Natural Language Processing).",
            "relation": "(NLP) isAlternativeNameFor (область обработки естественного языка)"
          },
          {
            "text": "Эта статья будет интересна не только тем, кто специализируется в NLP (Natural Language Processing), но и начинающим исследователям данных.",
            "relation": "(Natural Language Processing) isAlternativeNameFor (NLP)"
          },
          {
            "text": "Эта статья будет интересна специалистам в области обработки естественного языка (Natural Language Processing, NLP).",
            "relation": "(NLP) isAlternativeNameFor (области обработки естественного языка)"
          },
          {
            "text": "Эта статья будет интересна специалистам в области обработки естественного языка (Natural Language Processing, NLP).",
            "relation": "(NLP) isAlternativeNameFor (Natural Language Processing)"
          },
          {
            "text": "Эта статья будет интересна специалистам в области обработки естественного языка (Natural Language Processing, NLP).",
            "relation": "(Natural Language Processing) isAlternativeNameFor (области обработки естественного языка)"
          }
        ]
      }
    }
  },
  "Date_isDateOf_Method": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 22,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(2001-м) isDateOf (Artificial Intelligence Markup Language)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(2001-м) isDateOf (AIML)"
          },
          {
            "text": "Именно эти технологии, вместе с заметным продвижением в области технологий синтеза и распознавания речи, а также распространением мессенджеров и вебчатов – обусловили стремительный рост количества внедрений NLU-технологий в 2015-2018-м годах.",
            "relation": "(2015-2018-м) isDateOf (NLU-технологий)"
          },
          {
            "text": "Продвижение в области технологий синтеза и распознавания речи, а также расширение использования мессенджеров и веб-чатов, в сочетании с этими технологиями, существенно способствовали быстрому распространению NLU-технологий в период с 2015 по 2018 год.",
            "relation": "(2015) isDateOf (NLU-технологий)"
          },
          {
            "text": "Продвижение в области технологий синтеза и распознавания речи, а также расширение использования мессенджеров и веб-чатов, в сочетании с этими технологиями, существенно способствовали быстрому распространению NLU-технологий в период с 2015 по 2018 год.",
            "relation": "(2018) isDateOf (NLU-технологий)"
          },
          {
            "text": "Тест был разработан группой исследователей в 2019 году.",
            "relation": "(2019 году) isDateOf (Тест)"
          },
          {
            "text": "Исследовательская группа разработала тест в 2019 году.",
            "relation": "(2019 году) isDateOf (тест)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(2020) isDateOf (Russian SuperGLUE)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(2020) isDateOf (SuperGLUE)"
          },
          {
            "text": "Известный учёный Алан Тьюринг в 1950 году усомнился в том, что машина не может мыслить, и для проверки предложил свой знаменитый тест.",
            "relation": "(1950) isDateOf (тест)"
          },
          {
            "text": "Поэтому в 1980-е годы внимание переключилось на систему другого класса: на алгоритмы машинного обучения и так называемую корпусную лингвистику.",
            "relation": "(1980-е) isDateOf (алгоритмы машинного обучения)"
          },
          {
            "text": "Поэтому внимание в 1980-х годах было перенаправлено на системы другого типа: на алгоритмы машинного обучения и корпусную лингвистику.",
            "relation": "(1980-х годах) isDateOf (алгоритмы машинного)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(ноябре 2021 года) isDateOf (JARVIS)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(ноябре 2021 года) isDateOf (JARVIS)"
          },
          {
            "text": "В 1950 году Алан Тьюринг в философском журнале Mind предложил такой тест, где судья должен определить, с кем он ведет диалог: с человеком или компьютером.",
            "relation": "(1950) isDateOf (тест)"
          },
          {
            "text": "В 1950 году Алан Тьюринг предложил такой тест в философском журнале \"Mind\", в котором судье необходимо определить, ведет ли он диалог с человеком или с компьютером.",
            "relation": "(1950) isDateOf (тест)"
          },
          {
            "text": "1970 г. Машинный перевод на основе правил (англ. RBMT) был первой попыткой научить машину переводить.",
            "relation": "(1970 г.) isDateOf (. RBMT)"
          },
          {
            "text": "1970 г. Машинный перевод на основе правил (англ. RBMT) был первой попыткой научить машину переводить.",
            "relation": "(1970 г.) isDateOf (Машинный перевод на основе правил)"
          },
          {
            "text": "1984 г. Машинный перевод на основе примеров (англ. EBMT) был способен переводить даже совсем не похожие друг на друга языки, где задавать какие-то правила было бесполезно.",
            "relation": "(1984 г.) isDateOf (Машинный перевод на основе примеров)"
          },
          {
            "text": "1984 г. Машинный перевод на основе примеров (англ. EBMT) был способен переводить даже совсем не похожие друг на друга языки, где задавать какие-то правила было бесполезно.",
            "relation": "(1984 г.) isDateOf (EBMT)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(1990 г.) isDateOf (SMT)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(1990 г.) isDateOf (Статистический машинный перевод)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 22,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(2001-м) isDateOf (Artificial Intelligence Markup Language)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(2001-м) isDateOf (AIML)"
          },
          {
            "text": "Именно эти технологии, вместе с заметным продвижением в области технологий синтеза и распознавания речи, а также распространением мессенджеров и вебчатов – обусловили стремительный рост количества внедрений NLU-технологий в 2015-2018-м годах.",
            "relation": "(2015-2018-м) isDateOf (NLU-технологий)"
          },
          {
            "text": "Продвижение в области технологий синтеза и распознавания речи, а также расширение использования мессенджеров и веб-чатов, в сочетании с этими технологиями, существенно способствовали быстрому распространению NLU-технологий в период с 2015 по 2018 год.",
            "relation": "(2015) isDateOf (NLU-технологий)"
          },
          {
            "text": "Продвижение в области технологий синтеза и распознавания речи, а также расширение использования мессенджеров и веб-чатов, в сочетании с этими технологиями, существенно способствовали быстрому распространению NLU-технологий в период с 2015 по 2018 год.",
            "relation": "(2018) isDateOf (NLU-технологий)"
          },
          {
            "text": "Тест был разработан группой исследователей в 2019 году.",
            "relation": "(2019 году) isDateOf (Тест)"
          },
          {
            "text": "Исследовательская группа разработала тест в 2019 году.",
            "relation": "(2019 году) isDateOf (тест)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(2020) isDateOf (Russian SuperGLUE)"
          },
          {
            "text": "В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE.",
            "relation": "(2020) isDateOf (SuperGLUE)"
          },
          {
            "text": "Известный учёный Алан Тьюринг в 1950 году усомнился в том, что машина не может мыслить, и для проверки предложил свой знаменитый тест.",
            "relation": "(1950) isDateOf (тест)"
          },
          {
            "text": "Поэтому в 1980-е годы внимание переключилось на систему другого класса: на алгоритмы машинного обучения и так называемую корпусную лингвистику.",
            "relation": "(1980-е) isDateOf (алгоритмы машинного обучения)"
          },
          {
            "text": "Поэтому внимание в 1980-х годах было перенаправлено на системы другого типа: на алгоритмы машинного обучения и корпусную лингвистику.",
            "relation": "(1980-х годах) isDateOf (алгоритмы машинного)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(ноябре 2021 года) isDateOf (JARVIS)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(ноябре 2021 года) isDateOf (JARVIS)"
          },
          {
            "text": "В 1950 году Алан Тьюринг в философском журнале Mind предложил такой тест, где судья должен определить, с кем он ведет диалог: с человеком или компьютером.",
            "relation": "(1950) isDateOf (тест)"
          },
          {
            "text": "В 1950 году Алан Тьюринг предложил такой тест в философском журнале \"Mind\", в котором судье необходимо определить, ведет ли он диалог с человеком или с компьютером.",
            "relation": "(1950) isDateOf (тест)"
          },
          {
            "text": "1970 г. Машинный перевод на основе правил (англ. RBMT) был первой попыткой научить машину переводить.",
            "relation": "(1970 г.) isDateOf (. RBMT)"
          },
          {
            "text": "1970 г. Машинный перевод на основе правил (англ. RBMT) был первой попыткой научить машину переводить.",
            "relation": "(1970 г.) isDateOf (Машинный перевод на основе правил)"
          },
          {
            "text": "1984 г. Машинный перевод на основе примеров (англ. EBMT) был способен переводить даже совсем не похожие друг на друга языки, где задавать какие-то правила было бесполезно.",
            "relation": "(1984 г.) isDateOf (Машинный перевод на основе примеров)"
          },
          {
            "text": "1984 г. Машинный перевод на основе примеров (англ. EBMT) был способен переводить даже совсем не похожие друг на друга языки, где задавать какие-то правила было бесполезно.",
            "relation": "(1984 г.) isDateOf (EBMT)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(1990 г.) isDateOf (SMT)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(1990 г.) isDateOf (Статистический машинный перевод)"
          }
        ]
      }
    }
  },
  "Task_isAlternativeNameFor_Task": {
    "predicted": {
      "incorrect": {
        "count": 16,
        "examples": [
          {
            "text": "Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.",
            "relation": "(регрессионного анализа) isAlternativeNameFor (определение зависимости между переменными)"
          },
          {
            "text": "Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.",
            "relation": "(регрессионного анализа) isAlternativeNameFor (оценкой функции регрессии)"
          },
          {
            "text": "Также фреймворк может решать задачи регрессионного анализа, целью которого является определение зависимости между переменными и оценкой функции регрессии.",
            "relation": "(определение зависимости между переменными) isAlternativeNameFor (оценкой функции регрессии)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(проверки орфографии) isAlternativeNameFor (исправления ошибок)"
          },
          {
            "text": "Для решения этой проблемы требуется архитектура, которая позволяет GPT-3 анализировать содержание письма и оценивать, какая информация актуальна для ответа.",
            "relation": "(анализировать содержание письма) isAlternativeNameFor (оценивать, какая информация актуальна)"
          },
          {
            "text": "Модель по умолчанию для конвейера генерации текста — GPT-2, самая популярная модель декодирующего трансформера для генерации языка.",
            "relation": "(генерации текста) isAlternativeNameFor (генерации языка)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(Inappropriateness identification) isAlternativeNameFor (Intent classification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(IC) isAlternativeNameFor (ICX)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(II) isAlternativeNameFor (Intent classification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(Inappropriateness identification) isAlternativeNameFor (IC)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(II) isAlternativeNameFor (IC)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(Intent classification) isAlternativeNameFor (ICX)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(Inappropriateness identification) isAlternativeNameFor (ICX)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(II) isAlternativeNameFor (ICX)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(NER) isAlternativeNameFor (классификации)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(извлечения именованных сущностей) isAlternativeNameFor (классификации)"
          }
        ]
      },
      "correct": {
        "count": 28,
        "examples": [
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(NLU) isAlternativeNameFor (понимания естественного языка)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Natural Language Understanding) isAlternativeNameFor (понимания естественного языка)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Natural Language Understanding) isAlternativeNameFor (NLU)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(NLG) isAlternativeNameFor (генерация)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(NLU) isAlternativeNameFor (понимание естественного языка)"
          },
          {
            "text": "За эту конвертацию отвечают платформы ASR (распознавание речи), TTS (синтез речи), системы интеграции с телефонией.",
            "relation": "(распознавание речи) isAlternativeNameFor (ASR)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(NLU) isAlternativeNameFor (понимания естественного языка)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(Natural Language Understanding) isAlternativeNameFor (понимания естественного языка)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(NLU) isAlternativeNameFor (Natural Language Understanding)"
          },
          {
            "text": "Это генеративная нейронная сеть, способная решать множество задач по обработке естествнного языка (NLP).",
            "relation": "(NLP) isAlternativeNameFor (задач по обработке естествнного языка)"
          },
          {
            "text": "Это такие задачи как суммаризация (сделать из большого текста его резюме), понимание текста (NLU), вопросно-ответные системы, генерация (например, стихов, — на Хабре была хорошая статья) и другие.",
            "relation": "(NLU) isAlternativeNameFor (понимание текста)"
          },
          {
            "text": "Для англоязычного nlp-сообщества задача поиска сложного слова в тексте называется так: CWI – complex word identification.",
            "relation": "(complex word identification) isAlternativeNameFor (CWI)"
          },
          {
            "text": "Первая была в 2019 году, называлась AGRR: Automatic Gapping Resolution for Russian.",
            "relation": "(Automatic Gapping Resolution for Russian) isAlternativeNameFor (AGRR)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(NER) isAlternativeNameFor (распознавания именованных сущностей)"
          },
          {
            "text": "Оценка состояния диалога (DST — Dialogue State Traking) является основным компонентом в таких диалоговых системах.",
            "relation": "(DST) isAlternativeNameFor (Оценка состояния диалога)"
          },
          {
            "text": "Оценка состояния диалога (DST — Dialogue State Traking) является основным компонентом в таких диалоговых системах.",
            "relation": "(Dialogue State Traking) isAlternativeNameFor (DST)"
          },
          {
            "text": "Оценка состояния диалога (DST — Dialogue State Traking) является основным компонентом в таких диалоговых системах.",
            "relation": "(Dialogue State Traking) isAlternativeNameFor (Оценка состояния диалога)"
          },
          {
            "text": "Участникам предлагалось определить потенциальные заболевания коров по реальным жалобам людей из открытых источников, а также научиться выделять из текстов симптомы заболеваний (NER - Named Entity Recognition).",
            "relation": "(Named Entity Recognition) isAlternativeNameFor (NER)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(NER) isAlternativeNameFor (задача выделения симптомов)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(SA) isAlternativeNameFor (Sentiment analysis)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(STS) isAlternativeNameFor (Semantic text similarity)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(NLI) isAlternativeNameFor (Natural language inference)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(PI) isAlternativeNameFor (Paraphrase identification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(II) isAlternativeNameFor (Inappropriateness identification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(TI) isAlternativeNameFor (Toxicity identification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(IC) isAlternativeNameFor (Intent classification)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(NER) isAlternativeNameFor (извлечения именованных сущностей)"
          },
          {
            "text": "Нейросети, которые могут преобразовывать речь в текст называются (сюрприз-сюрприз), speech-to-text.",
            "relation": "(speech-to-text) isAlternativeNameFor (преобразовывать речь в текст)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 28,
        "examples": [
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(NLU) isAlternativeNameFor (понимания естественного языка)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Natural Language Understanding) isAlternativeNameFor (NLU)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Natural Language Understanding) isAlternativeNameFor (понимания естественного языка)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(NLG) isAlternativeNameFor (генерация)"
          },
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(NLU) isAlternativeNameFor (понимание естественного языка)"
          },
          {
            "text": "За эту конвертацию отвечают платформы ASR (распознавание речи), TTS (синтез речи), системы интеграции с телефонией.",
            "relation": "(распознавание речи) isAlternativeNameFor (ASR)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(NLU) isAlternativeNameFor (понимания естественного языка)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(Natural Language Understanding) isAlternativeNameFor (понимания естественного языка)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(NLU) isAlternativeNameFor (Natural Language Understanding)"
          },
          {
            "text": "Это генеративная нейронная сеть, способная решать множество задач по обработке естествнного языка (NLP).",
            "relation": "(NLP) isAlternativeNameFor (задач по обработке естествнного языка)"
          },
          {
            "text": "Это такие задачи как суммаризация (сделать из большого текста его резюме), понимание текста (NLU), вопросно-ответные системы, генерация (например, стихов, — на Хабре была хорошая статья) и другие.",
            "relation": "(NLU) isAlternativeNameFor (понимание текста)"
          },
          {
            "text": "Для англоязычного nlp-сообщества задача поиска сложного слова в тексте называется так: CWI – complex word identification.",
            "relation": "(complex word identification) isAlternativeNameFor (CWI)"
          },
          {
            "text": "Первая была в 2019 году, называлась AGRR: Automatic Gapping Resolution for Russian.",
            "relation": "(Automatic Gapping Resolution for Russian) isAlternativeNameFor (AGRR)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(NER) isAlternativeNameFor (распознавания именованных сущностей)"
          },
          {
            "text": "Оценка состояния диалога (DST — Dialogue State Traking) является основным компонентом в таких диалоговых системах.",
            "relation": "(DST) isAlternativeNameFor (Оценка состояния диалога)"
          },
          {
            "text": "Оценка состояния диалога (DST — Dialogue State Traking) является основным компонентом в таких диалоговых системах.",
            "relation": "(Dialogue State Traking) isAlternativeNameFor (DST)"
          },
          {
            "text": "Оценка состояния диалога (DST — Dialogue State Traking) является основным компонентом в таких диалоговых системах.",
            "relation": "(Dialogue State Traking) isAlternativeNameFor (Оценка состояния диалога)"
          },
          {
            "text": "Участникам предлагалось определить потенциальные заболевания коров по реальным жалобам людей из открытых источников, а также научиться выделять из текстов симптомы заболеваний (NER - Named Entity Recognition).",
            "relation": "(Named Entity Recognition) isAlternativeNameFor (NER)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(NER) isAlternativeNameFor (задача выделения симптомов)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(SA) isAlternativeNameFor (Sentiment analysis)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(STS) isAlternativeNameFor (Semantic text similarity)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(NLI) isAlternativeNameFor (Natural language inference)"
          },
          {
            "text": "В новой версии бенчмарка я оставил всё те же 10 задач, что и в прежней, но слегка изменил формат некоторых из них:Semantic text similarity (STS) на основе переведённого датасета STS-B; Paraphrase identification (PI) на основе датасета paraphraser.ru;Natural language inference (NLI) на датасете XNLI; Sentiment analysis (SA) на данных SentiRuEval2016.",
            "relation": "(PI) isAlternativeNameFor (Paraphrase identification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(II) isAlternativeNameFor (Inappropriateness identification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(TI) isAlternativeNameFor (Toxicity identification)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(IC) isAlternativeNameFor (Intent classification)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(NER) isAlternativeNameFor (извлечения именованных сущностей)"
          },
          {
            "text": "Нейросети, которые могут преобразовывать речь в текст называются (сюрприз-сюрприз), speech-to-text.",
            "relation": "(speech-to-text) isAlternativeNameFor (преобразовывать речь в текст)"
          }
        ]
      }
    }
  },
  "Method_isAppliedTo_Object": {
    "predicted": {
      "incorrect": {
        "count": 5,
        "examples": [
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(методом обучения без учителя) isAppliedTo (устойчивые группы)"
          },
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(кластеризация) isAppliedTo (устойчивые группы)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(Взвешивание) isAppliedTo (социально-демографическим атрибутам)"
          },
          {
            "text": "Изначально на этапе MVP (minimum viable product) мы применяли регулярные выражения для извлечения сущности.",
            "relation": "(регулярные выражения) isAppliedTo (MVP)"
          },
          {
            "text": "Сначала тексты при помощи токенизатора переводятся в вектора - это то, на чем обучается модель.",
            "relation": "(токенизатора) isAppliedTo (вектора)"
          }
        ]
      },
      "correct": {
        "count": 57,
        "examples": [
          {
            "text": "Тогда модель определяется так, чтобы обучить эту модель без доступа к истинным меткам, это нужно обучаться с помощью логарифмического негативного маргинализированного правдоподобия, зная матрицу.",
            "relation": "(логарифмического негативного маргинализированного правдоподобия) isAppliedTo (матрицу)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(контекстно-свободных грамматик) isAppliedTo (текста)"
          },
          {
            "text": "Визуализация кластеров похожих слов с использование t-SNE.",
            "relation": "(t-SNE) isAppliedTo (кластеров)"
          },
          {
            "text": "Используя новый алгоритм упаковки, в Graphcore ускорили обработку естественного языка более чем в 2 раза при обучении BERT-Large.",
            "relation": "(алгоритм упаковки) isAppliedTo (естественного языка)"
          },
          {
            "text": "Автоматическое определение эмоций в текстовых беседах с использованием нейронных сетей",
            "relation": "(нейронных сетей) isAppliedTo (текстовых беседах)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(рекуррентной нейросети) isAppliedTo (текстовых беседах)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (сложных выражений)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (акронимы)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (эмодзи)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (эмотиконов)"
          },
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(методом обучения без учителя) isAppliedTo (обучающая выборка)"
          },
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(кластеризация) isAppliedTo (обучающая выборка)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(topic modeling) isAppliedTo (текстов)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(подход обучения без учителя) isAppliedTo (текстов)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(тематическим моделированием) isAppliedTo (текстов)"
          },
          {
            "text": "Среднее количество слов в запросе — четыре, поэтому мы собрали n-grams (словосочетания из 3-5 слов) и решили кластеризовать их разными методами типа тематического моделирования – agglomerative clustering поверх sentence embedding.",
            "relation": "(agglomerative clustering) isAppliedTo (n-grams)"
          },
          {
            "text": "Среднее количество слов в запросе — четыре, поэтому мы собрали n-grams (словосочетания из 3-5 слов) и решили кластеризовать их разными методами типа тематического моделирования – agglomerative clustering поверх sentence embedding.",
            "relation": "(sentence embedding) isAppliedTo (n-grams)"
          },
          {
            "text": "Стоит отметить, что и для них всё было непросто – конкурсная задача матчинга позволила удачно применить разработанный в Лаборатории ИИ метод генерации эмбеддингов транзакционных данных одновременно для двух разных доменов событийных данных (транзакции и кликстрим – атрибуты посещения веб-страниц).",
            "relation": "(метод генерации эмбеддингов транзакционных данных) isAppliedTo (кликстрим)"
          },
          {
            "text": "Стоит отметить, что и для них всё было непросто – конкурсная задача матчинга позволила удачно применить разработанный в Лаборатории ИИ метод генерации эмбеддингов транзакционных данных одновременно для двух разных доменов событийных данных (транзакции и кликстрим – атрибуты посещения веб-страниц).",
            "relation": "(метод генерации эмбеддингов транзакционных данных) isAppliedTo (транзакции)"
          },
          {
            "text": "Однако использование разработанного в Лаборатории ИИ метода генерации эмбеддингов транзакционных данных позволило успешно применить его одновременно к двум различным доменам событийных данных – транзакциям и кликстриму (атрибутам посещения веб-страниц).",
            "relation": "(метода генерации эмбеддингов транзакционных данных) isAppliedTo (кликстриму)"
          },
          {
            "text": "Однако использование разработанного в Лаборатории ИИ метода генерации эмбеддингов транзакционных данных позволило успешно применить его одновременно к двум различным доменам событийных данных – транзакциям и кликстриму (атрибутам посещения веб-страниц).",
            "relation": "(метода генерации эмбеддингов транзакционных данных) isAppliedTo (транзакциям)"
          },
          {
            "text": "Фичи для транзакций и кликов объединялись и подавались в алгоритм бустинга.",
            "relation": "(бустинга) isAppliedTo (Фичи)"
          },
          {
            "text": "Специалисты Data Science часто применяют различные методы получения датасетов.",
            "relation": "(методы получения) isAppliedTo (датасетов)"
          },
          {
            "text": "Профессионалы в области Data Science часто используют различные подходы к созданию наборов данных.",
            "relation": "(подходы к созданию) isAppliedTo (наборов данных)"
          },
          {
            "text": "Речь шла о морфологической разметке (part of speech tagging) современных текстов на русском языке.",
            "relation": "(part of speech tagging) isAppliedTo (текстов)"
          },
          {
            "text": "Речь шла о морфологической разметке (part of speech tagging) современных текстов на русском языке.",
            "relation": "(морфологической разметке) isAppliedTo (текстов)"
          },
          {
            "text": "Хорошим решением мне видится регрессия на координаты строк при выравнивании батча и сдвиг окна на конец потока при выравнивании следующего.",
            "relation": "(регрессия) isAppliedTo (координаты строк)"
          },
          {
            "text": "Генератор берет каждый аудиосегмент и предсказывает фонему, соответствующую звуку на языке.",
            "relation": "(Генератор) isAppliedTo (фонему)"
          },
          {
            "text": "Генератор берет каждый аудиосегмент и предсказывает фонему, соответствующую звуку на языке.",
            "relation": "(Генератор) isAppliedTo (аудиосегмент)"
          },
          {
            "text": "Итоговые коэффициенты, корректирующие смещение онлайн-выборки, можно рассчитать по методу Хорвица-Томпсона.",
            "relation": "(методу Хорвица-Томпсона) isAppliedTo (коэффициенты)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(Взвешивание) isAppliedTo (перекосов выборок)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(random forest) isAppliedTo (онлайн-опросов)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(случайных лесов) isAppliedTo (онлайн-опросов)"
          },
          {
            "text": "Сейчас стандарт коррекции онлайн-выборок находится на стадии обсуждения и разработки и метод Propensity Score Adjustment, который мы рассмотрели, может стать общепринятым способом коррекции онлайн-панелей.",
            "relation": "(метод Propensity Score Adjustment) isAppliedTo (онлайн-панелей)"
          },
          {
            "text": "Первая концепция — стемминг, мы пытаемся найти основу слова.",
            "relation": "(стемминг) isAppliedTo (основу слова)"
          },
          {
            "text": "Например, при анализе эмоциональной окраски очень важно, к чему относилось, условно говоря, слово «хороший» или «нет».",
            "relation": "(анализе эмоциональной окраски) isAppliedTo (слово)"
          },
          {
            "text": "Отчасти эти ситуации позволяют обработать методы построения \"векторных представлений слов\", например, знаменитый word2vec или более модные skip-gramm.",
            "relation": "(методы построения) isAppliedTo (векторных представлений слов)"
          },
          {
            "text": "Отчасти эти ситуации позволяют обработать методы построения \"векторных представлений слов\", например, знаменитый word2vec или более модные skip-gramm.",
            "relation": "(word2vec) isAppliedTo (векторных представлений слов)"
          },
          {
            "text": "Отчасти эти ситуации позволяют обработать методы построения \"векторных представлений слов\", например, знаменитый word2vec или более модные skip-gramm.",
            "relation": "(skip-gramm) isAppliedTo (векторных представлений слов)"
          },
          {
            "text": "Зачастую суммаризация предполагает работу с большими генеративными текстовыми моделями, куда надо «положить» все отзывы.",
            "relation": "(суммаризация) isAppliedTo (генеративными текстовыми моделями)"
          },
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(алгоритма для качественного удаления) isAppliedTo (фона)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(Статистический машинный перевод) isAppliedTo (языковые корпуса)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(SMT) isAppliedTo (языковые корпуса)"
          },
          {
            "text": "Сначала тексты при помощи токенизатора переводятся в вектора - это то, на чем обучается модель.",
            "relation": "(токенизатора) isAppliedTo (тексты)"
          },
          {
            "text": "Токены, относящиеся к ФИО, мы выделяем с помощью клиентской базы и проверки с помощью библиотек для морфологического анализа.",
            "relation": "(морфологического анализа) isAppliedTo (Токены)"
          },
          {
            "text": "Лемматизация оставшихся токенов.",
            "relation": "(Лемматизация) isAppliedTo (токенов)"
          },
          {
            "text": "Одним из подходов, позволяющих находить такие компоненты, является группа методов матричной факторизации.",
            "relation": "(методов матричной факторизации) isAppliedTo (компоненты)"
          },
          {
            "text": "Но большинство методов графовой репрезентации работает с одномодальными графами, поэтому обычно двухмодальные графы следует трансформировать в граф, где узлы представлены одним видом сущностей.",
            "relation": "(методов графовой репрезентации) isAppliedTo (одномодальными графами)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) isAppliedTo (токенов)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) isAppliedTo (эмбеддингов)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(грамматики зависимостей) isAppliedTo (синтаксических корпусов)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(грамматики зависимостей) isAppliedTo (трибанков)"
          },
          {
            "text": "Если для дальнейшей обработки не важен порядок слов, то текст упаковывают в Мешок слов (Bag-of-words).",
            "relation": "(Мешок слов) isAppliedTo (текст)"
          },
          {
            "text": "Если для дальнейшей обработки не важен порядок слов, то текст упаковывают в Мешок слов (Bag-of-words).",
            "relation": "(Bag-of-words) isAppliedTo (текст)"
          },
          {
            "text": "В обучающей выборке мы имеем письма с отметками спам/не спам, и скармливаем их в нейросеть: в полносвязную сеть и CNN подаем Bag-of-words, а в RNN уже можно учесть порядок слов, отправив ей Word Vector.",
            "relation": "(RNN) isAppliedTo (Word Vector)"
          },
          {
            "text": "Я расскажу вам о проведении бинарного анализа тональности русскоязычных текстов с использованием сверточной нейронной сети, векторные представления слов для которой были созданы с использованием обученной модели Word2Vec.",
            "relation": "(бинарного анализа тональности) isAppliedTo (русскоязычных текстов)"
          },
          {
            "text": "Я представлю вам анализ тональности русскоязычных текстов с применением сверточной нейронной сети, используя векторные представления слов, полученные из обученной модели Word2Vec.",
            "relation": "(анализ тональности) isAppliedTo (русскоязычных текстов)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 5,
        "examples": [
          {
            "text": "Я познакомлю вас с бинарным анализом тональности русскоязычных текстов с помощью свёрточной нейронной сети, для которой векторные представления слов были сформированы на основе обученной Word2Vec модели.",
            "relation": "(бинарным анализом тональности русскоязычных текстов) isAppliedTo (векторные представления слов)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (даты)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (валюты)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (время)"
          },
          {
            "text": "Обычно для этой цели используются нейросети, а полученные векторы называются эмбеддингами.",
            "relation": "(нейросети) isAppliedTo (эмбеддингами)"
          }
        ]
      },
      "found": {
        "count": 57,
        "examples": [
          {
            "text": "Тогда модель определяется так, чтобы обучить эту модель без доступа к истинным меткам, это нужно обучаться с помощью логарифмического негативного маргинализированного правдоподобия, зная матрицу.",
            "relation": "(логарифмического негативного маргинализированного правдоподобия) isAppliedTo (матрицу)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(контекстно-свободных грамматик) isAppliedTo (текста)"
          },
          {
            "text": "Визуализация кластеров похожих слов с использование t-SNE.",
            "relation": "(t-SNE) isAppliedTo (кластеров)"
          },
          {
            "text": "Используя новый алгоритм упаковки, в Graphcore ускорили обработку естественного языка более чем в 2 раза при обучении BERT-Large.",
            "relation": "(алгоритм упаковки) isAppliedTo (естественного языка)"
          },
          {
            "text": "Автоматическое определение эмоций в текстовых беседах с использованием нейронных сетей",
            "relation": "(нейронных сетей) isAppliedTo (текстовых беседах)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(рекуррентной нейросети) isAppliedTo (текстовых беседах)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (сложных выражений)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (акронимы)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (эмодзи)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isAppliedTo (эмотиконов)"
          },
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(методом обучения без учителя) isAppliedTo (обучающая выборка)"
          },
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(кластеризация) isAppliedTo (обучающая выборка)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(topic modeling) isAppliedTo (текстов)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(подход обучения без учителя) isAppliedTo (текстов)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(тематическим моделированием) isAppliedTo (текстов)"
          },
          {
            "text": "Среднее количество слов в запросе — четыре, поэтому мы собрали n-grams (словосочетания из 3-5 слов) и решили кластеризовать их разными методами типа тематического моделирования – agglomerative clustering поверх sentence embedding.",
            "relation": "(agglomerative clustering) isAppliedTo (n-grams)"
          },
          {
            "text": "Среднее количество слов в запросе — четыре, поэтому мы собрали n-grams (словосочетания из 3-5 слов) и решили кластеризовать их разными методами типа тематического моделирования – agglomerative clustering поверх sentence embedding.",
            "relation": "(sentence embedding) isAppliedTo (n-grams)"
          },
          {
            "text": "Стоит отметить, что и для них всё было непросто – конкурсная задача матчинга позволила удачно применить разработанный в Лаборатории ИИ метод генерации эмбеддингов транзакционных данных одновременно для двух разных доменов событийных данных (транзакции и кликстрим – атрибуты посещения веб-страниц).",
            "relation": "(метод генерации эмбеддингов транзакционных данных) isAppliedTo (кликстрим)"
          },
          {
            "text": "Стоит отметить, что и для них всё было непросто – конкурсная задача матчинга позволила удачно применить разработанный в Лаборатории ИИ метод генерации эмбеддингов транзакционных данных одновременно для двух разных доменов событийных данных (транзакции и кликстрим – атрибуты посещения веб-страниц).",
            "relation": "(метод генерации эмбеддингов транзакционных данных) isAppliedTo (транзакции)"
          },
          {
            "text": "Однако использование разработанного в Лаборатории ИИ метода генерации эмбеддингов транзакционных данных позволило успешно применить его одновременно к двум различным доменам событийных данных – транзакциям и кликстриму (атрибутам посещения веб-страниц).",
            "relation": "(метода генерации эмбеддингов транзакционных данных) isAppliedTo (кликстриму)"
          },
          {
            "text": "Однако использование разработанного в Лаборатории ИИ метода генерации эмбеддингов транзакционных данных позволило успешно применить его одновременно к двум различным доменам событийных данных – транзакциям и кликстриму (атрибутам посещения веб-страниц).",
            "relation": "(метода генерации эмбеддингов транзакционных данных) isAppliedTo (транзакциям)"
          },
          {
            "text": "Фичи для транзакций и кликов объединялись и подавались в алгоритм бустинга.",
            "relation": "(бустинга) isAppliedTo (Фичи)"
          },
          {
            "text": "Специалисты Data Science часто применяют различные методы получения датасетов.",
            "relation": "(методы получения) isAppliedTo (датасетов)"
          },
          {
            "text": "Профессионалы в области Data Science часто используют различные подходы к созданию наборов данных.",
            "relation": "(подходы к созданию) isAppliedTo (наборов данных)"
          },
          {
            "text": "Речь шла о морфологической разметке (part of speech tagging) современных текстов на русском языке.",
            "relation": "(part of speech tagging) isAppliedTo (текстов)"
          },
          {
            "text": "Речь шла о морфологической разметке (part of speech tagging) современных текстов на русском языке.",
            "relation": "(морфологической разметке) isAppliedTo (текстов)"
          },
          {
            "text": "Хорошим решением мне видится регрессия на координаты строк при выравнивании батча и сдвиг окна на конец потока при выравнивании следующего.",
            "relation": "(регрессия) isAppliedTo (координаты строк)"
          },
          {
            "text": "Генератор берет каждый аудиосегмент и предсказывает фонему, соответствующую звуку на языке.",
            "relation": "(Генератор) isAppliedTo (фонему)"
          },
          {
            "text": "Генератор берет каждый аудиосегмент и предсказывает фонему, соответствующую звуку на языке.",
            "relation": "(Генератор) isAppliedTo (аудиосегмент)"
          },
          {
            "text": "Итоговые коэффициенты, корректирующие смещение онлайн-выборки, можно рассчитать по методу Хорвица-Томпсона.",
            "relation": "(методу Хорвица-Томпсона) isAppliedTo (коэффициенты)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(Взвешивание) isAppliedTo (перекосов выборок)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(random forest) isAppliedTo (онлайн-опросов)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(случайных лесов) isAppliedTo (онлайн-опросов)"
          },
          {
            "text": "Сейчас стандарт коррекции онлайн-выборок находится на стадии обсуждения и разработки и метод Propensity Score Adjustment, который мы рассмотрели, может стать общепринятым способом коррекции онлайн-панелей.",
            "relation": "(метод Propensity Score Adjustment) isAppliedTo (онлайн-панелей)"
          },
          {
            "text": "Первая концепция — стемминг, мы пытаемся найти основу слова.",
            "relation": "(стемминг) isAppliedTo (основу слова)"
          },
          {
            "text": "Например, при анализе эмоциональной окраски очень важно, к чему относилось, условно говоря, слово «хороший» или «нет».",
            "relation": "(анализе эмоциональной окраски) isAppliedTo (слово)"
          },
          {
            "text": "Отчасти эти ситуации позволяют обработать методы построения \"векторных представлений слов\", например, знаменитый word2vec или более модные skip-gramm.",
            "relation": "(методы построения) isAppliedTo (векторных представлений слов)"
          },
          {
            "text": "Отчасти эти ситуации позволяют обработать методы построения \"векторных представлений слов\", например, знаменитый word2vec или более модные skip-gramm.",
            "relation": "(word2vec) isAppliedTo (векторных представлений слов)"
          },
          {
            "text": "Отчасти эти ситуации позволяют обработать методы построения \"векторных представлений слов\", например, знаменитый word2vec или более модные skip-gramm.",
            "relation": "(skip-gramm) isAppliedTo (векторных представлений слов)"
          },
          {
            "text": "Зачастую суммаризация предполагает работу с большими генеративными текстовыми моделями, куда надо «положить» все отзывы.",
            "relation": "(суммаризация) isAppliedTo (генеративными текстовыми моделями)"
          },
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(алгоритма для качественного удаления) isAppliedTo (фона)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(Статистический машинный перевод) isAppliedTo (языковые корпуса)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(SMT) isAppliedTo (языковые корпуса)"
          },
          {
            "text": "Сначала тексты при помощи токенизатора переводятся в вектора - это то, на чем обучается модель.",
            "relation": "(токенизатора) isAppliedTo (тексты)"
          },
          {
            "text": "Токены, относящиеся к ФИО, мы выделяем с помощью клиентской базы и проверки с помощью библиотек для морфологического анализа.",
            "relation": "(морфологического анализа) isAppliedTo (Токены)"
          },
          {
            "text": "Лемматизация оставшихся токенов.",
            "relation": "(Лемматизация) isAppliedTo (токенов)"
          },
          {
            "text": "Одним из подходов, позволяющих находить такие компоненты, является группа методов матричной факторизации.",
            "relation": "(методов матричной факторизации) isAppliedTo (компоненты)"
          },
          {
            "text": "Но большинство методов графовой репрезентации работает с одномодальными графами, поэтому обычно двухмодальные графы следует трансформировать в граф, где узлы представлены одним видом сущностей.",
            "relation": "(методов графовой репрезентации) isAppliedTo (одномодальными графами)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) isAppliedTo (токенов)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(логистическую регрессию) isAppliedTo (эмбеддингов)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(грамматики зависимостей) isAppliedTo (синтаксических корпусов)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(грамматики зависимостей) isAppliedTo (трибанков)"
          },
          {
            "text": "Если для дальнейшей обработки не важен порядок слов, то текст упаковывают в Мешок слов (Bag-of-words).",
            "relation": "(Мешок слов) isAppliedTo (текст)"
          },
          {
            "text": "Если для дальнейшей обработки не важен порядок слов, то текст упаковывают в Мешок слов (Bag-of-words).",
            "relation": "(Bag-of-words) isAppliedTo (текст)"
          },
          {
            "text": "В обучающей выборке мы имеем письма с отметками спам/не спам, и скармливаем их в нейросеть: в полносвязную сеть и CNN подаем Bag-of-words, а в RNN уже можно учесть порядок слов, отправив ей Word Vector.",
            "relation": "(RNN) isAppliedTo (Word Vector)"
          },
          {
            "text": "Я расскажу вам о проведении бинарного анализа тональности русскоязычных текстов с использованием сверточной нейронной сети, векторные представления слов для которой были созданы с использованием обученной модели Word2Vec.",
            "relation": "(бинарного анализа тональности) isAppliedTo (русскоязычных текстов)"
          },
          {
            "text": "Я представлю вам анализ тональности русскоязычных текстов с применением сверточной нейронной сети, используя векторные представления слов, полученные из обученной модели Word2Vec.",
            "relation": "(анализ тональности) isAppliedTo (русскоязычных текстов)"
          }
        ]
      }
    }
  },
  "Method_uses_Model": {
    "predicted": {
      "incorrect": {
        "count": 10,
        "examples": [
          {
            "text": "Возникли модели, основанные на краудсорсинге: мы не только пытаемся что-то понять с помощью машины, а подключаем людей, которые за небольшую плату определяют, на каком языке написан текст.",
            "relation": "(краудсорсинге) uses (модели)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(JARVIS) uses (ruGPT-3)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(JARVIS) uses (ruGPT-3)"
          },
          {
            "text": "Чтобы определить, какие ещё есть потенциальные классы, мы повели так называемое тематическое моделирование, используя несколько подходов: начиная от пробалистических моделей (латентное распределение Дирихле, ARTM) и всё те же нейронные сети (BERT).",
            "relation": "(нейронные сети) uses (BERT)"
          },
          {
            "text": "Теперь нам нужно было использовать некоторые технические способы, чтобы сделать максимально высоким качество модели, которая на новых классах давала точность 72%.",
            "relation": "(технические способы) uses (модели)"
          },
          {
            "text": "Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).",
            "relation": "(самовнимании) uses (Трансформеры)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(сентимент анализу) uses (Байесовы модели)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(Байес) uses (Байесовы модели)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(федеративное обучение) uses (рекуррентную нейронную сеть с долгой краткосрочной памятью)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(LSTM) uses (глобальную модель)"
          }
        ]
      },
      "correct": {
        "count": 13,
        "examples": [
          {
            "text": "За основу возьмем данную статью, в которой была рассмотрена классификация тональности на архитектуре CNN с использованием Word2vec модели.",
            "relation": "(CNN) uses (Word2vec)"
          },
          {
            "text": "Я познакомлю вас с бинарным анализом тональности русскоязычных текстов с помощью свёрточной нейронной сети, для которой векторные представления слов были сформированы на основе обученной Word2Vec модели.",
            "relation": "(бинарным анализом тональности русскоязычных текстов) uses (свёрточной нейронной сети)"
          },
          {
            "text": "Я познакомлю вас с бинарным анализом тональности русскоязычных текстов с помощью свёрточной нейронной сети, для которой векторные представления слов были сформированы на основе обученной Word2Vec модели.",
            "relation": "(бинарным анализом тональности русскоязычных текстов) uses (Word2Vec)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(ансамблей моделей) uses (mGPT)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(FPB) uses (рекуррентную нейронную сеть с долгой краткосрочной памятью)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(способ обнаружения фишинговых сообщений) uses (рекуррентную нейронную сеть с долгой краткосрочной памятью)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(FPB) uses (LSTM)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(Federated Phish Bowl) uses (рекуррентную нейронную сеть с долгой краткосрочной памятью)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(способ обнаружения фишинговых сообщений) uses (LSTM)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(Federated Phish Bowl) uses (LSTM)"
          },
          {
            "text": "Я расскажу вам о проведении бинарного анализа тональности русскоязычных текстов с использованием сверточной нейронной сети, векторные представления слов для которой были созданы с использованием обученной модели Word2Vec.",
            "relation": "(бинарного анализа тональности) uses (Word2Vec)"
          },
          {
            "text": "Я расскажу вам о проведении бинарного анализа тональности русскоязычных текстов с использованием сверточной нейронной сети, векторные представления слов для которой были созданы с использованием обученной модели Word2Vec.",
            "relation": "(бинарного анализа тональности) uses (сверточной нейронной сети)"
          },
          {
            "text": "Я представлю вам анализ тональности русскоязычных текстов с применением сверточной нейронной сети, используя векторные представления слов, полученные из обученной модели Word2Vec.",
            "relation": "(анализ тональности) uses (Word2Vec)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 2,
        "examples": [
          {
            "text": "Я представлю вам анализ тональности русскоязычных текстов с применением сверточной нейронной сети, используя векторные представления слов, полученные из обученной модели Word2Vec.",
            "relation": "(анализ тональности) uses (сверточной нейронной сети)"
          },
          {
            "text": "Давайте обратимся к этой статье, где была исследована классификация тональности с использованием модели Word2vec в архитектуре CNN.",
            "relation": "(CNN) uses (Word2vec)"
          }
        ]
      },
      "found": {
        "count": 13,
        "examples": [
          {
            "text": "За основу возьмем данную статью, в которой была рассмотрена классификация тональности на архитектуре CNN с использованием Word2vec модели.",
            "relation": "(CNN) uses (Word2vec)"
          },
          {
            "text": "Я познакомлю вас с бинарным анализом тональности русскоязычных текстов с помощью свёрточной нейронной сети, для которой векторные представления слов были сформированы на основе обученной Word2Vec модели.",
            "relation": "(бинарным анализом тональности русскоязычных текстов) uses (свёрточной нейронной сети)"
          },
          {
            "text": "Я познакомлю вас с бинарным анализом тональности русскоязычных текстов с помощью свёрточной нейронной сети, для которой векторные представления слов были сформированы на основе обученной Word2Vec модели.",
            "relation": "(бинарным анализом тональности русскоязычных текстов) uses (Word2Vec)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(ансамблей моделей) uses (mGPT)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(способ обнаружения фишинговых сообщений) uses (рекуррентную нейронную сеть с долгой краткосрочной памятью)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(FPB) uses (LSTM)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(Federated Phish Bowl) uses (рекуррентную нейронную сеть с долгой краткосрочной памятью)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(способ обнаружения фишинговых сообщений) uses (LSTM)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(Federated Phish Bowl) uses (LSTM)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(FPB) uses (рекуррентную нейронную сеть с долгой краткосрочной памятью)"
          },
          {
            "text": "Я расскажу вам о проведении бинарного анализа тональности русскоязычных текстов с использованием сверточной нейронной сети, векторные представления слов для которой были созданы с использованием обученной модели Word2Vec.",
            "relation": "(бинарного анализа тональности) uses (Word2Vec)"
          },
          {
            "text": "Я расскажу вам о проведении бинарного анализа тональности русскоязычных текстов с использованием сверточной нейронной сети, векторные представления слов для которой были созданы с использованием обученной модели Word2Vec.",
            "relation": "(бинарного анализа тональности) uses (сверточной нейронной сети)"
          },
          {
            "text": "Я представлю вам анализ тональности русскоязычных текстов с применением сверточной нейронной сети, используя векторные представления слов, полученные из обученной модели Word2Vec.",
            "relation": "(анализ тональности) uses (Word2Vec)"
          }
        ]
      }
    }
  },
  "Model_isAlternativeNameFor_Model": {
    "predicted": {
      "incorrect": {
        "count": 4,
        "examples": [
          {
            "text": "Модель, которую построил заказчик использовала вектора слов word2vec и рекуррентную нейронную сеть на базе GRU (gated recurrent unit) (Рис 1а).",
            "relation": "(рекуррентную нейронную сеть) isAlternativeNameFor (gated recurrent unit)"
          },
          {
            "text": "Модель, которую построил заказчик использовала вектора слов word2vec и рекуррентную нейронную сеть на базе GRU (gated recurrent unit) (Рис 1а).",
            "relation": "(рекуррентную нейронную сеть) isAlternativeNameFor (GRU)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMO) isAlternativeNameFor (ELMo)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) isAlternativeNameFor (Трансформер)"
          }
        ]
      },
      "correct": {
        "count": 21,
        "examples": [
          {
            "text": "Модель, которую построил заказчик использовала вектора слов word2vec и рекуррентную нейронную сеть на базе GRU (gated recurrent unit) (Рис 1а).",
            "relation": "(GRU) isAlternativeNameFor (gated recurrent unit)"
          },
          {
            "text": "Кроме того, DeBERTa будет интегрирована в следующую версию Тьюринговой модели Microsoft Turing (Turing NLRv4).",
            "relation": "(Turing NLRv4) isAlternativeNameFor (Тьюринговой модели Microsoft Turing)"
          },
          {
            "text": "Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.",
            "relation": "(Turing NLRv4) isAlternativeNameFor (Microsoft Turing)"
          },
          {
            "text": "Она работает на языковой модели из семейства YaLM (Yet another Language Model).",
            "relation": "(Yet another Language Model) isAlternativeNameFor (YaLM)"
          },
          {
            "text": "Она использует языковую модель из семейства YaLM (Yet another Language Model).",
            "relation": "(Yet another Language Model) isAlternativeNameFor (YaLM)"
          },
          {
            "text": "В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM.",
            "relation": "(Hierarchical Fusion Model) isAlternativeNameFor (HFM)"
          },
          {
            "text": "SequenceEncoder – рекурентно-нейронная сеть (RNN), совместно используемая для транзакций и кликов.",
            "relation": "(RNN) isAlternativeNameFor (рекурентно-нейронная сеть)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) isAlternativeNameFor (DABUS)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) isAlternativeNameFor (DABUS)"
          },
          {
            "text": "Чтобы научиться распознавать слова в аудиозаписи, Facebook обучила генеративную состязательную сеть (GAN).",
            "relation": "(GAN) isAlternativeNameFor (генеративную состязательную сеть)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BLOOM) isAlternativeNameFor (BigScience Large Open-science Open-access Multilingual Language Model)"
          },
          {
            "text": "Большие языковые модели или LLM (Large Language Models) — это алгоритмы глубокого обучения, которые обучаются на огромных объемах данных.",
            "relation": "(Large Language Models) isAlternativeNameFor (LLM)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(Bidirectional Encoder Representations from Transformers) isAlternativeNameFor (BERT)"
          },
          {
            "text": "В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isAlternativeNameFor (GOLOMB)"
          },
          {
            "text": "В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isAlternativeNameFor (GOLOMB)"
          },
          {
            "text": "BERT, или Bidirectional Encoder Representations from Transformers, — нейросетевая модель-трансформер от Google, на которой сегодня строится большинство инструментов автоматической обработки языка.",
            "relation": "(Bidirectional Encoder Representations from Transformers) isAlternativeNameFor (BERT)"
          },
          {
            "text": "BERT, сокращение от Bidirectional Encoder Representations from Transformers, представляет собой нейросетевую модель-трансформер от Google, на базе которой в настоящее время разрабатывается большинство средств автоматической обработки языка.",
            "relation": "(Bidirectional Encoder Representations from Transformers) isAlternativeNameFor (BERT)"
          },
          {
            "text": "Можно попробовать прикрутить к итоговому набору текстов алгоритм BERT (Bi-directional Encoder Representation from Transformer), описание есть тут.",
            "relation": "(Bi-directional Encoder Representation from Transformer) isAlternativeNameFor (BERT)"
          },
          {
            "text": "Вы можете попробовать интегрировать алгоритм BERT (Bi-directional Encoder Representation from Transformer) в окончательный набор текстов, описание которого доступно здесь.",
            "relation": "(Bi-directional Encoder Representation from Transformer) isAlternativeNameFor (BERT)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(LSTM) isAlternativeNameFor (рекуррентную нейронную сеть с долгой краткосрочной памятью)"
          },
          {
            "text": "SequenceEncoder представляет собой рекуррентную нейронную сеть (RNN), применяемую для анализа последовательностей в данных о транзакциях и кликах.",
            "relation": "(RNN) isAlternativeNameFor (рекуррентную нейронную сеть)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 21,
        "examples": [
          {
            "text": "Модель, которую построил заказчик использовала вектора слов word2vec и рекуррентную нейронную сеть на базе GRU (gated recurrent unit) (Рис 1а).",
            "relation": "(GRU) isAlternativeNameFor (gated recurrent unit)"
          },
          {
            "text": "Кроме того, DeBERTa будет интегрирована в следующую версию Тьюринговой модели Microsoft Turing (Turing NLRv4).",
            "relation": "(Turing NLRv4) isAlternativeNameFor (Тьюринговой модели Microsoft Turing)"
          },
          {
            "text": "Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.",
            "relation": "(Turing NLRv4) isAlternativeNameFor (Microsoft Turing)"
          },
          {
            "text": "Она работает на языковой модели из семейства YaLM (Yet another Language Model).",
            "relation": "(Yet another Language Model) isAlternativeNameFor (YaLM)"
          },
          {
            "text": "Она использует языковую модель из семейства YaLM (Yet another Language Model).",
            "relation": "(Yet another Language Model) isAlternativeNameFor (YaLM)"
          },
          {
            "text": "В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM.",
            "relation": "(Hierarchical Fusion Model) isAlternativeNameFor (HFM)"
          },
          {
            "text": "SequenceEncoder – рекурентно-нейронная сеть (RNN), совместно используемая для транзакций и кликов.",
            "relation": "(RNN) isAlternativeNameFor (рекурентно-нейронная сеть)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) isAlternativeNameFor (DABUS)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) isAlternativeNameFor (DABUS)"
          },
          {
            "text": "Чтобы научиться распознавать слова в аудиозаписи, Facebook обучила генеративную состязательную сеть (GAN).",
            "relation": "(GAN) isAlternativeNameFor (генеративную состязательную сеть)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BLOOM) isAlternativeNameFor (BigScience Large Open-science Open-access Multilingual Language Model)"
          },
          {
            "text": "Большие языковые модели или LLM (Large Language Models) — это алгоритмы глубокого обучения, которые обучаются на огромных объемах данных.",
            "relation": "(Large Language Models) isAlternativeNameFor (LLM)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(Bidirectional Encoder Representations from Transformers) isAlternativeNameFor (BERT)"
          },
          {
            "text": "В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isAlternativeNameFor (GOLOMB)"
          },
          {
            "text": "В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isAlternativeNameFor (GOLOMB)"
          },
          {
            "text": "BERT, или Bidirectional Encoder Representations from Transformers, — нейросетевая модель-трансформер от Google, на которой сегодня строится большинство инструментов автоматической обработки языка.",
            "relation": "(Bidirectional Encoder Representations from Transformers) isAlternativeNameFor (BERT)"
          },
          {
            "text": "BERT, сокращение от Bidirectional Encoder Representations from Transformers, представляет собой нейросетевую модель-трансформер от Google, на базе которой в настоящее время разрабатывается большинство средств автоматической обработки языка.",
            "relation": "(Bidirectional Encoder Representations from Transformers) isAlternativeNameFor (BERT)"
          },
          {
            "text": "Можно попробовать прикрутить к итоговому набору текстов алгоритм BERT (Bi-directional Encoder Representation from Transformer), описание есть тут.",
            "relation": "(Bi-directional Encoder Representation from Transformer) isAlternativeNameFor (BERT)"
          },
          {
            "text": "Вы можете попробовать интегрировать алгоритм BERT (Bi-directional Encoder Representation from Transformer) в окончательный набор текстов, описание которого доступно здесь.",
            "relation": "(Bi-directional Encoder Representation from Transformer) isAlternativeNameFor (BERT)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(LSTM) isAlternativeNameFor (рекуррентную нейронную сеть с долгой краткосрочной памятью)"
          },
          {
            "text": "SequenceEncoder представляет собой рекуррентную нейронную сеть (RNN), применяемую для анализа последовательностей в данных о транзакциях и кликах.",
            "relation": "(RNN) isAlternativeNameFor (рекуррентную нейронную сеть)"
          }
        ]
      }
    }
  },
  "Model_hasAuthor_Organization": {
    "predicted": {
      "incorrect": {
        "count": 18,
        "examples": [
          {
            "text": "Генеративные модели на основании federated learning – будущее перспективное направление по мнению Google, которое находится “в ранних стадиях экспоненциального роста”.",
            "relation": "(Генеративные модели) hasAuthor (Google)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) hasAuthor (Microsoft)"
          },
          {
            "text": "Facebook AI отмечает, что эта модель может быть полезной не только при машинном переводе, но и при изучении языков.",
            "relation": "(модель) hasAuthor (Facebook AI)"
          },
          {
            "text": "Используя новый алгоритм упаковки, в Graphcore ускорили обработку естественного языка более чем в 2 раза при обучении BERT-Large.",
            "relation": "(BERT-Large) hasAuthor (Graphcore)"
          },
          {
            "text": "В новой работе Graphcore представили высокоэффективный алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами (или NNLSHP), а также алгоритм BERT, применяемый к упакованным последовательностям.",
            "relation": "(BERT) hasAuthor (Graphcore)"
          },
          {
            "text": "В последнем исследовании от Graphcore был представлен эффективный алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов (NNLSHP), а также алгоритм BERT, примененный к упакованным последовательностям.",
            "relation": "(BERT) hasAuthor (Graphcore)"
          },
          {
            "text": "В обоих случаях они от Texas Instruments, но в Станции Макс используется более свежая и мощная модель TAS5825M.",
            "relation": "(TAS5825M) hasAuthor (Texas Instruments)"
          },
          {
            "text": "На этапе обучения text-davinci-003 используются датасеты текстов и программного кода, собранные OpenAI на момент конца 2021 года.",
            "relation": "(text-davinci-003) hasAuthor (OpenAI)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(LLM) hasAuthor (Французского национального центра научных исследований)"
          },
          {
            "text": "И уже сейчас над BLOOM работают более тысячи исследователей-добровольцев в рамках проекта под названием BigScience, который координирует стартап Hugging Face, существующий за счет финансовой поддержки французского правительства.",
            "relation": "(BLOOM) hasAuthor (Hugging Face)"
          },
          {
            "text": "Более тысячи добровольных исследователей уже вовлечены в работу над моделью BLOOM в рамках проекта BigScience, который управляется стартапом Hugging Face.",
            "relation": "(BLOOM) hasAuthor (Hugging Face)"
          },
          {
            "text": "«Сбер» представил mGPT — версию нейросети GPT-3, способную генерировать тексты на 61 языке",
            "relation": "(GPT-3) hasAuthor (Сбер)"
          },
          {
            "text": "21 апреля 2022 года команда разработчиков SberDevices представила многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(GPT-3) hasAuthor (SberDevices)"
          },
          {
            "text": "21 апреля 2022 года SberDevices представили многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(GPT-3) hasAuthor (SberDevices)"
          },
          {
            "text": "Между тем создатели проекта GPT-Neo от EleutherAI решили воссоздать аналог GPT-3, но с открытым исходным кодом.",
            "relation": "(GPT-3) hasAuthor (EleutherAI)"
          },
          {
            "text": "Команда DeepPavlov интегрировала BERT в три последующие задачи: классификация текста, распознавание именованных сущностей и ответы на вопросы.",
            "relation": "(BERT) hasAuthor (DeepPavlov)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMO) hasAuthor (UW CSE)"
          },
          {
            "text": "В процессе обучения модели text-davinci-003 применяются наборы данных текстов и программного кода, собранные OpenAI к концу 2021 года.",
            "relation": "(text-davinci-003) hasAuthor (OpenAI)"
          }
        ]
      },
      "correct": {
        "count": 67,
        "examples": [
          {
            "text": "Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.",
            "relation": "(DeBERTa) hasAuthor (Microsoft)"
          },
          {
            "text": "Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.",
            "relation": "(Turing NLRv4) hasAuthor (Microsoft)"
          },
          {
            "text": "Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.",
            "relation": "(Microsoft Turing) hasAuthor (Microsoft)"
          },
          {
            "text": "Модель ULMFIT была представлена разработчиками fast.ai (Jeremy Howard, Sebastian Ruder) в 2018 году.",
            "relation": "(ULMFIT) hasAuthor (fast.ai)"
          },
          {
            "text": "«М.видео-Эльдорадо» внедряет нейросеть для ответов на вопросы покупателей",
            "relation": "(нейросеть) hasAuthor (М.видео-Эльдорадо)"
          },
          {
            "text": "Facebook AI представила новую систему машинного перевода M2M-100 с 15 млрд параметров.",
            "relation": "(M2M-100) hasAuthor (Facebook AI)"
          },
          {
            "text": "В этом посте мы расскажем, как мы создали датасет для задачи Common Sense Reasoning в одной из ее возможных формулировок, предложенной в статье event2mind, а также адаптировали английскую модель event2mind от AllenNLP для русского языка.",
            "relation": "(event2mind) hasAuthor (AllenNLP)"
          },
          {
            "text": "В последствии эта модель легла в основу модели SBERT наших коллег из смежной команды SberDevices, которую они выложили в открытый доступ.",
            "relation": "(SBERT) hasAuthor (SberDevices)"
          },
          {
            "text": "А на некоторых заданиях лучших результатов удалось достичь на few-shot, т. е. без дообучения модели (задача RCB и RuCoS, YaLM от Яндекса).",
            "relation": "(YaLM) hasAuthor (Яндекса)"
          },
          {
            "text": "Нейросеть от Стэнфорда демонстрирует точность в 85% при определении тональности текста.",
            "relation": "(Нейросеть) hasAuthor (Стэнфорда)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(DABUS) hasAuthor (Imagination Engines)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) hasAuthor (Imagination Engines)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(DABUS) hasAuthor (Imagination Engines)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) hasAuthor (Imagination Engines)"
          },
          {
            "text": "Чтобы научиться распознавать слова в аудиозаписи, Facebook обучила генеративную состязательную сеть (GAN).",
            "relation": "(генеративную состязательную сеть) hasAuthor (Facebook)"
          },
          {
            "text": "Новая модель распознавания речи Facebook AI — это последняя разработка за несколько лет работы над моделями распознавания речи.",
            "relation": "(модель распознавания речи) hasAuthor (Facebook AI)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BigScience Large Open-science Open-access Multilingual Language Model) hasAuthor (French National Center for Scientific Research)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BigScience Large Open-science Open-access Multilingual Language Model) hasAuthor (Французского национального центра научных исследований)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BLOOM) hasAuthor (French National Center for Scientific Research)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BLOOM) hasAuthor (Французского национального центра научных исследований)"
          },
          {
            "text": "Недавно ученые из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о выходе модели BLOOM.",
            "relation": "(BLOOM) hasAuthor (French National Center for Scientific Research)"
          },
          {
            "text": "Недавно ученые из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о выходе модели BLOOM.",
            "relation": "(BLOOM) hasAuthor (Французского национального центра научных исследований)"
          },
          {
            "text": "Недавно был релиз модели BLOOM, которую разработала команда из Французского национального центра научных исследований (French National Center for Scientific Research).",
            "relation": "(BLOOM) hasAuthor (French National Center for Scientific Research)"
          },
          {
            "text": "Недавно был релиз модели BLOOM, которую разработала команда из Французского национального центра научных исследований (French National Center for Scientific Research).",
            "relation": "(BLOOM) hasAuthor (Французского национального центра научных исследований)"
          },
          {
            "text": "Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.",
            "relation": "(GPT-3) hasAuthor (OpenAI)"
          },
          {
            "text": "Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.",
            "relation": "(LaMDA) hasAuthor (Google)"
          },
          {
            "text": "В июне текущего года инженер Google Блейк Лемуан (он на фото выше) ошарашил мировую общественность заявлением, что LLM LaMDA, над которой он работал вместе с другими программистами, может обладать некоторым подобием разума.",
            "relation": "(LLM LaMDA) hasAuthor (Google)"
          },
          {
            "text": "В частности, DALL-E 2 от OpenAI провалил тест на различение изображений астронавтов, едущих на лошадях, перепутав их с лошадьми, оседлавшими астронавтов.",
            "relation": "(DALL-E 2) hasAuthor (OpenAI)"
          },
          {
            "text": "«Сбер» представил mGPT — версию нейросети GPT-3, способную генерировать тексты на 61 языке",
            "relation": "(mGPT) hasAuthor (Сбер)"
          },
          {
            "text": "21 апреля 2022 года команда разработчиков SberDevices представила многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(mGPT) hasAuthor (SberDevices)"
          },
          {
            "text": "21 апреля 2022 года SberDevices представили многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(mGPT) hasAuthor (SberDevices)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(mGPT) hasAuthor (Сбер)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(mGPT) hasAuthor (Сбер)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(версию нейросети GPT-3) hasAuthor (Сбер)"
          },
          {
            "text": "Русскоязычная версия GPT-3, разработанная «Сбером», доступна на платформе SmartMarket.",
            "relation": "(версия GPT-3) hasAuthor (Сбером)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(ruGPT-3) hasAuthor (Сбер)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(ruGPT-3) hasAuthor (Сбер)"
          },
          {
            "text": "Для решения описанной задачи используется модель от DeepPavlov rubert-base-cased-sentence.",
            "relation": "(rubert-base-cased-sentence) hasAuthor (DeepPavlov)"
          },
          {
            "text": "С моделью от OpenAI связано сразу несколько новостей — хорошая и не очень.",
            "relation": "(моделью) hasAuthor (OpenAI)"
          },
          {
            "text": "ruGPT3 от Сбера.",
            "relation": "(ruGPT3) hasAuthor (Сбера)"
          },
          {
            "text": "OpenAI представила модель машинного обучения GPT-3, обученную на 175 млрд параметров, в июне 2020 года.",
            "relation": "(GPT-3) hasAuthor (OpenAI)"
          },
          {
            "text": "В июне 2020 года OpenAI представила модель машинного обучения GPT-3, обученную на 175 миллиардах параметров.",
            "relation": "(GPT-3) hasAuthor (OpenAI)"
          },
          {
            "text": "Прорывы #DeepPavlov в 2019 году: обзор и итоги года Московский физико-технический институт (МФТИ).",
            "relation": "(#DeepPavlov) hasAuthor (МФТИ)"
          },
          {
            "text": "Прорывы #DeepPavlov в 2019 году: обзор и итоги года Московский физико-технический институт (МФТИ).",
            "relation": "(#DeepPavlov) hasAuthor (Московский физико-технический институт)"
          },
          {
            "text": "Модель DeepPavlov была разработана командой из Московского физико-технического института (МФТИ).",
            "relation": "(DeepPavlov) hasAuthor (МФТИ)"
          },
          {
            "text": "Модель DeepPavlov была разработана командой из Московского физико-технического института (МФТИ).",
            "relation": "(DeepPavlov) hasAuthor (Московского физико-технического института)"
          },
          {
            "text": "Команда исследователей из Московского физико-технического института (МФТИ) представила модель DeepPavlov.",
            "relation": "(DeepPavlov) hasAuthor (МФТИ)"
          },
          {
            "text": "Команда исследователей из Московского физико-технического института (МФТИ) представила модель DeepPavlov.",
            "relation": "(DeepPavlov) hasAuthor (Московского физико-технического института)"
          },
          {
            "text": "Команда DeepPavlov обучила модель NER на англоязычном корпусе OntoNotes, который имеет 19 типов разметки, включая PER (человек), LOC (местоположение), ORG (организация) и многие другие.",
            "relation": "(модель NER) hasAuthor (DeepPavlov)"
          },
          {
            "text": "BERT, или Bidirectional Encoder Representations from Transformers, — нейросетевая модель-трансформер от Google, на которой сегодня строится большинство инструментов автоматической обработки языка.",
            "relation": "(BERT) hasAuthor (Google)"
          },
          {
            "text": "BERT, или Bidirectional Encoder Representations from Transformers, — нейросетевая модель-трансформер от Google, на которой сегодня строится большинство инструментов автоматической обработки языка.",
            "relation": "(Bidirectional Encoder Representations from Transformers) hasAuthor (Google)"
          },
          {
            "text": "BERT, сокращение от Bidirectional Encoder Representations from Transformers, представляет собой нейросетевую модель-трансформер от Google, на базе которой в настоящее время разрабатывается большинство средств автоматической обработки языка.",
            "relation": "(BERT) hasAuthor (Google)"
          },
          {
            "text": "BERT, сокращение от Bidirectional Encoder Representations from Transformers, представляет собой нейросетевую модель-трансформер от Google, на базе которой в настоящее время разрабатывается большинство средств автоматической обработки языка.",
            "relation": "(Bidirectional Encoder Representations from Transformers) hasAuthor (Google)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (OpenAI Radford)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMo) hasAuthor (UW CSE)"
          },
          {
            "text": "Разработкой и обучением модели BERT занималась целая группа исследователей Google AI Language на многомиллионном наборе слов на разных языках (более 100).",
            "relation": "(BERT) hasAuthor (Google AI Language)"
          },
          {
            "text": "На практике OpenAI уже давно не Open, а недавняя история с DALLE-2 / Midjourney / Stable Diffusion скорее иллюстрируют тренд.",
            "relation": "(DALLE-2) hasAuthor (OpenAI)"
          },
          {
            "text": "Эта модель GPT2 от CKIPLab предварительно обучена на китайском корпусе, поэтому мы можем использовать их модель без необходимости заниматься настройкой самостоятельно.",
            "relation": "(GPT2) hasAuthor (CKIPLab)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(rubert-base-cased-sentence) hasAuthor (DeepPavlov)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(distilrubert-tiny-cased-conversational) hasAuthor (DeepPavlov)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(sbert_large_nlu_ru) hasAuthor (Сбера)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(sbert_large_mt_nlu_ru) hasAuthor (Сбера)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(rubert-base-cased-conversational) hasAuthor (DeepPavlov)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(distilrubert-base-cased-conversational) hasAuthor (DeepPavlov)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(ruT5-large) hasAuthor (Сберовские)"
          },
          {
            "text": "Помимо BERTов и T5, я включил в бенчмарк большие мультиязычные модели Laser от FAIR и USE-multilingual-large от Google.",
            "relation": "(Laser) hasAuthor (FAIR)"
          },
          {
            "text": "Помимо BERTов и T5, я включил в бенчмарк большие мультиязычные модели Laser от FAIR и USE-multilingual-large от Google.",
            "relation": "(USE-multilingual-large) hasAuthor (Google)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 6,
        "examples": [
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMo) hasAuthor (AI2)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (UW CSE)"
          },
          {
            "text": "На практике OpenAI уже давно не Open, а недавняя история с DALLE-2 / Midjourney / Stable Diffusion скорее иллюстрируют тренд.",
            "relation": "(Stable Diffusion) hasAuthor (OpenAI)"
          },
          {
            "text": "На практике OpenAI уже давно не Open, а недавняя история с DALLE-2 / Midjourney / Stable Diffusion скорее иллюстрируют тренд.",
            "relation": "(Midjourney) hasAuthor (OpenAI)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(ruRoberta-large) hasAuthor (Сбера)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(ruT5-base) hasAuthor (Сберовские)"
          }
        ]
      },
      "found": {
        "count": 67,
        "examples": [
          {
            "text": "Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.",
            "relation": "(DeBERTa) hasAuthor (Microsoft)"
          },
          {
            "text": "Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.",
            "relation": "(Turing NLRv4) hasAuthor (Microsoft)"
          },
          {
            "text": "Дополнительно, DeBERTa будет включена в следующую версию модели Microsoft Turing (Turing NLRv4) от Microsoft.",
            "relation": "(Microsoft Turing) hasAuthor (Microsoft)"
          },
          {
            "text": "Модель ULMFIT была представлена разработчиками fast.ai (Jeremy Howard, Sebastian Ruder) в 2018 году.",
            "relation": "(ULMFIT) hasAuthor (fast.ai)"
          },
          {
            "text": "«М.видео-Эльдорадо» внедряет нейросеть для ответов на вопросы покупателей",
            "relation": "(нейросеть) hasAuthor (М.видео-Эльдорадо)"
          },
          {
            "text": "Facebook AI представила новую систему машинного перевода M2M-100 с 15 млрд параметров.",
            "relation": "(M2M-100) hasAuthor (Facebook AI)"
          },
          {
            "text": "В этом посте мы расскажем, как мы создали датасет для задачи Common Sense Reasoning в одной из ее возможных формулировок, предложенной в статье event2mind, а также адаптировали английскую модель event2mind от AllenNLP для русского языка.",
            "relation": "(event2mind) hasAuthor (AllenNLP)"
          },
          {
            "text": "В последствии эта модель легла в основу модели SBERT наших коллег из смежной команды SberDevices, которую они выложили в открытый доступ.",
            "relation": "(SBERT) hasAuthor (SberDevices)"
          },
          {
            "text": "А на некоторых заданиях лучших результатов удалось достичь на few-shot, т. е. без дообучения модели (задача RCB и RuCoS, YaLM от Яндекса).",
            "relation": "(YaLM) hasAuthor (Яндекса)"
          },
          {
            "text": "Нейросеть от Стэнфорда демонстрирует точность в 85% при определении тональности текста.",
            "relation": "(Нейросеть) hasAuthor (Стэнфорда)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(DABUS) hasAuthor (Imagination Engines)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) hasAuthor (Imagination Engines)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(DABUS) hasAuthor (Imagination Engines)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) hasAuthor (Imagination Engines)"
          },
          {
            "text": "Чтобы научиться распознавать слова в аудиозаписи, Facebook обучила генеративную состязательную сеть (GAN).",
            "relation": "(генеративную состязательную сеть) hasAuthor (Facebook)"
          },
          {
            "text": "Новая модель распознавания речи Facebook AI — это последняя разработка за несколько лет работы над моделями распознавания речи.",
            "relation": "(модель распознавания речи) hasAuthor (Facebook AI)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BigScience Large Open-science Open-access Multilingual Language Model) hasAuthor (French National Center for Scientific Research)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BigScience Large Open-science Open-access Multilingual Language Model) hasAuthor (Французского национального центра научных исследований)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BLOOM) hasAuthor (French National Center for Scientific Research)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BLOOM) hasAuthor (Французского национального центра научных исследований)"
          },
          {
            "text": "Недавно ученые из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о выходе модели BLOOM.",
            "relation": "(BLOOM) hasAuthor (French National Center for Scientific Research)"
          },
          {
            "text": "Недавно ученые из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о выходе модели BLOOM.",
            "relation": "(BLOOM) hasAuthor (Французского национального центра научных исследований)"
          },
          {
            "text": "Недавно был релиз модели BLOOM, которую разработала команда из Французского национального центра научных исследований (French National Center for Scientific Research).",
            "relation": "(BLOOM) hasAuthor (French National Center for Scientific Research)"
          },
          {
            "text": "Недавно был релиз модели BLOOM, которую разработала команда из Французского национального центра научных исследований (French National Center for Scientific Research).",
            "relation": "(BLOOM) hasAuthor (Французского национального центра научных исследований)"
          },
          {
            "text": "Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.",
            "relation": "(LaMDA) hasAuthor (Google)"
          },
          {
            "text": "Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.",
            "relation": "(GPT-3) hasAuthor (OpenAI)"
          },
          {
            "text": "В июне текущего года инженер Google Блейк Лемуан (он на фото выше) ошарашил мировую общественность заявлением, что LLM LaMDA, над которой он работал вместе с другими программистами, может обладать некоторым подобием разума.",
            "relation": "(LLM LaMDA) hasAuthor (Google)"
          },
          {
            "text": "В частности, DALL-E 2 от OpenAI провалил тест на различение изображений астронавтов, едущих на лошадях, перепутав их с лошадьми, оседлавшими астронавтов.",
            "relation": "(DALL-E 2) hasAuthor (OpenAI)"
          },
          {
            "text": "«Сбер» представил mGPT — версию нейросети GPT-3, способную генерировать тексты на 61 языке",
            "relation": "(mGPT) hasAuthor (Сбер)"
          },
          {
            "text": "21 апреля 2022 года команда разработчиков SberDevices представила многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(mGPT) hasAuthor (SberDevices)"
          },
          {
            "text": "21 апреля 2022 года SberDevices представили многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(mGPT) hasAuthor (SberDevices)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(mGPT) hasAuthor (Сбер)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(mGPT) hasAuthor (Сбер)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(версию нейросети GPT-3) hasAuthor (Сбер)"
          },
          {
            "text": "Русскоязычная версия GPT-3, разработанная «Сбером», доступна на платформе SmartMarket.",
            "relation": "(версия GPT-3) hasAuthor (Сбером)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(ruGPT-3) hasAuthor (Сбер)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(ruGPT-3) hasAuthor (Сбер)"
          },
          {
            "text": "Для решения описанной задачи используется модель от DeepPavlov rubert-base-cased-sentence.",
            "relation": "(rubert-base-cased-sentence) hasAuthor (DeepPavlov)"
          },
          {
            "text": "С моделью от OpenAI связано сразу несколько новостей — хорошая и не очень.",
            "relation": "(моделью) hasAuthor (OpenAI)"
          },
          {
            "text": "ruGPT3 от Сбера.",
            "relation": "(ruGPT3) hasAuthor (Сбера)"
          },
          {
            "text": "OpenAI представила модель машинного обучения GPT-3, обученную на 175 млрд параметров, в июне 2020 года.",
            "relation": "(GPT-3) hasAuthor (OpenAI)"
          },
          {
            "text": "В июне 2020 года OpenAI представила модель машинного обучения GPT-3, обученную на 175 миллиардах параметров.",
            "relation": "(GPT-3) hasAuthor (OpenAI)"
          },
          {
            "text": "Прорывы #DeepPavlov в 2019 году: обзор и итоги года Московский физико-технический институт (МФТИ).",
            "relation": "(#DeepPavlov) hasAuthor (МФТИ)"
          },
          {
            "text": "Прорывы #DeepPavlov в 2019 году: обзор и итоги года Московский физико-технический институт (МФТИ).",
            "relation": "(#DeepPavlov) hasAuthor (Московский физико-технический институт)"
          },
          {
            "text": "Модель DeepPavlov была разработана командой из Московского физико-технического института (МФТИ).",
            "relation": "(DeepPavlov) hasAuthor (МФТИ)"
          },
          {
            "text": "Модель DeepPavlov была разработана командой из Московского физико-технического института (МФТИ).",
            "relation": "(DeepPavlov) hasAuthor (Московского физико-технического института)"
          },
          {
            "text": "Команда исследователей из Московского физико-технического института (МФТИ) представила модель DeepPavlov.",
            "relation": "(DeepPavlov) hasAuthor (МФТИ)"
          },
          {
            "text": "Команда исследователей из Московского физико-технического института (МФТИ) представила модель DeepPavlov.",
            "relation": "(DeepPavlov) hasAuthor (Московского физико-технического института)"
          },
          {
            "text": "Команда DeepPavlov обучила модель NER на англоязычном корпусе OntoNotes, который имеет 19 типов разметки, включая PER (человек), LOC (местоположение), ORG (организация) и многие другие.",
            "relation": "(модель NER) hasAuthor (DeepPavlov)"
          },
          {
            "text": "BERT, или Bidirectional Encoder Representations from Transformers, — нейросетевая модель-трансформер от Google, на которой сегодня строится большинство инструментов автоматической обработки языка.",
            "relation": "(BERT) hasAuthor (Google)"
          },
          {
            "text": "BERT, или Bidirectional Encoder Representations from Transformers, — нейросетевая модель-трансформер от Google, на которой сегодня строится большинство инструментов автоматической обработки языка.",
            "relation": "(Bidirectional Encoder Representations from Transformers) hasAuthor (Google)"
          },
          {
            "text": "BERT, сокращение от Bidirectional Encoder Representations from Transformers, представляет собой нейросетевую модель-трансформер от Google, на базе которой в настоящее время разрабатывается большинство средств автоматической обработки языка.",
            "relation": "(BERT) hasAuthor (Google)"
          },
          {
            "text": "BERT, сокращение от Bidirectional Encoder Representations from Transformers, представляет собой нейросетевую модель-трансформер от Google, на базе которой в настоящее время разрабатывается большинство средств автоматической обработки языка.",
            "relation": "(Bidirectional Encoder Representations from Transformers) hasAuthor (Google)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (OpenAI Radford)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMo) hasAuthor (UW CSE)"
          },
          {
            "text": "Разработкой и обучением модели BERT занималась целая группа исследователей Google AI Language на многомиллионном наборе слов на разных языках (более 100).",
            "relation": "(BERT) hasAuthor (Google AI Language)"
          },
          {
            "text": "На практике OpenAI уже давно не Open, а недавняя история с DALLE-2 / Midjourney / Stable Diffusion скорее иллюстрируют тренд.",
            "relation": "(DALLE-2) hasAuthor (OpenAI)"
          },
          {
            "text": "Эта модель GPT2 от CKIPLab предварительно обучена на китайском корпусе, поэтому мы можем использовать их модель без необходимости заниматься настройкой самостоятельно.",
            "relation": "(GPT2) hasAuthor (CKIPLab)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(distilrubert-base-cased-conversational) hasAuthor (DeepPavlov)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(rubert-base-cased-sentence) hasAuthor (DeepPavlov)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(distilrubert-tiny-cased-conversational) hasAuthor (DeepPavlov)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(sbert_large_nlu_ru) hasAuthor (Сбера)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(rubert-base-cased-conversational) hasAuthor (DeepPavlov)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(sbert_large_mt_nlu_ru) hasAuthor (Сбера)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(ruT5-large) hasAuthor (Сберовские)"
          },
          {
            "text": "Помимо BERTов и T5, я включил в бенчмарк большие мультиязычные модели Laser от FAIR и USE-multilingual-large от Google.",
            "relation": "(Laser) hasAuthor (FAIR)"
          },
          {
            "text": "Помимо BERTов и T5, я включил в бенчмарк большие мультиязычные модели Laser от FAIR и USE-multilingual-large от Google.",
            "relation": "(USE-multilingual-large) hasAuthor (Google)"
          }
        ]
      }
    }
  },
  "Model_isExampleOf_Model": {
    "predicted": {
      "incorrect": {
        "count": 1,
        "examples": [
          {
            "text": "Примером данного решения является использование парафрайзера на основе “rut5-base-paraphraser” из библиотеки huggingface.",
            "relation": "(rut5-base-paraphraser) isExampleOf (парафрайзера)"
          }
        ]
      },
      "correct": {
        "count": 15,
        "examples": [
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BLOOM) isExampleOf (LLM)"
          },
          {
            "text": "Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.",
            "relation": "(LaMDA) isExampleOf (LLM)"
          },
          {
            "text": "Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.",
            "relation": "(BLOOM) isExampleOf (LLM)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(BERT) isExampleOf (нейронные сети)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(Bidirectional Encoder Representations from Transformers) isExampleOf (нейронные сети)"
          },
          {
            "text": "Релиз BERT в 2018 году стал некоторой переломной точкой в развитии NLP-моделей.",
            "relation": "(BERT) isExampleOf (NLP-моделей)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(distilrubert-tiny-cased-conversational) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(sbert_large_mt_nlu_ru) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(distilrubert-base-cased-conversational) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(sbert_large_nlu_ru) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(rubert-base-cased-conversational) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(rut5-small) isExampleOf (T5 модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(ruT5-large) isExampleOf (T5 модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(ruT5-base) isExampleOf (T5 модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(rut5-base) isExampleOf (T5 модели)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 23,
        "examples": [
          {
            "text": "С появлением в 2020 году нейронной сети GPT3 и других архитектур – трансформеров, генерируемые тексты стали невероятно правдоподобными.",
            "relation": "(архитектур – трансформеров) isExampleOf (GPT3)"
          },
          {
            "text": "SequenceEncoder – рекурентно-нейронная сеть (RNN), совместно используемая для транзакций и кликов.",
            "relation": "(SequenceEncoder) isExampleOf (рекурентно-нейронная сеть)"
          },
          {
            "text": "SequenceEncoder – рекурентно-нейронная сеть (RNN), совместно используемая для транзакций и кликов.",
            "relation": "(SequenceEncoder) isExampleOf (RNN)"
          },
          {
            "text": "Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.",
            "relation": "(GPT-3) isExampleOf (LLM)"
          },
          {
            "text": "Выход модели BERT в 2018 году стал своеобразным переломным моментом в развитии моделей обработки естественного языка (NLP).",
            "relation": "(BERT) isExampleOf (моделей обработки естественного языка)"
          },
          {
            "text": "Из интересных решений один из участников представил BiLSTM-сеть с CRF слоем.",
            "relation": "(CRF) isExampleOf (BiLSTM-сеть)"
          },
          {
            "text": "При создании нашей системы рекомендации кандидатов на позиции мы использовали нейронную сеть — StarSpace.",
            "relation": "(StarSpace) isExampleOf (нейронную сеть)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(LaBSE-en-ru) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(LaBSE) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(bert-base-multilingual-cased) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(rubert-tiny2) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(ruRoberta-large) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(rubert-tiny) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(rubert-base-cased-sentence) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(rut5-base-paraphraser) isExampleOf (T5 модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(rut5-base-multitask) isExampleOf (T5 модели)"
          },
          {
            "text": "UDPipe — это transition-based архитектура: она работает быстро, за линейное время проходя по всем токенам один раз.",
            "relation": "(UDPipe) isExampleOf (transition-based)"
          },
          {
            "text": "SequenceEncoder представляет собой рекуррентную нейронную сеть (RNN), применяемую для анализа последовательностей в данных о транзакциях и кликах.",
            "relation": "(SequenceEncoder) isExampleOf (рекуррентную нейронную сеть)"
          },
          {
            "text": "SequenceEncoder представляет собой рекуррентную нейронную сеть (RNN), применяемую для анализа последовательностей в данных о транзакциях и кликах.",
            "relation": "(SequenceEncoder) isExampleOf (RNN)"
          },
          {
            "text": "UDPipe представляет собой transition-based архитектуру на основе переходов: она обеспечивает быструю обработку, проходя по всем токенам один раз за линейное время.",
            "relation": "(UDPipe) isExampleOf (transition-based)"
          },
          {
            "text": "Среди замечательных подходов один из участников предложил использовать BiLSTM с уровнем CRF.",
            "relation": "(BiLSTM) isExampleOf (CRF)"
          },
          {
            "text": "Один из участников выделил BiLSTM-архитектуру с добавлением слоя CRF в качестве интересного решения.",
            "relation": "(BiLSTM-архитектуру) isExampleOf (CRF)"
          },
          {
            "text": "Появление модели BERT в 2018 году отметило своеобразный поворотный пункт в прогрессе развития моделей обработки естественного языка (NLP).",
            "relation": "(BERT) isExampleOf (моделей обработки естественного языка)"
          }
        ]
      },
      "found": {
        "count": 15,
        "examples": [
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(BLOOM) isExampleOf (LLM)"
          },
          {
            "text": "Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.",
            "relation": "(LaMDA) isExampleOf (LLM)"
          },
          {
            "text": "Новая LLM с открытым исходным кодом в отличие от таких известных LLM, как GPT-3 от OpenAI и LaMDA от Google, BLOOM является открытой языковой моделью, а исследователи охотно делятся подробностями о тех данных, на которых она обучалась, рассказывают о проблемах в ее разработке и о том, как они оценивали производительность BLOOM.",
            "relation": "(BLOOM) isExampleOf (LLM)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(BERT) isExampleOf (нейронные сети)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(Bidirectional Encoder Representations from Transformers) isExampleOf (нейронные сети)"
          },
          {
            "text": "Релиз BERT в 2018 году стал некоторой переломной точкой в развитии NLP-моделей.",
            "relation": "(BERT) isExampleOf (NLP-моделей)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(distilrubert-tiny-cased-conversational) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(sbert_large_nlu_ru) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(rubert-base-cased-conversational) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(sbert_large_mt_nlu_ru) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "В основу бенчмарка легли BERT-подобные модели: sbert_large_nlu_ru, sbert_large_mt_nlu_ru, и ruRoberta-large от Сбера; rubert-base-cased-sentence, rubert-base-cased-conversational, distilrubert-tiny-cased-conversational, и distilrubert-base-cased-conversational от DeepPavlov; мои   rubert-tiny и rubert-tiny2; мультиязычные LaBSE (плюс урезанная версия LaBSE-en-ru) и старый добрый bert-base-multilingual-cased.",
            "relation": "(distilrubert-base-cased-conversational) isExampleOf (BERT-подобные модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(rut5-small) isExampleOf (T5 модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(ruT5-large) isExampleOf (T5 модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(ruT5-base) isExampleOf (T5 модели)"
          },
          {
            "text": "Кроме этого, я добавил в бенчмарк разные T5 модели, т.к. они тоже должны хорошо понимать тексты: мои rut5-small, rut5-base, rut5-base-multitask, и rut5-base-paraphraser, и Сберовские ruT5-base и ruT5-large.",
            "relation": "(rut5-base) isExampleOf (T5 модели)"
          }
        ]
      }
    }
  },
  "Application_isUsedIn_Science": {
    "predicted": {
      "incorrect": {
        "count": 3,
        "examples": [
          {
            "text": "В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения.",
            "relation": "(IDE) isUsedIn (машинного обучения)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(api.ai) isUsedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Google Natural Language API  поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec.",
            "relation": "(Google Translate) isUsedIn (машинного перевода)"
          }
        ]
      },
      "correct": {
        "count": 13,
        "examples": [
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedIn (искусстве)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedIn (психотерапии)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedIn (искусстве)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedIn (психотерапии)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(A.L.I.C.E.) isUsedIn (машинного обучения)"
          },
          {
            "text": "IBM Automation Platform для цифрового бизнеса — это интегрированная платформа с пятью возможностями автоматизации, которая помогает бизнесу быстро и масштабно управлять практически всеми типами проектов автоматизации — от повторяющихся и административных до работы на уровне экспертов.",
            "relation": "(IBM Automation Platform) isUsedIn (цифрового бизнеса)"
          },
          {
            "text": "Платформа IBM Automation для цифрового бизнеса представляет собой интегрированную платформу с пятью функциями автоматизации, которая обеспечивает быстрое и масштабное управление практически любыми проектами автоматизации — от повторяющихся и административных до задач на уровне экспертов.",
            "relation": "(IBM Automation) isUsedIn (цифрового бизнеса)"
          },
          {
            "text": "По данным Google Books Ngram Viewer — поискового онлайн-сервиса Google, который строит графики частоты упоминания языковых единиц на основе огромного количества печатных источников, популярность и интерес к NLP стремительно растет последние 20 лет.",
            "relation": "(Google Books Ngram Viewer) isUsedIn (NLP)"
          },
          {
            "text": "В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения.",
            "relation": "(SageMaker Studio) isUsedIn (машинного обучения)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Translate) isUsedIn (машинного перевода)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedIn (машинного перевода)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(wit.ai) isUsedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Google Natural Language API  поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec.",
            "relation": "(Google Natural Language API) isUsedIn (машинного перевода)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 7,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Элиза) isUsedIn (машинного обучения)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(wit.ai) isUsedIn (машинного перевода)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(IBM AlchemyAPI) isUsedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Translate) isUsedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Синтаксис, разумеется, далеко не единственный модуль «под капотом» real-time системы, поэтому тратить на него больше десятка миллисекунд не стоит.",
            "relation": "(real-time) isUsedIn (Синтаксис)"
          },
          {
            "text": "Разумеется, синтаксис - не единственный модуль real-time системы, поэтому нецелесообразно затрачивать на него более десятка миллисекунд.",
            "relation": "(real-time) isUsedIn (синтаксис)"
          }
        ]
      },
      "found": {
        "count": 13,
        "examples": [
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedIn (искусстве)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedIn (психотерапии)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedIn (искусстве)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedIn (психотерапии)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(A.L.I.C.E.) isUsedIn (машинного обучения)"
          },
          {
            "text": "IBM Automation Platform для цифрового бизнеса — это интегрированная платформа с пятью возможностями автоматизации, которая помогает бизнесу быстро и масштабно управлять практически всеми типами проектов автоматизации — от повторяющихся и административных до работы на уровне экспертов.",
            "relation": "(IBM Automation Platform) isUsedIn (цифрового бизнеса)"
          },
          {
            "text": "Платформа IBM Automation для цифрового бизнеса представляет собой интегрированную платформу с пятью функциями автоматизации, которая обеспечивает быстрое и масштабное управление практически любыми проектами автоматизации — от повторяющихся и административных до задач на уровне экспертов.",
            "relation": "(IBM Automation) isUsedIn (цифрового бизнеса)"
          },
          {
            "text": "По данным Google Books Ngram Viewer — поискового онлайн-сервиса Google, который строит графики частоты упоминания языковых единиц на основе огромного количества печатных источников, популярность и интерес к NLP стремительно растет последние 20 лет.",
            "relation": "(Google Books Ngram Viewer) isUsedIn (NLP)"
          },
          {
            "text": "В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения.",
            "relation": "(SageMaker Studio) isUsedIn (машинного обучения)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Translate) isUsedIn (машинного перевода)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedIn (машинного перевода)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(wit.ai) isUsedIn (области анализа речи и естественного языка)"
          },
          {
            "text": "Google Natural Language API  поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec.",
            "relation": "(Google Natural Language API) isUsedIn (машинного перевода)"
          }
        ]
      }
    }
  },
  "Method_isUsedIn_Application": {
    "predicted": {
      "incorrect": {
        "count": 3,
        "examples": [
          {
            "text": "Google запускает Coral ai – аналог raspberry pi, мини-компьютер для внедрения нейросетей в экспериментальные установки.",
            "relation": "(нейросетей) isUsedIn (Coral ai)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(разметки) isUsedIn (A.L.I.C.E.)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(точная настройка) isUsedIn (Genius)"
          }
        ]
      },
      "correct": {
        "count": 16,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(AIML) isUsedIn (A.L.I.C.E.)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Artificial Intelligence Markup Language) isUsedIn (A.L.I.C.E.)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(контекстно-свободных грамматик) isUsedIn (Томита-парсер)"
          },
          {
            "text": "В Яндекс.Браузер внедрили машинный перевод видеороликов",
            "relation": "(машинный перевод) isUsedIn (Яндекс.Браузер)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isUsedIn (Emphasis)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NEAT) isUsedIn (фреймворк)"
          },
          {
            "text": "Платформа для видеозвонков Maxine объединяет в себе целый зоопарк ML-алгоритмов.",
            "relation": "(ML-алгоритмов) isUsedIn (Maxine)"
          },
          {
            "text": "Maxine, платформа для видеозвонков, включает в себя разнообразные алгоритмы машинного обучения.",
            "relation": "(алгоритмы машинного обучения) isUsedIn (Maxine)"
          },
          {
            "text": "Технологии языкового процессинга востребованы в разработках, связанных с построением искусственного интеллекта: в поисковых системах, для извлечения фактов, оценки тональности текста, машинного перевода и диалога.",
            "relation": "(Технологии языкового процессинга) isUsedIn (поисковых системах)"
          },
          {
            "text": "Технологии обработки естественного языка широко используются в разработках, связанных с созданием искусственного интеллекта, включая применение в поисковых системах и машинном переводе.",
            "relation": "(Технологии обработки естественного языка) isUsedIn (поисковых системах)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(AIML) isUsedIn (A.L.I.C.E.)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(Artificial Intelligence Markup Language) isUsedIn (A.L.I.C.E.)"
          },
          {
            "text": "При разработке разговорных агентов в основном применяется модульная архитектура для целенаправленного диалога, при котором разворачивается сценарий.",
            "relation": "(модульная архитектура) isUsedIn (разговорных агентов)"
          },
          {
            "text": "Программа для разметки YEDDA и процесс разметки.",
            "relation": "(разметки) isUsedIn (YEDDA)"
          },
          {
            "text": "В данном решении была использована готовая нейросеть от сервиса RusVectores, обученная на корпусе НКРЯ с использованием алгоритма word2vec CBOW с длиной вектора 300.",
            "relation": "(word2vec CBOW) isUsedIn (RusVectores)"
          },
          {
            "text": "Ответ прост: Syntaxnet начинался лишь с этапа морфологического анализа.",
            "relation": "(морфологического анализа) isUsedIn (Syntaxnet)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 16,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(AIML) isUsedIn (A.L.I.C.E.)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Artificial Intelligence Markup Language) isUsedIn (A.L.I.C.E.)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(контекстно-свободных грамматик) isUsedIn (Томита-парсер)"
          },
          {
            "text": "В Яндекс.Браузер внедрили машинный перевод видеороликов",
            "relation": "(машинный перевод) isUsedIn (Яндекс.Браузер)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(токенизатор) isUsedIn (Emphasis)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NEAT) isUsedIn (фреймворк)"
          },
          {
            "text": "Платформа для видеозвонков Maxine объединяет в себе целый зоопарк ML-алгоритмов.",
            "relation": "(ML-алгоритмов) isUsedIn (Maxine)"
          },
          {
            "text": "Maxine, платформа для видеозвонков, включает в себя разнообразные алгоритмы машинного обучения.",
            "relation": "(алгоритмы машинного обучения) isUsedIn (Maxine)"
          },
          {
            "text": "Технологии языкового процессинга востребованы в разработках, связанных с построением искусственного интеллекта: в поисковых системах, для извлечения фактов, оценки тональности текста, машинного перевода и диалога.",
            "relation": "(Технологии языкового процессинга) isUsedIn (поисковых системах)"
          },
          {
            "text": "Технологии обработки естественного языка широко используются в разработках, связанных с созданием искусственного интеллекта, включая применение в поисковых системах и машинном переводе.",
            "relation": "(Технологии обработки естественного языка) isUsedIn (поисковых системах)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(AIML) isUsedIn (A.L.I.C.E.)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(Artificial Intelligence Markup Language) isUsedIn (A.L.I.C.E.)"
          },
          {
            "text": "При разработке разговорных агентов в основном применяется модульная архитектура для целенаправленного диалога, при котором разворачивается сценарий.",
            "relation": "(модульная архитектура) isUsedIn (разговорных агентов)"
          },
          {
            "text": "Программа для разметки YEDDA и процесс разметки.",
            "relation": "(разметки) isUsedIn (YEDDA)"
          },
          {
            "text": "В данном решении была использована готовая нейросеть от сервиса RusVectores, обученная на корпусе НКРЯ с использованием алгоритма word2vec CBOW с длиной вектора 300.",
            "relation": "(word2vec CBOW) isUsedIn (RusVectores)"
          },
          {
            "text": "Ответ прост: Syntaxnet начинался лишь с этапа морфологического анализа.",
            "relation": "(морфологического анализа) isUsedIn (Syntaxnet)"
          }
        ]
      }
    }
  },
  "Activity_hasAuthor_Organization": {
    "predicted": {
      "incorrect": {
        "count": 1,
        "examples": [
          {
            "text": "Научная конференция по компьютерной лингвистике \"Диалог\" состоялась в Российском государственном гуманитарном университете (РГГУ).",
            "relation": "(Научная конференция по компьютерной лингвистике) hasAuthor (Российском государственном гуманитарном университете)"
          }
        ]
      },
      "correct": {
        "count": 15,
        "examples": [
          {
            "text": "Проект стартовал в Стэнфорде как инструмент для помощи в разметке датасетов для задачи information extraction, а сейчас разработчики делают платформу для пользования внешними заказчиками.",
            "relation": "(Проект) hasAuthor (Стэнфорде)"
          },
          {
            "text": "Было бы здорово составить базу с инструкциями не для людей, а для роботов, подумали инженеры из Института искусственного интеллекта при Бременском университете (Германия), авторы проекта RoboHow.",
            "relation": "(RoboHow) hasAuthor (Института искусственного интеллекта)"
          },
          {
            "text": "Было бы здорово составить базу с инструкциями не для людей, а для роботов, подумали инженеры из Института искусственного интеллекта при Бременском университете (Германия), авторы проекта RoboHow.",
            "relation": "(RoboHow) hasAuthor (Бременском университете)"
          },
          {
            "text": "Инженеры из Института искусственного интеллекта при Бременском университете (Германия), участники проекта RoboHow, рассматривают возможность создания базы данных с инструкциями, предназначенными не для людей, а для роботов.",
            "relation": "(RoboHow) hasAuthor (Института искусственного интеллекта)"
          },
          {
            "text": "Инженеры из Института искусственного интеллекта при Бременском университете (Германия), участники проекта RoboHow, рассматривают возможность создания базы данных с инструкциями, предназначенными не для людей, а для роботов.",
            "relation": "(RoboHow) hasAuthor (Бременском университете)"
          },
          {
            "text": "В данной статье я бы хотел познакомить читателей с одним из проектов Apache Software Foundation сообщества — NlpCraft.",
            "relation": "(NlpCraft) hasAuthor (Apache Software Foundation)"
          },
          {
            "text": "В этой статье я планирую представить читателям один из проектов сообщества Apache Software Foundation — NlpCraft.",
            "relation": "(NlpCraft) hasAuthor (Apache Software Foundation)"
          },
          {
            "text": "В начале апреля СМИ сообщили, что подрядчики Google в проекте по оценке ответов чат-бота Bard из-за нехватки времени часто ставили оценки на ответы ИИ по сложным запросам наугад.",
            "relation": "(проекте по оценке ответов чат-бота Bard) hasAuthor (Google)"
          },
          {
            "text": "И уже сейчас над BLOOM работают более тысячи исследователей-добровольцев в рамках проекта под названием BigScience, который координирует стартап Hugging Face, существующий за счет финансовой поддержки французского правительства.",
            "relation": "(BigScience) hasAuthor (Hugging Face)"
          },
          {
            "text": "Более тысячи добровольных исследователей уже вовлечены в работу над моделью BLOOM в рамках проекта BigScience, который управляется стартапом Hugging Face.",
            "relation": "(BigScience) hasAuthor (Hugging Face)"
          },
          {
            "text": "Между тем создатели проекта GPT-Neo от EleutherAI решили воссоздать аналог GPT-3, но с открытым исходным кодом.",
            "relation": "(GPT-Neo) hasAuthor (EleutherAI)"
          },
          {
            "text": "Тем временем, разработчики проекта GPT-Neo от EleutherAI решили разработать свой аналог GPT-3 с открытым исходным кодом.",
            "relation": "(GPT-Neo) hasAuthor (EleutherAI)"
          },
          {
            "text": "Вдохновленная этими усилиями по сбору данных, исследовательская группа Mozilla в сотрудничестве с группой открытых инноваций запустила проект Common Voice, цель которого заключалась в сборе и проверке речевых данных.",
            "relation": "(Common Voice) hasAuthor (Mozilla)"
          },
          {
            "text": "Подробно о том, что такое «Диалог» и почему ABBYY организует эту конференцию, мы писали здесь .",
            "relation": "(Диалог) hasAuthor (ABBYY)"
          },
          {
            "text": "Мы уже рассказали подробности о том, что представляет собой \"Диалог\" и почему ABBYY организует эту конференцию, в данной публикации.",
            "relation": "(Диалог) hasAuthor (ABBYY)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 15,
        "examples": [
          {
            "text": "Проект стартовал в Стэнфорде как инструмент для помощи в разметке датасетов для задачи information extraction, а сейчас разработчики делают платформу для пользования внешними заказчиками.",
            "relation": "(Проект) hasAuthor (Стэнфорде)"
          },
          {
            "text": "Было бы здорово составить базу с инструкциями не для людей, а для роботов, подумали инженеры из Института искусственного интеллекта при Бременском университете (Германия), авторы проекта RoboHow.",
            "relation": "(RoboHow) hasAuthor (Института искусственного интеллекта)"
          },
          {
            "text": "Было бы здорово составить базу с инструкциями не для людей, а для роботов, подумали инженеры из Института искусственного интеллекта при Бременском университете (Германия), авторы проекта RoboHow.",
            "relation": "(RoboHow) hasAuthor (Бременском университете)"
          },
          {
            "text": "Инженеры из Института искусственного интеллекта при Бременском университете (Германия), участники проекта RoboHow, рассматривают возможность создания базы данных с инструкциями, предназначенными не для людей, а для роботов.",
            "relation": "(RoboHow) hasAuthor (Института искусственного интеллекта)"
          },
          {
            "text": "Инженеры из Института искусственного интеллекта при Бременском университете (Германия), участники проекта RoboHow, рассматривают возможность создания базы данных с инструкциями, предназначенными не для людей, а для роботов.",
            "relation": "(RoboHow) hasAuthor (Бременском университете)"
          },
          {
            "text": "В данной статье я бы хотел познакомить читателей с одним из проектов Apache Software Foundation сообщества — NlpCraft.",
            "relation": "(NlpCraft) hasAuthor (Apache Software Foundation)"
          },
          {
            "text": "В этой статье я планирую представить читателям один из проектов сообщества Apache Software Foundation — NlpCraft.",
            "relation": "(NlpCraft) hasAuthor (Apache Software Foundation)"
          },
          {
            "text": "В начале апреля СМИ сообщили, что подрядчики Google в проекте по оценке ответов чат-бота Bard из-за нехватки времени часто ставили оценки на ответы ИИ по сложным запросам наугад.",
            "relation": "(проекте по оценке ответов чат-бота Bard) hasAuthor (Google)"
          },
          {
            "text": "И уже сейчас над BLOOM работают более тысячи исследователей-добровольцев в рамках проекта под названием BigScience, который координирует стартап Hugging Face, существующий за счет финансовой поддержки французского правительства.",
            "relation": "(BigScience) hasAuthor (Hugging Face)"
          },
          {
            "text": "Более тысячи добровольных исследователей уже вовлечены в работу над моделью BLOOM в рамках проекта BigScience, который управляется стартапом Hugging Face.",
            "relation": "(BigScience) hasAuthor (Hugging Face)"
          },
          {
            "text": "Между тем создатели проекта GPT-Neo от EleutherAI решили воссоздать аналог GPT-3, но с открытым исходным кодом.",
            "relation": "(GPT-Neo) hasAuthor (EleutherAI)"
          },
          {
            "text": "Тем временем, разработчики проекта GPT-Neo от EleutherAI решили разработать свой аналог GPT-3 с открытым исходным кодом.",
            "relation": "(GPT-Neo) hasAuthor (EleutherAI)"
          },
          {
            "text": "Вдохновленная этими усилиями по сбору данных, исследовательская группа Mozilla в сотрудничестве с группой открытых инноваций запустила проект Common Voice, цель которого заключалась в сборе и проверке речевых данных.",
            "relation": "(Common Voice) hasAuthor (Mozilla)"
          },
          {
            "text": "Подробно о том, что такое «Диалог» и почему ABBYY организует эту конференцию, мы писали здесь .",
            "relation": "(Диалог) hasAuthor (ABBYY)"
          },
          {
            "text": "Мы уже рассказали подробности о том, что представляет собой \"Диалог\" и почему ABBYY организует эту конференцию, в данной публикации.",
            "relation": "(Диалог) hasAuthor (ABBYY)"
          }
        ]
      }
    }
  },
  "Library_isAppliedTo_Object": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 4,
        "examples": [
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(Yagry) isAppliedTo (текста)"
          },
          {
            "text": "Библиотека предоставляет не только получение стандартных признаков на основе TF-IDF, но и на основе эмбеддингов:1) На основе встроенного FastText, который можно тренировать на том или ином корпусе2) Предобученных моделей Gensim3) Любой другой объект, который имеет вид словаря, где на вход подается слово, а на выходе его эмбеддинги",
            "relation": "(Библиотека) isAppliedTo (эмбеддингов)"
          },
          {
            "text": "В частности, это Apache Tika, японская библиотека language-detection и одна из последних разработок — питоновский пакет Ldig, который как раз работает на инфинитиграммах.",
            "relation": "(Ldig) isAppliedTo (инфинитиграммах)"
          },
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(фреймворка) isAppliedTo (фона)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 4,
        "examples": [
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(Yagry) isAppliedTo (текста)"
          },
          {
            "text": "Библиотека предоставляет не только получение стандартных признаков на основе TF-IDF, но и на основе эмбеддингов:1) На основе встроенного FastText, который можно тренировать на том или ином корпусе2) Предобученных моделей Gensim3) Любой другой объект, который имеет вид словаря, где на вход подается слово, а на выходе его эмбеддинги",
            "relation": "(Библиотека) isAppliedTo (эмбеддингов)"
          },
          {
            "text": "В частности, это Apache Tika, японская библиотека language-detection и одна из последних разработок — питоновский пакет Ldig, который как раз работает на инфинитиграммах.",
            "relation": "(Ldig) isAppliedTo (инфинитиграммах)"
          },
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(фреймворка) isAppliedTo (фона)"
          }
        ]
      }
    }
  },
  "Library_hasAuthor_Organization": {
    "predicted": {
      "incorrect": {
        "count": 2,
        "examples": [
          {
            "text": "Как отличить хороший ремонт от плохого, или как мы в SRG сделали из Томита-парсера многопоточную Java-библиотеку.",
            "relation": "(Java-библиотеку) hasAuthor (SRG)"
          },
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(фреймворка) hasAuthor (Google Meet)"
          }
        ]
      },
      "correct": {
        "count": 7,
        "examples": [
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(фреймворка) hasAuthor (Mediapipe)"
          },
          {
            "text": "Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) hasAuthor (Facebook)"
          },
          {
            "text": "Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.",
            "relation": "(NLP Architect) hasAuthor (Intel)"
          },
          {
            "text": "Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) hasAuthor (Facebook)"
          },
          {
            "text": "Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.",
            "relation": "(NLP Architect) hasAuthor (Intel)"
          },
          {
            "text": "Для задачи репрезентации графов связей между сущностями мы использовали фреймворк PyTorch BigGraph — это ещё один фреймворк от Facebook Research.",
            "relation": "(PyTorch BigGraph) hasAuthor (Facebook Research)"
          },
          {
            "text": "Мы будем использовать именитую библиотеку Transformers, разработанную Huggingface.",
            "relation": "(Transformers) hasAuthor (Huggingface)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 2,
        "examples": [
          {
            "text": "Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) hasAuthor (Uber)"
          },
          {
            "text": "Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) hasAuthor (Uber)"
          }
        ]
      },
      "found": {
        "count": 7,
        "examples": [
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(фреймворка) hasAuthor (Mediapipe)"
          },
          {
            "text": "Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) hasAuthor (Facebook)"
          },
          {
            "text": "Крупные компании также принимают участие в разработке библиотек для NLP, как например NLP Architect от Intel или PyTorch от исследователей из Facebook и Uber.",
            "relation": "(NLP Architect) hasAuthor (Intel)"
          },
          {
            "text": "Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.",
            "relation": "(PyTorch) hasAuthor (Facebook)"
          },
          {
            "text": "Большие компании также активно участвуют в разработке библиотек для обработки естественного языка, таких как NLP Architect от Intel и PyTorch от исследователей из Facebook и Uber.",
            "relation": "(NLP Architect) hasAuthor (Intel)"
          },
          {
            "text": "Для задачи репрезентации графов связей между сущностями мы использовали фреймворк PyTorch BigGraph — это ещё один фреймворк от Facebook Research.",
            "relation": "(PyTorch BigGraph) hasAuthor (Facebook Research)"
          },
          {
            "text": "Мы будем использовать именитую библиотеку Transformers, разработанную Huggingface.",
            "relation": "(Transformers) hasAuthor (Huggingface)"
          }
        ]
      }
    }
  },
  "Metric_isUsedIn_Task": {
    "predicted": {
      "incorrect": {
        "count": 3,
        "examples": [
          {
            "text": "Отмечается, что систему также можно использовать для дополнения наборов данных, предназначенных для обучения детекторов фейкньюс, что потенциально снижает предвзятость и повышает точность информации.",
            "relation": "(точность) isUsedIn (обучения детекторов фейкньюс)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(точность) isUsedIn (TI)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(точность) isUsedIn (II)"
          }
        ]
      },
      "correct": {
        "count": 28,
        "examples": [
          {
            "text": "Приведу только показатели качества классификации, которые были нами получены на тестах: Accuracy = 95% F1 score = 93%",
            "relation": "(F1 score) isUsedIn (классификации)"
          },
          {
            "text": "Приведу только показатели качества классификации, которые были нами получены на тестах: Accuracy = 95% F1 score = 93%",
            "relation": "(Accuracy) isUsedIn (классификации)"
          },
          {
            "text": "При обучении модели значение метрики F1-score достигло 0.894, соответственно можно сделать вывод о том, что модель хорошо справляется с задачей определения нейтральных и негативных обращений.",
            "relation": "(F1-score) isUsedIn (определения нейтральных и негативных обращений)"
          },
          {
            "text": "ЗаключениеВ итоге, моделью RuBioRoBERTa в задаче RuMedDaNet мне удалось добиться качества 73.24% на закрытой тестовой части данных (хотя на dev метрика Accuracy вообще была 81.64%).",
            "relation": "(Accuracy) isUsedIn (RuMedDaNet)"
          },
          {
            "text": "Сейчас точность выделения жестов в видеопотоке составляет 85—90%.",
            "relation": "(точность) isUsedIn (выделения жестов)"
          },
          {
            "text": "Так как задача является составной, то и метрика состояла из двух компонентов с весом 0.8 для задачи классификации и 0.2 для задачи NER.",
            "relation": "(метрика) isUsedIn (классификации)"
          },
          {
            "text": "Так как задача является составной, то и метрика состояла из двух компонентов с весом 0.8 для задачи классификации и 0.2 для задачи NER.",
            "relation": "(метрика) isUsedIn (NER)"
          },
          {
            "text": "В задаче классификации использовался logloss, вычисляемый как среднее значение метрики sklearn.metrics.log_loss по классам болезней.",
            "relation": "(logloss) isUsedIn (классификации)"
          },
          {
            "text": "В задаче классификации использовался logloss, вычисляемый как среднее значение метрики sklearn.metrics.log_loss по классам болезней.",
            "relation": "(sklearn.metrics.log_loss) isUsedIn (классификации)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(span-based F1-score) isUsedIn (NER)"
          },
          {
            "text": "Метрика LogisticDetection при помощи машинного обучения позволяет оценить насколько сложно отличить синтетические данные от исходных.",
            "relation": "(LogisticDetection) isUsedIn (отличить синтетические данные от исходных)"
          },
          {
            "text": "Для русского языка тоже было создано немало разного рода бенчмарков NLU моделей:RussianSuperGLUE: бенчмарк \"сложных\" NLP задач; фокус на дообучаемых моделях.",
            "relation": "(RussianSuperGLUE) isUsedIn (NLP задач)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(точность) isUsedIn (NLI)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(косинусной близости) isUsedIn (NLI)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(accuracy) isUsedIn (NLI)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(точность) isUsedIn (NLI)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(косинусной близости) isUsedIn (NLI)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(accuracy) isUsedIn (NLI)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(ROC AUC) isUsedIn (TI)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(accuracy) isUsedIn (ICX)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(ROC AUC) isUsedIn (II)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(точность) isUsedIn (ICX)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(точность) isUsedIn (IC)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(accuracy) isUsedIn (IC)"
          },
          {
            "text": "Для задач NER я классифицировал токены логистической регрессией поверх их эмбеддингов, и измерял macro F1 по всем классам токенов, кроме О.",
            "relation": "(macro F1) isUsedIn (NER)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(macro F1) isUsedIn (извлечения именованных сущностей)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(macro F1) isUsedIn (классификации)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(macro F1) isUsedIn (NER)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 2,
        "examples": [
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(accuracy) isUsedIn (SA)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(точность) isUsedIn (SA)"
          }
        ]
      },
      "found": {
        "count": 28,
        "examples": [
          {
            "text": "Приведу только показатели качества классификации, которые были нами получены на тестах: Accuracy = 95% F1 score = 93%",
            "relation": "(F1 score) isUsedIn (классификации)"
          },
          {
            "text": "Приведу только показатели качества классификации, которые были нами получены на тестах: Accuracy = 95% F1 score = 93%",
            "relation": "(Accuracy) isUsedIn (классификации)"
          },
          {
            "text": "При обучении модели значение метрики F1-score достигло 0.894, соответственно можно сделать вывод о том, что модель хорошо справляется с задачей определения нейтральных и негативных обращений.",
            "relation": "(F1-score) isUsedIn (определения нейтральных и негативных обращений)"
          },
          {
            "text": "ЗаключениеВ итоге, моделью RuBioRoBERTa в задаче RuMedDaNet мне удалось добиться качества 73.24% на закрытой тестовой части данных (хотя на dev метрика Accuracy вообще была 81.64%).",
            "relation": "(Accuracy) isUsedIn (RuMedDaNet)"
          },
          {
            "text": "Сейчас точность выделения жестов в видеопотоке составляет 85—90%.",
            "relation": "(точность) isUsedIn (выделения жестов)"
          },
          {
            "text": "Так как задача является составной, то и метрика состояла из двух компонентов с весом 0.8 для задачи классификации и 0.2 для задачи NER.",
            "relation": "(метрика) isUsedIn (классификации)"
          },
          {
            "text": "Так как задача является составной, то и метрика состояла из двух компонентов с весом 0.8 для задачи классификации и 0.2 для задачи NER.",
            "relation": "(метрика) isUsedIn (NER)"
          },
          {
            "text": "В задаче классификации использовался logloss, вычисляемый как среднее значение метрики sklearn.metrics.log_loss по классам болезней.",
            "relation": "(logloss) isUsedIn (классификации)"
          },
          {
            "text": "В задаче классификации использовался logloss, вычисляемый как среднее значение метрики sklearn.metrics.log_loss по классам болезней.",
            "relation": "(sklearn.metrics.log_loss) isUsedIn (классификации)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(span-based F1-score) isUsedIn (NER)"
          },
          {
            "text": "Метрика LogisticDetection при помощи машинного обучения позволяет оценить насколько сложно отличить синтетические данные от исходных.",
            "relation": "(LogisticDetection) isUsedIn (отличить синтетические данные от исходных)"
          },
          {
            "text": "Для русского языка тоже было создано немало разного рода бенчмарков NLU моделей:RussianSuperGLUE: бенчмарк \"сложных\" NLP задач; фокус на дообучаемых моделях.",
            "relation": "(RussianSuperGLUE) isUsedIn (NLP задач)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(точность) isUsedIn (NLI)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(косинусной близости) isUsedIn (NLI)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(accuracy) isUsedIn (NLI)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(точность) isUsedIn (NLI)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(косинусной близости) isUsedIn (NLI)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(accuracy) isUsedIn (NLI)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(ROC AUC) isUsedIn (TI)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(accuracy) isUsedIn (ICX)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(точность) isUsedIn (ICX)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(ROC AUC) isUsedIn (II)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(точность) isUsedIn (IC)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(accuracy) isUsedIn (IC)"
          },
          {
            "text": "Для задач NER я классифицировал токены логистической регрессией поверх их эмбеддингов, и измерял macro F1 по всем классам токенов, кроме О.",
            "relation": "(macro F1) isUsedIn (NER)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(macro F1) isUsedIn (извлечения именованных сущностей)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(macro F1) isUsedIn (классификации)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(macro F1) isUsedIn (NER)"
          }
        ]
      }
    }
  },
  "Model_isUsedForSolving_Task": {
    "predicted": {
      "incorrect": {
        "count": 7,
        "examples": [
          {
            "text": "Для задачи моделирования языка ULMFit использует архитектуру AWD-LSTM, которая предполагает активное использование dropout везде, где только можно и имеет смысл.",
            "relation": "(ULMFit) isUsedForSolving (моделирования)"
          },
          {
            "text": "«Сбер» представил mGPT — версию нейросети GPT-3, способную генерировать тексты на 61 языке",
            "relation": "(GPT-3) isUsedForSolving (генерировать тексты)"
          },
          {
            "text": "В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.",
            "relation": "(BERT) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).",
            "relation": "(BERT) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "Модель по умолчанию для конвейера генерации текста — GPT-2, самая популярная модель декодирующего трансформера для генерации языка.",
            "relation": "(трансформера) isUsedForSolving (генерации текста)"
          },
          {
            "text": "В рамках курса вы узнаете: Как латентные переменные применяются в задачах анализа текстов и как строить глубинные генеративные модели с латентными дискретными переменными.",
            "relation": "(глубинные генеративные модели) isUsedForSolving (анализа текстов)"
          },
          {
            "text": "SequenceEncoder представляет собой рекуррентную нейронную сеть (RNN), применяемую для анализа последовательностей в данных о транзакциях и кликах.",
            "relation": "(рекуррентную нейронную сеть) isUsedForSolving (анализа последовательностей)"
          }
        ]
      },
      "correct": {
        "count": 73,
        "examples": [
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(word2vec) isUsedForSolving (предсказания характеристик)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(doc2vec) isUsedForSolving (предсказания характеристик)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedForSolving (создание контента)"
          },
          {
            "text": "За основу возьмем данную статью, в которой была рассмотрена классификация тональности на архитектуре CNN с использованием Word2vec модели.",
            "relation": "(Word2vec) isUsedForSolving (классификация тональности)"
          },
          {
            "text": "В нашем примере будем решать ту же самую задачу разделения твитов на позитивные и негативные на том же самом датасете с использованием модели ULMFit.",
            "relation": "(ULMFit) isUsedForSolving (разделения твитов)"
          },
          {
            "text": "Для задачи моделирования языка ULMFit использует архитектуру AWD-LSTM, которая предполагает активное использование dropout везде, где только можно и имеет смысл.",
            "relation": "(AWD-LSTM) isUsedForSolving (моделирования)"
          },
          {
            "text": "«М.видео-Эльдорадо» внедряет нейросеть для ответов на вопросы покупателей",
            "relation": "(нейросеть) isUsedForSolving (ответов на вопросы)"
          },
          {
            "text": "Facebook AI отмечает, что эта модель может быть полезной не только при машинном переводе, но и при изучении языков.",
            "relation": "(модель) isUsedForSolving (машинном переводе)"
          },
          {
            "text": "С марта 2017 года нейросеть стали использовать для перевода на русский.",
            "relation": "(нейросеть) isUsedForSolving (перевода)"
          },
          {
            "text": "Эта модель помогает нейросети запоминать правила языка, выбирать подходящие слова и связывать их по смыслу.",
            "relation": "(модель) isUsedForSolving (выбирать подходящие слова)"
          },
          {
            "text": "Эта модель помогает нейросети запоминать правила языка, выбирать подходящие слова и связывать их по смыслу.",
            "relation": "(модель) isUsedForSolving (запоминать правила языка)"
          },
          {
            "text": "Вспомним теперь, что для нашей задачи языковая модель нужна для выбора наиболее подходящего следующего слова по уже сгенерированной последовательности.",
            "relation": "(модель) isUsedForSolving (выбора наиболее подходящего следующего слова)"
          },
          {
            "text": "В этом посте мы расскажем, как мы создали датасет для задачи Common Sense Reasoning в одной из ее возможных формулировок, предложенной в статье event2mind, а также адаптировали английскую модель event2mind от AllenNLP для русского языка.",
            "relation": "(event2mind) isUsedForSolving (Common Sense Reasoning)"
          },
          {
            "text": "На разных заданиях топовые метрики далеко не только у ruT5-large: лучшие single-model решения также есть у ruRoBERTa-large (задача TERRa и DaNetQA).",
            "relation": "(ruRoBERTa-large) isUsedForSolving (DaNetQA)"
          },
          {
            "text": "На разных заданиях топовые метрики далеко не только у ruT5-large: лучшие single-model решения также есть у ruRoBERTa-large (задача TERRa и DaNetQA).",
            "relation": "(ruRoBERTa-large) isUsedForSolving (TERRa)"
          },
          {
            "text": "А на некоторых заданиях лучших результатов удалось достичь на few-shot, т. е. без дообучения модели (задача RCB и RuCoS, YaLM от Яндекса).",
            "relation": "(YaLM) isUsedForSolving (few-shot)"
          },
          {
            "text": "А на некоторых заданиях лучших результатов удалось достичь на few-shot, т. е. без дообучения модели (задача RCB и RuCoS, YaLM от Яндекса).",
            "relation": "(YaLM) isUsedForSolving (RCB)"
          },
          {
            "text": "ЗаключениеВ итоге, моделью RuBioRoBERTa в задаче RuMedDaNet мне удалось добиться качества 73.24% на закрытой тестовой части данных (хотя на dev метрика Accuracy вообще была 81.64%).",
            "relation": "(RuBioRoBERTa) isUsedForSolving (RuMedDaNet)"
          },
          {
            "text": "Новая модель распознавания речи Facebook AI — это последняя разработка за несколько лет работы над моделями распознавания речи.",
            "relation": "(модель распознавания речи) isUsedForSolving (распознавания речи)"
          },
          {
            "text": "«Сбер» представил mGPT — версию нейросети GPT-3, способную генерировать тексты на 61 языке",
            "relation": "(mGPT) isUsedForSolving (генерировать тексты)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(mGPT) isUsedForSolving (генерации текста)"
          },
          {
            "text": "Разработчики уточнили, что модель mGPT показывает выдающиеся результаты на многих задачах few-shot и zero-shot learning: в этой области машинного обучения не требуется отдельно доучивать модель, достаточно сформулировать задачу текстом и привести несколько примеров, после чего mGPT научится выполнять новую задачу.",
            "relation": "(mGPT) isUsedForSolving (zero-shot learning)"
          },
          {
            "text": "Разработчики уточнили, что модель mGPT показывает выдающиеся результаты на многих задачах few-shot и zero-shot learning: в этой области машинного обучения не требуется отдельно доучивать модель, достаточно сформулировать задачу текстом и привести несколько примеров, после чего mGPT научится выполнять новую задачу.",
            "relation": "(mGPT) isUsedForSolving (few-shot)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(mGPT) isUsedForSolving (улучшения качества распознавания речи)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(mGPT) isUsedForSolving (генерации сценариев диалоговых систем)"
          },
          {
            "text": "В данной статье мы будем использовать модель трансформера для бинарной классификации текста.",
            "relation": "(модель трансформера) isUsedForSolving (бинарной классификации текста)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(нейронные сети) isUsedForSolving (распознаванием смысла и контекста)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(BERT) isUsedForSolving (распознаванием смысла и контекста)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(Bidirectional Encoder Representations from Transformers) isUsedForSolving (распознаванием смысла и контекста)"
          },
          {
            "text": "Эта модель была обучена на огромном корпусе русскоязычного текста с двумя задачами – предсказать замаскированное слово в предложениях и предсказать, если одно из предложений следует по смыслу за вторым.",
            "relation": "(модель) isUsedForSolving (предсказать замаскированное слово в предложениях)"
          },
          {
            "text": "На обширном корпусе русскоязычного текста данная модель была обучена выполнять две задачи: предсказывать замаскированные слова в предложениях и определять, следует ли одно предложение за другим по смыслу.",
            "relation": "(модель) isUsedForSolving (предсказывать замаскированные слова в предложениях)"
          },
          {
            "text": "Наша задача – дообучить эту языковую модель для нашего приложения (одна модель для классификации и одна – для извлечения сущности).",
            "relation": "(модель) isUsedForSolving (классификации)"
          },
          {
            "text": "Наша задача – дообучить эту языковую модель для нашего приложения (одна модель для классификации и одна – для извлечения сущности).",
            "relation": "(модель) isUsedForSolving (извлечения сущности)"
          },
          {
            "text": "Мы поняли, что даже извлечение сущности зависит от контекста, и решили использовать BERT.",
            "relation": "(BERT) isUsedForSolving (извлечение сущности)"
          },
          {
            "text": "Для решения этой проблемы требуется архитектура, которая позволяет GPT-3 анализировать содержание письма и оценивать, какая информация актуальна для ответа.",
            "relation": "(GPT-3) isUsedForSolving (анализировать содержание письма)"
          },
          {
            "text": "Для решения этой проблемы требуется архитектура, которая позволяет GPT-3 анализировать содержание письма и оценивать, какая информация актуальна для ответа.",
            "relation": "(GPT-3) isUsedForSolving (оценивать, какая информация актуальна)"
          },
          {
            "text": "DeepPavlov решает проблемы такие как: классификация текста, исправление опечаток, распознавание именованных сущностей, ответы на вопросы по базе знаний и многие другие.",
            "relation": "(DeepPavlov) isUsedForSolving (исправление опечаток)"
          },
          {
            "text": "DeepPavlov решает проблемы такие как: классификация текста, исправление опечаток, распознавание именованных сущностей, ответы на вопросы по базе знаний и многие другие.",
            "relation": "(DeepPavlov) isUsedForSolving (ответы на вопросы)"
          },
          {
            "text": "DeepPavlov решает проблемы такие как: классификация текста, исправление опечаток, распознавание именованных сущностей, ответы на вопросы по базе знаний и многие другие.",
            "relation": "(DeepPavlov) isUsedForSolving (распознавание именованных сущностей)"
          },
          {
            "text": "DeepPavlov решает проблемы такие как: классификация текста, исправление опечаток, распознавание именованных сущностей, ответы на вопросы по базе знаний и многие другие.",
            "relation": "(DeepPavlov) isUsedForSolving (классификация текста)"
          },
          {
            "text": "Команда DeepPavlov интегрировала BERT в три последующие задачи: классификация текста, распознавание именованных сущностей и ответы на вопросы.",
            "relation": "(BERT) isUsedForSolving (распознавание именованных сущностей)"
          },
          {
            "text": "Команда DeepPavlov интегрировала BERT в три последующие задачи: классификация текста, распознавание именованных сущностей и ответы на вопросы.",
            "relation": "(BERT) isUsedForSolving (классификация текста)"
          },
          {
            "text": "Команда DeepPavlov интегрировала BERT в три последующие задачи: классификация текста, распознавание именованных сущностей и ответы на вопросы.",
            "relation": "(BERT) isUsedForSolving (ответы на вопросы)"
          },
          {
            "text": "Модель классификации текста на основе BERT DeepPavlov служит, например, для решения проблемы обнаружения оскорблений.",
            "relation": "(BERT DeepPavlov) isUsedForSolving (обнаружения оскорблений)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(BERT) isUsedForSolving (распознавания именованных сущностей)"
          },
          {
            "text": "Например, модель может извлечь важную информацию из резюме, чтобы облегчить работу специалистов по кадрам.",
            "relation": "(модель) isUsedForSolving (извлечь важную информацию)"
          },
          {
            "text": "В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.",
            "relation": "(GOLOMB) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).",
            "relation": "(GOLOMB) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "Для предсказания состояния диалога модель решает несколько классификационных задач и задачу поиска подстроки.",
            "relation": "(модель) isUsedForSolving (классификационных задач)"
          },
          {
            "text": "Для предсказания состояния диалога модель решает несколько классификационных задач и задачу поиска подстроки.",
            "relation": "(модель) isUsedForSolving (задачу поиска подстроки)"
          },
          {
            "text": "SDV генерирует данные, применяя математические методы и модели машинного обучения.",
            "relation": "(модели машинного обучения) isUsedForSolving (генерирует данные)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(моделей машинного обучения) isUsedForSolving (создает данные)"
          },
          {
            "text": "Эти модели всегда ищут синонимы — даже для устоявшихся словосочетаний.",
            "relation": "(модели) isUsedForSolving (ищут синонимы)"
          },
          {
            "text": "В течение четырех лет вышло несколько версий модели, способных транскрибировать лекции, телефонные разговоры, телевизионные программы, радиошоу и другие прямые трансляции с «человеческой точностью».",
            "relation": "(модели) isUsedForSolving (транскрибировать лекции)"
          },
          {
            "text": "Модель DeepSpeech представляет собой сквозную обучаемую архитектуру на уровне символов, которая может транскрибировать аудио на различных языках.",
            "relation": "(DeepSpeech) isUsedForSolving (транскрибировать аудио)"
          },
          {
            "text": "В этой статье мы научим вас генерировать текст с помощью предварительно обученного GPT-2 — более легкого предшественника GPT-3.",
            "relation": "(GPT-2) isUsedForSolving (генерировать текст)"
          },
          {
            "text": "Модель по умолчанию для конвейера генерации текста — GPT-2, самая популярная модель декодирующего трансформера для генерации языка.",
            "relation": "(GPT-2) isUsedForSolving (генерации текста)"
          },
          {
            "text": "Модель по умолчанию для конвейера генерации текста — GPT-2, самая популярная модель декодирующего трансформера для генерации языка.",
            "relation": "(Модель) isUsedForSolving (генерации текста)"
          },
          {
            "text": "Модель по умолчанию для конвейера генерации текста — GPT-2, самая популярная модель декодирующего трансформера для генерации языка.",
            "relation": "(GPT-2) isUsedForSolving (генерации языка)"
          },
          {
            "text": "Для русского языка тоже было создано немало разного рода бенчмарков NLU моделей:RussianSuperGLUE: бенчмарк \"сложных\" NLP задач; фокус на дообучаемых моделях.",
            "relation": "(NLU моделей) isUsedForSolving (NLP задач)"
          },
          {
            "text": "Это доработанная версия rubert-tiny: я расширил словарь модели c 30К до 80К токенов, увеличил максимальную длину текста с 512 до 2048 токенов, и дообучил модель на комбинации задач masked language modelling, natural language inference, и аппроксимации эмбеддингов LaBSE.",
            "relation": "(rubert-tiny) isUsedForSolving (masked language modelling)"
          },
          {
            "text": "Это доработанная версия rubert-tiny: я расширил словарь модели c 30К до 80К токенов, увеличил максимальную длину текста с 512 до 2048 токенов, и дообучил модель на комбинации задач masked language modelling, natural language inference, и аппроксимации эмбеддингов LaBSE.",
            "relation": "(rubert-tiny) isUsedForSolving (natural language inference)"
          },
          {
            "text": "Это доработанная версия rubert-tiny: я расширил словарь модели c 30К до 80К токенов, увеличил максимальную длину текста с 512 до 2048 токенов, и дообучил модель на комбинации задач masked language modelling, natural language inference, и аппроксимации эмбеддингов LaBSE.",
            "relation": "(rubert-tiny) isUsedForSolving (аппроксимации эмбеддингов LaBSE)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(логистическую регрессию) isUsedForSolving (NLI)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(логистической регрессии) isUsedForSolving (NLI)"
          },
          {
            "text": "Для всех задач классификации я обучаю логистическую регрессию либо KNN поверх эмбеддингов предложений, и выбираю лучшую модель из двух.",
            "relation": "(логистическую регрессию) isUsedForSolving (классификации)"
          },
          {
            "text": "Для всех задач классификации я обучаю логистическую регрессию либо KNN поверх эмбеддингов предложений, и выбираю лучшую модель из двух.",
            "relation": "(KNN) isUsedForSolving (классификации)"
          },
          {
            "text": "Удивительно, но модели T5 очень хорошо показали себя на задачах NER.",
            "relation": "(T5) isUsedForSolving (NER)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(Байесовы модели) isUsedForSolving (классификации)"
          },
          {
            "text": "SequenceEncoder представляет собой рекуррентную нейронную сеть (RNN), применяемую для анализа последовательностей в данных о транзакциях и кликах.",
            "relation": "(SequenceEncoder) isUsedForSolving (анализа последовательностей)"
          },
          {
            "text": "Давайте обратимся к этой статье, где была исследована классификация тональности с использованием модели Word2vec в архитектуре CNN.",
            "relation": "(Word2vec) isUsedForSolving (классификация тональности)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 3,
        "examples": [
          {
            "text": "На разных заданиях топовые метрики далеко не только у ruT5-large: лучшие single-model решения также есть у ruRoBERTa-large (задача TERRa и DaNetQA).",
            "relation": "(ruT5-large) isUsedForSolving (DaNetQA)"
          },
          {
            "text": "На разных заданиях топовые метрики далеко не только у ruT5-large: лучшие single-model решения также есть у ruRoBERTa-large (задача TERRa и DaNetQA).",
            "relation": "(ruT5-large) isUsedForSolving (TERRa)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(BERT) isUsedForSolving (классификации текста)"
          }
        ]
      },
      "found": {
        "count": 73,
        "examples": [
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(word2vec) isUsedForSolving (предсказания характеристик)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(doc2vec) isUsedForSolving (предсказания характеристик)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Тьюринговые модели) isUsedForSolving (создание контента)"
          },
          {
            "text": "За основу возьмем данную статью, в которой была рассмотрена классификация тональности на архитектуре CNN с использованием Word2vec модели.",
            "relation": "(Word2vec) isUsedForSolving (классификация тональности)"
          },
          {
            "text": "В нашем примере будем решать ту же самую задачу разделения твитов на позитивные и негативные на том же самом датасете с использованием модели ULMFit.",
            "relation": "(ULMFit) isUsedForSolving (разделения твитов)"
          },
          {
            "text": "Для задачи моделирования языка ULMFit использует архитектуру AWD-LSTM, которая предполагает активное использование dropout везде, где только можно и имеет смысл.",
            "relation": "(AWD-LSTM) isUsedForSolving (моделирования)"
          },
          {
            "text": "«М.видео-Эльдорадо» внедряет нейросеть для ответов на вопросы покупателей",
            "relation": "(нейросеть) isUsedForSolving (ответов на вопросы)"
          },
          {
            "text": "Facebook AI отмечает, что эта модель может быть полезной не только при машинном переводе, но и при изучении языков.",
            "relation": "(модель) isUsedForSolving (машинном переводе)"
          },
          {
            "text": "С марта 2017 года нейросеть стали использовать для перевода на русский.",
            "relation": "(нейросеть) isUsedForSolving (перевода)"
          },
          {
            "text": "Эта модель помогает нейросети запоминать правила языка, выбирать подходящие слова и связывать их по смыслу.",
            "relation": "(модель) isUsedForSolving (выбирать подходящие слова)"
          },
          {
            "text": "Эта модель помогает нейросети запоминать правила языка, выбирать подходящие слова и связывать их по смыслу.",
            "relation": "(модель) isUsedForSolving (запоминать правила языка)"
          },
          {
            "text": "Вспомним теперь, что для нашей задачи языковая модель нужна для выбора наиболее подходящего следующего слова по уже сгенерированной последовательности.",
            "relation": "(модель) isUsedForSolving (выбора наиболее подходящего следующего слова)"
          },
          {
            "text": "В этом посте мы расскажем, как мы создали датасет для задачи Common Sense Reasoning в одной из ее возможных формулировок, предложенной в статье event2mind, а также адаптировали английскую модель event2mind от AllenNLP для русского языка.",
            "relation": "(event2mind) isUsedForSolving (Common Sense Reasoning)"
          },
          {
            "text": "На разных заданиях топовые метрики далеко не только у ruT5-large: лучшие single-model решения также есть у ruRoBERTa-large (задача TERRa и DaNetQA).",
            "relation": "(ruRoBERTa-large) isUsedForSolving (DaNetQA)"
          },
          {
            "text": "На разных заданиях топовые метрики далеко не только у ruT5-large: лучшие single-model решения также есть у ruRoBERTa-large (задача TERRa и DaNetQA).",
            "relation": "(ruRoBERTa-large) isUsedForSolving (TERRa)"
          },
          {
            "text": "А на некоторых заданиях лучших результатов удалось достичь на few-shot, т. е. без дообучения модели (задача RCB и RuCoS, YaLM от Яндекса).",
            "relation": "(YaLM) isUsedForSolving (RCB)"
          },
          {
            "text": "А на некоторых заданиях лучших результатов удалось достичь на few-shot, т. е. без дообучения модели (задача RCB и RuCoS, YaLM от Яндекса).",
            "relation": "(YaLM) isUsedForSolving (few-shot)"
          },
          {
            "text": "ЗаключениеВ итоге, моделью RuBioRoBERTa в задаче RuMedDaNet мне удалось добиться качества 73.24% на закрытой тестовой части данных (хотя на dev метрика Accuracy вообще была 81.64%).",
            "relation": "(RuBioRoBERTa) isUsedForSolving (RuMedDaNet)"
          },
          {
            "text": "Новая модель распознавания речи Facebook AI — это последняя разработка за несколько лет работы над моделями распознавания речи.",
            "relation": "(модель распознавания речи) isUsedForSolving (распознавания речи)"
          },
          {
            "text": "«Сбер» представил mGPT — версию нейросети GPT-3, способную генерировать тексты на 61 языке",
            "relation": "(mGPT) isUsedForSolving (генерировать тексты)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(mGPT) isUsedForSolving (генерации текста)"
          },
          {
            "text": "Разработчики уточнили, что модель mGPT показывает выдающиеся результаты на многих задачах few-shot и zero-shot learning: в этой области машинного обучения не требуется отдельно доучивать модель, достаточно сформулировать задачу текстом и привести несколько примеров, после чего mGPT научится выполнять новую задачу.",
            "relation": "(mGPT) isUsedForSolving (zero-shot learning)"
          },
          {
            "text": "Разработчики уточнили, что модель mGPT показывает выдающиеся результаты на многих задачах few-shot и zero-shot learning: в этой области машинного обучения не требуется отдельно доучивать модель, достаточно сформулировать задачу текстом и привести несколько примеров, после чего mGPT научится выполнять новую задачу.",
            "relation": "(mGPT) isUsedForSolving (few-shot)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(mGPT) isUsedForSolving (улучшения качества распознавания речи)"
          },
          {
            "text": "«Сбер» раскрыл, что модель mGPT может также использоваться как компонент различных речевых технологий — например, для улучшения качества распознавания речи, генерации сценариев диалоговых систем и других задачах.",
            "relation": "(mGPT) isUsedForSolving (генерации сценариев диалоговых систем)"
          },
          {
            "text": "В данной статье мы будем использовать модель трансформера для бинарной классификации текста.",
            "relation": "(модель трансформера) isUsedForSolving (бинарной классификации текста)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(нейронные сети) isUsedForSolving (распознаванием смысла и контекста)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(BERT) isUsedForSolving (распознаванием смысла и контекста)"
          },
          {
            "text": "На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).",
            "relation": "(Bidirectional Encoder Representations from Transformers) isUsedForSolving (распознаванием смысла и контекста)"
          },
          {
            "text": "Эта модель была обучена на огромном корпусе русскоязычного текста с двумя задачами – предсказать замаскированное слово в предложениях и предсказать, если одно из предложений следует по смыслу за вторым.",
            "relation": "(модель) isUsedForSolving (предсказать замаскированное слово в предложениях)"
          },
          {
            "text": "На обширном корпусе русскоязычного текста данная модель была обучена выполнять две задачи: предсказывать замаскированные слова в предложениях и определять, следует ли одно предложение за другим по смыслу.",
            "relation": "(модель) isUsedForSolving (предсказывать замаскированные слова в предложениях)"
          },
          {
            "text": "Наша задача – дообучить эту языковую модель для нашего приложения (одна модель для классификации и одна – для извлечения сущности).",
            "relation": "(модель) isUsedForSolving (классификации)"
          },
          {
            "text": "Наша задача – дообучить эту языковую модель для нашего приложения (одна модель для классификации и одна – для извлечения сущности).",
            "relation": "(модель) isUsedForSolving (извлечения сущности)"
          },
          {
            "text": "Мы поняли, что даже извлечение сущности зависит от контекста, и решили использовать BERT.",
            "relation": "(BERT) isUsedForSolving (извлечение сущности)"
          },
          {
            "text": "Для решения этой проблемы требуется архитектура, которая позволяет GPT-3 анализировать содержание письма и оценивать, какая информация актуальна для ответа.",
            "relation": "(GPT-3) isUsedForSolving (анализировать содержание письма)"
          },
          {
            "text": "Для решения этой проблемы требуется архитектура, которая позволяет GPT-3 анализировать содержание письма и оценивать, какая информация актуальна для ответа.",
            "relation": "(GPT-3) isUsedForSolving (оценивать, какая информация актуальна)"
          },
          {
            "text": "DeepPavlov решает проблемы такие как: классификация текста, исправление опечаток, распознавание именованных сущностей, ответы на вопросы по базе знаний и многие другие.",
            "relation": "(DeepPavlov) isUsedForSolving (исправление опечаток)"
          },
          {
            "text": "DeepPavlov решает проблемы такие как: классификация текста, исправление опечаток, распознавание именованных сущностей, ответы на вопросы по базе знаний и многие другие.",
            "relation": "(DeepPavlov) isUsedForSolving (ответы на вопросы)"
          },
          {
            "text": "DeepPavlov решает проблемы такие как: классификация текста, исправление опечаток, распознавание именованных сущностей, ответы на вопросы по базе знаний и многие другие.",
            "relation": "(DeepPavlov) isUsedForSolving (распознавание именованных сущностей)"
          },
          {
            "text": "DeepPavlov решает проблемы такие как: классификация текста, исправление опечаток, распознавание именованных сущностей, ответы на вопросы по базе знаний и многие другие.",
            "relation": "(DeepPavlov) isUsedForSolving (классификация текста)"
          },
          {
            "text": "Команда DeepPavlov интегрировала BERT в три последующие задачи: классификация текста, распознавание именованных сущностей и ответы на вопросы.",
            "relation": "(BERT) isUsedForSolving (распознавание именованных сущностей)"
          },
          {
            "text": "Команда DeepPavlov интегрировала BERT в три последующие задачи: классификация текста, распознавание именованных сущностей и ответы на вопросы.",
            "relation": "(BERT) isUsedForSolving (классификация текста)"
          },
          {
            "text": "Команда DeepPavlov интегрировала BERT в три последующие задачи: классификация текста, распознавание именованных сущностей и ответы на вопросы.",
            "relation": "(BERT) isUsedForSolving (ответы на вопросы)"
          },
          {
            "text": "Модель классификации текста на основе BERT DeepPavlov служит, например, для решения проблемы обнаружения оскорблений.",
            "relation": "(BERT DeepPavlov) isUsedForSolving (обнаружения оскорблений)"
          },
          {
            "text": "В дополнение к моделям классификации текста DeepPavlov содержит модель на основе BERT для распознавания именованных сущностей (NER).",
            "relation": "(BERT) isUsedForSolving (распознавания именованных сущностей)"
          },
          {
            "text": "Например, модель может извлечь важную информацию из резюме, чтобы облегчить работу специалистов по кадрам.",
            "relation": "(модель) isUsedForSolving (извлечь важную информацию)"
          },
          {
            "text": "В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.",
            "relation": "(GOLOMB) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).",
            "relation": "(GOLOMB) isUsedForSolving (отслеживания состояния диалога)"
          },
          {
            "text": "Для предсказания состояния диалога модель решает несколько классификационных задач и задачу поиска подстроки.",
            "relation": "(модель) isUsedForSolving (классификационных задач)"
          },
          {
            "text": "Для предсказания состояния диалога модель решает несколько классификационных задач и задачу поиска подстроки.",
            "relation": "(модель) isUsedForSolving (задачу поиска подстроки)"
          },
          {
            "text": "SDV генерирует данные, применяя математические методы и модели машинного обучения.",
            "relation": "(модели машинного обучения) isUsedForSolving (генерирует данные)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(моделей машинного обучения) isUsedForSolving (создает данные)"
          },
          {
            "text": "Эти модели всегда ищут синонимы — даже для устоявшихся словосочетаний.",
            "relation": "(модели) isUsedForSolving (ищут синонимы)"
          },
          {
            "text": "В течение четырех лет вышло несколько версий модели, способных транскрибировать лекции, телефонные разговоры, телевизионные программы, радиошоу и другие прямые трансляции с «человеческой точностью».",
            "relation": "(модели) isUsedForSolving (транскрибировать лекции)"
          },
          {
            "text": "Модель DeepSpeech представляет собой сквозную обучаемую архитектуру на уровне символов, которая может транскрибировать аудио на различных языках.",
            "relation": "(DeepSpeech) isUsedForSolving (транскрибировать аудио)"
          },
          {
            "text": "В этой статье мы научим вас генерировать текст с помощью предварительно обученного GPT-2 — более легкого предшественника GPT-3.",
            "relation": "(GPT-2) isUsedForSolving (генерировать текст)"
          },
          {
            "text": "Модель по умолчанию для конвейера генерации текста — GPT-2, самая популярная модель декодирующего трансформера для генерации языка.",
            "relation": "(Модель) isUsedForSolving (генерации текста)"
          },
          {
            "text": "Модель по умолчанию для конвейера генерации текста — GPT-2, самая популярная модель декодирующего трансформера для генерации языка.",
            "relation": "(GPT-2) isUsedForSolving (генерации текста)"
          },
          {
            "text": "Модель по умолчанию для конвейера генерации текста — GPT-2, самая популярная модель декодирующего трансформера для генерации языка.",
            "relation": "(GPT-2) isUsedForSolving (генерации языка)"
          },
          {
            "text": "Для русского языка тоже было создано немало разного рода бенчмарков NLU моделей:RussianSuperGLUE: бенчмарк \"сложных\" NLP задач; фокус на дообучаемых моделях.",
            "relation": "(NLU моделей) isUsedForSolving (NLP задач)"
          },
          {
            "text": "Это доработанная версия rubert-tiny: я расширил словарь модели c 30К до 80К токенов, увеличил максимальную длину текста с 512 до 2048 токенов, и дообучил модель на комбинации задач masked language modelling, natural language inference, и аппроксимации эмбеддингов LaBSE.",
            "relation": "(rubert-tiny) isUsedForSolving (masked language modelling)"
          },
          {
            "text": "Это доработанная версия rubert-tiny: я расширил словарь модели c 30К до 80К токенов, увеличил максимальную длину текста с 512 до 2048 токенов, и дообучил модель на комбинации задач masked language modelling, natural language inference, и аппроксимации эмбеддингов LaBSE.",
            "relation": "(rubert-tiny) isUsedForSolving (natural language inference)"
          },
          {
            "text": "Это доработанная версия rubert-tiny: я расширил словарь модели c 30К до 80К токенов, увеличил максимальную длину текста с 512 до 2048 токенов, и дообучил модель на комбинации задач masked language modelling, natural language inference, и аппроксимации эмбеддингов LaBSE.",
            "relation": "(rubert-tiny) isUsedForSolving (аппроксимации эмбеддингов LaBSE)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(логистическую регрессию) isUsedForSolving (NLI)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(логистической регрессии) isUsedForSolving (NLI)"
          },
          {
            "text": "Для всех задач классификации я обучаю логистическую регрессию либо KNN поверх эмбеддингов предложений, и выбираю лучшую модель из двух.",
            "relation": "(логистическую регрессию) isUsedForSolving (классификации)"
          },
          {
            "text": "Для всех задач классификации я обучаю логистическую регрессию либо KNN поверх эмбеддингов предложений, и выбираю лучшую модель из двух.",
            "relation": "(KNN) isUsedForSolving (классификации)"
          },
          {
            "text": "Удивительно, но модели T5 очень хорошо показали себя на задачах NER.",
            "relation": "(T5) isUsedForSolving (NER)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(Байесовы модели) isUsedForSolving (классификации)"
          },
          {
            "text": "SequenceEncoder представляет собой рекуррентную нейронную сеть (RNN), применяемую для анализа последовательностей в данных о транзакциях и кликах.",
            "relation": "(SequenceEncoder) isUsedForSolving (анализа последовательностей)"
          },
          {
            "text": "Давайте обратимся к этой статье, где была исследована классификация тональности с использованием модели Word2vec в архитектуре CNN.",
            "relation": "(Word2vec) isUsedForSolving (классификация тональности)"
          }
        ]
      }
    }
  },
  "Organization_isAlternativeNameFor_Organization": {
    "predicted": {
      "incorrect": {
        "count": 1,
        "examples": [
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(Сбер) isAlternativeNameFor (Сбера)"
          }
        ]
      },
      "correct": {
        "count": 15,
        "examples": [
          {
            "text": "Важным аспектом здесь является то, что Nearby Share опирается на Google Mobile Services (GMS), а это означает, что разработчик системы заменил доступную в AOSP функцию проприетарной службой, которая не является частью проекта AOSP.",
            "relation": "(GMS) isAlternativeNameFor (Google Mobile Services)"
          },
          {
            "text": "Nearby Share (NS) повторяют за Google Mobile Services (GMS).",
            "relation": "(NS) isAlternativeNameFor (Nearby Share)"
          },
          {
            "text": "Nearby Share (NS) повторяют за Google Mobile Services (GMS).",
            "relation": "(GMS) isAlternativeNameFor (Google Mobile Services)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(French National Center for Scientific Research) isAlternativeNameFor (Французского национального центра научных исследований)"
          },
          {
            "text": "Недавно ученые из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о выходе модели BLOOM.",
            "relation": "(French National Center for Scientific Research) isAlternativeNameFor (Французского национального центра научных исследований)"
          },
          {
            "text": "Недавно был релиз модели BLOOM, которую разработала команда из Французского национального центра научных исследований (French National Center for Scientific Research).",
            "relation": "(French National Center for Scientific Research) isAlternativeNameFor (Французского национального центра научных исследований)"
          },
          {
            "text": "Прорывы #DeepPavlov в 2019 году: обзор и итоги года Московский физико-технический институт (МФТИ).",
            "relation": "(МФТИ) isAlternativeNameFor (Московский физико-технический институт)"
          },
          {
            "text": "Модель DeepPavlov была разработана командой из Московского физико-технического института (МФТИ).",
            "relation": "(МФТИ) isAlternativeNameFor (Московского физико-технического института)"
          },
          {
            "text": "Команда исследователей из Московского физико-технического института (МФТИ) представила модель DeepPavlov.",
            "relation": "(МФТИ) isAlternativeNameFor (Московского физико-технического института)"
          },
          {
            "text": "С 27 по 30 мая в Российском государственном гуманитарном университете (РГГУ) пройдет международная научная конференция по компьютерной лингвистике «Диалог».",
            "relation": "(РГГУ) isAlternativeNameFor (Российском государственном гуманитарном университете)"
          },
          {
            "text": "Международная научная конференция по компьютерной лингвистике «Диалог» прошла в Российском государственном гуманитарном университете (РГГУ).",
            "relation": "(РГГУ) isAlternativeNameFor (Российском государственном гуманитарном университете)"
          },
          {
            "text": "Научная конференция по компьютерной лингвистике \"Диалог\" состоялась в Российском государственном гуманитарном университете (РГГУ).",
            "relation": "(РГГУ) isAlternativeNameFor (Российском государственном гуманитарном университете)"
          },
          {
            "text": "Российские ученые из Института проблем управления им. В.А. Трапезникова РАН (ИПУ РАН) несколько лет назад начали разработку подобного ИИ.",
            "relation": "(ИПУ РАН) isAlternativeNameFor (Института проблем управления им. В.А. Трапезникова РАН)"
          },
          {
            "text": "Несколько лет назад разработку такой системы начали специалисты из Института проблем управления им. В.А. Трапезникова РАН (ИПУ РАН).",
            "relation": "(ИПУ РАН) isAlternativeNameFor (Института проблем управления им. В.А. Трапезникова РАН)"
          },
          {
            "text": "Разработка системы началась недавно в Институте проблем управления им. В.А. Трапезникова РАН (ИПУ РАН).",
            "relation": "(ИПУ РАН) isAlternativeNameFor (Институте проблем управления им. В.А. Трапезникова РАН)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 15,
        "examples": [
          {
            "text": "Важным аспектом здесь является то, что Nearby Share опирается на Google Mobile Services (GMS), а это означает, что разработчик системы заменил доступную в AOSP функцию проприетарной службой, которая не является частью проекта AOSP.",
            "relation": "(GMS) isAlternativeNameFor (Google Mobile Services)"
          },
          {
            "text": "Nearby Share (NS) повторяют за Google Mobile Services (GMS).",
            "relation": "(NS) isAlternativeNameFor (Nearby Share)"
          },
          {
            "text": "Nearby Share (NS) повторяют за Google Mobile Services (GMS).",
            "relation": "(GMS) isAlternativeNameFor (Google Mobile Services)"
          },
          {
            "text": "В полку LLM прибыло: недавно специалисты из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о релизе новой большой языковой модели под названием BLOOM (расшифровывается как BigScience Large Open-science Open-access Multilingual Language Model).",
            "relation": "(French National Center for Scientific Research) isAlternativeNameFor (Французского национального центра научных исследований)"
          },
          {
            "text": "Недавно ученые из Французского национального центра научных исследований (French National Center for Scientific Research) объявили о выходе модели BLOOM.",
            "relation": "(French National Center for Scientific Research) isAlternativeNameFor (Французского национального центра научных исследований)"
          },
          {
            "text": "Недавно был релиз модели BLOOM, которую разработала команда из Французского национального центра научных исследований (French National Center for Scientific Research).",
            "relation": "(French National Center for Scientific Research) isAlternativeNameFor (Французского национального центра научных исследований)"
          },
          {
            "text": "Прорывы #DeepPavlov в 2019 году: обзор и итоги года Московский физико-технический институт (МФТИ).",
            "relation": "(МФТИ) isAlternativeNameFor (Московский физико-технический институт)"
          },
          {
            "text": "Модель DeepPavlov была разработана командой из Московского физико-технического института (МФТИ).",
            "relation": "(МФТИ) isAlternativeNameFor (Московского физико-технического института)"
          },
          {
            "text": "Команда исследователей из Московского физико-технического института (МФТИ) представила модель DeepPavlov.",
            "relation": "(МФТИ) isAlternativeNameFor (Московского физико-технического института)"
          },
          {
            "text": "С 27 по 30 мая в Российском государственном гуманитарном университете (РГГУ) пройдет международная научная конференция по компьютерной лингвистике «Диалог».",
            "relation": "(РГГУ) isAlternativeNameFor (Российском государственном гуманитарном университете)"
          },
          {
            "text": "Международная научная конференция по компьютерной лингвистике «Диалог» прошла в Российском государственном гуманитарном университете (РГГУ).",
            "relation": "(РГГУ) isAlternativeNameFor (Российском государственном гуманитарном университете)"
          },
          {
            "text": "Научная конференция по компьютерной лингвистике \"Диалог\" состоялась в Российском государственном гуманитарном университете (РГГУ).",
            "relation": "(РГГУ) isAlternativeNameFor (Российском государственном гуманитарном университете)"
          },
          {
            "text": "Российские ученые из Института проблем управления им. В.А. Трапезникова РАН (ИПУ РАН) несколько лет назад начали разработку подобного ИИ.",
            "relation": "(ИПУ РАН) isAlternativeNameFor (Института проблем управления им. В.А. Трапезникова РАН)"
          },
          {
            "text": "Несколько лет назад разработку такой системы начали специалисты из Института проблем управления им. В.А. Трапезникова РАН (ИПУ РАН).",
            "relation": "(ИПУ РАН) isAlternativeNameFor (Института проблем управления им. В.А. Трапезникова РАН)"
          },
          {
            "text": "Разработка системы началась недавно в Институте проблем управления им. В.А. Трапезникова РАН (ИПУ РАН).",
            "relation": "(ИПУ РАН) isAlternativeNameFor (Институте проблем управления им. В.А. Трапезникова РАН)"
          }
        ]
      }
    }
  },
  "Application_hasAuthor_Person": {
    "predicted": {
      "incorrect": {
        "count": 3,
        "examples": [
          {
            "text": "По сути эта часть библиотеки — порт замечательного морфологического анализатора pymorphy2 за авторством kmike (на Хабре была пара статей об этой библиотеке).",
            "relation": "(морфологического анализатора) hasAuthor (kmike)"
          },
          {
            "text": "Эта часть библиотеки по сути является переносом выдающегося морфологического анализатора pymorphy2, созданного kmike (о котором было написано несколько статей на Хабре).",
            "relation": "(морфологического анализатора) hasAuthor (kmike)"
          },
          {
            "text": "Первой успешной реализацией чат-бота стал виртуальный собеседник ELIZA, написанный в 1966 году Джозефом Вейценбаумом.",
            "relation": "(виртуальный собеседник) hasAuthor (Джозефом Вейценбаумом)"
          }
        ]
      },
      "correct": {
        "count": 14,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(A.L.I.C.E.) hasAuthor (Richard Wallace)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(A.L.I.C.E.) hasAuthor (Ричардом Уэлсом)"
          },
          {
            "text": "Его мне любезно предоставил разработчик приложения GoTrans, Александр Козлов.",
            "relation": "(GoTrans) hasAuthor (Александр Козлов)"
          },
          {
            "text": "Александр Козлов, разработчик приложения GoTrans, любезно предоставил его мне.",
            "relation": "(GoTrans) hasAuthor (Александр Козлов)"
          },
          {
            "text": "Американский разработчик Мэтью Гинсберг (Matthew Ginsberg) создал программу под названием Dr Fill, которая справляется с кроссвордами гораздо лучше, чем абсолютное большинство людей, пишет New Scientist.",
            "relation": "(Dr Fill) hasAuthor (Matthew Ginsberg)"
          },
          {
            "text": "Американский разработчик Мэтью Гинсберг (Matthew Ginsberg) создал программу под названием Dr Fill, которая справляется с кроссвордами гораздо лучше, чем абсолютное большинство людей, пишет New Scientist.",
            "relation": "(Dr Fill) hasAuthor (Мэтью Гинсберг)"
          },
          {
            "text": "Программа Dr Fill, разработанная американским специалистом Мэтью Гинсбергом (Matthew Ginsberg), согласно информации из издания New Scientist, проявляет более выдающуюся эффективность в решении кроссвордов по сравнению с абсолютным большинством людей.",
            "relation": "(Dr Fill) hasAuthor (Мэтью Гинсбергом)"
          },
          {
            "text": "Программа Dr Fill, разработанная американским специалистом Мэтью Гинсбергом (Matthew Ginsberg), согласно информации из издания New Scientist, проявляет более выдающуюся эффективность в решении кроссвордов по сравнению с абсолютным большинством людей.",
            "relation": "(Dr Fill) hasAuthor (Matthew Ginsberg)"
          },
          {
            "text": "Система Kaldi, разработанная британским специалистом по нейросетям Даниэлем Повеем, предоставляет пользователю наиболее широкий выбор алгоритмов для разных задач и удобна в использовании.",
            "relation": "(Kaldi) hasAuthor (Даниэлем Повеем)"
          },
          {
            "text": "Британский специалист по нейросетям Даниэль Пове создал систему Kaldi, которая предоставляет пользователю разнообразные алгоритмы для решения различных задач и отличается удобством в использовании.",
            "relation": "(Kaldi) hasAuthor (Даниэль Пове)"
          },
          {
            "text": "Первой успешной реализацией чат-бота стал виртуальный собеседник ELIZA, написанный в 1966 году Джозефом Вейценбаумом.",
            "relation": "(ELIZA) hasAuthor (Джозефом Вейценбаумом)"
          },
          {
            "text": "В 1968 году Терри Виноградом на языке LISP была разработана программа SHRDLU.",
            "relation": "(SHRDLU) hasAuthor (Терри Виноградом)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(A.L.I.C.E.) hasAuthor (Ричард Уоллес)"
          },
          {
            "text": "В 1966 году Джозефом Вейценбаумом был создан виртуальный собеседник ELIZA, который стал первым успешным примером реализации чат-бота.",
            "relation": "(ELIZA) hasAuthor (Джозефом Вейценбаумом)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 14,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(A.L.I.C.E.) hasAuthor (Richard Wallace)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(A.L.I.C.E.) hasAuthor (Ричардом Уэлсом)"
          },
          {
            "text": "Его мне любезно предоставил разработчик приложения GoTrans, Александр Козлов.",
            "relation": "(GoTrans) hasAuthor (Александр Козлов)"
          },
          {
            "text": "Александр Козлов, разработчик приложения GoTrans, любезно предоставил его мне.",
            "relation": "(GoTrans) hasAuthor (Александр Козлов)"
          },
          {
            "text": "Американский разработчик Мэтью Гинсберг (Matthew Ginsberg) создал программу под названием Dr Fill, которая справляется с кроссвордами гораздо лучше, чем абсолютное большинство людей, пишет New Scientist.",
            "relation": "(Dr Fill) hasAuthor (Matthew Ginsberg)"
          },
          {
            "text": "Американский разработчик Мэтью Гинсберг (Matthew Ginsberg) создал программу под названием Dr Fill, которая справляется с кроссвордами гораздо лучше, чем абсолютное большинство людей, пишет New Scientist.",
            "relation": "(Dr Fill) hasAuthor (Мэтью Гинсберг)"
          },
          {
            "text": "Программа Dr Fill, разработанная американским специалистом Мэтью Гинсбергом (Matthew Ginsberg), согласно информации из издания New Scientist, проявляет более выдающуюся эффективность в решении кроссвордов по сравнению с абсолютным большинством людей.",
            "relation": "(Dr Fill) hasAuthor (Мэтью Гинсбергом)"
          },
          {
            "text": "Программа Dr Fill, разработанная американским специалистом Мэтью Гинсбергом (Matthew Ginsberg), согласно информации из издания New Scientist, проявляет более выдающуюся эффективность в решении кроссвордов по сравнению с абсолютным большинством людей.",
            "relation": "(Dr Fill) hasAuthor (Matthew Ginsberg)"
          },
          {
            "text": "Система Kaldi, разработанная британским специалистом по нейросетям Даниэлем Повеем, предоставляет пользователю наиболее широкий выбор алгоритмов для разных задач и удобна в использовании.",
            "relation": "(Kaldi) hasAuthor (Даниэлем Повеем)"
          },
          {
            "text": "Британский специалист по нейросетям Даниэль Пове создал систему Kaldi, которая предоставляет пользователю разнообразные алгоритмы для решения различных задач и отличается удобством в использовании.",
            "relation": "(Kaldi) hasAuthor (Даниэль Пове)"
          },
          {
            "text": "Первой успешной реализацией чат-бота стал виртуальный собеседник ELIZA, написанный в 1966 году Джозефом Вейценбаумом.",
            "relation": "(ELIZA) hasAuthor (Джозефом Вейценбаумом)"
          },
          {
            "text": "В 1968 году Терри Виноградом на языке LISP была разработана программа SHRDLU.",
            "relation": "(SHRDLU) hasAuthor (Терри Виноградом)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(A.L.I.C.E.) hasAuthor (Ричард Уоллес)"
          },
          {
            "text": "В 1966 году Джозефом Вейценбаумом был создан виртуальный собеседник ELIZA, который стал первым успешным примером реализации чат-бота.",
            "relation": "(ELIZA) hasAuthor (Джозефом Вейценбаумом)"
          }
        ]
      }
    }
  },
  "Object_isUsedInSolving_Task": {
    "predicted": {
      "incorrect": {
        "count": 5,
        "examples": [
          {
            "text": "Их можно использовать в качестве чат-ботов, для поиска информации, модерации онлайн-контента, анализа литературы или для создания совершенно новых фрагментов текста на основе подсказок (чем занимается, например, «Порфирьевич», который способен генерировать весьма забавные короткие рассказы).",
            "relation": "(онлайн-контента) isUsedInSolving (поиска информации)"
          },
          {
            "text": "Изначально на этапе MVP (minimum viable product) мы применяли регулярные выражения для извлечения сущности.",
            "relation": "(MVP) isUsedInSolving (извлечения сущности)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(векторы) isUsedInSolving (классификация)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(векторы) isUsedInSolving (языковое моделирование)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(векторы) isUsedInSolving (определение фальшивых предложений)"
          }
        ]
      },
      "correct": {
        "count": 48,
        "examples": [
          {
            "text": "Проект стартовал в Стэнфорде как инструмент для помощи в разметке датасетов для задачи information extraction, а сейчас разработчики делают платформу для пользования внешними заказчиками.",
            "relation": "(инструмент) isUsedInSolving (разметке датасетов)"
          },
          {
            "text": "Проект стартовал в Стэнфорде как инструмент для помощи в разметке датасетов для задачи information extraction, а сейчас разработчики делают платформу для пользования внешними заказчиками.",
            "relation": "(инструмент) isUsedInSolving (information extraction)"
          },
          {
            "text": "Основная идея данного сервиса состояла в том, что он получает на вход текст написанный определенным человеком и определяет по этому тексту четыре группы характеристик личности.",
            "relation": "(тексту) isUsedInSolving (определяет)"
          },
          {
            "text": "Основная идея данного сервиса состояла в том, что он получает на вход текст написанный определенным человеком и определяет по этому тексту четыре группы характеристик личности.",
            "relation": "(группы характеристик личности) isUsedInSolving (определяет)"
          },
          {
            "text": "Надо сказать, что признаки, формируемые верхними слоями подобных моделей не всегда являются самыми лучшими, точнее даже сказать, как правило, не являются — в классических задачах, таких как поиск именованных сущностей или ответы на вопросы по тексту, признаки верхних уровней работают хуже, чем признаки промежуточных [18].",
            "relation": "(признаки) isUsedInSolving (поиск именованных сущностей)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(текста) isUsedInSolving (извлечения фактов)"
          },
          {
            "text": "В нашем примере будем решать ту же самую задачу разделения твитов на позитивные и негативные на том же самом датасете с использованием модели ULMFit.",
            "relation": "(негативные) isUsedInSolving (разделения твитов)"
          },
          {
            "text": "Вспомним теперь, что для нашей задачи языковая модель нужна для выбора наиболее подходящего следующего слова по уже сгенерированной последовательности.",
            "relation": "(сгенерированной последовательности) isUsedInSolving (выбора наиболее подходящего следующего слова)"
          },
          {
            "text": "Автоматическое определение эмоций в текстовых беседах с использованием нейронных сетей",
            "relation": "(текстовых беседах) isUsedInSolving (Автоматическое определение эмоций)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(текстовых беседах) isUsedInSolving (определения эмоций)"
          },
          {
            "text": "Он помогает исправить орфографию, нормализовать слова, сегментировать, а также определить, какие токены следует отбросить, нормализовать или аннотировать с помощью специальных тегов.",
            "relation": "(токены) isUsedInSolving (сегментировать)"
          },
          {
            "text": "Он помогает исправить орфографию, нормализовать слова, сегментировать, а также определить, какие токены следует отбросить, нормализовать или аннотировать с помощью специальных тегов.",
            "relation": "(токены) isUsedInSolving (исправить орфографию)"
          },
          {
            "text": "Он помогает исправить орфографию, нормализовать слова, сегментировать, а также определить, какие токены следует отбросить, нормализовать или аннотировать с помощью специальных тегов.",
            "relation": "(токены) isUsedInSolving (нормализовать слова)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(валюты) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(сложных выражений) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(эмодзи) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(даты) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(акронимы) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(эмотиконов) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(текстов) isUsedInSolving (выявить в неразмеченных текстах основные тематики)"
          },
          {
            "text": "Я приведу простой пример извлечения данных о погоде с общедоступного API Dark Sky.",
            "relation": "(данных о погоде) isUsedInSolving (извлечения)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(социально-демографическим атрибутам) isUsedInSolving (коррекции)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(перекосов выборок) isUsedInSolving (коррекции)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(онлайн-опросов) isUsedInSolving (корректировки)"
          },
          {
            "text": "Сейчас стандарт коррекции онлайн-выборок находится на стадии обсуждения и разработки и метод Propensity Score Adjustment, который мы рассмотрели, может стать общепринятым способом коррекции онлайн-панелей.",
            "relation": "(онлайн-панелей) isUsedInSolving (коррекции)"
          },
          {
            "text": "В случае многоклассовой классификации число классов должно быть более 2 и может достигать даже многих тысяч.",
            "relation": "(классов) isUsedInSolving (многоклассовой классификации)"
          },
          {
            "text": "Исследователи Массачусетского технологического университета разработали систему искусственного интеллекта, которая способна переписывать устаревшие предложения в статьях «Википедии».",
            "relation": "(статьях) isUsedInSolving (переписывать устаревшие предложения)"
          },
          {
            "text": "«Мы также вели работу над выделением эпентезы (межжестовое движение).",
            "relation": "(межжестовое движение) isUsedInSolving (выделением эпентезы)"
          },
          {
            "text": "Сейчас точность выделения жестов в видеопотоке составляет 85—90%.",
            "relation": "(видеопотоке) isUsedInSolving (выделения жестов)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(слова) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(токены) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(индексы) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(текста) isUsedInSolving (NER)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(текстах) isUsedInSolving (задача выделения симптомов)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(слова) isUsedInSolving (NER)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(слова) isUsedInSolving (задача выделения симптомов)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(текстах) isUsedInSolving (NER)"
          },
          {
            "text": "Эти модели всегда ищут синонимы — даже для устоявшихся словосочетаний.",
            "relation": "(словосочетаний) isUsedInSolving (ищут синонимы)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(эмбеддингов) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(токенов) isUsedInSolving (классификации)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(токенов) isUsedInSolving (извлечения именованных сущностей)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(токенов) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(эмбеддингов) isUsedInSolving (извлечения именованных сущностей)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(эмбеддингов) isUsedInSolving (классификации)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(синтаксических корпусов) isUsedInSolving (унификации разметки)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(трибанков) isUsedInSolving (унификации разметки)"
          },
          {
            "text": "Главной задачей проведенных ранее тестирований был автоматический анализ тональности в целом небольших текстов – отзывов пользователей (о фильмах, книгах, цифровых фотокамерах) или мнений, выраженных в форме прямой или косвенной речи (новости).",
            "relation": "(текстов) isUsedInSolving (автоматический анализ тональности)"
          },
          {
            "text": "В рамках курса вы узнаете: Как латентные переменные применяются в задачах анализа текстов и как строить глубинные генеративные модели с латентными дискретными переменными.",
            "relation": "(латентные переменные) isUsedInSolving (анализа текстов)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 2,
        "examples": [
          {
            "text": "В нашем примере будем решать ту же самую задачу разделения твитов на позитивные и негативные на том же самом датасете с использованием модели ULMFit.",
            "relation": "(позитивные) isUsedInSolving (разделения твитов)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(время) isUsedInSolving (идентифицировать)"
          }
        ]
      },
      "found": {
        "count": 48,
        "examples": [
          {
            "text": "Проект стартовал в Стэнфорде как инструмент для помощи в разметке датасетов для задачи information extraction, а сейчас разработчики делают платформу для пользования внешними заказчиками.",
            "relation": "(инструмент) isUsedInSolving (разметке датасетов)"
          },
          {
            "text": "Проект стартовал в Стэнфорде как инструмент для помощи в разметке датасетов для задачи information extraction, а сейчас разработчики делают платформу для пользования внешними заказчиками.",
            "relation": "(инструмент) isUsedInSolving (information extraction)"
          },
          {
            "text": "Основная идея данного сервиса состояла в том, что он получает на вход текст написанный определенным человеком и определяет по этому тексту четыре группы характеристик личности.",
            "relation": "(тексту) isUsedInSolving (определяет)"
          },
          {
            "text": "Основная идея данного сервиса состояла в том, что он получает на вход текст написанный определенным человеком и определяет по этому тексту четыре группы характеристик личности.",
            "relation": "(группы характеристик личности) isUsedInSolving (определяет)"
          },
          {
            "text": "Надо сказать, что признаки, формируемые верхними слоями подобных моделей не всегда являются самыми лучшими, точнее даже сказать, как правило, не являются — в классических задачах, таких как поиск именованных сущностей или ответы на вопросы по тексту, признаки верхних уровней работают хуже, чем признаки промежуточных [18].",
            "relation": "(признаки) isUsedInSolving (поиск именованных сущностей)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(текста) isUsedInSolving (извлечения фактов)"
          },
          {
            "text": "В нашем примере будем решать ту же самую задачу разделения твитов на позитивные и негативные на том же самом датасете с использованием модели ULMFit.",
            "relation": "(негативные) isUsedInSolving (разделения твитов)"
          },
          {
            "text": "Вспомним теперь, что для нашей задачи языковая модель нужна для выбора наиболее подходящего следующего слова по уже сгенерированной последовательности.",
            "relation": "(сгенерированной последовательности) isUsedInSolving (выбора наиболее подходящего следующего слова)"
          },
          {
            "text": "Автоматическое определение эмоций в текстовых беседах с использованием нейронных сетей",
            "relation": "(текстовых беседах) isUsedInSolving (Автоматическое определение эмоций)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(текстовых беседах) isUsedInSolving (определения эмоций)"
          },
          {
            "text": "Он помогает исправить орфографию, нормализовать слова, сегментировать, а также определить, какие токены следует отбросить, нормализовать или аннотировать с помощью специальных тегов.",
            "relation": "(токены) isUsedInSolving (исправить орфографию)"
          },
          {
            "text": "Он помогает исправить орфографию, нормализовать слова, сегментировать, а также определить, какие токены следует отбросить, нормализовать или аннотировать с помощью специальных тегов.",
            "relation": "(токены) isUsedInSolving (сегментировать)"
          },
          {
            "text": "Он помогает исправить орфографию, нормализовать слова, сегментировать, а также определить, какие токены следует отбросить, нормализовать или аннотировать с помощью специальных тегов.",
            "relation": "(токены) isUsedInSolving (нормализовать слова)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(валюты) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(сложных выражений) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(эмодзи) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(даты) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(эмотиконов) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(акронимы) isUsedInSolving (идентифицировать)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(текстов) isUsedInSolving (выявить в неразмеченных текстах основные тематики)"
          },
          {
            "text": "Я приведу простой пример извлечения данных о погоде с общедоступного API Dark Sky.",
            "relation": "(данных о погоде) isUsedInSolving (извлечения)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(социально-демографическим атрибутам) isUsedInSolving (коррекции)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(перекосов выборок) isUsedInSolving (коррекции)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(онлайн-опросов) isUsedInSolving (корректировки)"
          },
          {
            "text": "Сейчас стандарт коррекции онлайн-выборок находится на стадии обсуждения и разработки и метод Propensity Score Adjustment, который мы рассмотрели, может стать общепринятым способом коррекции онлайн-панелей.",
            "relation": "(онлайн-панелей) isUsedInSolving (коррекции)"
          },
          {
            "text": "В случае многоклассовой классификации число классов должно быть более 2 и может достигать даже многих тысяч.",
            "relation": "(классов) isUsedInSolving (многоклассовой классификации)"
          },
          {
            "text": "Исследователи Массачусетского технологического университета разработали систему искусственного интеллекта, которая способна переписывать устаревшие предложения в статьях «Википедии».",
            "relation": "(статьях) isUsedInSolving (переписывать устаревшие предложения)"
          },
          {
            "text": "«Мы также вели работу над выделением эпентезы (межжестовое движение).",
            "relation": "(межжестовое движение) isUsedInSolving (выделением эпентезы)"
          },
          {
            "text": "Сейчас точность выделения жестов в видеопотоке составляет 85—90%.",
            "relation": "(видеопотоке) isUsedInSolving (выделения жестов)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(слова) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(токены) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(индексы) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(текста) isUsedInSolving (NER)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(текстах) isUsedInSolving (задача выделения симптомов)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(слова) isUsedInSolving (NER)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(слова) isUsedInSolving (задача выделения симптомов)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(текстах) isUsedInSolving (NER)"
          },
          {
            "text": "Эти модели всегда ищут синонимы — даже для устоявшихся словосочетаний.",
            "relation": "(словосочетаний) isUsedInSolving (ищут синонимы)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(эмбеддингов) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(токенов) isUsedInSolving (классификации)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(эмбеддингов) isUsedInSolving (извлечения именованных сущностей)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(токенов) isUsedInSolving (NER)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(эмбеддингов) isUsedInSolving (классификации)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(токенов) isUsedInSolving (извлечения именованных сущностей)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(трибанков) isUsedInSolving (унификации разметки)"
          },
          {
            "text": "Universal Dependencies — это проект по унификации разметки синтаксических корпусов (трибанков) в рамках грамматики зависимостей.",
            "relation": "(синтаксических корпусов) isUsedInSolving (унификации разметки)"
          },
          {
            "text": "Главной задачей проведенных ранее тестирований был автоматический анализ тональности в целом небольших текстов – отзывов пользователей (о фильмах, книгах, цифровых фотокамерах) или мнений, выраженных в форме прямой или косвенной речи (новости).",
            "relation": "(текстов) isUsedInSolving (автоматический анализ тональности)"
          },
          {
            "text": "В рамках курса вы узнаете: Как латентные переменные применяются в задачах анализа текстов и как строить глубинные генеративные модели с латентными дискретными переменными.",
            "relation": "(латентные переменные) isUsedInSolving (анализа текстов)"
          }
        ]
      }
    }
  },
  "Metric_isUsedFor_Model": {
    "predicted": {
      "incorrect": {
        "count": 2,
        "examples": [
          {
            "text": "В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM.",
            "relation": "(точности) isUsedFor (нейросеть)"
          },
          {
            "text": "В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM.",
            "relation": "(точности) isUsedFor (HFM)"
          }
        ]
      },
      "correct": {
        "count": 26,
        "examples": [
          {
            "text": "На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.",
            "relation": "(MAE) isUsedFor (Watson)"
          },
          {
            "text": "На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.",
            "relation": "(коэффициента корреляции) isUsedFor (Watson)"
          },
          {
            "text": "На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.",
            "relation": "(средней абсолютной ошибки) isUsedFor (Watson)"
          },
          {
            "text": "На платформе Personality Insights модели Watson оценивались по двум метрикам — средней абсолютной ошибке (MAE) и коэффициенту корреляции.",
            "relation": "(MAE) isUsedFor (Watson)"
          },
          {
            "text": "На платформе Personality Insights модели Watson оценивались по двум метрикам — средней абсолютной ошибке (MAE) и коэффициенту корреляции.",
            "relation": "(средней абсолютной ошибке) isUsedFor (Watson)"
          },
          {
            "text": "На платформе Personality Insights модели Watson оценивались по двум метрикам — средней абсолютной ошибке (MAE) и коэффициенту корреляции.",
            "relation": "(коэффициенту корреляции) isUsedFor (Watson)"
          },
          {
            "text": "Обучалась модель с функцией ошибки MSE (среднеквадратичное отклонение).",
            "relation": "(среднеквадратичное отклонение) isUsedFor (модель)"
          },
          {
            "text": "Обучалась модель с функцией ошибки MSE (среднеквадратичное отклонение).",
            "relation": "(MSE) isUsedFor (модель)"
          },
          {
            "text": "Согласно метрикам BLEU, M2M-100 на 10 баллов опережает предшественника, где английский язык был промежуточным.",
            "relation": "(BLEU) isUsedFor (M2M-100)"
          },
          {
            "text": "Стэнфордская нейросеть определяет тональность текста с точностью 85%",
            "relation": "(точностью) isUsedFor (Стэнфордская нейросеть)"
          },
          {
            "text": "Нейросеть от Стэнфорда демонстрирует точность в 85% при определении тональности текста.",
            "relation": "(точность) isUsedFor (Нейросеть)"
          },
          {
            "text": "ЗаключениеВ итоге, моделью RuBioRoBERTa в задаче RuMedDaNet мне удалось добиться качества 73.24% на закрытой тестовой части данных (хотя на dev метрика Accuracy вообще была 81.64%).",
            "relation": "(Accuracy) isUsedFor (RuBioRoBERTa)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(MacroAVG F-меру) isUsedFor (FriendBERT)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(MacroAVG F-меру) isUsedFor (ChatBERT)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(точность) isUsedFor (FriendBERT)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(точность) isUsedFor (ChatBERT)"
          },
          {
            "text": "Самая простая и популярная связка – TF-IDF + линейная модель.",
            "relation": "(TF-IDF) isUsedFor (линейная модель)"
          },
          {
            "text": "Теперь нам нужно было использовать некоторые технические способы, чтобы сделать максимально высоким качество модели, которая на новых классах давала точность 72%.",
            "relation": "(точность) isUsedFor (модели)"
          },
          {
            "text": "Протестировав поведение модели на продовских данных, мы обнаружили, что точность извлечения была около 50%.",
            "relation": "(точность) isUsedFor (модели)"
          },
          {
            "text": "Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.",
            "relation": "(Точность) isUsedFor (BERT)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(косинусной близости) isUsedFor (логистическую регрессию)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(точность) isUsedFor (логистическую регрессию)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(accuracy) isUsedFor (логистическую регрессию)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(косинусной близости) isUsedFor (логистической регрессии)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(точность) isUsedFor (логистической регрессии)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(accuracy) isUsedFor (логистической регрессии)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "Для русского языка тоже было создано немало разного рода бенчмарков NLU моделей:RussianSuperGLUE: бенчмарк \"сложных\" NLP задач; фокус на дообучаемых моделях.",
            "relation": "(RussianSuperGLUE) isUsedFor (NLU моделей)"
          }
        ]
      },
      "found": {
        "count": 26,
        "examples": [
          {
            "text": "На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.",
            "relation": "(MAE) isUsedFor (Watson)"
          },
          {
            "text": "На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.",
            "relation": "(коэффициента корреляции) isUsedFor (Watson)"
          },
          {
            "text": "На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.",
            "relation": "(средней абсолютной ошибки) isUsedFor (Watson)"
          },
          {
            "text": "На платформе Personality Insights модели Watson оценивались по двум метрикам — средней абсолютной ошибке (MAE) и коэффициенту корреляции.",
            "relation": "(MAE) isUsedFor (Watson)"
          },
          {
            "text": "На платформе Personality Insights модели Watson оценивались по двум метрикам — средней абсолютной ошибке (MAE) и коэффициенту корреляции.",
            "relation": "(средней абсолютной ошибке) isUsedFor (Watson)"
          },
          {
            "text": "На платформе Personality Insights модели Watson оценивались по двум метрикам — средней абсолютной ошибке (MAE) и коэффициенту корреляции.",
            "relation": "(коэффициенту корреляции) isUsedFor (Watson)"
          },
          {
            "text": "Обучалась модель с функцией ошибки MSE (среднеквадратичное отклонение).",
            "relation": "(среднеквадратичное отклонение) isUsedFor (модель)"
          },
          {
            "text": "Обучалась модель с функцией ошибки MSE (среднеквадратичное отклонение).",
            "relation": "(MSE) isUsedFor (модель)"
          },
          {
            "text": "Согласно метрикам BLEU, M2M-100 на 10 баллов опережает предшественника, где английский язык был промежуточным.",
            "relation": "(BLEU) isUsedFor (M2M-100)"
          },
          {
            "text": "Стэнфордская нейросеть определяет тональность текста с точностью 85%",
            "relation": "(точностью) isUsedFor (Стэнфордская нейросеть)"
          },
          {
            "text": "Нейросеть от Стэнфорда демонстрирует точность в 85% при определении тональности текста.",
            "relation": "(точность) isUsedFor (Нейросеть)"
          },
          {
            "text": "ЗаключениеВ итоге, моделью RuBioRoBERTa в задаче RuMedDaNet мне удалось добиться качества 73.24% на закрытой тестовой части данных (хотя на dev метрика Accuracy вообще была 81.64%).",
            "relation": "(Accuracy) isUsedFor (RuBioRoBERTa)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(MacroAVG F-меру) isUsedFor (FriendBERT)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(MacroAVG F-меру) isUsedFor (ChatBERT)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(точность) isUsedFor (FriendBERT)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(точность) isUsedFor (ChatBERT)"
          },
          {
            "text": "Самая простая и популярная связка – TF-IDF + линейная модель.",
            "relation": "(TF-IDF) isUsedFor (линейная модель)"
          },
          {
            "text": "Теперь нам нужно было использовать некоторые технические способы, чтобы сделать максимально высоким качество модели, которая на новых классах давала точность 72%.",
            "relation": "(точность) isUsedFor (модели)"
          },
          {
            "text": "Протестировав поведение модели на продовских данных, мы обнаружили, что точность извлечения была около 50%.",
            "relation": "(точность) isUsedFor (модели)"
          },
          {
            "text": "Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.",
            "relation": "(Точность) isUsedFor (BERT)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(косинусной близости) isUsedFor (логистическую регрессию)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(точность) isUsedFor (логистическую регрессию)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(accuracy) isUsedFor (логистическую регрессию)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(косинусной близости) isUsedFor (логистической регрессии)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(точность) isUsedFor (логистической регрессии)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(accuracy) isUsedFor (логистической регрессии)"
          }
        ]
      }
    }
  },
  "Method_hasAuthor_Person": {
    "predicted": {
      "incorrect": {
        "count": 8,
        "examples": [
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(разметки) hasAuthor (Ричард Уоллес)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(трансферное обучение) hasAuthor (Sutskever)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(трансферное обучение) hasAuthor (Matthew Peters)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(трансферное обучение) hasAuthor (Quoc Le)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(трансферное обучение) hasAuthor (Sebastian Ruder)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(трансферное обучение) hasAuthor (Vaswani)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(трансферное обучение) hasAuthor (Jeremy Howard)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(статистические алгоритмы) hasAuthor (Антонова)"
          }
        ]
      },
      "correct": {
        "count": 22,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(AIML) hasAuthor (Ричардом Уэлсом)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Artificial Intelligence Markup Language) hasAuthor (Richard Wallace)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(AIML) hasAuthor (Richard Wallace)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Artificial Intelligence Markup Language) hasAuthor (Ричардом Уэлсом)"
          },
          {
            "text": "За более подробной информацией про методы сглаживания N-грамм стоит обратиться к известной книге Кристофера Маннинга “Foundations of Statistical Natural Language Processing”.",
            "relation": "(сглаживания N-грамм) hasAuthor (Кристофера Маннинга)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NEAT) hasAuthor (Ристо Мииккулайненом)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NEAT) hasAuthor (Кеннетом Стенли)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NeuroEvolution of Augmenting Topologies) hasAuthor (Кеннетом Стенли)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NeuroEvolution of Augmenting Topologies) hasAuthor (Ристо Мииккулайненом)"
          },
          {
            "text": "Известный учёный Алан Тьюринг в 1950 году усомнился в том, что машина не может мыслить, и для проверки предложил свой знаменитый тест.",
            "relation": "(тест) hasAuthor (Алан Тьюринг)"
          },
          {
            "text": "В 1950 году Алан Тьюринг в философском журнале Mind предложил такой тест, где судья должен определить, с кем он ведет диалог: с человеком или компьютером.",
            "relation": "(тест) hasAuthor (Алан Тьюринг)"
          },
          {
            "text": "В 1950 году Алан Тьюринг предложил такой тест в философском журнале \"Mind\", в котором судье необходимо определить, ведет ли он диалог с человеком или с компьютером.",
            "relation": "(тест) hasAuthor (Алан Тьюринг)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(Artificial Intelligence Markup Language) hasAuthor (Ричард Уоллес)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(AIML) hasAuthor (Ричард Уоллес)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(Semi-supervised Sequence learning) hasAuthor (Andrew Dai)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(Semi-supervised Sequence learning) hasAuthor (Quoc Le)"
          },
          {
            "text": "Исторически сложилось так, что традиционный подход к сентимент анализу представляет собой задачу классификации текста (части текста) на две-три категории (негативный, позитивный, нейтральный или просто: негативный или позитивный) [Pang & Lee; Turney ].",
            "relation": "(сентимент анализу) hasAuthor (Turney)"
          },
          {
            "text": "Исторически сложилось так, что традиционный подход к сентимент анализу представляет собой задачу классификации текста (части текста) на две-три категории (негативный, позитивный, нейтральный или просто: негативный или позитивный) [Pang & Lee; Turney ].",
            "relation": "(сентимент анализу) hasAuthor (Pang)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(методы, основанные на правилах) hasAuthor (Пазельская)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(CRF) hasAuthor (Антонова)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(методы, основанные на правилах) hasAuthor (Соловьев)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(CRF) hasAuthor (Соловьев)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "Исторически сложилось так, что традиционный подход к сентимент анализу представляет собой задачу классификации текста (части текста) на две-три категории (негативный, позитивный, нейтральный или просто: негативный или позитивный) [Pang & Lee; Turney ].",
            "relation": "(сентимент анализу) hasAuthor (Lee)"
          }
        ]
      },
      "found": {
        "count": 22,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(AIML) hasAuthor (Ричардом Уэлсом)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Artificial Intelligence Markup Language) hasAuthor (Richard Wallace)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(AIML) hasAuthor (Richard Wallace)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Artificial Intelligence Markup Language) hasAuthor (Ричардом Уэлсом)"
          },
          {
            "text": "За более подробной информацией про методы сглаживания N-грамм стоит обратиться к известной книге Кристофера Маннинга “Foundations of Statistical Natural Language Processing”.",
            "relation": "(сглаживания N-грамм) hasAuthor (Кристофера Маннинга)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NeuroEvolution of Augmenting Topologies) hasAuthor (Ристо Мииккулайненом)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NeuroEvolution of Augmenting Topologies) hasAuthor (Кеннетом Стенли)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NEAT) hasAuthor (Кеннетом Стенли)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NEAT) hasAuthor (Ристо Мииккулайненом)"
          },
          {
            "text": "Известный учёный Алан Тьюринг в 1950 году усомнился в том, что машина не может мыслить, и для проверки предложил свой знаменитый тест.",
            "relation": "(тест) hasAuthor (Алан Тьюринг)"
          },
          {
            "text": "В 1950 году Алан Тьюринг в философском журнале Mind предложил такой тест, где судья должен определить, с кем он ведет диалог: с человеком или компьютером.",
            "relation": "(тест) hasAuthor (Алан Тьюринг)"
          },
          {
            "text": "В 1950 году Алан Тьюринг предложил такой тест в философском журнале \"Mind\", в котором судье необходимо определить, ведет ли он диалог с человеком или с компьютером.",
            "relation": "(тест) hasAuthor (Алан Тьюринг)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(Artificial Intelligence Markup Language) hasAuthor (Ричард Уоллес)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(AIML) hasAuthor (Ричард Уоллес)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(Semi-supervised Sequence learning) hasAuthor (Andrew Dai)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(Semi-supervised Sequence learning) hasAuthor (Quoc Le)"
          },
          {
            "text": "Исторически сложилось так, что традиционный подход к сентимент анализу представляет собой задачу классификации текста (части текста) на две-три категории (негативный, позитивный, нейтральный или просто: негативный или позитивный) [Pang & Lee; Turney ].",
            "relation": "(сентимент анализу) hasAuthor (Turney)"
          },
          {
            "text": "Исторически сложилось так, что традиционный подход к сентимент анализу представляет собой задачу классификации текста (части текста) на две-три категории (негативный, позитивный, нейтральный или просто: негативный или позитивный) [Pang & Lee; Turney ].",
            "relation": "(сентимент анализу) hasAuthor (Pang)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(методы, основанные на правилах) hasAuthor (Пазельская)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(CRF) hasAuthor (Соловьев)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(CRF) hasAuthor (Антонова)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(методы, основанные на правилах) hasAuthor (Соловьев)"
          }
        ]
      }
    }
  },
  "Environment_isAlternativeNameFor_Environment": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 0,
        "examples": []
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 0,
        "examples": []
      }
    }
  },
  "Model_isTrainedOn_Dataset": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 12,
        "examples": [
          {
            "text": "Это было сделано путем fine-tune (точной настройки) предварительно обученного трансформера HuggingFace  на собранных данных Genius.",
            "relation": "(трансформера HuggingFace) isTrainedOn (Genius)"
          },
          {
            "text": "При этом fasttext embeddings, обученные на ruscorpora показали себя лучше обученных на araneum.",
            "relation": "(fasttext embeddings) isTrainedOn (ruscorpora)"
          },
          {
            "text": "Примеры обучения LDA часто демонстрируются на \"образцовых\" датасетах, например \"20 newsgroups dataset\", который есть в sklearn.",
            "relation": "(LDA) isTrainedOn (20 newsgroups dataset)"
          },
          {
            "text": "Для обучения модели был использован гигантский датасет mC4, включающий в себя 6,6 млрд веб-страниц на 101 языке.",
            "relation": "(модели) isTrainedOn (mC4)"
          },
          {
            "text": "Проверим этот метод на практике, обучив модель на табличном датасете California Housing, в котором нужно предсказывать цену недвижимости в разных районах Калифорнии, имея 8 исходных признаков.",
            "relation": "(модель) isTrainedOn (California Housing)"
          },
          {
            "text": "Давайте протестируем данную методику, обучив модель на датасете California Housing.",
            "relation": "(модель) isTrainedOn (California Housing)"
          },
          {
            "text": "На этапе обучения text-davinci-003 используются датасеты текстов и программного кода, собранные OpenAI на момент конца 2021 года.",
            "relation": "(text-davinci-003) isTrainedOn (датасеты текстов)"
          },
          {
            "text": "Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.",
            "relation": "(BERT) isTrainedOn (DataTurcks)"
          },
          {
            "text": "В частности, в одном из лучших решений использовался необычный FastText, предобученный на корпусе текстов RuDReC, который содержит отзывы потребителей на русском языке о фармацевтической продукции.",
            "relation": "(FastText) isTrainedOn (RuDReC)"
          },
          {
            "text": "В одном из выдающихся решений применялся особый FastText, предварительно обученный на корпусе текстов RuDReC, включающем отзывы на русском языке о медикаментозной продукции.",
            "relation": "(FastText) isTrainedOn (RuDReC)"
          },
          {
            "text": "В этом случае эмбеддинги fastText, обученные на ruscorpora, продемонстрировали более высокую эффективность по сравнению с теми, которые были обучены на корпусе araneum.",
            "relation": "(fastText) isTrainedOn (ruscorpora)"
          },
          {
            "text": "В процессе обучения модели text-davinci-003 применяются наборы данных текстов и программного кода, собранные OpenAI к концу 2021 года.",
            "relation": "(text-davinci-003) isTrainedOn (наборы данных текстов и программного кода)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 3,
        "examples": [
          {
            "text": "При этом fasttext embeddings, обученные на ruscorpora показали себя лучше обученных на araneum.",
            "relation": "(fasttext embeddings) isTrainedOn (araneum)"
          },
          {
            "text": "А на некоторых заданиях лучших результатов удалось достичь на few-shot, т. е. без дообучения модели (задача RCB и RuCoS, YaLM от Яндекса).",
            "relation": "(YaLM) isTrainedOn (RuCoS)"
          },
          {
            "text": "В этом случае эмбеддинги fastText, обученные на ruscorpora, продемонстрировали более высокую эффективность по сравнению с теми, которые были обучены на корпусе araneum.",
            "relation": "(fastText) isTrainedOn (araneum)"
          }
        ]
      },
      "found": {
        "count": 12,
        "examples": [
          {
            "text": "Это было сделано путем fine-tune (точной настройки) предварительно обученного трансформера HuggingFace  на собранных данных Genius.",
            "relation": "(трансформера HuggingFace) isTrainedOn (Genius)"
          },
          {
            "text": "При этом fasttext embeddings, обученные на ruscorpora показали себя лучше обученных на araneum.",
            "relation": "(fasttext embeddings) isTrainedOn (ruscorpora)"
          },
          {
            "text": "Примеры обучения LDA часто демонстрируются на \"образцовых\" датасетах, например \"20 newsgroups dataset\", который есть в sklearn.",
            "relation": "(LDA) isTrainedOn (20 newsgroups dataset)"
          },
          {
            "text": "Для обучения модели был использован гигантский датасет mC4, включающий в себя 6,6 млрд веб-страниц на 101 языке.",
            "relation": "(модели) isTrainedOn (mC4)"
          },
          {
            "text": "Проверим этот метод на практике, обучив модель на табличном датасете California Housing, в котором нужно предсказывать цену недвижимости в разных районах Калифорнии, имея 8 исходных признаков.",
            "relation": "(модель) isTrainedOn (California Housing)"
          },
          {
            "text": "Давайте протестируем данную методику, обучив модель на датасете California Housing.",
            "relation": "(модель) isTrainedOn (California Housing)"
          },
          {
            "text": "На этапе обучения text-davinci-003 используются датасеты текстов и программного кода, собранные OpenAI на момент конца 2021 года.",
            "relation": "(text-davinci-003) isTrainedOn (датасеты текстов)"
          },
          {
            "text": "Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.",
            "relation": "(BERT) isTrainedOn (DataTurcks)"
          },
          {
            "text": "В частности, в одном из лучших решений использовался необычный FastText, предобученный на корпусе текстов RuDReC, который содержит отзывы потребителей на русском языке о фармацевтической продукции.",
            "relation": "(FastText) isTrainedOn (RuDReC)"
          },
          {
            "text": "В одном из выдающихся решений применялся особый FastText, предварительно обученный на корпусе текстов RuDReC, включающем отзывы на русском языке о медикаментозной продукции.",
            "relation": "(FastText) isTrainedOn (RuDReC)"
          },
          {
            "text": "В этом случае эмбеддинги fastText, обученные на ruscorpora, продемонстрировали более высокую эффективность по сравнению с теми, которые были обучены на корпусе araneum.",
            "relation": "(fastText) isTrainedOn (ruscorpora)"
          },
          {
            "text": "В процессе обучения модели text-davinci-003 применяются наборы данных текстов и программного кода, собранные OpenAI к концу 2021 года.",
            "relation": "(text-davinci-003) isTrainedOn (наборы данных текстов и программного кода)"
          }
        ]
      }
    }
  },
  "Method_isUsedIn_Science": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 25,
        "examples": [
          {
            "text": "Сентиментный анализ, также известный как анализ тональности, представляет собой сферу компьютерной лингвистики, которая занимается изучением эмоций в текстовых документах, применяя методы машинного обучения.",
            "relation": "(методы машинного обучения) isUsedIn (Сентиментный анализ)"
          },
          {
            "text": "Сентиментный анализ, также известный как анализ тональности, представляет собой сферу компьютерной лингвистики, которая занимается изучением эмоций в текстовых документах, применяя методы машинного обучения.",
            "relation": "(методы машинного обучения) isUsedIn (анализ тональности)"
          },
          {
            "text": "Сентиментный анализ, также известный как анализ тональности, представляет собой сферу компьютерной лингвистики, которая занимается изучением эмоций в текстовых документах, применяя методы машинного обучения.",
            "relation": "(методы машинного обучения) isUsedIn (компьютерной лингвистики)"
          },
          {
            "text": "Сентимент-анализ, или анализ тональности, является разделом компьютерной лингвистики, в которой занимаются изучением эмоций в текстах с помощью методов машинного обучения.",
            "relation": "(методов машинного обучения) isUsedIn (анализ тональности)"
          },
          {
            "text": "Сентимент-анализ, или анализ тональности, является разделом компьютерной лингвистики, в которой занимаются изучением эмоций в текстах с помощью методов машинного обучения.",
            "relation": "(методов машинного обучения) isUsedIn (Сентимент-анализ)"
          },
          {
            "text": "Сентимент-анализ, или анализ тональности, является разделом компьютерной лингвистики, в которой занимаются изучением эмоций в текстах с помощью методов машинного обучения.",
            "relation": "(методов машинного обучения) isUsedIn (компьютерной лингвистики)"
          },
          {
            "text": "CNN изначально были разработаны для обработки изображений, однако они успешно справляются с решением задач в сфере автоматической обработки текстов.",
            "relation": "(CNN) isUsedIn (автоматической обработки текстов)"
          },
          {
            "text": "В Graphcore предполагают, что алгоритм упаковки также может применяться в геномике, в моделях фолдинга белков и других моделях с перекошенным распределением длины, оказывая гораздо более широкое влияние на различные отрасли и приложения.",
            "relation": "(алгоритм упаковки) isUsedIn (геномике)"
          },
          {
            "text": "В Graphcore считают, что алгоритм упаковки может быть успешно применен не только в области геномики, но и в моделях фолдинга белков и других моделях с неравномерным распределением длины.",
            "relation": "(алгоритм упаковки) isUsedIn (геномики)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(рекуррентной нейросети) isUsedIn (компьютерной лингвистике)"
          },
          {
            "text": "Специалисты Data Science часто применяют различные методы получения датасетов.",
            "relation": "(методы получения) isUsedIn (Data Science)"
          },
          {
            "text": "Профессионалы в области Data Science часто используют различные подходы к созданию наборов данных.",
            "relation": "(подходы к созданию) isUsedIn (Data Science)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(ансамблей моделей) isUsedIn (обработки естественного языка)"
          },
          {
            "text": "Технологии языкового процессинга востребованы в разработках, связанных с построением искусственного интеллекта: в поисковых системах, для извлечения фактов, оценки тональности текста, машинного перевода и диалога.",
            "relation": "(Технологии языкового процессинга) isUsedIn (машинного перевода)"
          },
          {
            "text": "Технологии обработки естественного языка широко используются в разработках, связанных с созданием искусственного интеллекта, включая применение в поисковых системах и машинном переводе.",
            "relation": "(Технологии обработки естественного языка) isUsedIn (машинном переводе)"
          },
          {
            "text": "NLP — направление искусственного интеллекта, нацеленное на обработку и анализ данных на естественном языке и обучение машин взаимодействию с людьми [1].",
            "relation": "(анализ данных) isUsedIn (искусственного интеллекта)"
          },
          {
            "text": "NLP — направление искусственного интеллекта, нацеленное на обработку и анализ данных на естественном языке и обучение машин взаимодействию с людьми [1].",
            "relation": "(анализ данных) isUsedIn (NLP)"
          },
          {
            "text": "LSTM часто используются в машинном переводе и в задачах генерирования текстов на естественном языке.",
            "relation": "(LSTM) isUsedIn (машинном переводе)"
          },
          {
            "text": "Часто в машинном переводе и задачах генерации текстов на естественном языке применяют LSTM.",
            "relation": "(LSTM) isUsedIn (машинном переводе)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(трансферное обучение) isUsedIn (NLP)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(Semi-supervised Sequence learning) isUsedIn (NLP)"
          },
          {
            "text": "Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).",
            "relation": "(self-attention) isUsedIn (машинном обучении)"
          },
          {
            "text": "Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).",
            "relation": "(самовнимании) isUsedIn (машинном обучении)"
          },
          {
            "text": "Во-вторых, участники использовали базовые подходы для NLP-задач: удаление стоп-слов и знаков пунктуации, приведение к нижнему регистру, стемминг и лемматизация.",
            "relation": "(лемматизация) isUsedIn (NLP)"
          },
          {
            "text": "Во-вторых, участники использовали базовые подходы для NLP-задач: удаление стоп-слов и знаков пунктуации, приведение к нижнему регистру, стемминг и лемматизация.",
            "relation": "(стемминг) isUsedIn (NLP)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 3,
        "examples": [
          {
            "text": "Хотя AI — это достаточно широкая область, включающая в себя машинное зрение, предиктивный анализ, машинный перевод и другие области – понимание естественного языка (NLU) и его генерация (NLG) является значительной и быстрорастущей его частью.",
            "relation": "(предиктивный анализ) isUsedIn (AI)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Artificial Intelligence Markup Language) isUsedIn (машинного обучения)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(AIML) isUsedIn (машинного обучения)"
          }
        ]
      },
      "found": {
        "count": 25,
        "examples": [
          {
            "text": "Сентиментный анализ, также известный как анализ тональности, представляет собой сферу компьютерной лингвистики, которая занимается изучением эмоций в текстовых документах, применяя методы машинного обучения.",
            "relation": "(методы машинного обучения) isUsedIn (Сентиментный анализ)"
          },
          {
            "text": "Сентиментный анализ, также известный как анализ тональности, представляет собой сферу компьютерной лингвистики, которая занимается изучением эмоций в текстовых документах, применяя методы машинного обучения.",
            "relation": "(методы машинного обучения) isUsedIn (анализ тональности)"
          },
          {
            "text": "Сентиментный анализ, также известный как анализ тональности, представляет собой сферу компьютерной лингвистики, которая занимается изучением эмоций в текстовых документах, применяя методы машинного обучения.",
            "relation": "(методы машинного обучения) isUsedIn (компьютерной лингвистики)"
          },
          {
            "text": "Сентимент-анализ, или анализ тональности, является разделом компьютерной лингвистики, в которой занимаются изучением эмоций в текстах с помощью методов машинного обучения.",
            "relation": "(методов машинного обучения) isUsedIn (анализ тональности)"
          },
          {
            "text": "Сентимент-анализ, или анализ тональности, является разделом компьютерной лингвистики, в которой занимаются изучением эмоций в текстах с помощью методов машинного обучения.",
            "relation": "(методов машинного обучения) isUsedIn (Сентимент-анализ)"
          },
          {
            "text": "Сентимент-анализ, или анализ тональности, является разделом компьютерной лингвистики, в которой занимаются изучением эмоций в текстах с помощью методов машинного обучения.",
            "relation": "(методов машинного обучения) isUsedIn (компьютерной лингвистики)"
          },
          {
            "text": "CNN изначально были разработаны для обработки изображений, однако они успешно справляются с решением задач в сфере автоматической обработки текстов.",
            "relation": "(CNN) isUsedIn (автоматической обработки текстов)"
          },
          {
            "text": "В Graphcore предполагают, что алгоритм упаковки также может применяться в геномике, в моделях фолдинга белков и других моделях с перекошенным распределением длины, оказывая гораздо более широкое влияние на различные отрасли и приложения.",
            "relation": "(алгоритм упаковки) isUsedIn (геномике)"
          },
          {
            "text": "В Graphcore считают, что алгоритм упаковки может быть успешно применен не только в области геномики, но и в моделях фолдинга белков и других моделях с неравномерным распределением длины.",
            "relation": "(алгоритм упаковки) isUsedIn (геномики)"
          },
          {
            "text": "В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике.",
            "relation": "(рекуррентной нейросети) isUsedIn (компьютерной лингвистике)"
          },
          {
            "text": "Специалисты Data Science часто применяют различные методы получения датасетов.",
            "relation": "(методы получения) isUsedIn (Data Science)"
          },
          {
            "text": "Профессионалы в области Data Science часто используют различные подходы к созданию наборов данных.",
            "relation": "(подходы к созданию) isUsedIn (Data Science)"
          },
          {
            "text": "«Сбер» рассказал, что модель mGPT может использоваться как просто для генерации текста, так и для решения различных задач в области обработки естественного языка на одном из поддерживаемых языков путем дообучения или в составе ансамблей моделей.",
            "relation": "(ансамблей моделей) isUsedIn (обработки естественного языка)"
          },
          {
            "text": "Технологии языкового процессинга востребованы в разработках, связанных с построением искусственного интеллекта: в поисковых системах, для извлечения фактов, оценки тональности текста, машинного перевода и диалога.",
            "relation": "(Технологии языкового процессинга) isUsedIn (машинного перевода)"
          },
          {
            "text": "Технологии обработки естественного языка широко используются в разработках, связанных с созданием искусственного интеллекта, включая применение в поисковых системах и машинном переводе.",
            "relation": "(Технологии обработки естественного языка) isUsedIn (машинном переводе)"
          },
          {
            "text": "NLP — направление искусственного интеллекта, нацеленное на обработку и анализ данных на естественном языке и обучение машин взаимодействию с людьми [1].",
            "relation": "(анализ данных) isUsedIn (искусственного интеллекта)"
          },
          {
            "text": "NLP — направление искусственного интеллекта, нацеленное на обработку и анализ данных на естественном языке и обучение машин взаимодействию с людьми [1].",
            "relation": "(анализ данных) isUsedIn (NLP)"
          },
          {
            "text": "LSTM часто используются в машинном переводе и в задачах генерирования текстов на естественном языке.",
            "relation": "(LSTM) isUsedIn (машинном переводе)"
          },
          {
            "text": "Часто в машинном переводе и задачах генерации текстов на естественном языке применяют LSTM.",
            "relation": "(LSTM) isUsedIn (машинном переводе)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(трансферное обучение) isUsedIn (NLP)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(Semi-supervised Sequence learning) isUsedIn (NLP)"
          },
          {
            "text": "Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).",
            "relation": "(self-attention) isUsedIn (машинном обучении)"
          },
          {
            "text": "Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).",
            "relation": "(самовнимании) isUsedIn (машинном обучении)"
          },
          {
            "text": "Во-вторых, участники использовали базовые подходы для NLP-задач: удаление стоп-слов и знаков пунктуации, приведение к нижнему регистру, стемминг и лемматизация.",
            "relation": "(лемматизация) isUsedIn (NLP)"
          },
          {
            "text": "Во-вторых, участники использовали базовые подходы для NLP-задач: удаление стоп-слов и знаков пунктуации, приведение к нижнему регистру, стемминг и лемматизация.",
            "relation": "(стемминг) isUsedIn (NLP)"
          }
        ]
      }
    }
  },
  "Application_hasAuthor_Organization": {
    "predicted": {
      "incorrect": {
        "count": 8,
        "examples": [
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Голосовые ассистенты) hasAuthor (Яндекса)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(чат-ботами) hasAuthor (Microsoft)"
          },
          {
            "text": "В обоих случаях они от Texas Instruments, но в Станции Макс используется более свежая и мощная модель TAS5825M.",
            "relation": "(Станции Макс) hasAuthor (Texas Instruments)"
          },
          {
            "text": "Сегодня мы расскажем, как помогли НПО Энергомаш создать корпоративную интеллектуальную информационно-поисковую систему (КИИПС) на базе ABBYY Intelligent Search – такую же удобную и быструю, как популярные поисковики.",
            "relation": "(ABBYY Intelligent Search) hasAuthor (НПО Энергомаш)"
          },
          {
            "text": "GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.",
            "relation": "(NMT) hasAuthor (Google)"
          },
          {
            "text": "6 февраля 2023 года Google представил свой аналог ChatGPT — экспериментальный диалоговый ИИ-сервис под названием Bard.",
            "relation": "(ChatGPT) hasAuthor (Google)"
          },
          {
            "text": "В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения.",
            "relation": "(IDE) hasAuthor (Amazon)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(wit.ai) hasAuthor (Facebook)"
          }
        ]
      },
      "correct": {
        "count": 53,
        "examples": [
          {
            "text": "Google запускает Coral ai – аналог raspberry pi, мини-компьютер для внедрения нейросетей в экспериментальные установки.",
            "relation": "(Coral ai) hasAuthor (Google)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Alexa) hasAuthor (Amazon)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Cortana) hasAuthor (Microsoft)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Google Assistant) hasAuthor (Google)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Алиса) hasAuthor (Яндекса)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Siri) hasAuthor (Apple)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(DeBERTa) hasAuthor (Microsoft)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Bing) hasAuthor (Microsoft)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Dynamics) hasAuthor (Microsoft)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Office) hasAuthor (Microsoft)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Azure Cognitive Services) hasAuthor (Microsoft)"
          },
          {
            "text": "Как отличить хороший ремонт от плохого, или как мы в SRG сделали из Томита-парсера многопоточную Java-библиотеку.",
            "relation": "(Томита-парсера) hasAuthor (SRG)"
          },
          {
            "text": "В этой статье речь пойдет о том, как мы интегрировали разработанный Яндексом Томита-парсер в нашу систему, превратили его в динамическую библиотеку, подружили с Java, сделали многопоточной и решили с её помощью задачу классификации текста для оценки недвижимости.",
            "relation": "(Томита-парсер) hasAuthor (Яндексом)"
          },
          {
            "text": "Созданный в Бременском университете робот PR2 (на фото вверху) учится понимать и выполнять «человеческие» инструкции из базы WikiHow.",
            "relation": "(PR2) hasAuthor (Бременском университете)"
          },
          {
            "text": "При разработке использовали инструмент CommonCrawl, который поддерживает открытый репозиторий данных веб-сканирования, и систему классификации текстов FastText, которую в Facebook представили несколько лет назад.",
            "relation": "(FastText) hasAuthor (Facebook)"
          },
          {
            "text": "Сейчас в Яндексе мой основной проект это Алиса, голосовой помощник, который Яндекс запустил в октябре прошлого года, и моя группа отвечает за то, что можно условно назвать мозгами Алисы.",
            "relation": "(Алиса) hasAuthor (Яндексе)"
          },
          {
            "text": "\"В июне Яндекс открыл доступ к нейросети «Балабоба» для всех пользователей.\"",
            "relation": "(Балабоба) hasAuthor (Яндекс)"
          },
          {
            "text": "Данные предоставлены Microsoft, скачать их можно в официальной группе в LinkedIn.",
            "relation": "(LinkedIn) hasAuthor (Microsoft)"
          },
          {
            "text": "Создателем ORES является Wikimedia Foundation.",
            "relation": "(ORES) hasAuthor (Wikimedia Foundation)"
          },
          {
            "text": "ORES (Objective Revision Evaluation Service) был разработан Wikimedia Foundation.",
            "relation": "(Objective Revision Evaluation Service) hasAuthor (Wikimedia Foundation)"
          },
          {
            "text": "ORES (Objective Revision Evaluation Service) был разработан Wikimedia Foundation.",
            "relation": "(ORES) hasAuthor (Wikimedia Foundation)"
          },
          {
            "text": "Сегодня мы расскажем, как помогли НПО Энергомаш создать корпоративную интеллектуальную информационно-поисковую систему (КИИПС) на базе ABBYY Intelligent Search – такую же удобную и быструю, как популярные поисковики.",
            "relation": "(корпоративную интеллектуальную информационно-поисковую систему) hasAuthor (НПО Энергомаш)"
          },
          {
            "text": "Сегодня мы расскажем, как помогли НПО Энергомаш создать корпоративную интеллектуальную информационно-поисковую систему (КИИПС) на базе ABBYY Intelligent Search – такую же удобную и быструю, как популярные поисковики.",
            "relation": "(КИИПС) hasAuthor (НПО Энергомаш)"
          },
          {
            "text": "Сегодня мы расскажем о том, как мы содействовали НПО \"Энергомаш\" в разработке и внедрении их корпоративной интеллектуальной информационно-поисковой системы (КИИПС).",
            "relation": "(корпоративной интеллектуальной информационно-поисковой системы) hasAuthor (НПО \"Энергомаш\")"
          },
          {
            "text": "Сегодня мы расскажем о том, как мы содействовали НПО \"Энергомаш\" в разработке и внедрении их корпоративной интеллектуальной информационно-поисковой системы (КИИПС).",
            "relation": "(КИИПС) hasAuthor (НПО \"Энергомаш\")"
          },
          {
            "text": "По данным Google Books Ngram Viewer — поискового онлайн-сервиса Google, который строит графики частоты упоминания языковых единиц на основе огромного количества печатных источников, популярность и интерес к NLP стремительно растет последние 20 лет.",
            "relation": "(Google Books Ngram Viewer) hasAuthor (Google)"
          },
          {
            "text": "Наконец, компания Forbes недавно сообщила, что тестирует собственную систему Bertie, которая помогает журналистам с написанием черновых вариантов и шаблонов статей.",
            "relation": "(Bertie) hasAuthor (Forbes)"
          },
          {
            "text": "GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.",
            "relation": "(GNMT) hasAuthor (Google)"
          },
          {
            "text": "GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.",
            "relation": "(Google Translate) hasAuthor (Google)"
          },
          {
            "text": "Google представила систему искусственного интеллекта MusicLM, которая способна генерировать музыку в любом жанре по текстовому описанию.",
            "relation": "(MusicLM) hasAuthor (Google)"
          },
          {
            "text": "Аналогичный описанному выше сервис был запущен Microsoft в прошлом, 2021 году, и получил название Copilot.",
            "relation": "(Copilot) hasAuthor (Microsoft)"
          },
          {
            "text": "Система может быть подключена в виде расширения для сред разработки: Visual Studio Code, Visual Studio, Neovim, набора IDE от JetBrains.",
            "relation": "(IDE) hasAuthor (JetBrains)"
          },
          {
            "text": "6 февраля 2023 года Google представил свой аналог ChatGPT — экспериментальный диалоговый ИИ-сервис под названием Bard.",
            "relation": "(Bard) hasAuthor (Google)"
          },
          {
            "text": "В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения.",
            "relation": "(SageMaker Studio) hasAuthor (Amazon)"
          },
          {
            "text": "Сбер создал и опубликовал в открытом доступе программную библиотеку PyTorch-LifeStream, содержащую несколько алгоритмов построения эмбеддингов событийных данных.",
            "relation": "(PyTorch-LifeStream) hasAuthor (Сбер)"
          },
          {
            "text": "Facebook представила систему распознавания речи wav2vec-U.",
            "relation": "(wav2vec-U) hasAuthor (Facebook)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(Салют) hasAuthor (Сбер)"
          },
          {
            "text": "Заблокированы: большая часть ссылок на открытом портале Open Source от разработчиков «Сбера»; SberDevices.",
            "relation": "(SberDevices) hasAuthor (Сбера)"
          },
          {
            "text": "Мы начали со внутреннего инструмента Яндекса — библиотеки регулярных выражений под названием Remorph.",
            "relation": "(Remorph) hasAuthor (Яндекса)"
          },
          {
            "text": "Мы начали со внутреннего инструмента Яндекса — библиотеки регулярных выражений под названием Remorph.",
            "relation": "(библиотеки регулярных выражений) hasAuthor (Яндекса)"
          },
          {
            "text": "Исследователи Массачусетского технологического университета разработали систему искусственного интеллекта, которая способна переписывать устаревшие предложения в статьях «Википедии».",
            "relation": "(систему искусственного интеллекта) hasAuthor (Массачусетского технологического университета)"
          },
          {
            "text": "Ученые Новосибирского государственного технического университета НЭТИ завершают разработку системы распознавания русского жестового языка.",
            "relation": "(системы распознавания) hasAuthor (Новосибирского государственного технического университета НЭТИ)"
          },
          {
            "text": "В 1954 году Джорджтаунский университет совместно с компанией IBM продемонстрировали программу машинного перевода с русского на английский, которая работала на базе словаря из 250 слов и набора из 6 грамматических правил.",
            "relation": "(программу машинного перевода) hasAuthor (IBM)"
          },
          {
            "text": "В 1954 году Джорджтаунский университет совместно с компанией IBM продемонстрировали программу машинного перевода с русского на английский, которая работала на базе словаря из 250 слов и набора из 6 грамматических правил.",
            "relation": "(программу машинного перевода) hasAuthor (Джорджтаунский университет)"
          },
          {
            "text": "Вчера OpenAI выпустили Whisper.",
            "relation": "(Whisper) hasAuthor (OpenAI)"
          },
          {
            "text": "В список не вошел Syntaxnet — парсер Google.",
            "relation": "(Syntaxnet) hasAuthor (Google)"
          },
          {
            "text": "Анализатор Mystem (разработка яндекса) в определении частей речи достигает лучших результатов, чем UDPipe.",
            "relation": "(Mystem) hasAuthor (яндекса)"
          },
          {
            "text": "Также очень похожая функциональность есть у Microsoft в Streams, но нигде не нашел упоминания про поддержку русского языка, судя по всему, ее тоже нет.",
            "relation": "(Streams) hasAuthor (Microsoft)"
          },
          {
            "text": "Программа, придуманная учеными из Новосибирского академгородка, распознает речь, анализирует смысл и переводит на жестовый язык.",
            "relation": "(Программа) hasAuthor (Новосибирского академгородка)"
          },
          {
            "text": "На сегодняшний день мы поделимся информацией о нашем вкладе в разработку и внедрение корпоративной интеллектуальной информационно-поисковой системы (КИИПС) для НПО \"Энергомаш\".",
            "relation": "(корпоративной интеллектуальной информационно-поисковой системы) hasAuthor (НПО \"Энергомаш\")"
          },
          {
            "text": "На сегодняшний день мы поделимся информацией о нашем вкладе в разработку и внедрение корпоративной интеллектуальной информационно-поисковой системы (КИИПС) для НПО \"Энергомаш\".",
            "relation": "(КИИПС) hasAuthor (НПО \"Энергомаш\")"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(Objective Revision Evaluation Service) hasAuthor (Wikimedia Foundation)"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(ORES) hasAuthor (Wikimedia Foundation)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "Забегая вперед, заметим, что новая версия UDPipe (Future) оказалась еще выше в этом году.",
            "relation": "(UDPipe) hasAuthor (Future)"
          }
        ]
      },
      "found": {
        "count": 53,
        "examples": [
          {
            "text": "Google запускает Coral ai – аналог raspberry pi, мини-компьютер для внедрения нейросетей в экспериментальные установки.",
            "relation": "(Coral ai) hasAuthor (Google)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Cortana) hasAuthor (Microsoft)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Google Assistant) hasAuthor (Google)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Alexa) hasAuthor (Amazon)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Алиса) hasAuthor (Яндекса)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Siri) hasAuthor (Apple)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(DeBERTa) hasAuthor (Microsoft)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Bing) hasAuthor (Microsoft)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Dynamics) hasAuthor (Microsoft)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Office) hasAuthor (Microsoft)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Azure Cognitive Services) hasAuthor (Microsoft)"
          },
          {
            "text": "Как отличить хороший ремонт от плохого, или как мы в SRG сделали из Томита-парсера многопоточную Java-библиотеку.",
            "relation": "(Томита-парсера) hasAuthor (SRG)"
          },
          {
            "text": "В этой статье речь пойдет о том, как мы интегрировали разработанный Яндексом Томита-парсер в нашу систему, превратили его в динамическую библиотеку, подружили с Java, сделали многопоточной и решили с её помощью задачу классификации текста для оценки недвижимости.",
            "relation": "(Томита-парсер) hasAuthor (Яндексом)"
          },
          {
            "text": "Созданный в Бременском университете робот PR2 (на фото вверху) учится понимать и выполнять «человеческие» инструкции из базы WikiHow.",
            "relation": "(PR2) hasAuthor (Бременском университете)"
          },
          {
            "text": "При разработке использовали инструмент CommonCrawl, который поддерживает открытый репозиторий данных веб-сканирования, и систему классификации текстов FastText, которую в Facebook представили несколько лет назад.",
            "relation": "(FastText) hasAuthor (Facebook)"
          },
          {
            "text": "Сейчас в Яндексе мой основной проект это Алиса, голосовой помощник, который Яндекс запустил в октябре прошлого года, и моя группа отвечает за то, что можно условно назвать мозгами Алисы.",
            "relation": "(Алиса) hasAuthor (Яндексе)"
          },
          {
            "text": "\"В июне Яндекс открыл доступ к нейросети «Балабоба» для всех пользователей.\"",
            "relation": "(Балабоба) hasAuthor (Яндекс)"
          },
          {
            "text": "Данные предоставлены Microsoft, скачать их можно в официальной группе в LinkedIn.",
            "relation": "(LinkedIn) hasAuthor (Microsoft)"
          },
          {
            "text": "Создателем ORES является Wikimedia Foundation.",
            "relation": "(ORES) hasAuthor (Wikimedia Foundation)"
          },
          {
            "text": "ORES (Objective Revision Evaluation Service) был разработан Wikimedia Foundation.",
            "relation": "(Objective Revision Evaluation Service) hasAuthor (Wikimedia Foundation)"
          },
          {
            "text": "ORES (Objective Revision Evaluation Service) был разработан Wikimedia Foundation.",
            "relation": "(ORES) hasAuthor (Wikimedia Foundation)"
          },
          {
            "text": "Сегодня мы расскажем, как помогли НПО Энергомаш создать корпоративную интеллектуальную информационно-поисковую систему (КИИПС) на базе ABBYY Intelligent Search – такую же удобную и быструю, как популярные поисковики.",
            "relation": "(корпоративную интеллектуальную информационно-поисковую систему) hasAuthor (НПО Энергомаш)"
          },
          {
            "text": "Сегодня мы расскажем, как помогли НПО Энергомаш создать корпоративную интеллектуальную информационно-поисковую систему (КИИПС) на базе ABBYY Intelligent Search – такую же удобную и быструю, как популярные поисковики.",
            "relation": "(КИИПС) hasAuthor (НПО Энергомаш)"
          },
          {
            "text": "Сегодня мы расскажем о том, как мы содействовали НПО \"Энергомаш\" в разработке и внедрении их корпоративной интеллектуальной информационно-поисковой системы (КИИПС).",
            "relation": "(корпоративной интеллектуальной информационно-поисковой системы) hasAuthor (НПО \"Энергомаш\")"
          },
          {
            "text": "Сегодня мы расскажем о том, как мы содействовали НПО \"Энергомаш\" в разработке и внедрении их корпоративной интеллектуальной информационно-поисковой системы (КИИПС).",
            "relation": "(КИИПС) hasAuthor (НПО \"Энергомаш\")"
          },
          {
            "text": "По данным Google Books Ngram Viewer — поискового онлайн-сервиса Google, который строит графики частоты упоминания языковых единиц на основе огромного количества печатных источников, популярность и интерес к NLP стремительно растет последние 20 лет.",
            "relation": "(Google Books Ngram Viewer) hasAuthor (Google)"
          },
          {
            "text": "Наконец, компания Forbes недавно сообщила, что тестирует собственную систему Bertie, которая помогает журналистам с написанием черновых вариантов и шаблонов статей.",
            "relation": "(Bertie) hasAuthor (Forbes)"
          },
          {
            "text": "GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.",
            "relation": "(GNMT) hasAuthor (Google)"
          },
          {
            "text": "GNMT есть система нейронного машинного перевода (NMT) компании Google, которая использует нейросеть (ANN) для повышения точности и скорости перевода, и в частности для создания лучших, более естественных вариантов перевода текста в Google Translate.",
            "relation": "(Google Translate) hasAuthor (Google)"
          },
          {
            "text": "Google представила систему искусственного интеллекта MusicLM, которая способна генерировать музыку в любом жанре по текстовому описанию.",
            "relation": "(MusicLM) hasAuthor (Google)"
          },
          {
            "text": "Аналогичный описанному выше сервис был запущен Microsoft в прошлом, 2021 году, и получил название Copilot.",
            "relation": "(Copilot) hasAuthor (Microsoft)"
          },
          {
            "text": "Система может быть подключена в виде расширения для сред разработки: Visual Studio Code, Visual Studio, Neovim, набора IDE от JetBrains.",
            "relation": "(IDE) hasAuthor (JetBrains)"
          },
          {
            "text": "6 февраля 2023 года Google представил свой аналог ChatGPT — экспериментальный диалоговый ИИ-сервис под названием Bard.",
            "relation": "(Bard) hasAuthor (Google)"
          },
          {
            "text": "В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения.",
            "relation": "(SageMaker Studio) hasAuthor (Amazon)"
          },
          {
            "text": "Сбер создал и опубликовал в открытом доступе программную библиотеку PyTorch-LifeStream, содержащую несколько алгоритмов построения эмбеддингов событийных данных.",
            "relation": "(PyTorch-LifeStream) hasAuthor (Сбер)"
          },
          {
            "text": "Facebook представила систему распознавания речи wav2vec-U.",
            "relation": "(wav2vec-U) hasAuthor (Facebook)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(Салют) hasAuthor (Сбер)"
          },
          {
            "text": "Заблокированы: большая часть ссылок на открытом портале Open Source от разработчиков «Сбера»; SberDevices.",
            "relation": "(SberDevices) hasAuthor (Сбера)"
          },
          {
            "text": "Мы начали со внутреннего инструмента Яндекса — библиотеки регулярных выражений под названием Remorph.",
            "relation": "(Remorph) hasAuthor (Яндекса)"
          },
          {
            "text": "Мы начали со внутреннего инструмента Яндекса — библиотеки регулярных выражений под названием Remorph.",
            "relation": "(библиотеки регулярных выражений) hasAuthor (Яндекса)"
          },
          {
            "text": "Исследователи Массачусетского технологического университета разработали систему искусственного интеллекта, которая способна переписывать устаревшие предложения в статьях «Википедии».",
            "relation": "(систему искусственного интеллекта) hasAuthor (Массачусетского технологического университета)"
          },
          {
            "text": "Ученые Новосибирского государственного технического университета НЭТИ завершают разработку системы распознавания русского жестового языка.",
            "relation": "(системы распознавания) hasAuthor (Новосибирского государственного технического университета НЭТИ)"
          },
          {
            "text": "В 1954 году Джорджтаунский университет совместно с компанией IBM продемонстрировали программу машинного перевода с русского на английский, которая работала на базе словаря из 250 слов и набора из 6 грамматических правил.",
            "relation": "(программу машинного перевода) hasAuthor (IBM)"
          },
          {
            "text": "В 1954 году Джорджтаунский университет совместно с компанией IBM продемонстрировали программу машинного перевода с русского на английский, которая работала на базе словаря из 250 слов и набора из 6 грамматических правил.",
            "relation": "(программу машинного перевода) hasAuthor (Джорджтаунский университет)"
          },
          {
            "text": "Вчера OpenAI выпустили Whisper.",
            "relation": "(Whisper) hasAuthor (OpenAI)"
          },
          {
            "text": "В список не вошел Syntaxnet — парсер Google.",
            "relation": "(Syntaxnet) hasAuthor (Google)"
          },
          {
            "text": "Анализатор Mystem (разработка яндекса) в определении частей речи достигает лучших результатов, чем UDPipe.",
            "relation": "(Mystem) hasAuthor (яндекса)"
          },
          {
            "text": "Также очень похожая функциональность есть у Microsoft в Streams, но нигде не нашел упоминания про поддержку русского языка, судя по всему, ее тоже нет.",
            "relation": "(Streams) hasAuthor (Microsoft)"
          },
          {
            "text": "Программа, придуманная учеными из Новосибирского академгородка, распознает речь, анализирует смысл и переводит на жестовый язык.",
            "relation": "(Программа) hasAuthor (Новосибирского академгородка)"
          },
          {
            "text": "На сегодняшний день мы поделимся информацией о нашем вкладе в разработку и внедрение корпоративной интеллектуальной информационно-поисковой системы (КИИПС) для НПО \"Энергомаш\".",
            "relation": "(корпоративной интеллектуальной информационно-поисковой системы) hasAuthor (НПО \"Энергомаш\")"
          },
          {
            "text": "На сегодняшний день мы поделимся информацией о нашем вкладе в разработку и внедрение корпоративной интеллектуальной информационно-поисковой системы (КИИПС) для НПО \"Энергомаш\".",
            "relation": "(КИИПС) hasAuthor (НПО \"Энергомаш\")"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(Objective Revision Evaluation Service) hasAuthor (Wikimedia Foundation)"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(ORES) hasAuthor (Wikimedia Foundation)"
          }
        ]
      }
    }
  },
  "Library_hasAuthor_Person": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 6,
        "examples": [
          {
            "text": "По сути эта часть библиотеки — порт замечательного морфологического анализатора pymorphy2 за авторством kmike (на Хабре была пара статей об этой библиотеке).",
            "relation": "(pymorphy2) hasAuthor (kmike)"
          },
          {
            "text": "Эта часть библиотеки по сути является переносом выдающегося морфологического анализатора pymorphy2, созданного kmike (о котором было написано несколько статей на Хабре).",
            "relation": "(pymorphy2) hasAuthor (kmike)"
          },
          {
            "text": "Выбор пал на C++ библиотеку marisa-trie, которую написал гуру структур данных Susumu Yata.",
            "relation": "(marisa-trie) hasAuthor (Susumu Yata)"
          },
          {
            "text": "Было решено использовать библиотеку marisa-trie на C++, созданную экспертом в области структур данных Сусуму Ята.",
            "relation": "(marisa-trie) hasAuthor (Сусуму Ята)"
          },
          {
            "text": "Та статья была написана совместно с Ильей Гусевым, у которого есть библиотека для анализа и генерации стихов на русском языке и поэтический корпус русского языка.",
            "relation": "(библиотека для анализа и генерации стихов) hasAuthor (Ильей Гусевым)"
          },
          {
            "text": "Этот материал был создан совместно с Ильей Гусевым, у которого имеется библиотека для анализа и генерации стихов на русском языке, а также поэтический корпус русского языка.",
            "relation": "(библиотека для анализа и генерации стихов) hasAuthor (Ильей Гусевым)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 6,
        "examples": [
          {
            "text": "По сути эта часть библиотеки — порт замечательного морфологического анализатора pymorphy2 за авторством kmike (на Хабре была пара статей об этой библиотеке).",
            "relation": "(pymorphy2) hasAuthor (kmike)"
          },
          {
            "text": "Эта часть библиотеки по сути является переносом выдающегося морфологического анализатора pymorphy2, созданного kmike (о котором было написано несколько статей на Хабре).",
            "relation": "(pymorphy2) hasAuthor (kmike)"
          },
          {
            "text": "Выбор пал на C++ библиотеку marisa-trie, которую написал гуру структур данных Susumu Yata.",
            "relation": "(marisa-trie) hasAuthor (Susumu Yata)"
          },
          {
            "text": "Было решено использовать библиотеку marisa-trie на C++, созданную экспертом в области структур данных Сусуму Ята.",
            "relation": "(marisa-trie) hasAuthor (Сусуму Ята)"
          },
          {
            "text": "Та статья была написана совместно с Ильей Гусевым, у которого есть библиотека для анализа и генерации стихов на русском языке и поэтический корпус русского языка.",
            "relation": "(библиотека для анализа и генерации стихов) hasAuthor (Ильей Гусевым)"
          },
          {
            "text": "Этот материал был создан совместно с Ильей Гусевым, у которого имеется библиотека для анализа и генерации стихов на русском языке, а также поэтический корпус русского языка.",
            "relation": "(библиотека для анализа и генерации стихов) hasAuthor (Ильей Гусевым)"
          }
        ]
      }
    }
  },
  "Method_isUsedIn_Library": {
    "predicted": {
      "incorrect": {
        "count": 2,
        "examples": [
          {
            "text": "Google Meet поделились кейсом создания своего алгоритма для качественного удаления фона на основе фреймворка от Mediapipe (который умеет отслеживание движение глаз, головы и рук).",
            "relation": "(алгоритма для качественного удаления) isUsedIn (фреймворка)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(точная настройка) isUsedIn (HuggingFace)"
          }
        ]
      },
      "correct": {
        "count": 9,
        "examples": [
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(контекстно-свободных грамматик) isUsedIn (Yagry)"
          },
          {
            "text": "На данный момент библиотека умеет две вещи: токенизацию и анализ морфологии.",
            "relation": "(токенизацию) isUsedIn (библиотека)"
          },
          {
            "text": "На данный момент библиотека умеет две вещи: токенизацию и анализ морфологии.",
            "relation": "(анализ морфологии) isUsedIn (библиотека)"
          },
          {
            "text": "В настоящее время библиотека обладает двумя функциональностями: выполнением токенизации и проведением анализа морфологии.",
            "relation": "(токенизации) isUsedIn (библиотека)"
          },
          {
            "text": "В настоящее время библиотека обладает двумя функциональностями: выполнением токенизации и проведением анализа морфологии.",
            "relation": "(анализа морфологии) isUsedIn (библиотека)"
          },
          {
            "text": "SDV генерирует данные, применяя математические методы и модели машинного обучения.",
            "relation": "(математические методы) isUsedIn (SDV)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(математических методов) isUsedIn (SDV)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(математических методов) isUsedIn (Synthetic Data Vault)"
          },
          {
            "text": "Воспользуемся функцией evaluate из SDV.",
            "relation": "(evaluate) isUsedIn (SDV)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 9,
        "examples": [
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(контекстно-свободных грамматик) isUsedIn (Yagry)"
          },
          {
            "text": "На данный момент библиотека умеет две вещи: токенизацию и анализ морфологии.",
            "relation": "(токенизацию) isUsedIn (библиотека)"
          },
          {
            "text": "На данный момент библиотека умеет две вещи: токенизацию и анализ морфологии.",
            "relation": "(анализ морфологии) isUsedIn (библиотека)"
          },
          {
            "text": "В настоящее время библиотека обладает двумя функциональностями: выполнением токенизации и проведением анализа морфологии.",
            "relation": "(токенизации) isUsedIn (библиотека)"
          },
          {
            "text": "В настоящее время библиотека обладает двумя функциональностями: выполнением токенизации и проведением анализа морфологии.",
            "relation": "(анализа морфологии) isUsedIn (библиотека)"
          },
          {
            "text": "SDV генерирует данные, применяя математические методы и модели машинного обучения.",
            "relation": "(математические методы) isUsedIn (SDV)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(математических методов) isUsedIn (SDV)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(математических методов) isUsedIn (Synthetic Data Vault)"
          },
          {
            "text": "Воспользуемся функцией evaluate из SDV.",
            "relation": "(evaluate) isUsedIn (SDV)"
          }
        ]
      }
    }
  },
  "Application_isAppliedTo_Object": {
    "predicted": {
      "incorrect": {
        "count": 5,
        "examples": [
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Голосовые ассистенты) isAppliedTo (интенты)"
          },
          {
            "text": "Я приведу простой пример извлечения данных о погоде с общедоступного API Dark Sky.",
            "relation": "(API Dark Sky) isAppliedTo (данных о погоде)"
          },
          {
            "text": "Их можно использовать в качестве чат-ботов, для поиска информации, модерации онлайн-контента, анализа литературы или для создания совершенно новых фрагментов текста на основе подсказок (чем занимается, например, «Порфирьевич», который способен генерировать весьма забавные короткие рассказы).",
            "relation": "(Порфирьевич) isAppliedTo (литературы)"
          },
          {
            "text": "Их можно использовать в качестве чат-ботов, для поиска информации, модерации онлайн-контента, анализа литературы или для создания совершенно новых фрагментов текста на основе подсказок (чем занимается, например, «Порфирьевич», который способен генерировать весьма забавные короткие рассказы).",
            "relation": "(Порфирьевич) isAppliedTo (новых фрагментов текста)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(IBM AlchemyAPI) isAppliedTo (графы связей)"
          }
        ]
      },
      "correct": {
        "count": 33,
        "examples": [
          {
            "text": "Некоторое время назад к нам обратился заказчик с не совсем обычной задачей — воспроизвести сервис IBM Watson Personality Insights, который анализировал текст, написанный человеком и определял по нему ряд личностных характеристик.",
            "relation": "(IBM Watson Personality Insights) isAppliedTo (личностных характеристик)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Alexa) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Siri) isAppliedTo (интенты)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Cortana) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Google Assistant) isAppliedTo (интенты)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Алиса) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Alexa) isAppliedTo (интенты)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Cortana) isAppliedTo (интенты)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Siri) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Google Assistant) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Алиса) isAppliedTo (интенты)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(Томита-парсер) isAppliedTo (текста)"
          },
          {
            "text": "HuggingArtists | Генерируем текст песен с трансформером за 5 минут",
            "relation": "(HuggingArtists) isAppliedTo (текст песен)"
          },
          {
            "text": "В этой статье я покажу, как мы использовали для этих целей внутреннюю разработку компании – фреймворк LightAutoML, в котором имеется всё для решения поставленной задачи – предобученные готовые векторные представления слов FastText и готовые текстовые пресеты, в которых необходимо только указать гиперпараметры.",
            "relation": "(LightAutoML) isAppliedTo (предобученные готовые векторные представления слов)"
          },
          {
            "text": "Американский разработчик Мэтью Гинсберг (Matthew Ginsberg) создал программу под названием Dr Fill, которая справляется с кроссвордами гораздо лучше, чем абсолютное большинство людей, пишет New Scientist.",
            "relation": "(Dr Fill) isAppliedTo (кроссвордами)"
          },
          {
            "text": "Программа Dr Fill, разработанная американским специалистом Мэтью Гинсбергом (Matthew Ginsberg), согласно информации из издания New Scientist, проявляет более выдающуюся эффективность в решении кроссвордов по сравнению с абсолютным большинством людей.",
            "relation": "(Dr Fill) isAppliedTo (кроссвордов)"
          },
          {
            "text": "Созданный в Бременском университете робот PR2 (на фото вверху) учится понимать и выполнять «человеческие» инструкции из базы WikiHow.",
            "relation": "(PR2) isAppliedTo (инструкции)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (сложных выражений)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (акронимы)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (эмотиконов)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (эмодзи)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (даты)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (валюты)"
          },
          {
            "text": "Система разбивает запись на речевые единицы, которые приблизительно соответствуют отдельным звукам.",
            "relation": "(Система) isAppliedTo (речевые единицы)"
          },
          {
            "text": "В 1990-е годы эта область получила очень мощный толчок благодаря развитию Всемирной паутины с большим количеством слабоструктурированного текста, по которому нужно было искать, его требовалось каталогизировать.",
            "relation": "(Всемирной паутины) isAppliedTo (слабоструктурированного текста)"
          },
          {
            "text": "Исследователи Массачусетского технологического университета разработали систему искусственного интеллекта, которая способна переписывать устаревшие предложения в статьях «Википедии».",
            "relation": "(систему искусственного интеллекта) isAppliedTo (статьях)"
          },
          {
            "text": "Ученые Новосибирского государственного технического университета НЭТИ завершают разработку системы распознавания русского жестового языка.",
            "relation": "(системы распознавания) isAppliedTo (русского жестового языка)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isAppliedTo (графы связей)"
          },
          {
            "text": "Многие знают, что Mystem не полностью понимает морфологическую омонимию.",
            "relation": "(Mystem) isAppliedTo (морфологическую омонимию)"
          },
          {
            "text": "В архитектуре стенфордского парсера и Syntaxnet заложена другая концепия: сначала они генерируют полный ориентированный граф, и дальше работа алгоритма состоит в том, чтобы оставить тот скелет (минимальное остовное дерево), который будет наиболее вероятным.",
            "relation": "(Syntaxnet) isAppliedTo (ориентированный граф)"
          },
          {
            "text": "В архитектуре стенфордского парсера и Syntaxnet заложена другая концепия: сначала они генерируют полный ориентированный граф, и дальше работа алгоритма состоит в том, чтобы оставить тот скелет (минимальное остовное дерево), который будет наиболее вероятным.",
            "relation": "(Syntaxnet) isAppliedTo (минимальное остовное дерево)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) распознают намерения пользователей и выполняют указания.",
            "relation": "(Голосовые ассистенты) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые виртуальные помощники (ГВП, ИВА) распознают намерения пользователей и выполняют указания.",
            "relation": "(Голосовые виртуальные помощники) isAppliedTo (намерения)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 2,
        "examples": [
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (время)"
          },
          {
            "text": "Программа, придуманная учеными из Новосибирского академгородка, распознает речь, анализирует смысл и переводит на жестовый язык.",
            "relation": "(Программа) isAppliedTo (жестовый язык)"
          }
        ]
      },
      "found": {
        "count": 33,
        "examples": [
          {
            "text": "Некоторое время назад к нам обратился заказчик с не совсем обычной задачей — воспроизвести сервис IBM Watson Personality Insights, который анализировал текст, написанный человеком и определял по нему ряд личностных характеристик.",
            "relation": "(IBM Watson Personality Insights) isAppliedTo (личностных характеристик)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Cortana) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Siri) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Google Assistant) isAppliedTo (интенты)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Alexa) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Google Assistant) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Alexa) isAppliedTo (интенты)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Алиса) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Алиса) isAppliedTo (интенты)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Cortana) isAppliedTo (интенты)"
          },
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(Siri) isAppliedTo (интенты)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(Томита-парсер) isAppliedTo (текста)"
          },
          {
            "text": "HuggingArtists | Генерируем текст песен с трансформером за 5 минут",
            "relation": "(HuggingArtists) isAppliedTo (текст песен)"
          },
          {
            "text": "В этой статье я покажу, как мы использовали для этих целей внутреннюю разработку компании – фреймворк LightAutoML, в котором имеется всё для решения поставленной задачи – предобученные готовые векторные представления слов FastText и готовые текстовые пресеты, в которых необходимо только указать гиперпараметры.",
            "relation": "(LightAutoML) isAppliedTo (предобученные готовые векторные представления слов)"
          },
          {
            "text": "Американский разработчик Мэтью Гинсберг (Matthew Ginsberg) создал программу под названием Dr Fill, которая справляется с кроссвордами гораздо лучше, чем абсолютное большинство людей, пишет New Scientist.",
            "relation": "(Dr Fill) isAppliedTo (кроссвордами)"
          },
          {
            "text": "Программа Dr Fill, разработанная американским специалистом Мэтью Гинсбергом (Matthew Ginsberg), согласно информации из издания New Scientist, проявляет более выдающуюся эффективность в решении кроссвордов по сравнению с абсолютным большинством людей.",
            "relation": "(Dr Fill) isAppliedTo (кроссвордов)"
          },
          {
            "text": "Созданный в Бременском университете робот PR2 (на фото вверху) учится понимать и выполнять «человеческие» инструкции из базы WikiHow.",
            "relation": "(PR2) isAppliedTo (инструкции)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (сложных выражений)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (акронимы)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (эмотиконов)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (эмодзи)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (даты)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isAppliedTo (валюты)"
          },
          {
            "text": "Система разбивает запись на речевые единицы, которые приблизительно соответствуют отдельным звукам.",
            "relation": "(Система) isAppliedTo (речевые единицы)"
          },
          {
            "text": "В 1990-е годы эта область получила очень мощный толчок благодаря развитию Всемирной паутины с большим количеством слабоструктурированного текста, по которому нужно было искать, его требовалось каталогизировать.",
            "relation": "(Всемирной паутины) isAppliedTo (слабоструктурированного текста)"
          },
          {
            "text": "Исследователи Массачусетского технологического университета разработали систему искусственного интеллекта, которая способна переписывать устаревшие предложения в статьях «Википедии».",
            "relation": "(систему искусственного интеллекта) isAppliedTo (статьях)"
          },
          {
            "text": "Ученые Новосибирского государственного технического университета НЭТИ завершают разработку системы распознавания русского жестового языка.",
            "relation": "(системы распознавания) isAppliedTo (русского жестового языка)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isAppliedTo (графы связей)"
          },
          {
            "text": "Многие знают, что Mystem не полностью понимает морфологическую омонимию.",
            "relation": "(Mystem) isAppliedTo (морфологическую омонимию)"
          },
          {
            "text": "В архитектуре стенфордского парсера и Syntaxnet заложена другая концепия: сначала они генерируют полный ориентированный граф, и дальше работа алгоритма состоит в том, чтобы оставить тот скелет (минимальное остовное дерево), который будет наиболее вероятным.",
            "relation": "(Syntaxnet) isAppliedTo (ориентированный граф)"
          },
          {
            "text": "В архитектуре стенфордского парсера и Syntaxnet заложена другая концепия: сначала они генерируют полный ориентированный граф, и дальше работа алгоритма состоит в том, чтобы оставить тот скелет (минимальное остовное дерево), который будет наиболее вероятным.",
            "relation": "(Syntaxnet) isAppliedTo (минимальное остовное дерево)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) распознают намерения пользователей и выполняют указания.",
            "relation": "(Голосовые ассистенты) isAppliedTo (намерения)"
          },
          {
            "text": "Голосовые виртуальные помощники (ГВП, ИВА) распознают намерения пользователей и выполняют указания.",
            "relation": "(Голосовые виртуальные помощники) isAppliedTo (намерения)"
          }
        ]
      }
    }
  },
  "Method_isAlternativeNameFor_Method": {
    "predicted": {
      "incorrect": {
        "count": 22,
        "examples": [
          {
            "text": "В разметочные функции (labeling functions) закодированы все возможные правила, по которым можно поставить какую-либо метку каждому примеру из набора данных.",
            "relation": "(разметочные функции) isAlternativeNameFor (правила)"
          },
          {
            "text": "В разметочные функции (labeling functions) закодированы все возможные правила, по которым можно поставить какую-либо метку каждому примеру из набора данных.",
            "relation": "(labeling functions) isAlternativeNameFor (правила)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(подход обучения без учителя) isAlternativeNameFor (тематическим моделированием)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(подход обучения без учителя) isAlternativeNameFor (topic modeling)"
          },
          {
            "text": "Если отказываемся от методов unsupervised learning, то логично обратиться к методам обучения с учителем (supervised learning) и в частности к классификации.",
            "relation": "(методам обучения с учителем) isAlternativeNameFor (supervised learning)"
          },
          {
            "text": "Если отказываемся от методов unsupervised learning, то логично обратиться к методам обучения с учителем (supervised learning) и в частности к классификации.",
            "relation": "(методам обучения с учителем) isAlternativeNameFor (классификации)"
          },
          {
            "text": "Если отказываемся от методов unsupervised learning, то логично обратиться к методам обучения с учителем (supervised learning) и в частности к классификации.",
            "relation": "(supervised learning) isAlternativeNameFor (классификации)"
          },
          {
            "text": "Современный подход — анализ семантики без учителя, поэтому его называют анализом скрытой (латентной) семантики.",
            "relation": "(анализ семантики без учителя) isAlternativeNameFor (анализом скрытой (латентной) семантики)"
          },
          {
            "text": "Исторически первый подход к латентно-семантическому анализу — это латентно-семантическое индексирование.",
            "relation": "(латентно-семантическому анализу) isAlternativeNameFor (латентно-семантическое индексирование)"
          },
          {
            "text": "По сравнению с классической факторизацией на основе сингулярного разложения у вероятностной генерирующей модели есть важное преимущество.",
            "relation": "(классической факторизацией) isAlternativeNameFor (сингулярного разложения)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(рекуррентными нейронными сетями) isAlternativeNameFor (сети с долгой краткосрочной памятью)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(рекуррентными нейронными сетями) isAlternativeNameFor (LSTM)"
          },
          {
            "text": "Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(рекуррентных нейронных сетей) isAlternativeNameFor (сети с долгой краткосрочной памятью)"
          },
          {
            "text": "Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(рекуррентных нейронных сетей) isAlternativeNameFor (LSTM)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LSA) isAlternativeNameFor (латентное размещение Дирихле)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(алгоритмы семантической близости) isAlternativeNameFor (латентно-семантический анализ)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LSA) isAlternativeNameFor (LDA)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(алгоритмы семантической близости) isAlternativeNameFor (LDA)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(алгоритмы семантической близости) isAlternativeNameFor (латентное размещение Дирихле)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(латентно-семантический анализ) isAlternativeNameFor (LDA)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(латентно-семантический анализ) isAlternativeNameFor (латентное размещение Дирихле)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(алгоритмы семантической близости) isAlternativeNameFor (LSA)"
          }
        ]
      },
      "correct": {
        "count": 47,
        "examples": [
          {
            "text": "В разметочные функции (labeling functions) закодированы все возможные правила, по которым можно поставить какую-либо метку каждому примеру из набора данных.",
            "relation": "(labeling functions) isAlternativeNameFor (разметочные функции)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Artificial Intelligence Markup Language) isAlternativeNameFor (AIML)"
          },
          {
            "text": "За эту конвертацию отвечают платформы ASR (распознавание речи), TTS (синтез речи), системы интеграции с телефонией.",
            "relation": "(синтез речи) isAlternativeNameFor (TTS)"
          },
          {
            "text": "В отличии от машин, люди хорошо умеют использовать знания, ранее полученные при выполнении различных задач, для решения новых – это называется композиционным обобщением (англ. compositional generalization).",
            "relation": "(compositional generalization) isAlternativeNameFor (композиционным обобщением)"
          },
          {
            "text": "Это было сделано путем fine-tune (точной настройки) предварительно обученного трансформера HuggingFace  на собранных данных Genius.",
            "relation": "(точной настройки) isAlternativeNameFor (fine-tune)"
          },
          {
            "text": "Среди используемых стратегий извлечения представлений текстов из эмбеддингов слов, можно выделить:1) Weighted Average Transformer (WAT) – взвешивается каждое слово с некоторым весом",
            "relation": "(WAT) isAlternativeNameFor (Weighted Average Transformer)"
          },
          {
            "text": "Bag of Random Embedding Projections (BOREP) – строится линейная модель со случайными весами",
            "relation": "(BOREP) isAlternativeNameFor (Bag of Random Embedding Projections)"
          },
          {
            "text": "Есть много способов решать такую задачу, и один из них — свёрточные нейронные сети (Convolutional Neural Networks).",
            "relation": "(Convolutional Neural Networks) isAlternativeNameFor (свёрточные нейронные сети)"
          },
          {
            "text": "В отличие от предыдущего уровня (phrase-based translation– однократное нахождение соответствий отдельных слов и фраз), нейронный переводчик в какой-то степени трансформирует предложения, анализирует их как единое целое и устанавливает соответствия «из конца в конец» в несколько стадий(end-to-end mapping – сквозное преобразование, полного цикла, непрерывная трансформация многообразия данных со входа на выход).",
            "relation": "(сквозное преобразование) isAlternativeNameFor (end-to-end mapping)"
          },
          {
            "text": "В новой работе Graphcore представили высокоэффективный алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами (или NNLSHP), а также алгоритм BERT, применяемый к упакованным последовательностям.",
            "relation": "(NNLSHP) isAlternativeNameFor (алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами)"
          },
          {
            "text": "В последнем исследовании от Graphcore был представлен эффективный алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов (NNLSHP), а также алгоритм BERT, примененный к упакованным последовательностям.",
            "relation": "(NNLSHP) isAlternativeNameFor (алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов)"
          },
          {
            "text": "Для решения этой проблемы мы делаем лучевой поиск (beam search), выбирая на каждом шаге вместо одного сразу N путей с наивысшими вероятностями.",
            "relation": "(beam search) isAlternativeNameFor (лучевой поиск)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(topic modeling) isAlternativeNameFor (тематическим моделированием)"
          },
          {
            "text": "Для сверточных нейросетей хорошо настроенный метод стохастического градиента (SGD) почти всегда немного превосходит Adam, но область оптимальной скорости обучения гораздо более узкая и зависит от задачи.",
            "relation": "(SGD) isAlternativeNameFor (метод стохастического градиента)"
          },
          {
            "text": "В случае GNMT речь идет о так называемом методе перевода на основе примеров (EBMT), т.е.",
            "relation": "(EBMT) isAlternativeNameFor (методе перевода на основе примеров)"
          },
          {
            "text": "Решать задачу будем с использованием нейронных сетей, но оптимизируемых генетическим алгоритмом (ГА) – такой процесс называют нейроэволюцией.",
            "relation": "(ГА) isAlternativeNameFor (генетическим алгоритмом)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NeuroEvolution of Augmenting Topologies) isAlternativeNameFor (NEAT)"
          },
          {
            "text": "Речь шла о морфологической разметке (part of speech tagging) современных текстов на русском языке.",
            "relation": "(part of speech tagging) isAlternativeNameFor (морфологической разметке)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(Weighting) isAlternativeNameFor (Взвешивание)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(random forest) isAlternativeNameFor (случайных лесов)"
          },
          {
            "text": "В иностранной литературе можно встретить термин Continuous Learning (CL), который объединяет различные методы использования новых данных для поддержания эффективности моделей.",
            "relation": "(CL) isAlternativeNameFor (Continuous Learning)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(Artificial Intelligence Markup Language) isAlternativeNameFor (AIML)"
          },
          {
            "text": "1970 г. Машинный перевод на основе правил (англ. RBMT) был первой попыткой научить машину переводить.",
            "relation": "(. RBMT) isAlternativeNameFor (Машинный перевод на основе правил)"
          },
          {
            "text": "1984 г. Машинный перевод на основе примеров (англ. EBMT) был способен переводить даже совсем не похожие друг на друга языки, где задавать какие-то правила было бесполезно.",
            "relation": "(EBMT) isAlternativeNameFor (Машинный перевод на основе примеров)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(SMT) isAlternativeNameFor (Статистический машинный перевод)"
          },
          {
            "text": "Так родился статистический метод анализа текста word2vec (англ. Word to vector).",
            "relation": "(Word to vector) isAlternativeNameFor (word2vec)"
          },
          {
            "text": "Под эти критерии отлично подходит рекуррентная нейронная сеть (RNN), однако по мере увеличения расстояния между связанными частями текста необходимо увеличивать и размер RNN, из-за чего падает качество обработки информации.",
            "relation": "(RNN) isAlternativeNameFor (рекуррентная нейронная сеть)"
          },
          {
            "text": "Эту проблему решает сеть LSTM (англ. Long short-term memory).",
            "relation": "(Long short-term memory) isAlternativeNameFor (LSTM)"
          },
          {
            "text": "Такой подход называется методом вложения слов (word embedding).",
            "relation": "(word embedding) isAlternativeNameFor (методом вложения слов)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(сети с долгой краткосрочной памятью) isAlternativeNameFor (LSTM)"
          },
          {
            "text": "Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(сети с долгой краткосрочной памятью) isAlternativeNameFor (LSTM)"
          },
          {
            "text": "Описание упомянутых рекуррентных нейросетей (RNN), LSTM и GRU выходит за рамки темы статьи.",
            "relation": "(RNN) isAlternativeNameFor (рекуррентных нейросетей)"
          },
          {
            "text": "Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).",
            "relation": "(self-attention) isAlternativeNameFor (самовнимании)"
          },
          {
            "text": "CBOW – это аббревиатура Continuous Bag of Words.",
            "relation": "(Continuous Bag of Words) isAlternativeNameFor (CBOW)"
          },
          {
            "text": "Кодирование в переменные — One-Hot Encoding (OHE)",
            "relation": "(OHE) isAlternativeNameFor (One-Hot Encoding)"
          },
          {
            "text": "Это группа методов очень похожа на методы, применяемые для репрезентации текстов — w2v (skip-gram), doc2vec.",
            "relation": "(skip-gram) isAlternativeNameFor (w2v)"
          },
          {
            "text": "Сверточные сети на графах (Graph Convolutional Networks).",
            "relation": "(Graph Convolutional Networks) isAlternativeNameFor (Сверточные сети на графах)"
          },
          {
            "text": "Энкодер предложений (sentence encoder) – это модель, которая сопоставляет коротким текстам векторы в многомерном пространстве, причём так, что у текстов, похожих по смыслу, и векторы тоже похожи.",
            "relation": "(sentence encoder) isAlternativeNameFor (Энкодер предложений)"
          },
          {
            "text": "Такой вид сентимент анализа называется объектной тональностью (object-based).",
            "relation": "(object-based) isAlternativeNameFor (объектной тональностью)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(SVM) isAlternativeNameFor (метод опорных векторов)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LSA) isAlternativeNameFor (латентно-семантический анализ)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LDA) isAlternativeNameFor (латентное размещение Дирихле)"
          },
          {
            "text": "Если для дальнейшей обработки не важен порядок слов, то текст упаковывают в Мешок слов (Bag-of-words).",
            "relation": "(Bag-of-words) isAlternativeNameFor (Мешок слов)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(FPB) isAlternativeNameFor (Federated Phish Bowl)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(FL) isAlternativeNameFor (федеративного обучения)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(PS) isAlternativeNameFor (сервер параметров)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(fine-tune) isAlternativeNameFor (точная настройка)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 3,
        "examples": [
          {
            "text": "В отличие от предыдущего уровня (phrase-based translation– однократное нахождение соответствий отдельных слов и фраз), нейронный переводчик в какой-то степени трансформирует предложения, анализирует их как единое целое и устанавливает соответствия «из конца в конец» в несколько стадий(end-to-end mapping – сквозное преобразование, полного цикла, непрерывная трансформация многообразия данных со входа на выход).",
            "relation": "(однократное нахождение соответствий отдельных слов) isAlternativeNameFor (phrase-based translation)"
          },
          {
            "text": "Чтобы определить, какие ещё есть потенциальные классы, мы повели так называемое тематическое моделирование, используя несколько подходов: начиная от пробалистических моделей (латентное распределение Дирихле, ARTM) и всё те же нейронные сети (BERT).",
            "relation": "(ARTM) isAlternativeNameFor (латентное распределение Дирихле)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(LSTM) isAlternativeNameFor (DL)"
          }
        ]
      },
      "found": {
        "count": 47,
        "examples": [
          {
            "text": "В разметочные функции (labeling functions) закодированы все возможные правила, по которым можно поставить какую-либо метку каждому примеру из набора данных.",
            "relation": "(labeling functions) isAlternativeNameFor (разметочные функции)"
          },
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Artificial Intelligence Markup Language) isAlternativeNameFor (AIML)"
          },
          {
            "text": "За эту конвертацию отвечают платформы ASR (распознавание речи), TTS (синтез речи), системы интеграции с телефонией.",
            "relation": "(синтез речи) isAlternativeNameFor (TTS)"
          },
          {
            "text": "В отличии от машин, люди хорошо умеют использовать знания, ранее полученные при выполнении различных задач, для решения новых – это называется композиционным обобщением (англ. compositional generalization).",
            "relation": "(compositional generalization) isAlternativeNameFor (композиционным обобщением)"
          },
          {
            "text": "Это было сделано путем fine-tune (точной настройки) предварительно обученного трансформера HuggingFace  на собранных данных Genius.",
            "relation": "(точной настройки) isAlternativeNameFor (fine-tune)"
          },
          {
            "text": "Среди используемых стратегий извлечения представлений текстов из эмбеддингов слов, можно выделить:1) Weighted Average Transformer (WAT) – взвешивается каждое слово с некоторым весом",
            "relation": "(WAT) isAlternativeNameFor (Weighted Average Transformer)"
          },
          {
            "text": "Bag of Random Embedding Projections (BOREP) – строится линейная модель со случайными весами",
            "relation": "(BOREP) isAlternativeNameFor (Bag of Random Embedding Projections)"
          },
          {
            "text": "Есть много способов решать такую задачу, и один из них — свёрточные нейронные сети (Convolutional Neural Networks).",
            "relation": "(Convolutional Neural Networks) isAlternativeNameFor (свёрточные нейронные сети)"
          },
          {
            "text": "В отличие от предыдущего уровня (phrase-based translation– однократное нахождение соответствий отдельных слов и фраз), нейронный переводчик в какой-то степени трансформирует предложения, анализирует их как единое целое и устанавливает соответствия «из конца в конец» в несколько стадий(end-to-end mapping – сквозное преобразование, полного цикла, непрерывная трансформация многообразия данных со входа на выход).",
            "relation": "(сквозное преобразование) isAlternativeNameFor (end-to-end mapping)"
          },
          {
            "text": "В новой работе Graphcore представили высокоэффективный алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами (или NNLSHP), а также алгоритм BERT, применяемый к упакованным последовательностям.",
            "relation": "(NNLSHP) isAlternativeNameFor (алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами)"
          },
          {
            "text": "В последнем исследовании от Graphcore был представлен эффективный алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов (NNLSHP), а также алгоритм BERT, примененный к упакованным последовательностям.",
            "relation": "(NNLSHP) isAlternativeNameFor (алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов)"
          },
          {
            "text": "Для решения этой проблемы мы делаем лучевой поиск (beam search), выбирая на каждом шаге вместо одного сразу N путей с наивысшими вероятностями.",
            "relation": "(beam search) isAlternativeNameFor (лучевой поиск)"
          },
          {
            "text": "Другой подход обучения без учителя для текстов называется тематическим моделированием (topic modeling), позволяющим выявить в неразмеченных текстах основные тематики.",
            "relation": "(topic modeling) isAlternativeNameFor (тематическим моделированием)"
          },
          {
            "text": "Для сверточных нейросетей хорошо настроенный метод стохастического градиента (SGD) почти всегда немного превосходит Adam, но область оптимальной скорости обучения гораздо более узкая и зависит от задачи.",
            "relation": "(SGD) isAlternativeNameFor (метод стохастического градиента)"
          },
          {
            "text": "В случае GNMT речь идет о так называемом методе перевода на основе примеров (EBMT), т.е.",
            "relation": "(EBMT) isAlternativeNameFor (методе перевода на основе примеров)"
          },
          {
            "text": "Решать задачу будем с использованием нейронных сетей, но оптимизируемых генетическим алгоритмом (ГА) – такой процесс называют нейроэволюцией.",
            "relation": "(ГА) isAlternativeNameFor (генетическим алгоритмом)"
          },
          {
            "text": "Мы воспользовались методом NEAT (NeuroEvolution of Augmenting Topologies), изобретенным Кеннетом Стенли и Ристо Мииккулайненом в начале века [1]: во-первых, он хорошо зарекомендовал себя в важных для народного хозяйства проблемах, во-вторых, к началу работы над проектом у нас уже был свой фреймворк, реализующий NEAT.",
            "relation": "(NeuroEvolution of Augmenting Topologies) isAlternativeNameFor (NEAT)"
          },
          {
            "text": "Речь шла о морфологической разметке (part of speech tagging) современных текстов на русском языке.",
            "relation": "(part of speech tagging) isAlternativeNameFor (морфологической разметке)"
          },
          {
            "text": "Взвешивание (Weighting) - метод предназначен для коррекции известных перекосов выборок по социально-демографическим атрибутам.",
            "relation": "(Weighting) isAlternativeNameFor (Взвешивание)"
          },
          {
            "text": "Авторы оригинального исследования Pew Research рекомендуют использовать для корректировки онлайн-опросов модели случайных лесов (random forest).",
            "relation": "(random forest) isAlternativeNameFor (случайных лесов)"
          },
          {
            "text": "В иностранной литературе можно встретить термин Continuous Learning (CL), который объединяет различные методы использования новых данных для поддержания эффективности моделей.",
            "relation": "(CL) isAlternativeNameFor (Continuous Learning)"
          },
          {
            "text": "Следующим шагом в развитии чат-ботов стала программа A.L.I.C.E., для которой Ричард Уоллес разработал специальный язык разметки — AIML (англ. Artificial Intelligence Markup Language).",
            "relation": "(Artificial Intelligence Markup Language) isAlternativeNameFor (AIML)"
          },
          {
            "text": "1970 г. Машинный перевод на основе правил (англ. RBMT) был первой попыткой научить машину переводить.",
            "relation": "(. RBMT) isAlternativeNameFor (Машинный перевод на основе правил)"
          },
          {
            "text": "1984 г. Машинный перевод на основе примеров (англ. EBMT) был способен переводить даже совсем не похожие друг на друга языки, где задавать какие-то правила было бесполезно.",
            "relation": "(EBMT) isAlternativeNameFor (Машинный перевод на основе примеров)"
          },
          {
            "text": "1990 г. Статистический машинный перевод (англ. SMT) в эпоху развития интернета позволил использовать не только готовые языковые корпуса, но даже книги и вольно переведенные статьи.",
            "relation": "(SMT) isAlternativeNameFor (Статистический машинный перевод)"
          },
          {
            "text": "Так родился статистический метод анализа текста word2vec (англ. Word to vector).",
            "relation": "(Word to vector) isAlternativeNameFor (word2vec)"
          },
          {
            "text": "Под эти критерии отлично подходит рекуррентная нейронная сеть (RNN), однако по мере увеличения расстояния между связанными частями текста необходимо увеличивать и размер RNN, из-за чего падает качество обработки информации.",
            "relation": "(RNN) isAlternativeNameFor (рекуррентная нейронная сеть)"
          },
          {
            "text": "Эту проблему решает сеть LSTM (англ. Long short-term memory).",
            "relation": "(Long short-term memory) isAlternativeNameFor (LSTM)"
          },
          {
            "text": "Такой подход называется методом вложения слов (word embedding).",
            "relation": "(word embedding) isAlternativeNameFor (методом вложения слов)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(сети с долгой краткосрочной памятью) isAlternativeNameFor (LSTM)"
          },
          {
            "text": "Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(сети с долгой краткосрочной памятью) isAlternativeNameFor (LSTM)"
          },
          {
            "text": "Описание упомянутых рекуррентных нейросетей (RNN), LSTM и GRU выходит за рамки темы статьи.",
            "relation": "(RNN) isAlternativeNameFor (рекуррентных нейросетей)"
          },
          {
            "text": "Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).",
            "relation": "(self-attention) isAlternativeNameFor (самовнимании)"
          },
          {
            "text": "CBOW – это аббревиатура Continuous Bag of Words.",
            "relation": "(Continuous Bag of Words) isAlternativeNameFor (CBOW)"
          },
          {
            "text": "Кодирование в переменные — One-Hot Encoding (OHE)",
            "relation": "(OHE) isAlternativeNameFor (One-Hot Encoding)"
          },
          {
            "text": "Это группа методов очень похожа на методы, применяемые для репрезентации текстов — w2v (skip-gram), doc2vec.",
            "relation": "(skip-gram) isAlternativeNameFor (w2v)"
          },
          {
            "text": "Сверточные сети на графах (Graph Convolutional Networks).",
            "relation": "(Graph Convolutional Networks) isAlternativeNameFor (Сверточные сети на графах)"
          },
          {
            "text": "Энкодер предложений (sentence encoder) – это модель, которая сопоставляет коротким текстам векторы в многомерном пространстве, причём так, что у текстов, похожих по смыслу, и векторы тоже похожи.",
            "relation": "(sentence encoder) isAlternativeNameFor (Энкодер предложений)"
          },
          {
            "text": "Такой вид сентимент анализа называется объектной тональностью (object-based).",
            "relation": "(object-based) isAlternativeNameFor (объектной тональностью)"
          },
          {
            "text": "При статистическом подходе для решения задачи общей классификации текстов на классы тональности широко используют метод опорных векторов (SVM), Байесовы модели, различного рода регрессии [Chetviorkin & Loukachevitch — описание соревнования ROMIP-2011 по сентимент анализу данных, практически все участники использовали SVM или Байес].",
            "relation": "(SVM) isAlternativeNameFor (метод опорных векторов)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LDA) isAlternativeNameFor (латентное размещение Дирихле)"
          },
          {
            "text": "Если же целью является определение тональности у определенного, заранее заданного объекта (нескольких объектов), то применяют более сложные статистические алгоритмы, такие как CRF [Антонова и Соловьев], алгоритмы семантической близости (например, латентно-семантический анализ – LSA, латентное размещение Дирихле — LDA) и др., а также методы, основанные на правилах [Пазельская и Соловьев].",
            "relation": "(LSA) isAlternativeNameFor (латентно-семантический анализ)"
          },
          {
            "text": "Если для дальнейшей обработки не важен порядок слов, то текст упаковывают в Мешок слов (Bag-of-words).",
            "relation": "(Bag-of-words) isAlternativeNameFor (Мешок слов)"
          },
          {
            "text": "Поэтому в статье предлагается способ обнаружения фишинговых сообщений, называемый Federated Phish Bowl (далее FPB), использующий федеративное обучение и рекуррентную нейронную сеть с долгой краткосрочной памятью (LSTM).",
            "relation": "(FPB) isAlternativeNameFor (Federated Phish Bowl)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(FL) isAlternativeNameFor (федеративного обучения)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(PS) isAlternativeNameFor (сервер параметров)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(fine-tune) isAlternativeNameFor (точная настройка)"
          }
        ]
      }
    }
  },
  "Metric_hasValue_Value": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 51,
        "examples": [
          {
            "text": "Вычислив MAE отдельно для характеристики личности и отдельно для потребительских предпочтений получили значения 0.11 и 0.148 соответственно, т. е. потребительские предпочтения сильно портят общую картину.",
            "relation": "(MAE) hasValue (0.11)"
          },
          {
            "text": "Вычислив MAE отдельно для характеристики личности и отдельно для потребительских предпочтений получили значения 0.11 и 0.148 соответственно, т. е. потребительские предпочтения сильно портят общую картину.",
            "relation": "(MAE) hasValue (0.148)"
          },
          {
            "text": "Итоговый MAE составил 0.073 для характеристик личности и 0.098 для потребительских предпочтений.",
            "relation": "(MAE) hasValue (0.073)"
          },
          {
            "text": "Итоговый MAE составил 0.073 для характеристик личности и 0.098 для потребительских предпочтений.",
            "relation": "(MAE) hasValue (0.098)"
          },
          {
            "text": "Получились немного разные цифры, но средний коэффициент корреляции по всем параметрам составил 0.68, что говорит о том, что характеристики, выдаваемые с разных переводов одного текста должны быть весьма похожи.",
            "relation": "(коэффициент корреляции) hasValue (0.68)"
          },
          {
            "text": "Приведу только показатели качества классификации, которые были нами получены на тестах: Accuracy = 95% F1 score = 93%",
            "relation": "(F1 score) hasValue (93%)"
          },
          {
            "text": "Приведу только показатели качества классификации, которые были нами получены на тестах: Accuracy = 95% F1 score = 93%",
            "relation": "(Accuracy) hasValue (95%)"
          },
          {
            "text": "Результат из статьи (average F1-score = 0.78142) примем в качестве baseline.",
            "relation": "(F1-score) hasValue (0.78142)"
          },
          {
            "text": "Результат, показанный на тестовой выборке average F1-score = 0,80064.",
            "relation": "(F1-score) hasValue (0,80064)"
          },
          {
            "text": "При обучении модели значение метрики F1-score достигло 0.894, соответственно можно сделать вывод о том, что модель хорошо справляется с задачей определения нейтральных и негативных обращений.",
            "relation": "(F1-score) hasValue (0.894)"
          },
          {
            "text": "Конкретно в нашем случае нам удалось создать модель сентиментного анализа, которая с 89% точностью определяет эмоциональный окрас обращения и слова, которые оказывают на это наибольшее влияние.",
            "relation": "(точностью) hasValue (89%)"
          },
          {
            "text": "Точность распознавания естественного языка сейчас у лидеров когнитивных систем (IBM Watson, Google, ABBYY, Microsoft, Наносемантика) позволяет в общем понять смысл и ответить на письменный вопрос при заранее определенной предметной базы знаний, но разговор даже с 90% точностью распознавания фраз на самом деле очень утомителен.",
            "relation": "(точностью) hasValue (90%)"
          },
          {
            "text": "На всех классах accuracy = 0.65.",
            "relation": "(accuracy) hasValue (0.65)"
          },
          {
            "text": "Рассчитаем macro f1 score (0.72 + 0.28 + 0.66 + 0.66)/4 ~ 0.6, weighted f1 score (0.720.85+0.280.05+0.660.05+0.660.05) ~ 0.69.",
            "relation": "(macro f1 score) hasValue (0.6)"
          },
          {
            "text": "Рассчитаем macro f1 score (0.72 + 0.28 + 0.66 + 0.66)/4 ~ 0.6, weighted f1 score (0.720.85+0.280.05+0.660.05+0.660.05) ~ 0.69.",
            "relation": "(weighted f1 score) hasValue (0.69)"
          },
          {
            "text": "Только на одном классе accuracy = 0.85.",
            "relation": "(accuracy) hasValue (0.85)"
          },
          {
            "text": "Рассчитаем macro f1 score (0.92 + 0 + 0 + 0)/4 ~ 0.23, weighted f1 score (0.920.85+00.05+00.05+00.05) ~ 0.78.",
            "relation": "(weighted f1 score) hasValue (0.78)"
          },
          {
            "text": "Рассчитаем macro f1 score (0.92 + 0 + 0 + 0)/4 ~ 0.23, weighted f1 score (0.920.85+00.05+00.05+00.05) ~ 0.78.",
            "relation": "(macro f1 score) hasValue (0.23)"
          },
          {
            "text": "В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM.",
            "relation": "(точности) hasValue (83%)"
          },
          {
            "text": "В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM.",
            "relation": "(точности) hasValue (86%)"
          },
          {
            "text": "Тем не менее, в Facebook признали, что алгоритмы пока не готовы к широкому развертыванию — точность их работы составляет около 65-70%.",
            "relation": "(точность) hasValue (65-70%)"
          },
          {
            "text": "таблицу 2), у этого источника коэффициент согласованности аннотаторов (Cohen's kappa coefficient), равный 0.57.",
            "relation": "(коэффициент согласованности аннотаторов) hasValue (0.57)"
          },
          {
            "text": "таблицу 2), у этого источника коэффициент согласованности аннотаторов (Cohen's kappa coefficient), равный 0.57.",
            "relation": "(Cohen's kappa coefficient) hasValue (0.57)"
          },
          {
            "text": "У топовых решений F1-мера для имён была 0.9+.",
            "relation": "(F1-мера) hasValue (0.9)"
          },
          {
            "text": "Стэнфордская нейросеть определяет тональность текста с точностью 85%",
            "relation": "(точностью) hasValue (85%)"
          },
          {
            "text": "Нейросеть от Стэнфорда демонстрирует точность в 85% при определении тональности текста.",
            "relation": "(точность) hasValue (85%)"
          },
          {
            "text": "Объединенная команда специалистов Пенсильванского и Шеффилдского университетов создала слабую форму искусственного интеллекта, которая способна предсказывать решения Европейского суда по правам человека (European Court of Human Rights, ECtHR, ЕСПЧ) с точностью в 79%.",
            "relation": "(точностью) hasValue (79%)"
          },
          {
            "text": "Он демонстрирует точность 95%.",
            "relation": "(точность) hasValue (95%)"
          },
          {
            "text": "На данный момент подход дает прогноз с accuracy 0,64, что выше случайного предсказания.",
            "relation": "(accuracy) hasValue (0,64)"
          },
          {
            "text": "Таким образом, хоть и удается достигнуть высокой точности, но результат не всегда стабилен и в моем случае колеблется в промежутке 75-80%.",
            "relation": "(точности) hasValue (75-80%)"
          },
          {
            "text": "Видно, что при перестановках качество падает, но это падение не критично и точность остается в диапазоне 69-80%.",
            "relation": "(точность) hasValue (69-80%)"
          },
          {
            "text": "ЗаключениеВ итоге, моделью RuBioRoBERTa в задаче RuMedDaNet мне удалось добиться качества 73.24% на закрытой тестовой части данных (хотя на dev метрика Accuracy вообще была 81.64%).",
            "relation": "(Accuracy) hasValue (81.64%)"
          },
          {
            "text": "Точность модели составила 58%, если учитывать все слот.",
            "relation": "(Точность) hasValue (58%)"
          },
          {
            "text": "После тонкой настройки модель показала примерно 63%-ю точность как на учебном, так и на контрольном наборах данных.",
            "relation": "(точность) hasValue (63%-ю)"
          },
          {
            "text": "Самые интересные для нас сущности – судья и прокурор – быстро идентифицируются из более чем 200 миллионов документов с точностью выше 92%».",
            "relation": "(точностью) hasValue (92%)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(MacroAVG F-меру) hasValue (69,5%)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(MacroAVG F-меру) hasValue (73%)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(точность) hasValue (69,5%)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(точность) hasValue (73%)"
          },
          {
            "text": "В итоге это дало самый большой прирост качества: для ансамбля из пяти моделей метрика качества R1 выросла с 0.2819 до 0.2949.",
            "relation": "(R1) hasValue (0.2819)"
          },
          {
            "text": "В итоге это дало самый большой прирост качества: для ансамбля из пяти моделей метрика качества R1 выросла с 0.2819 до 0.2949.",
            "relation": "(R1) hasValue (0.2949)"
          },
          {
            "text": "На выходе мы получаем метрику f1 = 0.91.",
            "relation": "(f1) hasValue (0.91)"
          },
          {
            "text": "результат первой модели – точность 77%",
            "relation": "(точность) hasValue (77%)"
          },
          {
            "text": "Теперь нам нужно было использовать некоторые технические способы, чтобы сделать максимально высоким качество модели, которая на новых классах давала точность 72%.",
            "relation": "(точность) hasValue (72%)"
          },
          {
            "text": "Протестировав поведение модели на продовских данных, мы обнаружили, что точность извлечения была около 50%.",
            "relation": "(точность) hasValue (50%)"
          },
          {
            "text": "Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.",
            "relation": "(Точность) hasValue (94%)"
          },
          {
            "text": "Метод BERT демонстрирует точность 94% на этапе обучения, и эта точность проверена на тестовых данных.",
            "relation": "(точность) hasValue (94%)"
          },
          {
            "text": "Это постобработка увеличила точность до 98%.",
            "relation": "(точность) hasValue (98%)"
          },
          {
            "text": "Точность распознавания составляет 92%.",
            "relation": "(Точность) hasValue (92%)"
          },
          {
            "text": "Сейчас точность выделения жестов в видеопотоке составляет 85—90%.",
            "relation": "(точность) hasValue (85—90%)"
          },
          {
            "text": "Так как задача является составной, то и метрика состояла из двух компонентов с весом 0.8 для задачи классификации и 0.2 для задачи NER.",
            "relation": "(метрика) hasValue (0.8)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "Так как задача является составной, то и метрика состояла из двух компонентов с весом 0.8 для задачи классификации и 0.2 для задачи NER.",
            "relation": "(метрика) hasValue (0.2)"
          }
        ]
      },
      "found": {
        "count": 51,
        "examples": [
          {
            "text": "Вычислив MAE отдельно для характеристики личности и отдельно для потребительских предпочтений получили значения 0.11 и 0.148 соответственно, т. е. потребительские предпочтения сильно портят общую картину.",
            "relation": "(MAE) hasValue (0.11)"
          },
          {
            "text": "Вычислив MAE отдельно для характеристики личности и отдельно для потребительских предпочтений получили значения 0.11 и 0.148 соответственно, т. е. потребительские предпочтения сильно портят общую картину.",
            "relation": "(MAE) hasValue (0.148)"
          },
          {
            "text": "Итоговый MAE составил 0.073 для характеристик личности и 0.098 для потребительских предпочтений.",
            "relation": "(MAE) hasValue (0.073)"
          },
          {
            "text": "Итоговый MAE составил 0.073 для характеристик личности и 0.098 для потребительских предпочтений.",
            "relation": "(MAE) hasValue (0.098)"
          },
          {
            "text": "Получились немного разные цифры, но средний коэффициент корреляции по всем параметрам составил 0.68, что говорит о том, что характеристики, выдаваемые с разных переводов одного текста должны быть весьма похожи.",
            "relation": "(коэффициент корреляции) hasValue (0.68)"
          },
          {
            "text": "Приведу только показатели качества классификации, которые были нами получены на тестах: Accuracy = 95% F1 score = 93%",
            "relation": "(F1 score) hasValue (93%)"
          },
          {
            "text": "Приведу только показатели качества классификации, которые были нами получены на тестах: Accuracy = 95% F1 score = 93%",
            "relation": "(Accuracy) hasValue (95%)"
          },
          {
            "text": "Результат из статьи (average F1-score = 0.78142) примем в качестве baseline.",
            "relation": "(F1-score) hasValue (0.78142)"
          },
          {
            "text": "Результат, показанный на тестовой выборке average F1-score = 0,80064.",
            "relation": "(F1-score) hasValue (0,80064)"
          },
          {
            "text": "При обучении модели значение метрики F1-score достигло 0.894, соответственно можно сделать вывод о том, что модель хорошо справляется с задачей определения нейтральных и негативных обращений.",
            "relation": "(F1-score) hasValue (0.894)"
          },
          {
            "text": "Конкретно в нашем случае нам удалось создать модель сентиментного анализа, которая с 89% точностью определяет эмоциональный окрас обращения и слова, которые оказывают на это наибольшее влияние.",
            "relation": "(точностью) hasValue (89%)"
          },
          {
            "text": "Точность распознавания естественного языка сейчас у лидеров когнитивных систем (IBM Watson, Google, ABBYY, Microsoft, Наносемантика) позволяет в общем понять смысл и ответить на письменный вопрос при заранее определенной предметной базы знаний, но разговор даже с 90% точностью распознавания фраз на самом деле очень утомителен.",
            "relation": "(точностью) hasValue (90%)"
          },
          {
            "text": "На всех классах accuracy = 0.65.",
            "relation": "(accuracy) hasValue (0.65)"
          },
          {
            "text": "Рассчитаем macro f1 score (0.72 + 0.28 + 0.66 + 0.66)/4 ~ 0.6, weighted f1 score (0.720.85+0.280.05+0.660.05+0.660.05) ~ 0.69.",
            "relation": "(macro f1 score) hasValue (0.6)"
          },
          {
            "text": "Рассчитаем macro f1 score (0.72 + 0.28 + 0.66 + 0.66)/4 ~ 0.6, weighted f1 score (0.720.85+0.280.05+0.660.05+0.660.05) ~ 0.69.",
            "relation": "(weighted f1 score) hasValue (0.69)"
          },
          {
            "text": "Только на одном классе accuracy = 0.85.",
            "relation": "(accuracy) hasValue (0.85)"
          },
          {
            "text": "Рассчитаем macro f1 score (0.92 + 0 + 0 + 0)/4 ~ 0.23, weighted f1 score (0.920.85+00.05+00.05+00.05) ~ 0.78.",
            "relation": "(weighted f1 score) hasValue (0.78)"
          },
          {
            "text": "Рассчитаем macro f1 score (0.92 + 0 + 0 + 0)/4 ~ 0.23, weighted f1 score (0.920.85+00.05+00.05+00.05) ~ 0.78.",
            "relation": "(macro f1 score) hasValue (0.23)"
          },
          {
            "text": "В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM.",
            "relation": "(точности) hasValue (83%)"
          },
          {
            "text": "В ходе тестирования модель китайских ученых показала улучшение на 2,74% по шкале F1 (оценка классификатора) сравнению с HFM (Hierarchical Fusion Model), представленной в прошлом году: новая нейросеть достигла 86% точности по сравнению с 83% у HFM.",
            "relation": "(точности) hasValue (86%)"
          },
          {
            "text": "Тем не менее, в Facebook признали, что алгоритмы пока не готовы к широкому развертыванию — точность их работы составляет около 65-70%.",
            "relation": "(точность) hasValue (65-70%)"
          },
          {
            "text": "таблицу 2), у этого источника коэффициент согласованности аннотаторов (Cohen's kappa coefficient), равный 0.57.",
            "relation": "(коэффициент согласованности аннотаторов) hasValue (0.57)"
          },
          {
            "text": "таблицу 2), у этого источника коэффициент согласованности аннотаторов (Cohen's kappa coefficient), равный 0.57.",
            "relation": "(Cohen's kappa coefficient) hasValue (0.57)"
          },
          {
            "text": "У топовых решений F1-мера для имён была 0.9+.",
            "relation": "(F1-мера) hasValue (0.9)"
          },
          {
            "text": "Стэнфордская нейросеть определяет тональность текста с точностью 85%",
            "relation": "(точностью) hasValue (85%)"
          },
          {
            "text": "Нейросеть от Стэнфорда демонстрирует точность в 85% при определении тональности текста.",
            "relation": "(точность) hasValue (85%)"
          },
          {
            "text": "Объединенная команда специалистов Пенсильванского и Шеффилдского университетов создала слабую форму искусственного интеллекта, которая способна предсказывать решения Европейского суда по правам человека (European Court of Human Rights, ECtHR, ЕСПЧ) с точностью в 79%.",
            "relation": "(точностью) hasValue (79%)"
          },
          {
            "text": "Он демонстрирует точность 95%.",
            "relation": "(точность) hasValue (95%)"
          },
          {
            "text": "На данный момент подход дает прогноз с accuracy 0,64, что выше случайного предсказания.",
            "relation": "(accuracy) hasValue (0,64)"
          },
          {
            "text": "Таким образом, хоть и удается достигнуть высокой точности, но результат не всегда стабилен и в моем случае колеблется в промежутке 75-80%.",
            "relation": "(точности) hasValue (75-80%)"
          },
          {
            "text": "Видно, что при перестановках качество падает, но это падение не критично и точность остается в диапазоне 69-80%.",
            "relation": "(точность) hasValue (69-80%)"
          },
          {
            "text": "ЗаключениеВ итоге, моделью RuBioRoBERTa в задаче RuMedDaNet мне удалось добиться качества 73.24% на закрытой тестовой части данных (хотя на dev метрика Accuracy вообще была 81.64%).",
            "relation": "(Accuracy) hasValue (81.64%)"
          },
          {
            "text": "Точность модели составила 58%, если учитывать все слот.",
            "relation": "(Точность) hasValue (58%)"
          },
          {
            "text": "После тонкой настройки модель показала примерно 63%-ю точность как на учебном, так и на контрольном наборах данных.",
            "relation": "(точность) hasValue (63%-ю)"
          },
          {
            "text": "Самые интересные для нас сущности – судья и прокурор – быстро идентифицируются из более чем 200 миллионов документов с точностью выше 92%».",
            "relation": "(точностью) hasValue (92%)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(MacroAVG F-меру) hasValue (73%)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(MacroAVG F-меру) hasValue (69,5%)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(точность) hasValue (73%)"
          },
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(точность) hasValue (69,5%)"
          },
          {
            "text": "В итоге это дало самый большой прирост качества: для ансамбля из пяти моделей метрика качества R1 выросла с 0.2819 до 0.2949.",
            "relation": "(R1) hasValue (0.2819)"
          },
          {
            "text": "В итоге это дало самый большой прирост качества: для ансамбля из пяти моделей метрика качества R1 выросла с 0.2819 до 0.2949.",
            "relation": "(R1) hasValue (0.2949)"
          },
          {
            "text": "На выходе мы получаем метрику f1 = 0.91.",
            "relation": "(f1) hasValue (0.91)"
          },
          {
            "text": "результат первой модели – точность 77%",
            "relation": "(точность) hasValue (77%)"
          },
          {
            "text": "Теперь нам нужно было использовать некоторые технические способы, чтобы сделать максимально высоким качество модели, которая на новых классах давала точность 72%.",
            "relation": "(точность) hasValue (72%)"
          },
          {
            "text": "Протестировав поведение модели на продовских данных, мы обнаружили, что точность извлечения была около 50%.",
            "relation": "(точность) hasValue (50%)"
          },
          {
            "text": "Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.",
            "relation": "(Точность) hasValue (94%)"
          },
          {
            "text": "Метод BERT демонстрирует точность 94% на этапе обучения, и эта точность проверена на тестовых данных.",
            "relation": "(точность) hasValue (94%)"
          },
          {
            "text": "Это постобработка увеличила точность до 98%.",
            "relation": "(точность) hasValue (98%)"
          },
          {
            "text": "Точность распознавания составляет 92%.",
            "relation": "(Точность) hasValue (92%)"
          },
          {
            "text": "Сейчас точность выделения жестов в видеопотоке составляет 85—90%.",
            "relation": "(точность) hasValue (85—90%)"
          },
          {
            "text": "Так как задача является составной, то и метрика состояла из двух компонентов с весом 0.8 для задачи классификации и 0.2 для задачи NER.",
            "relation": "(метрика) hasValue (0.8)"
          }
        ]
      }
    }
  },
  "Dataset_isAlternativeNameFor_Dataset": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 3,
        "examples": [
          {
            "text": "Набор данных назвали Гансом (Heuristic Analysis for Natural-Language-Inference Systems, HANS) [эвристический анализ систем, делающих заключения на основе естественного языка].",
            "relation": "(HANS) isAlternativeNameFor (Гансом)"
          },
          {
            "text": "Набор данных назвали Гансом (Heuristic Analysis for Natural-Language-Inference Systems, HANS) [эвристический анализ систем, делающих заключения на основе естественного языка].",
            "relation": "(HANS) isAlternativeNameFor (Heuristic Analysis for Natural-Language-Inference Systems)"
          },
          {
            "text": "Набор данных назвали Гансом (Heuristic Analysis for Natural-Language-Inference Systems, HANS) [эвристический анализ систем, делающих заключения на основе естественного языка].",
            "relation": "(Heuristic Analysis for Natural-Language-Inference Systems) isAlternativeNameFor (Гансом)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "Распознавание именованных сущностей () на датасетах factRuEval-2016E1 и RuDReC (NE2).",
            "relation": "(NE2) isAlternativeNameFor (RuDReC)"
          }
        ]
      },
      "found": {
        "count": 3,
        "examples": [
          {
            "text": "Набор данных назвали Гансом (Heuristic Analysis for Natural-Language-Inference Systems, HANS) [эвристический анализ систем, делающих заключения на основе естественного языка].",
            "relation": "(HANS) isAlternativeNameFor (Гансом)"
          },
          {
            "text": "Набор данных назвали Гансом (Heuristic Analysis for Natural-Language-Inference Systems, HANS) [эвристический анализ систем, делающих заключения на основе естественного языка].",
            "relation": "(HANS) isAlternativeNameFor (Heuristic Analysis for Natural-Language-Inference Systems)"
          },
          {
            "text": "Набор данных назвали Гансом (Heuristic Analysis for Natural-Language-Inference Systems, HANS) [эвристический анализ систем, делающих заключения на основе естественного языка].",
            "relation": "(Heuristic Analysis for Natural-Language-Inference Systems) isAlternativeNameFor (Гансом)"
          }
        ]
      }
    }
  },
  "Object_isPartOf_Object": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 4,
        "examples": [
          {
            "text": "Спаны - это участки текста, которые содержат в себе определенный смысл.",
            "relation": "(Спаны) isPartOf (текста)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(токены) isPartOf (текста)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(слова) isPartOf (текстах)"
          },
          {
            "text": "В архитектуре стенфордского парсера и Syntaxnet заложена другая концепия: сначала они генерируют полный ориентированный граф, и дальше работа алгоритма состоит в том, чтобы оставить тот скелет (минимальное остовное дерево), который будет наиболее вероятным.",
            "relation": "(минимальное остовное дерево) isPartOf (ориентированный граф)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 10,
        "examples": [
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(устойчивые группы) isPartOf (обучающая выборка)"
          },
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(кластеры) isPartOf (обучающая выборка)"
          },
          {
            "text": "Эмбеддинг (Embedding) – преобразования сложноструктурированных данных,  например слов, текстов, атрибутов событий, событий и их последовательностей, в машинно-читаемый набор чисел – числовой вектор.",
            "relation": "(текстов) isPartOf (сложноструктурированных данных)"
          },
          {
            "text": "Эмбеддинг (Embedding) – преобразования сложноструктурированных данных,  например слов, текстов, атрибутов событий, событий и их последовательностей, в машинно-читаемый набор чисел – числовой вектор.",
            "relation": "(слов) isPartOf (сложноструктурированных данных)"
          },
          {
            "text": "Эмбеддинг (Embedding) – преобразования сложноструктурированных данных,  например слов, текстов, атрибутов событий, событий и их последовательностей, в машинно-читаемый набор чисел – числовой вектор.",
            "relation": "(событий) isPartOf (сложноструктурированных данных)"
          },
          {
            "text": "Эмбеддинг (Embedding) – преобразования сложноструктурированных данных,  например слов, текстов, атрибутов событий, событий и их последовательностей, в машинно-читаемый набор чисел – числовой вектор.",
            "relation": "(атрибутов событий) isPartOf (сложноструктурированных данных)"
          },
          {
            "text": "Мы выбираем случайный базис из случайных векторов.",
            "relation": "(базис) isPartOf (случайных векторов)"
          },
          {
            "text": "Таким образом, тональность высказывания определяется тремя компонентами: субъектом тональности (кто высказал оценку), объектом тональности (о ком или о чём высказана оценка) и собственно тональной оценкой (как оценили).",
            "relation": "(тональной оценкой) isPartOf (тональность высказывания)"
          },
          {
            "text": "Таким образом, тональность высказывания определяется тремя компонентами: субъектом тональности (кто высказал оценку), объектом тональности (о ком или о чём высказана оценка) и собственно тональной оценкой (как оценили).",
            "relation": "(субъектом тональности) isPartOf (тональность высказывания)"
          },
          {
            "text": "Таким образом, тональность высказывания определяется тремя компонентами: субъектом тональности (кто высказал оценку), объектом тональности (о ком или о чём высказана оценка) и собственно тональной оценкой (как оценили).",
            "relation": "(объектом тональности) isPartOf (тональность высказывания)"
          }
        ]
      },
      "found": {
        "count": 4,
        "examples": [
          {
            "text": "Спаны - это участки текста, которые содержат в себе определенный смысл.",
            "relation": "(Спаны) isPartOf (текста)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(токены) isPartOf (текста)"
          },
          {
            "text": "Сначала решается задача выделения симптомов (NER), после чего в текстах убираются все слова, не являющиеся симптомами.",
            "relation": "(слова) isPartOf (текстах)"
          },
          {
            "text": "В архитектуре стенфордского парсера и Syntaxnet заложена другая концепия: сначала они генерируют полный ориентированный граф, и дальше работа алгоритма состоит в том, чтобы оставить тот скелет (минимальное остовное дерево), который будет наиболее вероятным.",
            "relation": "(минимальное остовное дерево) isPartOf (ориентированный граф)"
          }
        ]
      }
    }
  },
  "Object_isAlternativeNameFor_Object": {
    "predicted": {
      "incorrect": {
        "count": 5,
        "examples": [
          {
            "text": "Типичным методом обучения без учителя является кластеризация, благодаря которому обучающая выборка разбивается на устойчивые группы или кластеры.",
            "relation": "(устойчивые группы) isAlternativeNameFor (кластеры)"
          },
          {
            "text": "Эмбеддинг (Embedding) – преобразования сложноструктурированных данных,  например слов, текстов, атрибутов событий, событий и их последовательностей, в машинно-читаемый набор чисел – числовой вектор.",
            "relation": "(машинно-читаемый набор чисел) isAlternativeNameFor (числовой вектор)"
          },
          {
            "text": "В задаче NER использовался span-based F1-score, рассчитываемый следующим образом: для каждого текста берутся предсказанные индексы начала и конца размеченных признаков болезни, по ним выделяются из текста токены (отдельные слова, разделенные пробелом) и сравниваются с истинной (экспертной) разметкой.",
            "relation": "(токены) isAlternativeNameFor (слова)"
          },
          {
            "text": "Для ее решения обычно используют один из следующих инструментов: Готовые векторы / эмбеддинги слов [6]; Внутренние состояния CNN, натренированных на таких задачах как, как определение фальшивых предложений / языковое моделирование / классификация [7]; Комбинация выше перечисленных методов; Кроме того, уже много раз было показано [9], что в качестве хорошего бейслайна для эмбеддингов предложений можно взять и просто усредненные (с парой незначительных деталей, которые сейчас опустим) векторы слов.",
            "relation": "(векторы) isAlternativeNameFor (эмбеддинги слов)"
          },
          {
            "text": "Таким образом, тональность высказывания определяется тремя компонентами: субъектом тональности (кто высказал оценку), объектом тональности (о ком или о чём высказана оценка) и собственно тональной оценкой (как оценили).",
            "relation": "(тональность высказывания) isAlternativeNameFor (тональной оценкой)"
          }
        ]
      },
      "correct": {
        "count": 3,
        "examples": [
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(намерения) isAlternativeNameFor (интенты)"
          },
          {
            "text": "Эмбеддинг (Embedding) – преобразования сложноструктурированных данных,  например слов, текстов, атрибутов событий, событий и их последовательностей, в машинно-читаемый набор чисел – числовой вектор.",
            "relation": "(Embedding) isAlternativeNameFor (Эмбеддинг)"
          },
          {
            "text": "Изначально на этапе MVP (minimum viable product) мы применяли регулярные выражения для извлечения сущности.",
            "relation": "(minimum viable product) isAlternativeNameFor (MVP)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 3,
        "examples": [
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(намерения) isAlternativeNameFor (интенты)"
          },
          {
            "text": "Эмбеддинг (Embedding) – преобразования сложноструктурированных данных,  например слов, текстов, атрибутов событий, событий и их последовательностей, в машинно-читаемый набор чисел – числовой вектор.",
            "relation": "(Embedding) isAlternativeNameFor (Эмбеддинг)"
          },
          {
            "text": "Изначально на этапе MVP (minimum viable product) мы применяли регулярные выражения для извлечения сущности.",
            "relation": "(minimum viable product) isAlternativeNameFor (MVP)"
          }
        ]
      }
    }
  },
  "Model_hasAuthor_Person": {
    "predicted": {
      "incorrect": {
        "count": 2,
        "examples": [
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (Vaswani)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMO) hasAuthor (Quoc Le)"
          }
        ]
      },
      "correct": {
        "count": 17,
        "examples": [
          {
            "text": "Модель ULMFIT была представлена разработчиками fast.ai (Jeremy Howard, Sebastian Ruder) в 2018 году.",
            "relation": "(ULMFIT) hasAuthor (Sebastian Ruder)"
          },
          {
            "text": "Модель ULMFIT была представлена разработчиками fast.ai (Jeremy Howard, Sebastian Ruder) в 2018 году.",
            "relation": "(ULMFIT) hasAuthor (Jeremy Howard)"
          },
          {
            "text": "Для векторизации текста использовалась модель LaBSE от @cointegrated.",
            "relation": "(LaBSE) hasAuthor (@cointegrated)"
          },
          {
            "text": "Я использовал для этого модель ruT5 за авторством @cointegrated.",
            "relation": "(ruT5) hasAuthor (@cointegrated)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) hasAuthor (Stephen L. Thaler)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(DABUS) hasAuthor (Stephen L. Thaler)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(DABUS) hasAuthor (Стивен Л. Тейлер)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) hasAuthor (Стивен Л. Тейлер)"
          },
          {
            "text": "В июне текущего года инженер Google Блейк Лемуан (он на фото выше) ошарашил мировую общественность заявлением, что LLM LaMDA, над которой он работал вместе с другими программистами, может обладать некоторым подобием разума.",
            "relation": "(LLM LaMDA) hasAuthor (Блейк Лемуан)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ULMFiT) hasAuthor (Sebastian Ruder)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ULMFiT) hasAuthor (Jeremy Howard)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMo) hasAuthor (Matthew Peters)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (Salimans)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (Narasimhan)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(Трансформер) hasAuthor (Vaswani)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (Sutskever)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMO) hasAuthor (Matthew Peters)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 17,
        "examples": [
          {
            "text": "Модель ULMFIT была представлена разработчиками fast.ai (Jeremy Howard, Sebastian Ruder) в 2018 году.",
            "relation": "(ULMFIT) hasAuthor (Sebastian Ruder)"
          },
          {
            "text": "Модель ULMFIT была представлена разработчиками fast.ai (Jeremy Howard, Sebastian Ruder) в 2018 году.",
            "relation": "(ULMFIT) hasAuthor (Jeremy Howard)"
          },
          {
            "text": "Для векторизации текста использовалась модель LaBSE от @cointegrated.",
            "relation": "(LaBSE) hasAuthor (@cointegrated)"
          },
          {
            "text": "Я использовал для этого модель ruT5 за авторством @cointegrated.",
            "relation": "(ruT5) hasAuthor (@cointegrated)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) hasAuthor (Stephen L. Thaler)"
          },
          {
            "text": "Основатель компании Imagination Engines, Stephen L. Thaler продвигает свою нейронную сеть по имени DABUS (Device for the Autonomous Boot-strapping of Unified Sentience), указывая ее в качестве автора изобретения в заявках на патенты на разные изобретения, сгенерированные этой сетью.",
            "relation": "(DABUS) hasAuthor (Stephen L. Thaler)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(DABUS) hasAuthor (Стивен Л. Тейлер)"
          },
          {
            "text": "Стивен Л. Тейлер, основатель компании Imagination Engines, продвигает свою нейросеть под названием DABUS (Device for the Autonomous Boot-strapping of Unified Sentience).",
            "relation": "(Device for the Autonomous Boot-strapping of Unified Sentience) hasAuthor (Стивен Л. Тейлер)"
          },
          {
            "text": "В июне текущего года инженер Google Блейк Лемуан (он на фото выше) ошарашил мировую общественность заявлением, что LLM LaMDA, над которой он работал вместе с другими программистами, может обладать некоторым подобием разума.",
            "relation": "(LLM LaMDA) hasAuthor (Блейк Лемуан)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (Sutskever)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMo) hasAuthor (Matthew Peters)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ULMFiT) hasAuthor (Sebastian Ruder)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ELMO) hasAuthor (Matthew Peters)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (Salimans)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(ULMFiT) hasAuthor (Jeremy Howard)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(OpenAI Transformer) hasAuthor (Narasimhan)"
          },
          {
            "text": "Его появлению предшествовал ряд недавних разработок в области обработки естественного языка (BERT, ELMO и Ко в картинках — как в NLP пришло трансферное обучение): Semi-supervised Sequence learning (Andrew Dai и Quoc Le), ELMo (Matthew Peters и исследователи из AI2 и UW CSE), ULMFiT (Jeremy Howard и Sebastian Ruder), OpenAI Transformer (исследователи OpenAI Radford, Narasimhan, Salimans, и Sutskever) и Трансформер (Vaswani et al).",
            "relation": "(Трансформер) hasAuthor (Vaswani)"
          }
        ]
      }
    }
  },
  "Application_isAlternativeNameFor_Application": {
    "predicted": {
      "incorrect": {
        "count": 3,
        "examples": [
          {
            "text": "Многопоточный вариант Томиты — TomitaPooledParser использует для парсинга пул объектов TomitaParser, одинаковым образом сконфигурированных.",
            "relation": "(Томиты) isAlternativeNameFor (TomitaParser)"
          },
          {
            "text": "Сейчас в Яндексе мой основной проект это Алиса, голосовой помощник, который Яндекс запустил в октябре прошлого года, и моя группа отвечает за то, что можно условно назвать мозгами Алисы.",
            "relation": "(Алиса) isAlternativeNameFor (голосовой помощник)"
          },
          {
            "text": "Сейчас в Яндексе мой основной проект это Алиса, голосовой помощник, который Яндекс запустил в октябре прошлого года, и моя группа отвечает за то, что можно условно назвать мозгами Алисы.",
            "relation": "(голосовой помощник) isAlternativeNameFor (Алисы)"
          }
        ]
      },
      "correct": {
        "count": 18,
        "examples": [
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(IVA) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) определяют интенты пользователей и исполняют команды.",
            "relation": "(ГА) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) определяют интенты пользователей и исполняют команды.",
            "relation": "(IVA) isAlternativeNameFor (ГА)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) определяют интенты пользователей и исполняют команды.",
            "relation": "(IVA) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Сервис ORES (Objective Revision Evaluation Service) будет проверять все правки на наличие спама или троллинга.",
            "relation": "(Objective Revision Evaluation Service) isAlternativeNameFor (ORES)"
          },
          {
            "text": "Сервис ORES (Objective Revision Evaluation Service) будет осуществлять проверку всех изменений на предмет наличия спама или троллинга.",
            "relation": "(Objective Revision Evaluation Service) isAlternativeNameFor (ORES)"
          },
          {
            "text": "ORES (Objective Revision Evaluation Service) был разработан Wikimedia Foundation.",
            "relation": "(Objective Revision Evaluation Service) isAlternativeNameFor (ORES)"
          },
          {
            "text": "Сегодня мы расскажем, как помогли НПО Энергомаш создать корпоративную интеллектуальную информационно-поисковую систему (КИИПС) на базе ABBYY Intelligent Search – такую же удобную и быструю, как популярные поисковики.",
            "relation": "(КИИПС) isAlternativeNameFor (корпоративную интеллектуальную информационно-поисковую систему)"
          },
          {
            "text": "Сегодня мы расскажем о том, как мы содействовали НПО \"Энергомаш\" в разработке и внедрении их корпоративной интеллектуальной информационно-поисковой системы (КИИПС).",
            "relation": "(КИИПС) isAlternativeNameFor (корпоративной интеллектуальной информационно-поисковой системы)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) распознают намерения пользователей и выполняют указания.",
            "relation": "(ГА) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) распознают намерения пользователей и выполняют указания.",
            "relation": "(IVA) isAlternativeNameFor (ГА)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) распознают намерения пользователей и выполняют указания.",
            "relation": "(IVA) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Голосовые виртуальные помощники (ГВП, ИВА) распознают намерения пользователей и выполняют указания.",
            "relation": "(ГВП) isAlternativeNameFor (Голосовые виртуальные помощники)"
          },
          {
            "text": "Голосовые виртуальные помощники (ГВП, ИВА) распознают намерения пользователей и выполняют указания.",
            "relation": "(ИВА) isAlternativeNameFor (ГВП)"
          },
          {
            "text": "Голосовые виртуальные помощники (ГВП, ИВА) распознают намерения пользователей и выполняют указания.",
            "relation": "(ИВА) isAlternativeNameFor (Голосовые виртуальные помощники)"
          },
          {
            "text": "На сегодняшний день мы поделимся информацией о нашем вкладе в разработку и внедрение корпоративной интеллектуальной информационно-поисковой системы (КИИПС) для НПО \"Энергомаш\".",
            "relation": "(КИИПС) isAlternativeNameFor (корпоративной интеллектуальной информационно-поисковой системы)"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(ORES) isAlternativeNameFor (Objective Revision Evaluation Service)"
          },
          {
            "text": "Сервис Objective Revision Evaluation Service (ORES) будет производить анализ всех изменений с целью выявления признаков спама или троллинга.",
            "relation": "(ORES) isAlternativeNameFor (Objective Revision Evaluation Service)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 18,
        "examples": [
          {
            "text": "Голосовые ассистенты (IVA): Alexa от Amazon, Google Assistant от Google, Siri от Apple, Cortana от Microsoft, Алиса от Яндекса – они определяют интенты (намерения) пользователей и исполняют команды.",
            "relation": "(IVA) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) определяют интенты пользователей и исполняют команды.",
            "relation": "(ГА) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) определяют интенты пользователей и исполняют команды.",
            "relation": "(IVA) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) определяют интенты пользователей и исполняют команды.",
            "relation": "(IVA) isAlternativeNameFor (ГА)"
          },
          {
            "text": "Сервис ORES (Objective Revision Evaluation Service) будет проверять все правки на наличие спама или троллинга.",
            "relation": "(Objective Revision Evaluation Service) isAlternativeNameFor (ORES)"
          },
          {
            "text": "Сервис ORES (Objective Revision Evaluation Service) будет осуществлять проверку всех изменений на предмет наличия спама или троллинга.",
            "relation": "(Objective Revision Evaluation Service) isAlternativeNameFor (ORES)"
          },
          {
            "text": "ORES (Objective Revision Evaluation Service) был разработан Wikimedia Foundation.",
            "relation": "(Objective Revision Evaluation Service) isAlternativeNameFor (ORES)"
          },
          {
            "text": "Сегодня мы расскажем, как помогли НПО Энергомаш создать корпоративную интеллектуальную информационно-поисковую систему (КИИПС) на базе ABBYY Intelligent Search – такую же удобную и быструю, как популярные поисковики.",
            "relation": "(КИИПС) isAlternativeNameFor (корпоративную интеллектуальную информационно-поисковую систему)"
          },
          {
            "text": "Сегодня мы расскажем о том, как мы содействовали НПО \"Энергомаш\" в разработке и внедрении их корпоративной интеллектуальной информационно-поисковой системы (КИИПС).",
            "relation": "(КИИПС) isAlternativeNameFor (корпоративной интеллектуальной информационно-поисковой системы)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) распознают намерения пользователей и выполняют указания.",
            "relation": "(ГА) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) распознают намерения пользователей и выполняют указания.",
            "relation": "(IVA) isAlternativeNameFor (Голосовые ассистенты)"
          },
          {
            "text": "Голосовые ассистенты (ГА, IVA) распознают намерения пользователей и выполняют указания.",
            "relation": "(IVA) isAlternativeNameFor (ГА)"
          },
          {
            "text": "Голосовые виртуальные помощники (ГВП, ИВА) распознают намерения пользователей и выполняют указания.",
            "relation": "(ГВП) isAlternativeNameFor (Голосовые виртуальные помощники)"
          },
          {
            "text": "Голосовые виртуальные помощники (ГВП, ИВА) распознают намерения пользователей и выполняют указания.",
            "relation": "(ИВА) isAlternativeNameFor (ГВП)"
          },
          {
            "text": "Голосовые виртуальные помощники (ГВП, ИВА) распознают намерения пользователей и выполняют указания.",
            "relation": "(ИВА) isAlternativeNameFor (Голосовые виртуальные помощники)"
          },
          {
            "text": "На сегодняшний день мы поделимся информацией о нашем вкладе в разработку и внедрение корпоративной интеллектуальной информационно-поисковой системы (КИИПС) для НПО \"Энергомаш\".",
            "relation": "(КИИПС) isAlternativeNameFor (корпоративной интеллектуальной информационно-поисковой системы)"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(ORES) isAlternativeNameFor (Objective Revision Evaluation Service)"
          },
          {
            "text": "Сервис Objective Revision Evaluation Service (ORES) будет производить анализ всех изменений с целью выявления признаков спама или троллинга.",
            "relation": "(ORES) isAlternativeNameFor (Objective Revision Evaluation Service)"
          }
        ]
      }
    }
  },
  "Metric_isAppliedTo_Method": {
    "predicted": {
      "incorrect": {
        "count": 3,
        "examples": [
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(IDF) isAppliedTo (линейная регрессия)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(IDF) isAppliedTo (SVM)"
          },
          {
            "text": "В литературе для предсказания характеристик Big 5 использовались различные методы линейная регрессия с использованием признаков полученных латентным семантическим анализом [11], ридж-регрессия по большому набору собранных вручную признаков [12], SVM с признаками TF/IDF [13], word2vec и doc2vec [14].",
            "relation": "(TF) isAppliedTo (SVM)"
          }
        ]
      },
      "correct": {
        "count": 13,
        "examples": [
          {
            "text": "При использовании TF-IDF (например, вот) подхода с фильтром по частотам и логистической регрессии уже можно получить прекрасные результаты: изначально в краулер отправлялись очень разные тексты, и модель прекрасно справляется.",
            "relation": "(TF-IDF) isAppliedTo (логистической регрессии)"
          },
          {
            "text": "Используя TF-IDF с фильтром по частотам и логистической регрессией, уже можно достичь отличных результатов.",
            "relation": "(TF-IDF) isAppliedTo (логистической регрессией)"
          },
          {
            "text": "На данный момент подход дает прогноз с accuracy 0,64, что выше случайного предсказания.",
            "relation": "(accuracy) isAppliedTo (подход)"
          },
          {
            "text": "Второе, мы стандартно провели экстенсивный тюнинг гиперпараметров и изменили нашу метрику с точности на F1, чтобы ставить больше акцента на точность по каждому классу, так как общая точность предвзято относится к доминирующим классам.",
            "relation": "(F1) isAppliedTo (экстенсивный тюнинг гиперпараметров)"
          },
          {
            "text": "Мы провели экстенсивный тюнинг гиперпараметров и переключили нашу метрику с точности на F1.",
            "relation": "(F1) isAppliedTo (экстенсивный тюнинг гиперпараметров)"
          },
          {
            "text": "Метод BERT демонстрирует точность 94% на этапе обучения, и эта точность проверена на тестовых данных.",
            "relation": "(точность) isAppliedTo (Метод BERT)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (рекуррентными нейронными сетями)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (сети с долгой краткосрочной памятью)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (LSTM)"
          },
          {
            "text": "Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (рекуррентных нейронных сетей)"
          },
          {
            "text": "Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (LSTM)"
          },
          {
            "text": "Для задач NER я классифицировал токены логистической регрессией поверх их эмбеддингов, и измерял macro F1 по всем классам токенов, кроме О.",
            "relation": "(macro F1) isAppliedTo (логистической регрессией)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(macro F1) isAppliedTo (логистическую регрессию)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 2,
        "examples": [
          {
            "text": "Второе, мы стандартно провели экстенсивный тюнинг гиперпараметров и изменили нашу метрику с точности на F1, чтобы ставить больше акцента на точность по каждому классу, так как общая точность предвзято относится к доминирующим классам.",
            "relation": "(точности) isAppliedTo (экстенсивный тюнинг гиперпараметров)"
          },
          {
            "text": "Мы провели экстенсивный тюнинг гиперпараметров и переключили нашу метрику с точности на F1.",
            "relation": "(точности) isAppliedTo (экстенсивный тюнинг гиперпараметров)"
          }
        ]
      },
      "found": {
        "count": 13,
        "examples": [
          {
            "text": "При использовании TF-IDF (например, вот) подхода с фильтром по частотам и логистической регрессии уже можно получить прекрасные результаты: изначально в краулер отправлялись очень разные тексты, и модель прекрасно справляется.",
            "relation": "(TF-IDF) isAppliedTo (логистической регрессии)"
          },
          {
            "text": "Используя TF-IDF с фильтром по частотам и логистической регрессией, уже можно достичь отличных результатов.",
            "relation": "(TF-IDF) isAppliedTo (логистической регрессией)"
          },
          {
            "text": "На данный момент подход дает прогноз с accuracy 0,64, что выше случайного предсказания.",
            "relation": "(accuracy) isAppliedTo (подход)"
          },
          {
            "text": "Второе, мы стандартно провели экстенсивный тюнинг гиперпараметров и изменили нашу метрику с точности на F1, чтобы ставить больше акцента на точность по каждому классу, так как общая точность предвзято относится к доминирующим классам.",
            "relation": "(F1) isAppliedTo (экстенсивный тюнинг гиперпараметров)"
          },
          {
            "text": "Мы провели экстенсивный тюнинг гиперпараметров и переключили нашу метрику с точности на F1.",
            "relation": "(F1) isAppliedTo (экстенсивный тюнинг гиперпараметров)"
          },
          {
            "text": "Метод BERT демонстрирует точность 94% на этапе обучения, и эта точность проверена на тестовых данных.",
            "relation": "(точность) isAppliedTo (Метод BERT)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (рекуррентными нейронными сетями)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (сети с долгой краткосрочной памятью)"
          },
          {
            "text": "И в ее решении наилучшие метрики точности были достигнуты рекуррентными нейронными сетями, LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (LSTM)"
          },
          {
            "text": "Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (рекуррентных нейронных сетей)"
          },
          {
            "text": "Лучшие показатели точности в ее решении были достигнуты с использованием рекуррентных нейронных сетей, таких как LSTM (сети с долгой краткосрочной памятью).",
            "relation": "(точности) isAppliedTo (LSTM)"
          },
          {
            "text": "Для задач NER я классифицировал токены логистической регрессией поверх их эмбеддингов, и измерял macro F1 по всем классам токенов, кроме О.",
            "relation": "(macro F1) isAppliedTo (логистической регрессией)"
          },
          {
            "text": "В задаче извлечения именованных сущностей (NER) я использовал логистическую регрессию для классификации токенов на основе их эмбеддингов и вычислял macro F1 для всех классов токенов, кроме класса \"O\".",
            "relation": "(macro F1) isAppliedTo (логистическую регрессию)"
          }
        ]
      }
    }
  },
  "Method_isUsedForTraining_Model": {
    "predicted": {
      "incorrect": {
        "count": 17,
        "examples": [
          {
            "text": "В новой работе Graphcore представили высокоэффективный алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами (или NNLSHP), а также алгоритм BERT, применяемый к упакованным последовательностям.",
            "relation": "(алгоритм гистограммной упаковки с неотрицательными наименьшими квадратами) isUsedForTraining (BERT)"
          },
          {
            "text": "В последнем исследовании от Graphcore был представлен эффективный алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов (NNLSHP), а также алгоритм BERT, примененный к упакованным последовательностям.",
            "relation": "(алгоритм гистограммной упаковки с использованием неотрицательных наименьших квадратов) isUsedForTraining (BERT)"
          },
          {
            "text": "По сравнению с классической факторизацией на основе сингулярного разложения у вероятностной генерирующей модели есть важное преимущество.",
            "relation": "(классической факторизацией) isUsedForTraining (вероятностной генерирующей модели)"
          },
          {
            "text": "Чтобы определить, какие ещё есть потенциальные классы, мы повели так называемое тематическое моделирование, используя несколько подходов: начиная от пробалистических моделей (латентное распределение Дирихле, ARTM) и всё те же нейронные сети (BERT).",
            "relation": "(тематическое моделирование) isUsedForTraining (пробалистических моделей)"
          },
          {
            "text": "Чтобы определить, какие ещё есть потенциальные классы, мы повели так называемое тематическое моделирование, используя несколько подходов: начиная от пробалистических моделей (латентное распределение Дирихле, ARTM) и всё те же нейронные сети (BERT).",
            "relation": "(тематическое моделирование) isUsedForTraining (BERT)"
          },
          {
            "text": "Чтобы определить, какие ещё есть потенциальные классы, мы повели так называемое тематическое моделирование, используя несколько подходов: начиная от пробалистических моделей (латентное распределение Дирихле, ARTM) и всё те же нейронные сети (BERT).",
            "relation": "(латентное распределение Дирихле) isUsedForTraining (пробалистических моделей)"
          },
          {
            "text": "Чтобы определить, какие ещё есть потенциальные классы, мы повели так называемое тематическое моделирование, используя несколько подходов: начиная от пробалистических моделей (латентное распределение Дирихле, ARTM) и всё те же нейронные сети (BERT).",
            "relation": "(ARTM) isUsedForTraining (пробалистических моделей)"
          },
          {
            "text": "Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.",
            "relation": "(разметку) isUsedForTraining (BERT)"
          },
          {
            "text": "Команда DeepPavlov обучила модель NER на англоязычном корпусе OntoNotes, который имеет 19 типов разметки, включая PER (человек), LOC (местоположение), ORG (организация) и многие другие.",
            "relation": "(разметки) isUsedForTraining (модель NER)"
          },
          {
            "text": "SDV генерирует данные, применяя математические методы и модели машинного обучения.",
            "relation": "(математические методы) isUsedForTraining (модели машинного обучения)"
          },
          {
            "text": "Synthetic Data Vault (SDV) создает данные с использованием математических методов и моделей машинного обучения.",
            "relation": "(математических методов) isUsedForTraining (моделей машинного обучения)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(сервер параметров) isUsedForTraining (FPB)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(DL) isUsedForTraining (глобальную модель)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(DL) isUsedForTraining (FPB)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(сервер параметров) isUsedForTraining (глобальную модель)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(федеративного обучения) isUsedForTraining (глобальную модель)"
          },
          {
            "text": "Давайте обратимся к этой статье, где была исследована классификация тональности с использованием модели Word2vec в архитектуре CNN.",
            "relation": "(CNN) isUsedForTraining (Word2vec)"
          }
        ]
      },
      "correct": {
        "count": 9,
        "examples": [
          {
            "text": "Генеративные модели на основании federated learning – будущее перспективное направление по мнению Google, которое находится “в ранних стадиях экспоненциального роста”.",
            "relation": "(federated learning) isUsedForTraining (Генеративные модели)"
          },
          {
            "text": "Это было сделано путем fine-tune (точной настройки) предварительно обученного трансформера HuggingFace  на собранных данных Genius.",
            "relation": "(fine-tune) isUsedForTraining (трансформера HuggingFace)"
          },
          {
            "text": "Это было сделано путем fine-tune (точной настройки) предварительно обученного трансформера HuggingFace  на собранных данных Genius.",
            "relation": "(точной настройки) isUsedForTraining (трансформера HuggingFace)"
          },
          {
            "text": "Используя новый алгоритм упаковки, в Graphcore ускорили обработку естественного языка более чем в 2 раза при обучении BERT-Large.",
            "relation": "(алгоритм упаковки) isUsedForTraining (BERT-Large)"
          },
          {
            "text": "Кажется, самым простым способом построить такую модель является использование N-граммной статистики.",
            "relation": "(N-граммной статистики) isUsedForTraining (модель)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(FL) isUsedForTraining (FPB)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(федеративного обучения) isUsedForTraining (FPB)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(точная настройка) isUsedForTraining (модели трансформера)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(fine-tune) isUsedForTraining (модели трансформера)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 6,
        "examples": [
          {
            "text": "Возникли модели, основанные на краудсорсинге: мы не только пытаемся что-то понять с помощью машины, а подключаем людей, которые за небольшую плату определяют, на каком языке написан текст.",
            "relation": "(краудсорсинге) isUsedForTraining (модели)"
          },
          {
            "text": "В ноябре 2021 года «Сбер» обучил нейросеть ruGPT-3 автоматически писать код и назвал эту функцию JARVIS.",
            "relation": "(JARVIS) isUsedForTraining (ruGPT-3)"
          },
          {
            "text": "В ноябре 2021 года компания \"Сбер\" провела обучение нейросети ruGPT-3 для автоматического написания кода, представив эту функцию под названием JARVIS.",
            "relation": "(JARVIS) isUsedForTraining (ruGPT-3)"
          },
          {
            "text": "Теперь нам нужно было использовать некоторые технические способы, чтобы сделать максимально высоким качество модели, которая на новых классах давала точность 72%.",
            "relation": "(технические способы) isUsedForTraining (модели)"
          },
          {
            "text": "Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).",
            "relation": "(self-attention) isUsedForTraining (Трансформеры)"
          },
          {
            "text": "Трансформеры в машинном обучении — это семейство архитектур нейронных сетей, общая идея которых основана на так называемом «самовнимании» (self-attention).",
            "relation": "(самовнимании) isUsedForTraining (Трансформеры)"
          }
        ]
      },
      "found": {
        "count": 9,
        "examples": [
          {
            "text": "Генеративные модели на основании federated learning – будущее перспективное направление по мнению Google, которое находится “в ранних стадиях экспоненциального роста”.",
            "relation": "(federated learning) isUsedForTraining (Генеративные модели)"
          },
          {
            "text": "Это было сделано путем fine-tune (точной настройки) предварительно обученного трансформера HuggingFace  на собранных данных Genius.",
            "relation": "(fine-tune) isUsedForTraining (трансформера HuggingFace)"
          },
          {
            "text": "Это было сделано путем fine-tune (точной настройки) предварительно обученного трансформера HuggingFace  на собранных данных Genius.",
            "relation": "(точной настройки) isUsedForTraining (трансформера HuggingFace)"
          },
          {
            "text": "Используя новый алгоритм упаковки, в Graphcore ускорили обработку естественного языка более чем в 2 раза при обучении BERT-Large.",
            "relation": "(алгоритм упаковки) isUsedForTraining (BERT-Large)"
          },
          {
            "text": "Кажется, самым простым способом построить такую модель является использование N-граммной статистики.",
            "relation": "(N-граммной статистики) isUsedForTraining (модель)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(FL) isUsedForTraining (FPB)"
          },
          {
            "text": "Для обучения модели FPB с использованием федеративного обучения (FL) сервер параметров (PS) инициализирует глобальную модель (DL) на основе вышеупомянутых двунаправленных нейронных сетей LSTM и отправляет глобальную модель с глобальной матрицей преобразования слов в векторы всем клиентам на первом этапе обучения.",
            "relation": "(федеративного обучения) isUsedForTraining (FPB)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(точная настройка) isUsedForTraining (модели трансформера)"
          },
          {
            "text": "Для этого использовалась точная настройка (fine-tune ) предварительно обученной модели трансформера от HuggingFace на данных, собранных с платформы Genius.",
            "relation": "(fine-tune) isUsedForTraining (модели трансформера)"
          }
        ]
      }
    }
  },
  "InfoResource_isAlternativeNameFor_InfoResource": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 0,
        "examples": []
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 0,
        "examples": []
      }
    }
  },
  "Application_isUsedForSolving_Task": {
    "predicted": {
      "incorrect": {
        "count": 12,
        "examples": [
          {
            "text": "Это такие задачи как суммаризация (сделать из большого текста его резюме), понимание текста (NLU), вопросно-ответные системы, генерация (например, стихов, — на Хабре была хорошая статья) и другие.",
            "relation": "(вопросно-ответные системы) isUsedForSolving (понимание текста)"
          },
          {
            "text": "Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.",
            "relation": "(Google Assistant) isUsedForSolving (убавить громкость)"
          },
          {
            "text": "Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.",
            "relation": "(Siri) isUsedForSolving (заказать такси)"
          },
          {
            "text": "Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.",
            "relation": "(Google Assistant) isUsedForSolving (завести будильник)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(wit.ai) isUsedForSolving (преобразование речи в текст)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedForSolving (выявление сущностей и ключевых слов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(IBM AlchemyAPI) isUsedForSolving (классификация текстов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedForSolving (анализ тональности текста)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(wit.ai) isUsedForSolving (понимание текстовых и голосовых команд и вопросов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedForSolving (понимание текстовых и голосовых команд и вопросов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(api.ai) isUsedForSolving (выявление сущностей и ключевых слов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(IBM AlchemyAPI) isUsedForSolving (извлечение информации из текстов)"
          }
        ]
      },
      "correct": {
        "count": 77,
        "examples": [
          {
            "text": "Для наглядности оставляю здесь иллюстрацию с последовательностью работы со Снокрелем для задачи information extraction из оригинальной статьи.",
            "relation": "(Снокрелем) isUsedForSolving (information extraction)"
          },
          {
            "text": "Зайдя на несколько из них я увидел что большая половина типа Wix используют технологию Искусственного Интеллекта, чтобы создать шаблон разметки страницы и далее её уже заполнить.",
            "relation": "(технологию Искусственного Интеллекта) isUsedForSolving (создать шаблон разметки страницы)"
          },
          {
            "text": "Некоторое время назад к нам обратился заказчик с не совсем обычной задачей — воспроизвести сервис IBM Watson Personality Insights, который анализировал текст, написанный человеком и определял по нему ряд личностных характеристик.",
            "relation": "(IBM Watson Personality Insights) isUsedForSolving (анализировал текст)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (оценка личности персонажей пьес Шекспира)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (определении спама)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (оценки состояния пациентов)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (выявлении спама)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (анализ личности персонажей пьес Шекспира)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (оценки состояния пациентов)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Чатботы) isUsedForSolving (Natural Language Understanding)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(искусственный интеллект) isUsedForSolving (Natural Language Understanding)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Чатботы) isUsedForSolving (NLU)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Чатботы) isUsedForSolving (понимания естественного языка)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(искусственный интеллект) isUsedForSolving (понимания естественного языка)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(искусственный интеллект) isUsedForSolving (NLU)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(DeBERTa) isUsedForSolving (NLU)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(DeBERTa) isUsedForSolving (понимания естественного языка)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(DeBERTa) isUsedForSolving (Natural Language Understanding)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Office) isUsedForSolving (создание контента)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Bing) isUsedForSolving (создание контента)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Azure Cognitive Services) isUsedForSolving (создание контента)"
          },
          {
            "text": "В этой статье речь пойдет о том, как мы интегрировали разработанный Яндексом Томита-парсер в нашу систему, превратили его в динамическую библиотеку, подружили с Java, сделали многопоточной и решили с её помощью задачу классификации текста для оценки недвижимости.",
            "relation": "(Томита-парсер) isUsedForSolving (классификации)"
          },
          {
            "text": "В этой статье речь пойдет о том, как мы интегрировали разработанный Яндексом Томита-парсер в нашу систему, превратили его в динамическую библиотеку, подружили с Java, сделали многопоточной и решили с её помощью задачу классификации текста для оценки недвижимости.",
            "relation": "(Томита-парсер) isUsedForSolving (оценки недвижимости)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(Томита-парсер) isUsedForSolving (извлечения фактов)"
          },
          {
            "text": "Многопоточный вариант Томиты — TomitaPooledParser использует для парсинга пул объектов TomitaParser, одинаковым образом сконфигурированных.",
            "relation": "(TomitaPooledParser) isUsedForSolving (парсинга)"
          },
          {
            "text": "Многопоточный вариант Томиты — TomitaPooledParser использует для парсинга пул объектов TomitaParser, одинаковым образом сконфигурированных.",
            "relation": "(Томиты) isUsedForSolving (парсинга)"
          },
          {
            "text": "В HuggingArtists, мы можем создавать тексты песен на основе конкретного исполнителя.",
            "relation": "(HuggingArtists) isUsedForSolving (создавать тексты)"
          },
          {
            "text": "Анализ тональности текста с использованием фреймворка Lightautoml",
            "relation": "(Lightautoml) isUsedForSolving (Анализ тональности текста)"
          },
          {
            "text": "Подводя итоги стоит сказать, что LightAutoML благодаря встроенному инструментарию способен показывать достаточно хорошие результаты в задачах бинарной или мультиклассовой классификации и регрессии.",
            "relation": "(LightAutoML) isUsedForSolving (бинарной или мультиклассовой классификации)"
          },
          {
            "text": "Подводя итоги стоит сказать, что LightAutoML благодаря встроенному инструментарию способен показывать достаточно хорошие результаты в задачах бинарной или мультиклассовой классификации и регрессии.",
            "relation": "(LightAutoML) isUsedForSolving (регрессии)"
          },
          {
            "text": "Тогда к статистической модели, которая была в «Переводчике» с момента запуска, добавили технологию перевода с помощью нейросети.",
            "relation": "(Переводчике) isUsedForSolving (перевода)"
          },
          {
            "text": "У «Балабобы» нет своего мнения, она выдает случайные продолжения и может закончить историю, придумать подпись или написать небольшой рассказ.",
            "relation": "(Балабобы) isUsedForSolving (придумать подпись)"
          },
          {
            "text": "У «Балабобы» нет своего мнения, она выдает случайные продолжения и может закончить историю, придумать подпись или написать небольшой рассказ.",
            "relation": "(Балабобы) isUsedForSolving (написать небольшой рассказ)"
          },
          {
            "text": "AntiToxicBot — бот, распознающий токсичных пользователей в телеграм чатах.",
            "relation": "(AntiToxicBot) isUsedForSolving (распознающий токсичных пользователей)"
          },
          {
            "text": "Одна из основных задач диалоговых систем состоит не только в предоставлении нужной пользователю информации, но и в генерации как можно более человеческих ответов.",
            "relation": "(диалоговых систем) isUsedForSolving (генерации)"
          },
          {
            "text": "Одна из основных задач диалоговых систем состоит не только в предоставлении нужной пользователю информации, но и в генерации как можно более человеческих ответов.",
            "relation": "(диалоговых систем) isUsedForSolving (предоставлении нужной пользователю информации)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isUsedForSolving (идентифицировать)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (формирования текстовой формы числительных)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (проверки орфографии)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (постановки слова в нужную словоформу)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (исправления ошибок)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (подсказки следующего слова)"
          },
          {
            "text": "Мы обучали движок Amazon Translate, используя «Active Custom Translation», который позволяет выполнять перевод на лету с использованием двуязычного корпуса.",
            "relation": "(Active Custom Translation) isUsedForSolving (перевод)"
          },
          {
            "text": "Мы обучали движок Amazon Translate, используя «Active Custom Translation», который позволяет выполнять перевод на лету с использованием двуязычного корпуса.",
            "relation": "(Amazon Translate) isUsedForSolving (перевод)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(ChatGPT) isUsedForSolving (получения точных ответов)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(ChatGPT) isUsedForSolving (перевода)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(ChatGPT) isUsedForSolving (создание текстов)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(ChatGPT) isUsedForSolving (написание кода)"
          },
          {
            "text": "Я приведу простой пример извлечения данных о погоде с общедоступного API Dark Sky.",
            "relation": "(API Dark Sky) isUsedForSolving (извлечения)"
          },
          {
            "text": "Facebook представила систему распознавания речи wav2vec-U.",
            "relation": "(wav2vec-U) isUsedForSolving (распознавания речи)"
          },
          {
            "text": "В 2000-е анализ естественных языков начал применяться уже не только для поиска в Интернете, но и для решения разнообразных задач.",
            "relation": "(Интернете) isUsedForSolving (поиска)"
          },
          {
            "text": "Он опубликовал программу (репозиторий на гитхабе), которая делает именно это: генерирует политические речи, удивительно похожие на настоящие.",
            "relation": "(программу) isUsedForSolving (генерирует политические речи)"
          },
          {
            "text": "Исследователи Массачусетского технологического университета разработали систему искусственного интеллекта, которая способна переписывать устаревшие предложения в статьях «Википедии».",
            "relation": "(систему искусственного интеллекта) isUsedForSolving (переписывать устаревшие предложения)"
          },
          {
            "text": "Отмечается, что систему также можно использовать для дополнения наборов данных, предназначенных для обучения детекторов фейкньюс, что потенциально снижает предвзятость и повышает точность информации.",
            "relation": "(систему) isUsedForSolving (дополнения наборов данных)"
          },
          {
            "text": "Отмечается, что систему также можно использовать для дополнения наборов данных, предназначенных для обучения детекторов фейкньюс, что потенциально снижает предвзятость и повышает точность информации.",
            "relation": "(систему) isUsedForSolving (обучения детекторов фейкньюс)"
          },
          {
            "text": "Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.",
            "relation": "(Алису) isUsedForSolving (убавить громкость)"
          },
          {
            "text": "Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.",
            "relation": "(Siri) isUsedForSolving (завести будильник)"
          },
          {
            "text": "Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.",
            "relation": "(Google Assistant) isUsedForSolving (заказать такси)"
          },
          {
            "text": "Для решения этой задачи в октябре 2019 года вышел первый релиз DeepPavlov Agent 1.0 — платформы для создания многозадачных чат-ботов.",
            "relation": "(DeepPavlov Agent 1.0) isUsedForSolving (задачи)"
          },
          {
            "text": "Для решения этой задачи в октябре 2019 года вышел первый релиз DeepPavlov Agent 1.0 — платформы для создания многозадачных чат-ботов.",
            "relation": "(DeepPavlov Agent 1.0) isUsedForSolving (создания многозадачных чат-ботов)"
          },
          {
            "text": "DeepPavlov Cloud позволяет анализировать текст, а также хранить документы в облачном хранилище.",
            "relation": "(DeepPavlov Cloud) isUsedForSolving (анализировать текст)"
          },
          {
            "text": "DeepPavlov Cloud позволяет анализировать текст, а также хранить документы в облачном хранилище.",
            "relation": "(DeepPavlov Cloud) isUsedForSolving (хранить документы)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedForSolving (анализ тональности)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedForSolving (извлечение информации из текстов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(api.ai) isUsedForSolving (понимание текстовых и голосовых команд и вопросов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(IBM AlchemyAPI) isUsedForSolving (выявление сущностей и ключевых слов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedForSolving (классификация текстов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(IBM AlchemyAPI) isUsedForSolving (анализ тональности текста)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(api.ai) isUsedForSolving (преобразование речи в текст)"
          },
          {
            "text": "Например, Diffbot позволяет автоматически сканировать страницы сайтов, извлекать из них нужную информацию: тексты, изображения, видео, информацию о продуктах, комментарии и др., в очищенном в структурированном виде, а также позволяет классифицировать страницы.",
            "relation": "(Diffbot) isUsedForSolving (сканировать страницы сайтов)"
          },
          {
            "text": "Например, Diffbot позволяет автоматически сканировать страницы сайтов, извлекать из них нужную информацию: тексты, изображения, видео, информацию о продуктах, комментарии и др., в очищенном в структурированном виде, а также позволяет классифицировать страницы.",
            "relation": "(Diffbot) isUsedForSolving (классифицировать страницы)"
          },
          {
            "text": "Решения, основанные на Deepomatic, позволяют находить информацию о фильме по его постеру, информацию о картине или скульптуре на выставке по ее фото, сделанному на камеру телефона, позволяют скачивать музыку, сфотографировав обложку альбома на диске и т.п.",
            "relation": "(Deepomatic) isUsedForSolving (находить информацию о фильме)"
          },
          {
            "text": "Custom Vocabularies – позволяет создать «словарь» из тех, слов, которые должна «выучить» нейросеть перед тем, как приступить к распознаванию.",
            "relation": "(Custom Vocabularies) isUsedForSolving (распознаванию)"
          },
          {
            "text": "Программа, придуманная учеными из Новосибирского академгородка, распознает речь, анализирует смысл и переводит на жестовый язык.",
            "relation": "(Программа) isUsedForSolving (анализирует смысл)"
          },
          {
            "text": "Программа, придуманная учеными из Новосибирского академгородка, распознает речь, анализирует смысл и переводит на жестовый язык.",
            "relation": "(Программа) isUsedForSolving (распознает речь)"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(Objective Revision Evaluation Service) isUsedForSolving (наличие спама)"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(ORES) isUsedForSolving (наличие спама)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 4,
        "examples": [
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(чат-ботами) isUsedForSolving (создание контента)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Dynamics) isUsedForSolving (создание контента)"
          },
          {
            "text": "Их можно использовать в качестве чат-ботов, для поиска информации, модерации онлайн-контента, анализа литературы или для создания совершенно новых фрагментов текста на основе подсказок (чем занимается, например, «Порфирьевич», который способен генерировать весьма забавные короткие рассказы).",
            "relation": "(чат-ботов) isUsedForSolving (поиска информации)"
          },
          {
            "text": "Если получится найти публичный сервис speech-to-text, то его можно использовать, чтобы «оцифровать» речь во всех вебинарах, а сделать потом нечеткий поиск по тексту – более простая задача.",
            "relation": "(сервис speech-to-text) isUsedForSolving (поиск по тексту)"
          }
        ]
      },
      "found": {
        "count": 77,
        "examples": [
          {
            "text": "Для наглядности оставляю здесь иллюстрацию с последовательностью работы со Снокрелем для задачи information extraction из оригинальной статьи.",
            "relation": "(Снокрелем) isUsedForSolving (information extraction)"
          },
          {
            "text": "Зайдя на несколько из них я увидел что большая половина типа Wix используют технологию Искусственного Интеллекта, чтобы создать шаблон разметки страницы и далее её уже заполнить.",
            "relation": "(технологию Искусственного Интеллекта) isUsedForSolving (создать шаблон разметки страницы)"
          },
          {
            "text": "Некоторое время назад к нам обратился заказчик с не совсем обычной задачей — воспроизвести сервис IBM Watson Personality Insights, который анализировал текст, написанный человеком и определял по нему ряд личностных характеристик.",
            "relation": "(IBM Watson Personality Insights) isUsedForSolving (анализировал текст)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (оценка личности персонажей пьес Шекспира)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (определении спама)"
          },
          {
            "text": "Например, Personality Insights использовался в психотерапии для оценки состояния пациентов [5], в искусстве (оценка личности персонажей пьес Шекспира) [6], определении спама [7] а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (оценки состояния пациентов)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (выявлении спама)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (анализ личности персонажей пьес Шекспира)"
          },
          {
            "text": "Personality Insights был применен в психотерапии для оценки состояния пациентов, в искусстве (анализ личности персонажей пьес Шекспира), выявлении спама, а также в научных исследованиях.",
            "relation": "(Personality Insights) isUsedForSolving (оценки состояния пациентов)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Чатботы) isUsedForSolving (Natural Language Understanding)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(искусственный интеллект) isUsedForSolving (Natural Language Understanding)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Чатботы) isUsedForSolving (NLU)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(Чатботы) isUsedForSolving (понимания естественного языка)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(искусственный интеллект) isUsedForSolving (NLU)"
          },
          {
            "text": "Чатботы и искусственный интеллект для понимания естественного языка (NLU – Natural Language Understanding) тема достаточно горячая, про нее не раз говорилось на Хабре.",
            "relation": "(искусственный интеллект) isUsedForSolving (понимания естественного языка)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(DeBERTa) isUsedForSolving (NLU)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(DeBERTa) isUsedForSolving (понимания естественного языка)"
          },
          {
            "text": "Алгоритм понимания естественного языка (Natural Language Understanding, NLU) Microsoft DeBERTa превзошел человеческие возможности в одном из самых сложных тестов для подобных алгоритмов SuperGLUE.",
            "relation": "(DeBERTa) isUsedForSolving (Natural Language Understanding)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Office) isUsedForSolving (создание контента)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Bing) isUsedForSolving (создание контента)"
          },
          {
            "text": "Тьюринговые модели используются в таких продуктах Microsoft, как Bing, Office, Dynamics и Azure Cognitive Services, чтобы совершенствовать, к примеру, взаимодействие с чат-ботами, предоставление рекомендаций и ответов на вопросы, поиск, автоматизацию поддержки клиентов, создание контента и решение многих других задач на пользу сотен миллионов пользователей.",
            "relation": "(Azure Cognitive Services) isUsedForSolving (создание контента)"
          },
          {
            "text": "В этой статье речь пойдет о том, как мы интегрировали разработанный Яндексом Томита-парсер в нашу систему, превратили его в динамическую библиотеку, подружили с Java, сделали многопоточной и решили с её помощью задачу классификации текста для оценки недвижимости.",
            "relation": "(Томита-парсер) isUsedForSolving (классификации)"
          },
          {
            "text": "В этой статье речь пойдет о том, как мы интегрировали разработанный Яндексом Томита-парсер в нашу систему, превратили его в динамическую библиотеку, подружили с Java, сделали многопоточной и решили с её помощью задачу классификации текста для оценки недвижимости.",
            "relation": "(Томита-парсер) isUsedForSolving (оценки недвижимости)"
          },
          {
            "text": "Из доступных средств для извлечения фактов из текста на основе контекстно-свободных грамматик, способных работать с русским языком, наше внимание привлекли Томита-парсер и библиотека Yagry на питоне.",
            "relation": "(Томита-парсер) isUsedForSolving (извлечения фактов)"
          },
          {
            "text": "Многопоточный вариант Томиты — TomitaPooledParser использует для парсинга пул объектов TomitaParser, одинаковым образом сконфигурированных.",
            "relation": "(TomitaPooledParser) isUsedForSolving (парсинга)"
          },
          {
            "text": "Многопоточный вариант Томиты — TomitaPooledParser использует для парсинга пул объектов TomitaParser, одинаковым образом сконфигурированных.",
            "relation": "(Томиты) isUsedForSolving (парсинга)"
          },
          {
            "text": "В HuggingArtists, мы можем создавать тексты песен на основе конкретного исполнителя.",
            "relation": "(HuggingArtists) isUsedForSolving (создавать тексты)"
          },
          {
            "text": "Анализ тональности текста с использованием фреймворка Lightautoml",
            "relation": "(Lightautoml) isUsedForSolving (Анализ тональности текста)"
          },
          {
            "text": "Подводя итоги стоит сказать, что LightAutoML благодаря встроенному инструментарию способен показывать достаточно хорошие результаты в задачах бинарной или мультиклассовой классификации и регрессии.",
            "relation": "(LightAutoML) isUsedForSolving (бинарной или мультиклассовой классификации)"
          },
          {
            "text": "Подводя итоги стоит сказать, что LightAutoML благодаря встроенному инструментарию способен показывать достаточно хорошие результаты в задачах бинарной или мультиклассовой классификации и регрессии.",
            "relation": "(LightAutoML) isUsedForSolving (регрессии)"
          },
          {
            "text": "Тогда к статистической модели, которая была в «Переводчике» с момента запуска, добавили технологию перевода с помощью нейросети.",
            "relation": "(Переводчике) isUsedForSolving (перевода)"
          },
          {
            "text": "У «Балабобы» нет своего мнения, она выдает случайные продолжения и может закончить историю, придумать подпись или написать небольшой рассказ.",
            "relation": "(Балабобы) isUsedForSolving (придумать подпись)"
          },
          {
            "text": "У «Балабобы» нет своего мнения, она выдает случайные продолжения и может закончить историю, придумать подпись или написать небольшой рассказ.",
            "relation": "(Балабобы) isUsedForSolving (написать небольшой рассказ)"
          },
          {
            "text": "AntiToxicBot — бот, распознающий токсичных пользователей в телеграм чатах.",
            "relation": "(AntiToxicBot) isUsedForSolving (распознающий токсичных пользователей)"
          },
          {
            "text": "Одна из основных задач диалоговых систем состоит не только в предоставлении нужной пользователю информации, но и в генерации как можно более человеческих ответов.",
            "relation": "(диалоговых систем) isUsedForSolving (генерации)"
          },
          {
            "text": "Одна из основных задач диалоговых систем состоит не только в предоставлении нужной пользователю информации, но и в генерации как можно более человеческих ответов.",
            "relation": "(диалоговых систем) isUsedForSolving (предоставлении нужной пользователю информации)"
          },
          {
            "text": "Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.",
            "relation": "(Emphasis) isUsedForSolving (идентифицировать)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (формирования текстовой формы числительных)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (проверки орфографии)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (постановки слова в нужную словоформу)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (исправления ошибок)"
          },
          {
            "text": "TextIT API включает в себя функции проверки орфографии и исправления ошибок, формирования текстовой формы числительных (например, преобразовать “102 рубль” в “сто два рубля”), подсказки следующего слова по ранее введенному тексту, постановки слова в нужную словоформу (число, род, падеж, лицо и время) и другие полезные функции обработки и формирования текста.",
            "relation": "(TextIT API) isUsedForSolving (подсказки следующего слова)"
          },
          {
            "text": "Мы обучали движок Amazon Translate, используя «Active Custom Translation», который позволяет выполнять перевод на лету с использованием двуязычного корпуса.",
            "relation": "(Active Custom Translation) isUsedForSolving (перевод)"
          },
          {
            "text": "Мы обучали движок Amazon Translate, используя «Active Custom Translation», который позволяет выполнять перевод на лету с использованием двуязычного корпуса.",
            "relation": "(Amazon Translate) isUsedForSolving (перевод)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(ChatGPT) isUsedForSolving (получения точных ответов)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(ChatGPT) isUsedForSolving (перевода)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(ChatGPT) isUsedForSolving (создание текстов)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(ChatGPT) isUsedForSolving (написание кода)"
          },
          {
            "text": "Я приведу простой пример извлечения данных о погоде с общедоступного API Dark Sky.",
            "relation": "(API Dark Sky) isUsedForSolving (извлечения)"
          },
          {
            "text": "Facebook представила систему распознавания речи wav2vec-U.",
            "relation": "(wav2vec-U) isUsedForSolving (распознавания речи)"
          },
          {
            "text": "В 2000-е анализ естественных языков начал применяться уже не только для поиска в Интернете, но и для решения разнообразных задач.",
            "relation": "(Интернете) isUsedForSolving (поиска)"
          },
          {
            "text": "Он опубликовал программу (репозиторий на гитхабе), которая делает именно это: генерирует политические речи, удивительно похожие на настоящие.",
            "relation": "(программу) isUsedForSolving (генерирует политические речи)"
          },
          {
            "text": "Исследователи Массачусетского технологического университета разработали систему искусственного интеллекта, которая способна переписывать устаревшие предложения в статьях «Википедии».",
            "relation": "(систему искусственного интеллекта) isUsedForSolving (переписывать устаревшие предложения)"
          },
          {
            "text": "Отмечается, что систему также можно использовать для дополнения наборов данных, предназначенных для обучения детекторов фейкньюс, что потенциально снижает предвзятость и повышает точность информации.",
            "relation": "(систему) isUsedForSolving (дополнения наборов данных)"
          },
          {
            "text": "Отмечается, что систему также можно использовать для дополнения наборов данных, предназначенных для обучения детекторов фейкньюс, что потенциально снижает предвзятость и повышает точность информации.",
            "relation": "(систему) isUsedForSolving (обучения детекторов фейкньюс)"
          },
          {
            "text": "Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.",
            "relation": "(Google Assistant) isUsedForSolving (заказать такси)"
          },
          {
            "text": "Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.",
            "relation": "(Алису) isUsedForSolving (убавить громкость)"
          },
          {
            "text": "Однако только сейчас мы немного приблизились к сюжетам фантастических фильмов: можем попросить Алису убавить громкость, Google Assistant — заказать такси или Siri — завести будильник.",
            "relation": "(Siri) isUsedForSolving (завести будильник)"
          },
          {
            "text": "Для решения этой задачи в октябре 2019 года вышел первый релиз DeepPavlov Agent 1.0 — платформы для создания многозадачных чат-ботов.",
            "relation": "(DeepPavlov Agent 1.0) isUsedForSolving (задачи)"
          },
          {
            "text": "Для решения этой задачи в октябре 2019 года вышел первый релиз DeepPavlov Agent 1.0 — платформы для создания многозадачных чат-ботов.",
            "relation": "(DeepPavlov Agent 1.0) isUsedForSolving (создания многозадачных чат-ботов)"
          },
          {
            "text": "DeepPavlov Cloud позволяет анализировать текст, а также хранить документы в облачном хранилище.",
            "relation": "(DeepPavlov Cloud) isUsedForSolving (анализировать текст)"
          },
          {
            "text": "DeepPavlov Cloud позволяет анализировать текст, а также хранить документы в облачном хранилище.",
            "relation": "(DeepPavlov Cloud) isUsedForSolving (хранить документы)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedForSolving (анализ тональности)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedForSolving (извлечение информации из текстов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(api.ai) isUsedForSolving (понимание текстовых и голосовых команд и вопросов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(IBM AlchemyAPI) isUsedForSolving (выявление сущностей и ключевых слов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(Google Natural Language API) isUsedForSolving (классификация текстов)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(IBM AlchemyAPI) isUsedForSolving (анализ тональности текста)"
          },
          {
            "text": "Возможности этого сервиса в области анализа речи и естественного языка пока ограничиваются английским языком, однако многие другие сервисы поддерживают русский язык, например, полностью бесплатный wit.ai, приобретённый Facebook, и его российский конкурент api.ai (понимание текстовых и голосовых команд и вопросов на естественных языках, преобразование речи в текст), IBM AlchemyAPI (анализ тональности текста, выявление сущностей и ключевых слов), Google Natural Language API (классификация текстов, графы связей, извлечение информации из текстов, анализ тональности, намерений, извлечение инсайтов; поддерживает русский язык с помощью технологии машинного перевода Google Translate, использует глубокое обучение и word2vec).",
            "relation": "(api.ai) isUsedForSolving (преобразование речи в текст)"
          },
          {
            "text": "Например, Diffbot позволяет автоматически сканировать страницы сайтов, извлекать из них нужную информацию: тексты, изображения, видео, информацию о продуктах, комментарии и др., в очищенном в структурированном виде, а также позволяет классифицировать страницы.",
            "relation": "(Diffbot) isUsedForSolving (сканировать страницы сайтов)"
          },
          {
            "text": "Например, Diffbot позволяет автоматически сканировать страницы сайтов, извлекать из них нужную информацию: тексты, изображения, видео, информацию о продуктах, комментарии и др., в очищенном в структурированном виде, а также позволяет классифицировать страницы.",
            "relation": "(Diffbot) isUsedForSolving (классифицировать страницы)"
          },
          {
            "text": "Решения, основанные на Deepomatic, позволяют находить информацию о фильме по его постеру, информацию о картине или скульптуре на выставке по ее фото, сделанному на камеру телефона, позволяют скачивать музыку, сфотографировав обложку альбома на диске и т.п.",
            "relation": "(Deepomatic) isUsedForSolving (находить информацию о фильме)"
          },
          {
            "text": "Custom Vocabularies – позволяет создать «словарь» из тех, слов, которые должна «выучить» нейросеть перед тем, как приступить к распознаванию.",
            "relation": "(Custom Vocabularies) isUsedForSolving (распознаванию)"
          },
          {
            "text": "Программа, придуманная учеными из Новосибирского академгородка, распознает речь, анализирует смысл и переводит на жестовый язык.",
            "relation": "(Программа) isUsedForSolving (анализирует смысл)"
          },
          {
            "text": "Программа, придуманная учеными из Новосибирского академгородка, распознает речь, анализирует смысл и переводит на жестовый язык.",
            "relation": "(Программа) isUsedForSolving (распознает речь)"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(Objective Revision Evaluation Service) isUsedForSolving (наличие спама)"
          },
          {
            "text": "Objective Revision Evaluation Service (ORES), разработанная Wikimedia Foundation, проверяет наличие спама.",
            "relation": "(ORES) isUsedForSolving (наличие спама)"
          }
        ]
      }
    }
  },
  "Model_Language_Lang": {
    "predicted": {
      "incorrect": {
        "count": 2,
        "examples": [
          {
            "text": "Для русского языка тоже было создано немало разного рода бенчмарков NLU моделей:RussianSuperGLUE: бенчмарк \"сложных\" NLP задач; фокус на дообучаемых моделях.",
            "relation": "(NLU моделей) Language (русского)"
          },
          {
            "text": "В одном из выдающихся решений применялся особый FastText, предварительно обученный на корпусе текстов RuDReC, включающем отзывы на русском языке о медикаментозной продукции.",
            "relation": "(FastText) Language (русском языке)"
          }
        ]
      },
      "correct": {
        "count": 44,
        "examples": [
          {
            "text": "С марта 2017 года нейросеть стали использовать для перевода на русский.",
            "relation": "(нейросеть) Language (русский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (бенгали)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (вьетнамский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (французский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (каталанский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (арабский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (испанский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (хинди)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (маратхи)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (китайский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (индонезийский)"
          },
          {
            "text": "На русском BLOOM тоже пишет, но пока довольно вяло.",
            "relation": "(BLOOM) Language (русском)"
          },
          {
            "text": "Почти треть обучающих данных была введена в модель BLOOM на английском языке: следствие того, что именно английский является наиболее часто используемым языком в интернете.",
            "relation": "(BLOOM) Language (английский)"
          },
          {
            "text": "Почти треть обучающих данных была введена в модель BLOOM на английском языке: следствие того, что именно английский является наиболее часто используемым языком в интернете.",
            "relation": "(BLOOM) Language (английском)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (голландский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (бурятский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (башкирский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (испанский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (бенгали)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (датский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (болгарский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (баскский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (африкаанс)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (иврит)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (белорусский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (английский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (арабский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (йоруба)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (венгерский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (бирманский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (грузинский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (азербайджанский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (индонезийский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (греческий)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (вьетнамский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (калмыцкий)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (армянский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (итальянский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (казахский)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(версию нейросети GPT-3) Language (русскоязычную)"
          },
          {
            "text": "Русскоязычная версия GPT-3, разработанная «Сбером», доступна на платформе SmartMarket.",
            "relation": "(версия GPT-3) Language (Русскоязычная)"
          },
          {
            "text": "В частности, в одном из лучших решений использовался необычный FastText, предобученный на корпусе текстов RuDReC, который содержит отзывы потребителей на русском языке о фармацевтической продукции.",
            "relation": "(FastText) Language (русском языке)"
          },
          {
            "text": "В IC классификатор обучается на русских данных, а в ICX – на английских, а тестируется в обоих случаях на русских.",
            "relation": "(ICX) Language (английских)"
          },
          {
            "text": "В IC классификатор обучается на русских данных, а в ICX – на английских, а тестируется в обоих случаях на русских.",
            "relation": "(IC классификатор) Language (русских)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 37,
        "examples": [
          {
            "text": "В этом посте мы расскажем, как мы создали датасет для задачи Common Sense Reasoning в одной из ее возможных формулировок, предложенной в статье event2mind, а также адаптировали английскую модель event2mind от AllenNLP для русского языка.",
            "relation": "(event2mind) Language (русского языка)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (турецкий)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (малаялам)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (чувашский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (немецкий)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (узбекский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (китайский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (молдавский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (тувинский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (якутский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (португальский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (урду)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (польский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (французский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (киргизский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (литовский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (маратхи)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (монгольский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (румынский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (тайский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (японский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (таджикский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (украинский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (малайский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (финский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (телугу)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (осетинский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (тамильский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (русский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (латышский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (шведский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (хинди)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (корейский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (персидский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (туркменский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (суахили)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (татарский)"
          }
        ]
      },
      "found": {
        "count": 44,
        "examples": [
          {
            "text": "С марта 2017 года нейросеть стали использовать для перевода на русский.",
            "relation": "(нейросеть) Language (русский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (индонезийский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (маратхи)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (вьетнамский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (французский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (каталанский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (испанский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (хинди)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (бенгали)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (китайский)"
          },
          {
            "text": "BLOOM может обрабатывать 46 языков, включая французский, испанский, арабский, вьетнамский, китайский, индонезийский, каталанский, целых 13 языков Индии (хинди, бенгали, маратхи и ряд других) и аж 20 африканских.",
            "relation": "(BLOOM) Language (арабский)"
          },
          {
            "text": "На русском BLOOM тоже пишет, но пока довольно вяло.",
            "relation": "(BLOOM) Language (русском)"
          },
          {
            "text": "Почти треть обучающих данных была введена в модель BLOOM на английском языке: следствие того, что именно английский является наиболее часто используемым языком в интернете.",
            "relation": "(BLOOM) Language (английский)"
          },
          {
            "text": "Почти треть обучающих данных была введена в модель BLOOM на английском языке: следствие того, что именно английский является наиболее часто используемым языком в интернете.",
            "relation": "(BLOOM) Language (английском)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (голландский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (бурятский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (башкирский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (испанский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (бенгали)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (датский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (болгарский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (баскский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (африкаанс)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (иврит)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (белорусский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (английский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (арабский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (йоруба)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (венгерский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (бирманский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (грузинский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (азербайджанский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (индонезийский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (греческий)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (вьетнамский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (калмыцкий)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (армянский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (итальянский)"
          },
          {
            "text": "Полный перечень языков, доступный в модели mGPT: азербайджанский, английский, арабский, армянский, африкаанс, баскский, башкирский, белорусский, бенгали, бирманский, болгарский, бурятский, венгерский, вьетнамский, голландский, греческий, грузинский, датский, иврит, индонезийский, испанский, итальянский, йоруба, казахский, калмыцкий, киргизский, китайский, корейский, латышский, литовский, малайский, малаялам, маратхи, молдавский, монгольский, немецкий, осетинский, персидский, польский, португальский, румынский, русский, суахили, таджикский, тайский, тамильский, татарский, телугу, тувинский, турецкий, туркменский, узбекский, украинский, урду, финский, французский, хинди, чувашский, шведский, якутский, японский.",
            "relation": "(mGPT) Language (казахский)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(версию нейросети GPT-3) Language (русскоязычную)"
          },
          {
            "text": "Русскоязычная версия GPT-3, разработанная «Сбером», доступна на платформе SmartMarket.",
            "relation": "(версия GPT-3) Language (Русскоязычная)"
          },
          {
            "text": "В частности, в одном из лучших решений использовался необычный FastText, предобученный на корпусе текстов RuDReC, который содержит отзывы потребителей на русском языке о фармацевтической продукции.",
            "relation": "(FastText) Language (русском языке)"
          },
          {
            "text": "В IC классификатор обучается на русских данных, а в ICX – на английских, а тестируется в обоих случаях на русских.",
            "relation": "(ICX) Language (английских)"
          },
          {
            "text": "В IC классификатор обучается на русских данных, а в ICX – на английских, а тестируется в обоих случаях на русских.",
            "relation": "(IC классификатор) Language (русских)"
          }
        ]
      }
    }
  },
  "Metric_isAlternativeNameFor_Metric": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 18,
        "examples": [
          {
            "text": "На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.",
            "relation": "(MAE) isAlternativeNameFor (средней абсолютной ошибки)"
          },
          {
            "text": "На платформе Personality Insights модели Watson оценивались по двум метрикам — средней абсолютной ошибке (MAE) и коэффициенту корреляции.",
            "relation": "(MAE) isAlternativeNameFor (средней абсолютной ошибке)"
          },
          {
            "text": "Обучалась модель с функцией ошибки MSE (среднеквадратичное отклонение).",
            "relation": "(среднеквадратичное отклонение) isAlternativeNameFor (MSE)"
          },
          {
            "text": "Также одним из способов оценить работу модели в целом можно по кривой ROC-AUC, которая описывает площадь под кривой (Area Under Curve – Receiver Operating Characteristic).",
            "relation": "(Area Under Curve – Receiver Operating Characteristic) isAlternativeNameFor (ROC-AUC)"
          },
          {
            "text": "Они отличаются хорошей сбалансированностью: достаточно высокий уровень чувствительности одновременно с хорошим соотношением сигнал/шум и уровнем AOP (Acoustic Overload Point — это такой аналог максимального звукового давления для цифровых микрофонов).",
            "relation": "(Acoustic Overload Point) isAlternativeNameFor (AOP)"
          },
          {
            "text": "TCR (Task completed rate) — процент диалогов, в которых частично или полностью решили проблему абонента.",
            "relation": "(Task completed rate) isAlternativeNameFor (TCR)"
          },
          {
            "text": "CSI (Customer Satisfaction Index) — средняя оценка, которую поставили клиенты боту.",
            "relation": "(Customer Satisfaction Index)) isAlternativeNameFor (CSI)"
          },
          {
            "text": "AR (Automation rate) — процент диалогов, в которых клиент не перешел на оператора.",
            "relation": "(Automation rate) isAlternativeNameFor (AR)"
          },
          {
            "text": "таблицу 2), у этого источника коэффициент согласованности аннотаторов (Cohen's kappa coefficient), равный 0.57.",
            "relation": "(Cohen's kappa coefficient) isAlternativeNameFor (коэффициент согласованности аннотаторов)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(accuracy) isAlternativeNameFor (точность)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(accuracy) isAlternativeNameFor (точность)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(accuracy) isAlternativeNameFor (точность)"
          },
          {
            "text": "Мы можем оценивать, правильно ли нашли вершину слова — метрика UAS (Unlabeled attachment score).",
            "relation": "(Unlabeled attachment score) isAlternativeNameFor (UAS)"
          },
          {
            "text": "Мы можем оценивать, корректно ли обнаружены вершины слова, используя метрику UAS (Unlabeled Attachment Score).",
            "relation": "(Unlabeled Attachment Score) isAlternativeNameFor (UAS)"
          },
          {
            "text": "Или оценивать, правильно ли найдена как вершина, так и тип зависимости — метрика LAS (Labeled attachment score).",
            "relation": "(Labeled attachment score) isAlternativeNameFor (LAS)"
          },
          {
            "text": "Либо проверять, были ли правильно определены и вершина, и тип зависимости, используя метрику LAS (Labeled Attachment Score).",
            "relation": "(Labeled Attachment Score) isAlternativeNameFor (LAS)"
          },
          {
            "text": "Казалось бы, здесь напрашивается оценка точности (accuracy) — считаем, сколько раз мы попали из общего количества случаев.",
            "relation": "(accuracy) isAlternativeNameFor (точности)"
          },
          {
            "text": "Поэтому формулой оценки в данном случае является ф-мера, где точность (precision) — доля точных попаданий относительно общего числа предсказаний, а полнота — доля точных попаданий относительно числа связей в размеченных данных.",
            "relation": "(precision) isAlternativeNameFor (точность)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 1,
        "examples": [
          {
            "text": "В сравнении показываются FriendBERT и ChatBERT, которые по итогу исследования представили точность (MacroAVG F-меру), равную 73% для первой и 69,5% для второй модели соответственно.",
            "relation": "(MacroAVG F-меру) isAlternativeNameFor (точность)"
          }
        ]
      },
      "found": {
        "count": 18,
        "examples": [
          {
            "text": "На сайте Personality Insights качество моделей Watson оценивалось с помощью двух показателей — средней абсолютной ошибки (MAE) и коэффициента корреляции.",
            "relation": "(MAE) isAlternativeNameFor (средней абсолютной ошибки)"
          },
          {
            "text": "На платформе Personality Insights модели Watson оценивались по двум метрикам — средней абсолютной ошибке (MAE) и коэффициенту корреляции.",
            "relation": "(MAE) isAlternativeNameFor (средней абсолютной ошибке)"
          },
          {
            "text": "Обучалась модель с функцией ошибки MSE (среднеквадратичное отклонение).",
            "relation": "(среднеквадратичное отклонение) isAlternativeNameFor (MSE)"
          },
          {
            "text": "Также одним из способов оценить работу модели в целом можно по кривой ROC-AUC, которая описывает площадь под кривой (Area Under Curve – Receiver Operating Characteristic).",
            "relation": "(Area Under Curve – Receiver Operating Characteristic) isAlternativeNameFor (ROC-AUC)"
          },
          {
            "text": "Они отличаются хорошей сбалансированностью: достаточно высокий уровень чувствительности одновременно с хорошим соотношением сигнал/шум и уровнем AOP (Acoustic Overload Point — это такой аналог максимального звукового давления для цифровых микрофонов).",
            "relation": "(Acoustic Overload Point) isAlternativeNameFor (AOP)"
          },
          {
            "text": "TCR (Task completed rate) — процент диалогов, в которых частично или полностью решили проблему абонента.",
            "relation": "(Task completed rate) isAlternativeNameFor (TCR)"
          },
          {
            "text": "CSI (Customer Satisfaction Index) — средняя оценка, которую поставили клиенты боту.",
            "relation": "(Customer Satisfaction Index)) isAlternativeNameFor (CSI)"
          },
          {
            "text": "AR (Automation rate) — процент диалогов, в которых клиент не перешел на оператора.",
            "relation": "(Automation rate) isAlternativeNameFor (AR)"
          },
          {
            "text": "таблицу 2), у этого источника коэффициент согласованности аннотаторов (Cohen's kappa coefficient), равный 0.57.",
            "relation": "(Cohen's kappa coefficient) isAlternativeNameFor (коэффициент согласованности аннотаторов)"
          },
          {
            "text": "Для NLI я обучил трёхклассовую (entail/contradict/neutral) логистическую регрессию поверх косинусной близости, и измеряю её точность (accuracy).",
            "relation": "(accuracy) isAlternativeNameFor (точность)"
          },
          {
            "text": "Для задачи NLI я провел обучение логистической регрессии с тремя классами (entail/contradict/neutral) на основе косинусной близости и измеряю ее точность (accuracy).",
            "relation": "(accuracy) isAlternativeNameFor (точность)"
          },
          {
            "text": "Для задач бинарной классификации TI и II я измеряю ROC AUC, а в задачах многоклассовой классификации SA, IC и ICX – точность (accuracy).",
            "relation": "(accuracy) isAlternativeNameFor (точность)"
          },
          {
            "text": "Мы можем оценивать, правильно ли нашли вершину слова — метрика UAS (Unlabeled attachment score).",
            "relation": "(Unlabeled attachment score) isAlternativeNameFor (UAS)"
          },
          {
            "text": "Мы можем оценивать, корректно ли обнаружены вершины слова, используя метрику UAS (Unlabeled Attachment Score).",
            "relation": "(Unlabeled Attachment Score) isAlternativeNameFor (UAS)"
          },
          {
            "text": "Или оценивать, правильно ли найдена как вершина, так и тип зависимости — метрика LAS (Labeled attachment score).",
            "relation": "(Labeled attachment score) isAlternativeNameFor (LAS)"
          },
          {
            "text": "Либо проверять, были ли правильно определены и вершина, и тип зависимости, используя метрику LAS (Labeled Attachment Score).",
            "relation": "(Labeled Attachment Score) isAlternativeNameFor (LAS)"
          },
          {
            "text": "Казалось бы, здесь напрашивается оценка точности (accuracy) — считаем, сколько раз мы попали из общего количества случаев.",
            "relation": "(accuracy) isAlternativeNameFor (точности)"
          },
          {
            "text": "Поэтому формулой оценки в данном случае является ф-мера, где точность (precision) — доля точных попаданий относительно общего числа предсказаний, а полнота — доля точных попаданий относительно числа связей в размеченных данных.",
            "relation": "(precision) isAlternativeNameFor (точность)"
          }
        ]
      }
    }
  },
  "Person_isAlternativeNameFor_Person": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 3,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Richard Wallace) isAlternativeNameFor (Ричардом Уэлсом)"
          },
          {
            "text": "Американский разработчик Мэтью Гинсберг (Matthew Ginsberg) создал программу под названием Dr Fill, которая справляется с кроссвордами гораздо лучше, чем абсолютное большинство людей, пишет New Scientist.",
            "relation": "(Matthew Ginsberg) isAlternativeNameFor (Мэтью Гинсберг)"
          },
          {
            "text": "Программа Dr Fill, разработанная американским специалистом Мэтью Гинсбергом (Matthew Ginsberg), согласно информации из издания New Scientist, проявляет более выдающуюся эффективность в решении кроссвордов по сравнению с абсолютным большинством людей.",
            "relation": "(Matthew Ginsberg) isAlternativeNameFor (Мэтью Гинсбергом)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 3,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(Richard Wallace) isAlternativeNameFor (Ричардом Уэлсом)"
          },
          {
            "text": "Американский разработчик Мэтью Гинсберг (Matthew Ginsberg) создал программу под названием Dr Fill, которая справляется с кроссвордами гораздо лучше, чем абсолютное большинство людей, пишет New Scientist.",
            "relation": "(Matthew Ginsberg) isAlternativeNameFor (Мэтью Гинсберг)"
          },
          {
            "text": "Программа Dr Fill, разработанная американским специалистом Мэтью Гинсбергом (Matthew Ginsberg), согласно информации из издания New Scientist, проявляет более выдающуюся эффективность в решении кроссвордов по сравнению с абсолютным большинством людей.",
            "relation": "(Matthew Ginsberg) isAlternativeNameFor (Мэтью Гинсбергом)"
          }
        ]
      }
    }
  },
  "Model_isModificationOf_Model": {
    "predicted": {
      "incorrect": {
        "count": 0,
        "examples": []
      },
      "correct": {
        "count": 4,
        "examples": [
          {
            "text": "Новая версия GPT-3, InstructGPT, лучше выполняет инструкции и выдает меньше оскорбительных выражений, дезинформации и ошибок в целом.",
            "relation": "(InstructGPT) isModificationOf (GPT-3)"
          },
          {
            "text": "«Сбер» представил mGPT — версию нейросети GPT-3, способную генерировать тексты на 61 языке",
            "relation": "(mGPT) isModificationOf (GPT-3)"
          },
          {
            "text": "21 апреля 2022 года команда разработчиков SberDevices представила многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(mGPT) isModificationOf (GPT-3)"
          },
          {
            "text": "21 апреля 2022 года SberDevices представили многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(mGPT) isModificationOf (GPT-3)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 8,
        "examples": [
          {
            "text": "Модель, которую построил заказчик использовала вектора слов word2vec и рекуррентную нейронную сеть на базе GRU (gated recurrent unit) (Рис 1а).",
            "relation": "(рекуррентную нейронную сеть) isModificationOf (GRU)"
          },
          {
            "text": "В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isModificationOf (BERT)"
          },
          {
            "text": "В ходе участия команды в DSTC8 была разработана модель GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker) — целеориентированная мультизадачная модель на базе BERT для отслеживания состояния диалога.",
            "relation": "(GOLOMB) isModificationOf (BERT)"
          },
          {
            "text": "В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).",
            "relation": "(GOaL-Oriented Multi-task BERT-based dialogue state tracker) isModificationOf (BERT)"
          },
          {
            "text": "В рамках участия в DSTC8 команда разработала целеориентированную мультизадачную модель отслеживания состояния диалога с использованием BERT, названную GOLOMB (GOaL-Oriented Multi-task BERT-based dialogue state tracker).",
            "relation": "(GOLOMB) isModificationOf (BERT)"
          },
          {
            "text": "По своей сути BERT — это обученный стек энкодеров Трансформера.",
            "relation": "(энкодеров Трансформера) isModificationOf (BERT)"
          },
          {
            "text": "Примером данного решения является использование парафрайзера на основе “rut5-base-paraphraser” из библиотеки huggingface.",
            "relation": "(парафрайзера) isModificationOf (rut5-base-paraphraser)"
          },
          {
            "text": "Суть BERT заключается в том, что это предварительно обученная модель, основанная на стеке энкодеров Трансформера.",
            "relation": "(энкодеров Трансформера) isModificationOf (BERT)"
          }
        ]
      },
      "found": {
        "count": 4,
        "examples": [
          {
            "text": "Новая версия GPT-3, InstructGPT, лучше выполняет инструкции и выдает меньше оскорбительных выражений, дезинформации и ошибок в целом.",
            "relation": "(InstructGPT) isModificationOf (GPT-3)"
          },
          {
            "text": "«Сбер» представил mGPT — версию нейросети GPT-3, способную генерировать тексты на 61 языке",
            "relation": "(mGPT) isModificationOf (GPT-3)"
          },
          {
            "text": "21 апреля 2022 года команда разработчиков SberDevices представила многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(mGPT) isModificationOf (GPT-3)"
          },
          {
            "text": "21 апреля 2022 года SberDevices представили многоязычную версию нейросети GPT-3 под названием mGPT.",
            "relation": "(mGPT) isModificationOf (GPT-3)"
          }
        ]
      }
    }
  },
  "Dataset_Language_Lang": {
    "predicted": {
      "incorrect": {
        "count": 1,
        "examples": [
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(датасете токсичных комментариев) Language (русский)"
          }
        ]
      },
      "correct": {
        "count": 13,
        "examples": [
          {
            "text": "Dusha: самый большой открытый датасет для распознавания эмоций в устной речи на русском языке.",
            "relation": "(Dusha) Language (русском языке)"
          },
          {
            "text": "Dusha: самый большой открытый датасет для распознавания эмоций в устной речи на русском языке.",
            "relation": "(датасет) Language (русском языке)"
          },
          {
            "text": "Dusha - это крупнейший открытый набор данных на русском языке для распознавания эмоций в речи.",
            "relation": "(Dusha) Language (русском языке)"
          },
          {
            "text": "Dusha - это крупнейший открытый набор данных на русском языке для распознавания эмоций в речи.",
            "relation": "(набор данных) Language (русском языке)"
          },
          {
            "text": "Де-факто, в подавляющем большинстве случаев, бенчмарком для новых моделей распознавания эмоций является англоязычный датасет IEMOCAP с игрой профессиональных актёров.",
            "relation": "(IEMOCAP) Language (англоязычный)"
          },
          {
            "text": "IEMOCAP, англоязычный набор данных, служит стандартом для распознавания эмоций.",
            "relation": "(IEMOCAP) Language (англоязычный)"
          },
          {
            "text": "В частности, в одном из лучших решений использовался необычный FastText, предобученный на корпусе текстов RuDReC, который содержит отзывы потребителей на русском языке о фармацевтической продукции.",
            "relation": "(RuDReC) Language (русском языке)"
          },
          {
            "text": "Первой известной попыткой системно сравнить английские эмбеддинги предложений был SentEval, сочетающий чисто лингвистические задачи со вполне прикладными.",
            "relation": "(SentEval) Language (английские)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(NLU-evaluation-data) Language (русский)"
          },
          {
            "text": "Dusha представляет собой самый обширный открытый корпус данных на русском языке, предназначенный для анализа эмоций в речи.",
            "relation": "(Dusha) Language (русском языке)"
          },
          {
            "text": "В одном из выдающихся решений применялся особый FastText, предварительно обученный на корпусе текстов RuDReC, включающем отзывы на русском языке о медикаментозной продукции.",
            "relation": "(RuDReC) Language (русском языке)"
          },
          {
            "text": "Набор данных IEMOCAP на английском языке является эталоном для анализа эмоций.",
            "relation": "(IEMOCAP) Language (английском языке)"
          },
          {
            "text": "SentEval был первой известной попыткой системного сопоставления английских векторных представлений предложений, объединяющей лингвистические задачи с практическими применениями.",
            "relation": "(SentEval) Language (английских)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 13,
        "examples": [
          {
            "text": "Dusha: самый большой открытый датасет для распознавания эмоций в устной речи на русском языке.",
            "relation": "(Dusha) Language (русском языке)"
          },
          {
            "text": "Dusha: самый большой открытый датасет для распознавания эмоций в устной речи на русском языке.",
            "relation": "(датасет) Language (русском языке)"
          },
          {
            "text": "Dusha - это крупнейший открытый набор данных на русском языке для распознавания эмоций в речи.",
            "relation": "(Dusha) Language (русском языке)"
          },
          {
            "text": "Dusha - это крупнейший открытый набор данных на русском языке для распознавания эмоций в речи.",
            "relation": "(набор данных) Language (русском языке)"
          },
          {
            "text": "Де-факто, в подавляющем большинстве случаев, бенчмарком для новых моделей распознавания эмоций является англоязычный датасет IEMOCAP с игрой профессиональных актёров.",
            "relation": "(IEMOCAP) Language (англоязычный)"
          },
          {
            "text": "IEMOCAP, англоязычный набор данных, служит стандартом для распознавания эмоций.",
            "relation": "(IEMOCAP) Language (англоязычный)"
          },
          {
            "text": "В частности, в одном из лучших решений использовался необычный FastText, предобученный на корпусе текстов RuDReC, который содержит отзывы потребителей на русском языке о фармацевтической продукции.",
            "relation": "(RuDReC) Language (русском языке)"
          },
          {
            "text": "Первой известной попыткой системно сравнить английские эмбеддинги предложений был SentEval, сочетающий чисто лингвистические задачи со вполне прикладными.",
            "relation": "(SentEval) Language (английские)"
          },
          {
            "text": "В прошлой версии бенчмарка я собрал кривые тестовые выборки, поэтому этот датасет я переделал; Toxicity identification (TI) на датасете токсичных комментариев из OKMLCup; Inappropriateness identification (II) на датасете Сколтеха; Intent classification (IC) и её кросс-язычная версия ICX на датасете NLU-evaluation-data, который я автоматически перевёл на русский.",
            "relation": "(NLU-evaluation-data) Language (русский)"
          },
          {
            "text": "Dusha представляет собой самый обширный открытый корпус данных на русском языке, предназначенный для анализа эмоций в речи.",
            "relation": "(Dusha) Language (русском языке)"
          },
          {
            "text": "В одном из выдающихся решений применялся особый FastText, предварительно обученный на корпусе текстов RuDReC, включающем отзывы на русском языке о медикаментозной продукции.",
            "relation": "(RuDReC) Language (русском языке)"
          },
          {
            "text": "Набор данных IEMOCAP на английском языке является эталоном для анализа эмоций.",
            "relation": "(IEMOCAP) Language (английском языке)"
          },
          {
            "text": "SentEval был первой известной попыткой системного сопоставления английских векторных представлений предложений, объединяющей лингвистические задачи с практическими применениями.",
            "relation": "(SentEval) Language (английских)"
          }
        ]
      }
    }
  },
  "Date_isDateOf_Application": {
    "predicted": {
      "incorrect": {
        "count": 4,
        "examples": [
          {
            "text": "Опуская историю, начавшуюся еще в 50-е годы с Алана Тьюринга и программы Элиза в 60-е годы, а также научные исследования в области лингвистики и машинного обучения 90-х годов, значимым событием более новой истории стало появление языка разметки AIML (Artificial Intelligence Markup Language), разработанной в 2001-м году Ричардом Уэлсом (Richard Wallace) и созданным на его основе чатботом A.L.I.C.E.",
            "relation": "(2001-м) isDateOf (A.L.I.C.E.)"
          },
          {
            "text": "В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения.",
            "relation": "(2021) isDateOf (IDE)"
          },
          {
            "text": "В 2020 году «Сбер» представил русскоязычную версию нейросети GPT-3, именно она используется в двух виртуальных ассистентах семейства «Салют» от «Сбера».",
            "relation": "(2020) isDateOf (Салют)"
          },
          {
            "text": "Первой успешной реализацией чат-бота стал виртуальный собеседник ELIZA, написанный в 1966 году Джозефом Вейценбаумом.",
            "relation": "(1966 году) isDateOf (виртуальный собеседник)"
          }
        ]
      },
      "correct": {
        "count": 18,
        "examples": [
          {
            "text": "Аналогичный описанному выше сервис был запущен Microsoft в прошлом, 2021 году, и получил название Copilot.",
            "relation": "(2021) isDateOf (Copilot)"
          },
          {
            "text": "6 февраля 2023 года Google представил свой аналог ChatGPT — экспериментальный диалоговый ИИ-сервис под названием Bard.",
            "relation": "(2023) isDateOf (Bard)"
          },
          {
            "text": "Однако, по мере углубления в тему, автор связался с разработчиками и в январе 2023 года получил первую версию ScoreCloud Songwriter на тестирование под Windows 10.",
            "relation": "(2023) isDateOf (ScoreCloud Songwriter)"
          },
          {
            "text": "В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения.",
            "relation": "(2021) isDateOf (SageMaker Studio)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(30 ноября 2022) isDateOf (ChatGPT)"
          },
          {
            "text": "Компания уже давно работает над сложным поисковым ИИ под названием LaMDA: о нем впервые объявили еще в мае 2021 года.",
            "relation": "(2021) isDateOf (LaMDA)"
          },
          {
            "text": "Так и появился AIDungeon — уникальная для своего времени (2019 год) вещь, которая не сильно потеряла в популярности и по сей день.",
            "relation": "(2019) isDateOf (AIDungeon)"
          },
          {
            "text": "В 1960-е годы появились первые чат-боты, очень примитивные: в основном они перефразировали то, что говорил им собеседник-человек.",
            "relation": "(1960-е) isDateOf (чат-боты)"
          },
          {
            "text": "В 1990-е годы эта область получила очень мощный толчок благодаря развитию Всемирной паутины с большим количеством слабоструктурированного текста, по которому нужно было искать, его требовалось каталогизировать.",
            "relation": "(1990-е) isDateOf (Всемирной паутины)"
          },
          {
            "text": "В 1954 году Джорджтаунский университет совместно с компанией IBM продемонстрировали программу машинного перевода с русского на английский, которая работала на базе словаря из 250 слов и набора из 6 грамматических правил.",
            "relation": "(1954) isDateOf (программу машинного перевода)"
          },
          {
            "text": "Первой успешной реализацией чат-бота стал виртуальный собеседник ELIZA, написанный в 1966 году Джозефом Вейценбаумом.",
            "relation": "(1966 году) isDateOf (ELIZA)"
          },
          {
            "text": "В 1968 году Терри Виноградом на языке LISP была разработана программа SHRDLU.",
            "relation": "(1968) isDateOf (SHRDLU)"
          },
          {
            "text": "Разговоры о нейронных сетях и глубоком обучении ходили уже в 90-е годы, а первый нейрокомпьютер «Марк-1» появился вообще в 1958 году.",
            "relation": "(1958 году) isDateOf (нейрокомпьютер)"
          },
          {
            "text": "Разговоры о нейронных сетях и глубоком обучении ходили уже в 90-е годы, а первый нейрокомпьютер «Марк-1» появился вообще в 1958 году.",
            "relation": "(1958 году) isDateOf (Марк-1)"
          },
          {
            "text": "Для решения этой задачи в октябре 2019 года вышел первый релиз DeepPavlov Agent 1.0 — платформы для создания многозадачных чат-ботов.",
            "relation": "(2019 года) isDateOf (DeepPavlov Agent 1.0)"
          },
          {
            "text": "Чтобы упростить работу с предобученными NLP моделями из DeepPavlov, в сентябрь 2019 года был запущен SaaS сервис.",
            "relation": "(сентябрь 2019 года) isDateOf (SaaS сервис)"
          },
          {
            "text": "В сентябре 2019 года был запущен сервис SaaS для упрощения взаимодействия с предварительно обученными моделями NLP от DeepPavlov.",
            "relation": "(сентябре 2019 года) isDateOf (SaaS)"
          },
          {
            "text": "В 1966 году Джозефом Вейценбаумом был создан виртуальный собеседник ELIZA, который стал первым успешным примером реализации чат-бота.",
            "relation": "(1966 году) isDateOf (ELIZA)"
          }
        ]
      }
    },
    "expected": {
      "not_found": {
        "count": 0,
        "examples": []
      },
      "found": {
        "count": 18,
        "examples": [
          {
            "text": "Аналогичный описанному выше сервис был запущен Microsoft в прошлом, 2021 году, и получил название Copilot.",
            "relation": "(2021) isDateOf (Copilot)"
          },
          {
            "text": "6 февраля 2023 года Google представил свой аналог ChatGPT — экспериментальный диалоговый ИИ-сервис под названием Bard.",
            "relation": "(2023) isDateOf (Bard)"
          },
          {
            "text": "Однако, по мере углубления в тему, автор связался с разработчиками и в январе 2023 года получил первую версию ScoreCloud Songwriter на тестирование под Windows 10.",
            "relation": "(2023) isDateOf (ScoreCloud Songwriter)"
          },
          {
            "text": "В 2021 году Amazon запустила SageMaker Studio — первый IDE для машинного обучения.",
            "relation": "(2021) isDateOf (SageMaker Studio)"
          },
          {
            "text": "ChatGPT был запущен 30 ноября 2022 года и привлек внимание своими широкими возможностями: написание кода, создание текстов, возможности перевода, получения точных ответов и использование контекста диалога для ответов, хотя его фактическая точность подверглась критике (источник — Википедия).",
            "relation": "(30 ноября 2022) isDateOf (ChatGPT)"
          },
          {
            "text": "Компания уже давно работает над сложным поисковым ИИ под названием LaMDA: о нем впервые объявили еще в мае 2021 года.",
            "relation": "(2021) isDateOf (LaMDA)"
          },
          {
            "text": "Так и появился AIDungeon — уникальная для своего времени (2019 год) вещь, которая не сильно потеряла в популярности и по сей день.",
            "relation": "(2019) isDateOf (AIDungeon)"
          },
          {
            "text": "В 1960-е годы появились первые чат-боты, очень примитивные: в основном они перефразировали то, что говорил им собеседник-человек.",
            "relation": "(1960-е) isDateOf (чат-боты)"
          },
          {
            "text": "В 1990-е годы эта область получила очень мощный толчок благодаря развитию Всемирной паутины с большим количеством слабоструктурированного текста, по которому нужно было искать, его требовалось каталогизировать.",
            "relation": "(1990-е) isDateOf (Всемирной паутины)"
          },
          {
            "text": "В 1954 году Джорджтаунский университет совместно с компанией IBM продемонстрировали программу машинного перевода с русского на английский, которая работала на базе словаря из 250 слов и набора из 6 грамматических правил.",
            "relation": "(1954) isDateOf (программу машинного перевода)"
          },
          {
            "text": "Первой успешной реализацией чат-бота стал виртуальный собеседник ELIZA, написанный в 1966 году Джозефом Вейценбаумом.",
            "relation": "(1966 году) isDateOf (ELIZA)"
          },
          {
            "text": "В 1968 году Терри Виноградом на языке LISP была разработана программа SHRDLU.",
            "relation": "(1968) isDateOf (SHRDLU)"
          },
          {
            "text": "Разговоры о нейронных сетях и глубоком обучении ходили уже в 90-е годы, а первый нейрокомпьютер «Марк-1» появился вообще в 1958 году.",
            "relation": "(1958 году) isDateOf (нейрокомпьютер)"
          },
          {
            "text": "Разговоры о нейронных сетях и глубоком обучении ходили уже в 90-е годы, а первый нейрокомпьютер «Марк-1» появился вообще в 1958 году.",
            "relation": "(1958 году) isDateOf (Марк-1)"
          },
          {
            "text": "Для решения этой задачи в октябре 2019 года вышел первый релиз DeepPavlov Agent 1.0 — платформы для создания многозадачных чат-ботов.",
            "relation": "(2019 года) isDateOf (DeepPavlov Agent 1.0)"
          },
          {
            "text": "Чтобы упростить работу с предобученными NLP моделями из DeepPavlov, в сентябрь 2019 года был запущен SaaS сервис.",
            "relation": "(сентябрь 2019 года) isDateOf (SaaS сервис)"
          },
          {
            "text": "В сентябре 2019 года был запущен сервис SaaS для упрощения взаимодействия с предварительно обученными моделями NLP от DeepPavlov.",
            "relation": "(сентябре 2019 года) isDateOf (SaaS)"
          },
          {
            "text": "В 1966 году Джозефом Вейценбаумом был создан виртуальный собеседник ELIZA, который стал первым успешным примером реализации чат-бота.",
            "relation": "(1966 году) isDateOf (ELIZA)"
          }
        ]
      }
    }
  }
}